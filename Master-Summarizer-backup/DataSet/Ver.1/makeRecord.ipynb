{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# from product import *\n",
    "from data_util.product import *\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import struct\n",
    "import subprocess\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.example import example_pb2\n",
    "import nltk\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "# from product import *\n",
    "\n",
    "VOCAB_SIZE = 50000\n",
    "CHUNK_SIZE = 1000  # num examples per chunk, for the chunked data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key word Attention DataSet 讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLSX/category/Electronics_Cameras_key.xlsx Read finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356566400</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>too small .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book was almost as small a pamphlet . '...</td>\n",
       "      <td>&lt;s&gt; too small &lt;/s&gt; \\n</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pamphlet as small,pamphlet small</td>\n",
       "      <td>this book was almost as small a pamphlet .</td>\n",
       "      <td>book small pamphlet intend gift expect descrip...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book is a collector item and i love the...</td>\n",
       "      <td>&lt;s&gt; wonderful book a keepsake &lt;/s&gt; \\n</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i would like to say the the cannon elph37 oz...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt; \\n</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i have have and use q 370z for over a year a...</td>\n",
       "      <td>&lt;s&gt; a good all around aps camera &lt;/s&gt; \\n</td>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i use this camera once and it take relativel...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/...</td>\n",
       "      <td>94</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "0  1356566400  this book was almost as small a pamphlet . for...   \n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "0                             too small .    Electronics     Camera Cases   \n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "0  ['this book was almost as small a pamphlet . '...   \n",
       "1  ['this book is a collector item and i love the...   \n",
       "2  ['i would like to say the the cannon elph37 oz...   \n",
       "3  ['i have have and use q 370z for over a year a...   \n",
       "4  ['i use this camera once and it take relativel...   \n",
       "\n",
       "                                        lemm_summary  lemm_review_len  \\\n",
       "0                              <s> too small </s> \\n               45   \n",
       "1              <s> wonderful book a keepsake </s> \\n               54   \n",
       "2                 <s> elph 37 oz is the best </s> \\n               58   \n",
       "3           <s> a good all around aps camera </s> \\n              137   \n",
       "4   <s> terrible camera worse customer service </...               94   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "0                 6        1     2   \n",
       "1                 8        5     9   \n",
       "2                10        5    51   \n",
       "3                10        5    13   \n",
       "4                 9        1    48   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "0                   pamphlet as small,pamphlet small   \n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "0        this book was almost as small a pamphlet .    \n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "0  book small pamphlet intend gift expect descrip...                            \n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from data_util.config import *\n",
    "# _, category1, category2, _ = DVD_Player().getAttr()\n",
    "_,category1,category2,_ = Cameras().getAttr()\n",
    "# _,category1,category2,_ = Cell_Phones().getAttr()\n",
    "# _,category1,category2,_ = GPS().getAttr()\n",
    "# _,category1,category2,_ = Keyboards().getAttr()\n",
    "# category1,category2 = config.category1 , config.category2\n",
    "\n",
    "xlsx_path = \"XLSX/category/%s_%s_key.xlsx\"%(category1,category2)\n",
    "# df.to_csv(csv_path) #默认dt是DataFrame的一个实例，参数解释如下\n",
    "# key_train_df.to_excel(csv_path, encoding='utf8')\n",
    "orign_key_df = pd.read_excel(xlsx_path)\n",
    "print(xlsx_path + \" Read finished\")\n",
    "len(orign_key_df)\n",
    "\n",
    "orign_key_df['bert_review'] = '' \n",
    "orign_key_df['bert_summary'] = ''\n",
    "orign_key_df['bert_review_len'] = 0\n",
    "orign_key_df['bert_summary_len'] = 0\n",
    "\n",
    "orign_key_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key word load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load FOP-View/Electronics_Cameras_keywords2.txt keywords...\n"
     ]
    }
   ],
   "source": [
    "fn = 'FOP-View/%s_%s_keywords2.txt' % (category1, category2)\n",
    "print('load %s keywords...' % (fn))\n",
    "total_keywords = set()\n",
    "with open(fn, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        k, v = line.split(\":\")\n",
    "        total_keywords.add(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative-words.txt\n",
      "positive-words.txt\n",
      "total-words 已取得\n"
     ]
    }
   ],
   "source": [
    "opinion_lexicon = {}\n",
    "for filename in os.listdir('opinion-lexicon-English/'):      \n",
    "    if \"txt\" not in filename: continue\n",
    "    print(filename)\n",
    "    with open('opinion-lexicon-English/'+filename,'r') as f_input:\n",
    "        lexion = []\n",
    "        for line in f_input:\n",
    "            if line.startswith(\";\"):\n",
    "                continue\n",
    "            word = line.replace(\"\\n\",\"\")\n",
    "            if word != \"\" : lexion.append(word)\n",
    "        pos = filename.replace(\".txt\",\"\")\n",
    "        opinion_lexicon[pos] = lexion\n",
    "\n",
    "opinion_lexicon[\"total-words\"] = opinion_lexicon[\"negative-words\"] + opinion_lexicon[\"positive-words\"]\n",
    "print(\"total-words 已取得\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 裡頭的字典資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字典大小： 30522\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, do_basic_tokenize=True)\n",
    "vocab = tokenizer.vocab # word_to_id\n",
    "print(\"字典大小：\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-Summary 資料清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def isnumber(aString):\n",
    "    try:\n",
    "        float(aString)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def create_custom_tokenizer(nlp):\n",
    "    prefix_re = re.compile(r'[0-9]\\.')\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search)\n",
    "\n",
    "nlp.tokenizer = create_custom_tokenizer(nlp)\n",
    "\n",
    "alphbet_stopword = ['b','c','d','e','f','g','h','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356566400</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>too small .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book was almost as small a pamphlet . '...</td>\n",
       "      <td>&lt;s&gt; too small &lt;/s&gt; \\n</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pamphlet as small,pamphlet small</td>\n",
       "      <td>this book was almost as small a pamphlet .</td>\n",
       "      <td>book small pamphlet intend gift expect descrip...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book is a collector item and i love the...</td>\n",
       "      <td>&lt;s&gt; wonderful book a keepsake &lt;/s&gt; \\n</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i would like to say the the cannon elph37 oz...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt; \\n</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i have have and use q 370z for over a year a...</td>\n",
       "      <td>&lt;s&gt; a good all around aps camera &lt;/s&gt; \\n</td>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i use this camera once and it take relativel...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/...</td>\n",
       "      <td>94</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "0  1356566400  this book was almost as small a pamphlet . for...   \n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "0                             too small .    Electronics     Camera Cases   \n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "0  ['this book was almost as small a pamphlet . '...   \n",
       "1  ['this book is a collector item and i love the...   \n",
       "2  ['i would like to say the the cannon elph37 oz...   \n",
       "3  ['i have have and use q 370z for over a year a...   \n",
       "4  ['i use this camera once and it take relativel...   \n",
       "\n",
       "                                        lemm_summary  lemm_review_len  \\\n",
       "0                              <s> too small </s> \\n               45   \n",
       "1              <s> wonderful book a keepsake </s> \\n               54   \n",
       "2                 <s> elph 37 oz is the best </s> \\n               58   \n",
       "3           <s> a good all around aps camera </s> \\n              137   \n",
       "4   <s> terrible camera worse customer service </...               94   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "0                 6        1     2   \n",
       "1                 8        5     9   \n",
       "2                10        5    51   \n",
       "3                10        5    13   \n",
       "4                 9        1    48   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "0                   pamphlet as small,pamphlet small   \n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "0        this book was almost as small a pamphlet .    \n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "0  book small pamphlet intend gift expect descrip...                            \n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compose_summary(x):\n",
    "    x = x.replace(\"\\n\",\" \")\n",
    "    #x = x.replace(\"\\n\",\"\").replace(\"</s>\",\"\").replace(\"<s>\",\"\")\n",
    "    #x = \"<s>\" + x + \"</s>\"  \n",
    "    tokens = [str(token) for token in x.split(\" \") if (\" \" not in str(token)) and \\\n",
    "                   #(str(token).isalpha()) and \\\n",
    "                  (len(str(token)) > 1)   ]\n",
    "    # print(tokens)\n",
    "    #return \" \".join(tokens),tokens\n",
    "    \n",
    "    newtokens = []\n",
    "    for token in tokens:\n",
    "        if (isnumber(token) or len(token) == 1 or token == \".\") and (token not in alphbet_stopword):\n",
    "            newtokens.append(token)\n",
    "        else:\n",
    "            token = token.replace(\".\",\" . \")\n",
    "            sub_tokens = token.split(\" \")\n",
    "            sub_tokens = [t for t in sub_tokens if t != \"\" and t not in alphbet_stopword]\n",
    "            newtokens.extend(sub_tokens)\n",
    "    \n",
    "#     dot_tokens = [token for token in newtokens if (token[0] == \".\" or token[-1] == \".\") and (len(token)>1)]\n",
    "#     if len(dot_tokens) > 0 :print(dot_tokens)\n",
    "        \n",
    "    return \" \".join(newtokens).replace(' . . ',' . '),newtokens\n",
    "    \n",
    "\n",
    "def bert_compose_summary(newtokens):\n",
    "#     x = x.replace(\"\\n\",\"\").replace(\"</s>\",\"\").replace(\"<s>\",\"\")\n",
    "#     x = \"<s>\" + x + \"</s>\"  \n",
    "#     tokens = [str(token) for token in nlp(x) if (\" \" not in str(token)) and \\\n",
    "#                   (str(token).isalpha()) and \\\n",
    "#                   (len(str(token)) > 1)   ]\n",
    "    \n",
    "#     newtokens = []\n",
    "#     for token in tokens:\n",
    "#         if (isnumber(token) or len(token) == 1 or token == \".\") and (token not in alphbet_stopword):\n",
    "#             newtokens.append(token)\n",
    "#         else:\n",
    "#             token = token.replace(\".\",\" . \")\n",
    "#             sub_tokens = token.split(\" \")\n",
    "#             sub_tokens = [t for t in sub_tokens if t != \"\" and t not in alphbet_stopword]\n",
    "#             newtokens.extend(sub_tokens)\n",
    "\n",
    "#     dot_tokens = [t for t in newtokens if (\".\" in t) and (len(t) > 1) ]\n",
    "#     if len(dot_tokens) > 0 :print(dot_tokens)\n",
    "    newtokens = [t for t in newtokens if t not in [\"<s>\",\"</s>\"]]\n",
    "    newtokens = ['[CLS]'] + tokenizer.tokenize(\" \".join(newtokens)) + ['[SEP]']\n",
    "    return \" \".join(newtokens)\n",
    "\n",
    "'''\n",
    "def calc_summary_len(x):\n",
    "#     tokens = [token for token in nlp(x)]\n",
    "#     print(tokens)\n",
    "#     print([len(t) for t in tokens])\n",
    "#     return len(tokens)\n",
    "    return len(x.split(\" \"))\n",
    "\n",
    "nlp.tokenizer = create_custom_tokenizer(nlp)\n",
    "\n",
    "orign_key_df['lemm_summary'] = orign_key_df['lemm_summary'].apply(compose_summary)\n",
    "orign_key_df['lemm_summary_len'] = orign_key_df['lemm_summary'].apply(calc_summary_len)\n",
    "\n",
    "\n",
    "amount = len(orign_key_df)\n",
    "print('Total data : %s'%(amount))\n",
    "\n",
    "orign_key_df.head()\n",
    "'''\n",
    "orign_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "row 165309 : 100%|██████████| 165310/165310 [1:16:40<00:00, 35.93it/s]Total data : 165310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356566400</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>too small .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book was almost as small a pamphlet . '...</td>\n",
       "      <td>&lt;s&gt; too small &lt;/s&gt;</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pamphlet as small,pamphlet small</td>\n",
       "      <td>this book was almost as small a pamphlet .</td>\n",
       "      <td>book small pamphlet intend gift expect descrip...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book is a collector item and i love the...</td>\n",
       "      <td>&lt;s&gt; wonderful book keepsake &lt;/s&gt;</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i would like to say the the cannon elph37 oz...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt;</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i have have and use q 370z for over a year a...</td>\n",
       "      <td>&lt;s&gt; good all around aps camera &lt;/s&gt;</td>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i use this camera once and it take relativel...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "0  1356566400  this book was almost as small a pamphlet . for...   \n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "0                             too small .    Electronics     Camera Cases   \n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "0  ['this book was almost as small a pamphlet . '...   \n",
       "1  ['this book is a collector item and i love the...   \n",
       "2  ['i would like to say the the cannon elph37 oz...   \n",
       "3  ['i have have and use q 370z for over a year a...   \n",
       "4  ['i use this camera once and it take relativel...   \n",
       "\n",
       "                                      lemm_summary  lemm_review_len  \\\n",
       "0                               <s> too small </s>               45   \n",
       "1                 <s> wonderful book keepsake </s>               54   \n",
       "2                  <s> elph 37 oz is the best </s>               58   \n",
       "3              <s> good all around aps camera </s>              137   \n",
       "4  <s> terrible camera worse customer service </s>               94   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "0                 4        1     2   \n",
       "1                 5        5     9   \n",
       "2                 8        5    51   \n",
       "3                 7        5    13   \n",
       "4                 7        1    48   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "0                   pamphlet as small,pamphlet small   \n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "0        this book was almost as small a pamphlet .    \n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "0  book small pamphlet intend gift expect descrip...                            \n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# 非符號alpha word重疊數\n",
    "with tqdm(total=len(orign_key_df)) as pbar:\n",
    "    for i ,row in orign_key_df.iterrows():        \n",
    "        pbar.update(1)\n",
    "        pbar.set_description(\"row %s \" % (i))\n",
    "\n",
    "        lemm_summary,newtokens = compose_summary(row['lemm_summary'])\n",
    "        # bert_summary = bert_compose_summary(newtokens)\n",
    "        \n",
    "        orign_key_df.loc[i,'lemm_summary'] = lemm_summary\n",
    "        # orign_key_df.loc[i,'bert_summary'] = bert_summary\n",
    "        \n",
    "        orign_key_df.loc[i,'lemm_summary_len'] = len(lemm_summary.split(\" \"))       \n",
    "        # orign_key_df.loc[i,'bert_summary_len'] = len(bert_summary.split(\" \"))\n",
    "\n",
    "        \n",
    "        \n",
    "amount = len(orign_key_df)\n",
    "print('Total data : %s'%(amount))\n",
    "orign_key_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-review 多句合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "def compose_review(x):\n",
    "    x = eval(x)\n",
    "    x = \"\\n\".join(x)\n",
    "    x = x.replace(\".\\n\",\" . \").replace(\"\\n.\",\" . \").replace(\"\\n\",\" \")\n",
    "#     x = x.replace(\"\\n\",\" \")    \n",
    "    tokens = [str(token) for token in x.split(\" \") if (\" \" not in str(token))and (str(token) == '.' or str(token).isalpha())]\n",
    "#    tokens = [str(token) for token in x.split(\" \") if (\" \" not in str(token)) ]\n",
    "\n",
    "    #return \" \".join(tokens)\n",
    "    \n",
    "    newtokens = []\n",
    "    for token in tokens:\n",
    "#         if (len(token) == 1 or token == \".\"):\n",
    "        if (isnumber(token) or len(token) == 1 or token == \".\")and (token not in alphbet_stopword):\n",
    "            newtokens.append(token)\n",
    "#             if (token not in ['a','i']) and (token != \".\"): print(token)\n",
    "        else:\n",
    "#             token = token.replace(\".\",\" . \")\n",
    "            token = token.replace(\".\",\" . \")\n",
    "            sub_tokens = token.split(\" \")\n",
    "            sub_tokens = [t for t in sub_tokens if t != \"\" and t not in alphbet_stopword]\n",
    "            if len(sub_tokens) == 0: continue\n",
    "            newtokens.extend(sub_tokens)\n",
    "\n",
    "    dot_tokens = [token for token in newtokens if (token[0] == \".\" or token[-1] == \".\") and (len(token)>1)]\n",
    "    if len(dot_tokens) > 0 :print(dot_tokens)\n",
    "    \n",
    "    return \" \".join(newtokens).replace(' . . ',' . ')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def calc_review_len(x):\n",
    "#     tokens = [token for token in nlp(x)]\n",
    "#     print(tokens)\n",
    "#     print([len(t) for t in tokens])\n",
    "#     return len(tokens)\n",
    "    return len(x.split(\" \"))\n",
    "key_df = deepcopy(orign_key_df)\n",
    "key_df['lemm_review'] = key_df['lemm_review'].apply(compose_review)\n",
    "key_df['lemm_review_len'] = key_df['lemm_review'].apply(calc_review_len)\n",
    "key_df.head()\n",
    "\n",
    "'''\n",
    "def bert_compose_review(x):\n",
    "    x = eval(x)\n",
    "    review_sents = deepcopy(x)\n",
    "    total_tokens = []\n",
    "    for sent in review_sents:\n",
    "        sent = sent.replace('\\n','[SEP]')\n",
    "        tokens = [str(token) for token in sent.split(\" \") if (\" \" not in str(token)) ]\n",
    "        newtokens = []\n",
    "        for token in tokens:\n",
    "            if (isnumber(token) or len(token) == 1 or token == \".\")and (token not in alphbet_stopword):\n",
    "                newtokens.append(token)\n",
    "            else:\n",
    "                token = token.replace(\".\",\" . \")\n",
    "                sub_tokens = token.split(\" \")\n",
    "                sub_tokens = [t for t in sub_tokens if t != \"\" and t not in alphbet_stopword]\n",
    "                newtokens.extend(sub_tokens)\n",
    "        newtokens = newtokens + ['[SEP]']        \n",
    "        total_tokens.extend(newtokens)\n",
    "    total_tokens = ['[CLS]'] + tokenizer.tokenize(\" \".join(total_tokens))    \n",
    "    return \" \".join(total_tokens)\n",
    "\n",
    "'''\n",
    "# def compose_review(bert_review):\n",
    "#     return bert_review.replace('[CLS] ','').replace('[SEP] ','')\n",
    "'''\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356566400</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>too small .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book was almost as small a pamphlet . '...</td>\n",
       "      <td>&lt;s&gt; too small &lt;/s&gt;</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pamphlet as small,pamphlet small</td>\n",
       "      <td>this book was almost as small a pamphlet .</td>\n",
       "      <td>book small pamphlet intend gift expect descrip...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>['this book is a collector item and i love the...</td>\n",
       "      <td>&lt;s&gt; wonderful book keepsake &lt;/s&gt;</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i would like to say the the cannon elph37 oz...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt;</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i have have and use q 370z for over a year a...</td>\n",
       "      <td>&lt;s&gt; good all around aps camera &lt;/s&gt;</td>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>['i use this camera once and it take relativel...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "0  1356566400  this book was almost as small a pamphlet . for...   \n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "0                             too small .    Electronics     Camera Cases   \n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "0  ['this book was almost as small a pamphlet . '...   \n",
       "1  ['this book is a collector item and i love the...   \n",
       "2  ['i would like to say the the cannon elph37 oz...   \n",
       "3  ['i have have and use q 370z for over a year a...   \n",
       "4  ['i use this camera once and it take relativel...   \n",
       "\n",
       "                                      lemm_summary  lemm_review_len  \\\n",
       "0                               <s> too small </s>               45   \n",
       "1                 <s> wonderful book keepsake </s>               54   \n",
       "2                  <s> elph 37 oz is the best </s>               58   \n",
       "3              <s> good all around aps camera </s>              137   \n",
       "4  <s> terrible camera worse customer service </s>               94   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "0                 4        1     2   \n",
       "1                 5        5     9   \n",
       "2                 8        5    51   \n",
       "3                 7        5    13   \n",
       "4                 7        1    48   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "0                   pamphlet as small,pamphlet small   \n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "0        this book was almost as small a pamphlet .    \n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "0  book small pamphlet intend gift expect descrip...                            \n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orign_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "row 165309 : 100%|██████████| 165310/165310 [1:59:40<00:00, 23.02it/s]\n",
      "Total data : 165310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356566400</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>too small .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>this book was almost as small a pamphlet . for...</td>\n",
       "      <td>&lt;s&gt; too small &lt;/s&gt;</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pamphlet as small,pamphlet small</td>\n",
       "      <td>this book was almost as small a pamphlet .</td>\n",
       "      <td>book small pamphlet intend gift expect descrip...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>this book is a collector item and i love they ...</td>\n",
       "      <td>&lt;s&gt; wonderful book keepsake &lt;/s&gt;</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i would like to say the the cannon oz is worth...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt;</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i have have and use for over a year and i have...</td>\n",
       "      <td>&lt;s&gt; good all around aps camera &lt;/s&gt;</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i use this camera once and it take relatively ...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "0  1356566400  this book was almost as small a pamphlet . for...   \n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "0                             too small .    Electronics     Camera Cases   \n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "0  this book was almost as small a pamphlet . for...   \n",
       "1  this book is a collector item and i love they ...   \n",
       "2  i would like to say the the cannon oz is worth...   \n",
       "3  i have have and use for over a year and i have...   \n",
       "4  i use this camera once and it take relatively ...   \n",
       "\n",
       "                                      lemm_summary  lemm_review_len  \\\n",
       "0                               <s> too small </s>               47   \n",
       "1                 <s> wonderful book keepsake </s>               56   \n",
       "2                  <s> elph 37 oz is the best </s>               61   \n",
       "3              <s> good all around aps camera </s>              135   \n",
       "4  <s> terrible camera worse customer service </s>               99   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "0                 4        1     2   \n",
       "1                 5        5     9   \n",
       "2                 8        5    51   \n",
       "3                 7        5    13   \n",
       "4                 7        1    48   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "0                   pamphlet as small,pamphlet small   \n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "0        this book was almost as small a pamphlet .    \n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "0  book small pamphlet intend gift expect descrip...                            \n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_df = deepcopy(orign_key_df)\n",
    "\n",
    "from tqdm import tqdm\n",
    "# 非符號alpha word重疊數\n",
    "with tqdm(total=len(key_df)) as pbar:\n",
    "    for i ,row in key_df.iterrows():  \n",
    "        try:\n",
    "            lemm_review = compose_review(row['lemm_review'])\n",
    "            # bert_review = bert_compose_review(row['lemm_review'])\n",
    "\n",
    "            # key_df.loc[i,'bert_review'] = bert_review\n",
    "            key_df.loc[i,'lemm_review'] = lemm_review\n",
    "            \n",
    "            # key_df.loc[i,'bert_review_len'] = len(bert_review.split(\" \"))\n",
    "            key_df.loc[i,'lemm_review_len'] = len(lemm_review.split(\" \"))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # key_df.loc[i,'bert_review_len'] = 0\n",
    "            # key_df.loc[i,'lemm_review_len'] = 0     \n",
    "        \n",
    "        pbar.set_description(\"row %s \" % (i))\n",
    "        pbar.update(1)\n",
    "\n",
    "key_df = key_df[(key_df.lemm_review_len > 0) ] # 過濾 lemm_review_len = 0\n",
    "\n",
    "amount = len(key_df)\n",
    "print('Total data : %s'%(amount))\n",
    "\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_df.loc[66152]['lemm_review']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過濾不合適的訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(text):\n",
    "    keywords = set()\n",
    "    for words in text.split(\",\"):\n",
    "        for word in words.split(\" \"):\n",
    "            keywords.add(word)\n",
    "    keywords = \" \".join(keywords)\n",
    "    return keywords\n",
    "\n",
    "def calc_keyword_num(x):\n",
    "    return len(x.split(\" \"))\n",
    "\n",
    "# and(key_df.lemm_review_len>20)\n",
    "flit_key_df = key_df[(key_df.lemm_summary_len>=4) ] # 過濾single word summary\n",
    "flit_key_df = flit_key_df[(flit_key_df.lemm_review_len <= 1000) ] # 過濾single word summary\n",
    "flit_key_df = flit_key_df[(flit_key_df.lemm_review_len >= 50) ] # 過濾single word summary\n",
    "\n",
    "flit_key_df = flit_key_df.dropna(\n",
    "    axis=0,     # 0: 对行进行操作; 1: 对列进行操作\n",
    "    how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOP_keywords 資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "      <th>FOP_keywords</th>\n",
       "      <th>FOP_keywords_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325721600</td>\n",
       "      <td>this book is a collectors item and i love they...</td>\n",
       "      <td>wonderful book a keepsake</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera Cases</td>\n",
       "      <td>this book is a collector item and i love they ...</td>\n",
       "      <td>&lt;s&gt; wonderful book keepsake &lt;/s&gt;</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>item wonderful,item great,quality item,quality...</td>\n",
       "      <td>\\ngreat quality though and a wonderful nostalg...</td>\n",
       "      <td>book collector item price copy high price buy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>great item wonderful quality nostalgia</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951782400</td>\n",
       "      <td>i would like to say the the cannon elph37oz is...</td>\n",
       "      <td>elph 37oz is the best .</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i would like to say the the cannon oz is worth...</td>\n",
       "      <td>&lt;s&gt; elph 37 oz is the best &lt;/s&gt;</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>money extra,camera inferior,camera cheap</td>\n",
       "      <td>\\npay the extra money and get this one rather ...</td>\n",
       "      <td>cannon money decide buy camera camera picture ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cheap inferior camera money extra</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>985910400</td>\n",
       "      <td>i have had and used q 370z for over a year and...</td>\n",
       "      <td>a good all around aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i have have and use for over a year and i have...</td>\n",
       "      <td>&lt;s&gt; good all around aps camera &lt;/s&gt;</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>light low,eye red room increase slrs lense,len...</td>\n",
       "      <td>\\nyes i sometimes get red eye in low light but...</td>\n",
       "      <td>photographer snapshot year low lens avoid red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>increase light lense slrs red low eye mm room</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i use this camera once and it take relatively ...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internal send stylus memory money camera servi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>999388800</td>\n",
       "      <td>if you are considering a regular canon elph go...</td>\n",
       "      <td>great purchase</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>if you are consider a regular canon elph go wi...</td>\n",
       "      <td>&lt;s&gt; great purchase &lt;/s&gt;</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>zooming powerful,elph regular camera lightweig...</td>\n",
       "      <td>if you are consider a regular canon elph go wi...</td>\n",
       "      <td>zooming elph canon extra enlarge print picture...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lightweight professional zooming postcard smal...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "1  1325721600  this book is a collectors item and i love they...   \n",
       "2   951782400  i would like to say the the cannon elph37oz is...   \n",
       "3   985910400  i have had and used q 370z for over a year and...   \n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "5   999388800  if you are considering a regular canon elph go...   \n",
       "\n",
       "                                  summary big_categories small_categories  \\\n",
       "1               wonderful book a keepsake    Electronics     Camera Cases   \n",
       "2                 elph 37oz is the best .    Electronics      APS Cameras   \n",
       "3            a good all around aps camera    Electronics      APS Cameras   \n",
       "4  terrible camera worse customer service    Electronics      APS Cameras   \n",
       "5                          great purchase    Electronics      APS Cameras   \n",
       "\n",
       "                                         lemm_review  \\\n",
       "1  this book is a collector item and i love they ...   \n",
       "2  i would like to say the the cannon oz is worth...   \n",
       "3  i have have and use for over a year and i have...   \n",
       "4  i use this camera once and it take relatively ...   \n",
       "5  if you are consider a regular canon elph go wi...   \n",
       "\n",
       "                                      lemm_summary  lemm_review_len  \\\n",
       "1                 <s> wonderful book keepsake </s>               56   \n",
       "2                  <s> elph 37 oz is the best </s>               61   \n",
       "3              <s> good all around aps camera </s>              135   \n",
       "4  <s> terrible camera worse customer service </s>               99   \n",
       "5                          <s> great purchase </s>              134   \n",
       "\n",
       "   lemm_summary_len  overall  vote  \\\n",
       "1                 5        5     9   \n",
       "2                 8        5    51   \n",
       "3                 7        5    13   \n",
       "4                 7        1    48   \n",
       "5                 4        5    15   \n",
       "\n",
       "                                       total_keyword  \\\n",
       "1  item wonderful,item great,quality item,quality...   \n",
       "2           money extra,camera inferior,camera cheap   \n",
       "3  light low,eye red room increase slrs lense,len...   \n",
       "4  memory internal camera service camera send sty...   \n",
       "5  zooming powerful,elph regular camera lightweig...   \n",
       "\n",
       "                                           FOP_sents  \\\n",
       "1  \\ngreat quality though and a wonderful nostalg...   \n",
       "2  \\npay the extra money and get this one rather ...   \n",
       "3  \\nyes i sometimes get red eye in low light but...   \n",
       "4  \\nhowever on my next trip the camera internal ...   \n",
       "5  if you are consider a regular canon elph go wi...   \n",
       "\n",
       "                              total_mention_features bert_review bert_summary  \\\n",
       "1  book collector item price copy high price buy ...                            \n",
       "2  cannon money decide buy camera camera picture ...                            \n",
       "3  photographer snapshot year low lens avoid red ...                            \n",
       "4  camera picture memory camera trip company warr...                            \n",
       "5  zooming elph canon extra enlarge print picture...                            \n",
       "\n",
       "   bert_review_len  bert_summary_len  \\\n",
       "1                0                 0   \n",
       "2                0                 0   \n",
       "3                0                 0   \n",
       "4                0                 0   \n",
       "5                0                 0   \n",
       "\n",
       "                                        FOP_keywords  FOP_keywords_num  \n",
       "1             great item wonderful quality nostalgia                 5  \n",
       "2                  cheap inferior camera money extra                 5  \n",
       "3      increase light lense slrs red low eye mm room                 9  \n",
       "4  internal send stylus memory money camera servi...                 9  \n",
       "5  lightweight professional zooming postcard smal...                 9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flit_key_df['FOP_keywords'] = flit_key_df['total_keyword']\n",
    "flit_key_df['FOP_keywords'] = flit_key_df['FOP_keywords'].apply(to_words)\n",
    "flit_key_df['FOP_keywords_num'] = flit_key_df['FOP_keywords'].apply(calc_keyword_num)\n",
    "flit_key_df = flit_key_df[(flit_key_df.FOP_keywords_num>=2) ] # 過濾single word summary\n",
    "flit_key_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115243/115243 [03:40<00:00, 522.94it/s]\n",
      "Total data : 36394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>...</th>\n",
       "      <th>total_keyword</th>\n",
       "      <th>FOP_sents</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "      <th>FOP_keywords</th>\n",
       "      <th>FOP_keywords_num</th>\n",
       "      <th>Cheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i use this camera once and it take relatively ...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>memory internal camera service camera send sty...</td>\n",
       "      <td>\\nhowever on my next trip the camera internal ...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internal send stylus memory money camera servi...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>951868800</td>\n",
       "      <td>my review will focus on how well the 370z repl...</td>\n",
       "      <td>a good enough replacement for 35mm point and s...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>my review will focus on how well the replace a...</td>\n",
       "      <td>&lt;s&gt; good enough replacement for 35 mm point an...</td>\n",
       "      <td>425</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>definition precise situation light,situation b...</td>\n",
       "      <td>\\nlack of precise definition of edge with asa ...</td>\n",
       "      <td>replace mm shoot review focus point replace pe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>length light feature suitcase much definition ...</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>974332800</td>\n",
       "      <td>if you want a point and shoot camera that you ...</td>\n",
       "      <td>best compact aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>if you want a point and shoot camera that you ...</td>\n",
       "      <td>&lt;s&gt; best compact aps camera &lt;/s&gt;</td>\n",
       "      <td>188</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>set pretty broad,range size,camera elph,size z...</td>\n",
       "      <td>\\ni look at a pretty broad set of camera inclu...</td>\n",
       "      <td>carry shirt shoot pocket camera bag point thro...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zoon good pretty simplicity quality size camer...</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>942883200</td>\n",
       "      <td>i have had my camera for two months and i love...</td>\n",
       "      <td>great first digital camera for non photographers</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Digital Cameras</td>\n",
       "      <td>i have have my camera for two month and i love...</td>\n",
       "      <td>&lt;s&gt; great first digital camera for non photogr...</td>\n",
       "      <td>105</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>quality very good,mb card,quality good</td>\n",
       "      <td>\\ni wish that it would take the 16 mb and the ...</td>\n",
       "      <td>camera month professional photographer picture...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>card very good mb quality</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>960163200</td>\n",
       "      <td>when i got this camera it is nice looking and ...</td>\n",
       "      <td>use 3 days to trouble shoot the connecting the...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Digital Cameras</td>\n",
       "      <td>when i get this camera it is nice looking and ...</td>\n",
       "      <td>&lt;s&gt; use day to trouble shoot the connect the s...</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>buying worth picture nice photo upload cable s...</td>\n",
       "      <td>when i get this camera it is nice looking and ...</td>\n",
       "      <td>camera buying picture day memory photo compute...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>download nice buying photo serial cable softwa...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "8   951868800  my review will focus on how well the 370z repl...   \n",
       "10  974332800  if you want a point and shoot camera that you ...   \n",
       "35  942883200  i have had my camera for two months and i love...   \n",
       "44  960163200  when i got this camera it is nice looking and ...   \n",
       "\n",
       "                                              summary big_categories  \\\n",
       "4              terrible camera worse customer service    Electronics   \n",
       "8   a good enough replacement for 35mm point and s...    Electronics   \n",
       "10                            best compact aps camera    Electronics   \n",
       "35   great first digital camera for non photographers    Electronics   \n",
       "44  use 3 days to trouble shoot the connecting the...    Electronics   \n",
       "\n",
       "   small_categories                                        lemm_review  \\\n",
       "4       APS Cameras  i use this camera once and it take relatively ...   \n",
       "8       APS Cameras  my review will focus on how well the replace a...   \n",
       "10      APS Cameras  if you want a point and shoot camera that you ...   \n",
       "35  Digital Cameras  i have have my camera for two month and i love...   \n",
       "44  Digital Cameras  when i get this camera it is nice looking and ...   \n",
       "\n",
       "                                         lemm_summary  lemm_review_len  \\\n",
       "4     <s> terrible camera worse customer service </s>               99   \n",
       "8   <s> good enough replacement for 35 mm point an...              425   \n",
       "10                   <s> best compact aps camera </s>              188   \n",
       "35  <s> great first digital camera for non photogr...              105   \n",
       "44  <s> use day to trouble shoot the connect the s...              194   \n",
       "\n",
       "    lemm_summary_len  overall  ...    \\\n",
       "4                  7        1  ...     \n",
       "8                 11        4  ...     \n",
       "10                 6        5  ...     \n",
       "35                 9        4  ...     \n",
       "44                12        3  ...     \n",
       "\n",
       "                                        total_keyword  \\\n",
       "4   memory internal camera service camera send sty...   \n",
       "8   definition precise situation light,situation b...   \n",
       "10  set pretty broad,range size,camera elph,size z...   \n",
       "35             quality very good,mb card,quality good   \n",
       "44  buying worth picture nice photo upload cable s...   \n",
       "\n",
       "                                            FOP_sents  \\\n",
       "4   \\nhowever on my next trip the camera internal ...   \n",
       "8   \\nlack of precise definition of edge with asa ...   \n",
       "10  \\ni look at a pretty broad set of camera inclu...   \n",
       "35  \\ni wish that it would take the 16 mb and the ...   \n",
       "44  when i get this camera it is nice looking and ...   \n",
       "\n",
       "                               total_mention_features bert_review  \\\n",
       "4   camera picture memory camera trip company warr...               \n",
       "8   replace mm shoot review focus point replace pe...               \n",
       "10  carry shirt shoot pocket camera bag point thro...               \n",
       "35  camera month professional photographer picture...               \n",
       "44  camera buying picture day memory photo compute...               \n",
       "\n",
       "   bert_summary bert_review_len  bert_summary_len  \\\n",
       "4                             0                 0   \n",
       "8                             0                 0   \n",
       "10                            0                 0   \n",
       "35                            0                 0   \n",
       "44                            0                 0   \n",
       "\n",
       "                                         FOP_keywords FOP_keywords_num  Cheat  \n",
       "4   internal send stylus memory money camera servi...                9   True  \n",
       "8   length light feature suitcase much definition ...               27   True  \n",
       "10  zoon good pretty simplicity quality size camer...               13   True  \n",
       "35                          card very good mb quality                5   True  \n",
       "44  download nice buying photo serial cable softwa...               10   True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flit_key_df['Cheat'] = False \n",
    "\n",
    "# flit_key_df.head()\n",
    "from tqdm import tqdm\n",
    "# 非符號alpha word重疊數\n",
    "with tqdm(total=len(flit_key_df)) as pbar:\n",
    "    for i ,row in flit_key_df.iterrows():\n",
    "        rev_tokens = set(row['lemm_review'].split(\" \"))\n",
    "        summ_tokens = set(row['lemm_summary'].split(\" \"))\n",
    "        key_words = rev_tokens & summ_tokens & (total_keywords| set(opinion_lexicon[\"total-words\"]))\n",
    "        if len(key_words) > 2: \n",
    "            flit_key_df.loc[i,'Cheat'] = True\n",
    "        pbar.update(1)\n",
    "    \n",
    "flit_key_df = flit_key_df[(flit_key_df.Cheat == True) ] # 過濾single word summary\n",
    "amount = len(flit_key_df)\n",
    "print('Total data : %s'%(amount))\n",
    "flit_key_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank_keywords 資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords as TextRank\n",
    "from summa.summarizer import summarize\n",
    "def textrank_keys(text):\n",
    "    keywords1 = list()\n",
    "    for words in TextRank.keywords(text).split('\\n'):\n",
    "        keywords1.extend(words.split(\" \"))\n",
    "    keywords1 = set(keywords1)    \n",
    "    \n",
    "    return \" \".join(list(keywords1))\n",
    "\n",
    "def textrank_summ_keys(text): \n",
    "    keywords2 = list()\n",
    "    for words in summarize(text, words=8).split('\\n'):\n",
    "        keywords2.extend(words.split(\" \"))\n",
    "    keywords2 = set(keywords2)\n",
    "    \n",
    "    return \" \".join(list(keywords2))\n",
    "\n",
    "flit_key_df.loc[:,'TextRank_keywords'] = ''\n",
    "flit_key_df.loc[:,'TextRank_summary'] = ''\n",
    "# flit_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36394/36394 [10:27<00:00, 57.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_ID</th>\n",
       "      <th>review</th>\n",
       "      <th>summary</th>\n",
       "      <th>big_categories</th>\n",
       "      <th>small_categories</th>\n",
       "      <th>lemm_review</th>\n",
       "      <th>lemm_summary</th>\n",
       "      <th>lemm_review_len</th>\n",
       "      <th>lemm_summary_len</th>\n",
       "      <th>overall</th>\n",
       "      <th>...</th>\n",
       "      <th>total_mention_features</th>\n",
       "      <th>bert_review</th>\n",
       "      <th>bert_summary</th>\n",
       "      <th>bert_review_len</th>\n",
       "      <th>bert_summary_len</th>\n",
       "      <th>FOP_keywords</th>\n",
       "      <th>FOP_keywords_num</th>\n",
       "      <th>Cheat</th>\n",
       "      <th>TextRank_keywords</th>\n",
       "      <th>TextRank_keywords_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967075200</td>\n",
       "      <td>i used this camera once and it took relatively...</td>\n",
       "      <td>terrible camera worse customer service</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>i use this camera once and it take relatively ...</td>\n",
       "      <td>&lt;s&gt; terrible camera worse customer service &lt;/s&gt;</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>camera picture memory camera trip company warr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>internal send stylus memory money camera servi...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>camera good equipment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>951868800</td>\n",
       "      <td>my review will focus on how well the 370z repl...</td>\n",
       "      <td>a good enough replacement for 35mm point and s...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>my review will focus on how well the replace a...</td>\n",
       "      <td>&lt;s&gt; good enough replacement for 35 mm point an...</td>\n",
       "      <td>425</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>replace mm shoot review focus point replace pe...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>length light feature suitcase much definition ...</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>length night use day excellent red zoom eye fo...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>974332800</td>\n",
       "      <td>if you want a point and shoot camera that you ...</td>\n",
       "      <td>best compact aps camera</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>APS Cameras</td>\n",
       "      <td>if you want a point and shoot camera that you ...</td>\n",
       "      <td>&lt;s&gt; best compact aps camera &lt;/s&gt;</td>\n",
       "      <td>188</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>carry shirt shoot pocket camera bag point thro...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zoon good pretty simplicity quality size camer...</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>expensive include best pocket camera elph shir...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>942883200</td>\n",
       "      <td>i have had my camera for two months and i love...</td>\n",
       "      <td>great first digital camera for non photographers</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Digital Cameras</td>\n",
       "      <td>i have have my camera for two month and i love...</td>\n",
       "      <td>&lt;s&gt; great first digital camera for non photogr...</td>\n",
       "      <td>105</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>camera month professional photographer picture...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>card very good mb quality</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>photographer quality professional</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>960163200</td>\n",
       "      <td>when i got this camera it is nice looking and ...</td>\n",
       "      <td>use 3 days to trouble shoot the connecting the...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Digital Cameras</td>\n",
       "      <td>when i get this camera it is nice looking and ...</td>\n",
       "      <td>&lt;s&gt; use day to trouble shoot the connect the s...</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>camera buying picture day memory photo compute...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>download nice buying photo serial cable softwa...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>come nice way serial box worth</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_ID                                             review  \\\n",
       "4   967075200  i used this camera once and it took relatively...   \n",
       "8   951868800  my review will focus on how well the 370z repl...   \n",
       "10  974332800  if you want a point and shoot camera that you ...   \n",
       "35  942883200  i have had my camera for two months and i love...   \n",
       "44  960163200  when i got this camera it is nice looking and ...   \n",
       "\n",
       "                                              summary big_categories  \\\n",
       "4              terrible camera worse customer service    Electronics   \n",
       "8   a good enough replacement for 35mm point and s...    Electronics   \n",
       "10                            best compact aps camera    Electronics   \n",
       "35   great first digital camera for non photographers    Electronics   \n",
       "44  use 3 days to trouble shoot the connecting the...    Electronics   \n",
       "\n",
       "   small_categories                                        lemm_review  \\\n",
       "4       APS Cameras  i use this camera once and it take relatively ...   \n",
       "8       APS Cameras  my review will focus on how well the replace a...   \n",
       "10      APS Cameras  if you want a point and shoot camera that you ...   \n",
       "35  Digital Cameras  i have have my camera for two month and i love...   \n",
       "44  Digital Cameras  when i get this camera it is nice looking and ...   \n",
       "\n",
       "                                         lemm_summary  lemm_review_len  \\\n",
       "4     <s> terrible camera worse customer service </s>               99   \n",
       "8   <s> good enough replacement for 35 mm point an...              425   \n",
       "10                   <s> best compact aps camera </s>              188   \n",
       "35  <s> great first digital camera for non photogr...              105   \n",
       "44  <s> use day to trouble shoot the connect the s...              194   \n",
       "\n",
       "    lemm_summary_len  overall          ...            \\\n",
       "4                  7        1          ...             \n",
       "8                 11        4          ...             \n",
       "10                 6        5          ...             \n",
       "35                 9        4          ...             \n",
       "44                12        3          ...             \n",
       "\n",
       "                               total_mention_features bert_review  \\\n",
       "4   camera picture memory camera trip company warr...               \n",
       "8   replace mm shoot review focus point replace pe...               \n",
       "10  carry shirt shoot pocket camera bag point thro...               \n",
       "35  camera month professional photographer picture...               \n",
       "44  camera buying picture day memory photo compute...               \n",
       "\n",
       "   bert_summary bert_review_len bert_summary_len  \\\n",
       "4                             0                0   \n",
       "8                             0                0   \n",
       "10                            0                0   \n",
       "35                            0                0   \n",
       "44                            0                0   \n",
       "\n",
       "                                         FOP_keywords  FOP_keywords_num  \\\n",
       "4   internal send stylus memory money camera servi...                 9   \n",
       "8   length light feature suitcase much definition ...                27   \n",
       "10  zoon good pretty simplicity quality size camer...                13   \n",
       "35                          card very good mb quality                 5   \n",
       "44  download nice buying photo serial cable softwa...                10   \n",
       "\n",
       "    Cheat                                  TextRank_keywords  \\\n",
       "4    True                              camera good equipment   \n",
       "8    True  length night use day excellent red zoom eye fo...   \n",
       "10   True  expensive include best pocket camera elph shir...   \n",
       "35   True                  photographer quality professional   \n",
       "44   True                     come nice way serial box worth   \n",
       "\n",
       "    TextRank_keywords_num  \n",
       "4                       3  \n",
       "8                      16  \n",
       "10                      9  \n",
       "35                      3  \n",
       "44                      6  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with tqdm(total=len(flit_key_df)) as pbar:\n",
    "    for i ,row in flit_key_df.iterrows():\n",
    "        TextRank_keywords = textrank_keys(row['lemm_review'])\n",
    "        TextRank_summary = textrank_summ_keys(row['lemm_review'])  \n",
    "#         num = calc_keyword_num(TextRank_keywords)\n",
    "        flit_key_df.loc[i,'TextRank_keywords'] = TextRank_keywords\n",
    "        flit_key_df.loc[i,'TextRank_summary'] = TextRank_summary\n",
    "#         flit_key_df.loc[i,'TextRank_keywords_num'] = num\n",
    "        pbar.update(1)\n",
    "        \n",
    "flit_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "if not os.path.exists('XLSX/statistic'):\n",
    "    os.makedirs('XLSX/statistic')\n",
    "with open('XLSX/statistic/%s_%s_info.txt'%(category1,category2),'w') as f:\n",
    "    max_rev_len = flit_key_df['lemm_review_len'].max()\n",
    "    min_rev_len = flit_key_df['lemm_review_len'].min()\n",
    "    mean_rev_len = flit_key_df['lemm_review_len'].mean()\n",
    "    median_rev_len = flit_key_df['lemm_review_len'].median()\n",
    "\n",
    "    f.write('max_rev_len :%s \\n'%(max_rev_len))\n",
    "    f.write('min_rev_len :%s \\n'%(min_rev_len))\n",
    "    f.write('mean_rev_len :%s \\n'%(mean_rev_len))\n",
    "    f.write('median_rev_len :%s \\n'%(median_rev_len))\n",
    "    \n",
    "    f.write('\\n\\n\\n')\n",
    "    max_summary_len = flit_key_df['lemm_summary_len'].max()\n",
    "    min_summary_len = flit_key_df['lemm_summary_len'].min()\n",
    "    mean_summary_len = flit_key_df['lemm_summary_len'].mean()\n",
    "    median_summary_len = flit_key_df['lemm_summary_len'].median()\n",
    "\n",
    "    f.write('max_summary_len :%s \\n'%(max_summary_len))\n",
    "    f.write('min_summary_len :%s \\n'%(min_summary_len))\n",
    "    f.write('mean_summary_len :%s \\n'%(mean_summary_len))\n",
    "    f.write('median_summary_len :%s \\n'%(median_summary_len))\n",
    "    \n",
    "    f.write('\\n\\n\\n')\n",
    "    max_FOP_keywords_num = flit_key_df['FOP_keywords_num'].max()\n",
    "    min_FOP_keywords_num = flit_key_df['FOP_keywords_num'].min()\n",
    "    mean_FOP_keywords_num = flit_key_df['FOP_keywords_num'].mean()\n",
    "    median_FOP_keywords_num = flit_key_df['FOP_keywords_num'].median()\n",
    "\n",
    "    f.write('max_FOP_keywords_num :%s \\n'%(max_FOP_keywords_num))\n",
    "    f.write('min_FOP_keywords_num :%s \\n'%(min_FOP_keywords_num))\n",
    "    f.write('mean_FOP_keywords_num :%s \\n'%(mean_FOP_keywords_num))\n",
    "    f.write('median_FOP_keywords_num :%s \\n'%(median_FOP_keywords_num))\n",
    "    \n",
    "    f.write('\\n\\n\\n')\n",
    "#     max_TextRank_keywords_num = flit_key_df['TextRank_keywords_num'].max()\n",
    "#     min_TextRank_keywords_num = flit_key_df['TextRank_keywords_num'].min()\n",
    "#     mean_TextRank_keywords_num = flit_key_df['TextRank_keywords_num'].mean()\n",
    "#     median_TextRank_keywords_num = flit_key_df['TextRank_keywords_num'].median()\n",
    "\n",
    "#     f.write('max_TextRank_keywords_num :%s \\n'%(max_TextRank_keywords_num))\n",
    "#     f.write('min_TextRank_keywords_num :%s \\n'%(min_TextRank_keywords_num))\n",
    "#     f.write('mean_TextRank_keywords_num :%s \\n'%(mean_TextRank_keywords_num))\n",
    "#     f.write('median_TextRank_keywords_num :%s \\n'%(median_TextRank_keywords_num))\n",
    "\n",
    "    '''\n",
    "    f.write('\\n\\n\\n')    \n",
    "    max_bert_rev_len = flit_key_df['bert_review_len'].max()\n",
    "    min_bert_rev_len = flit_key_df['bert_review_len'].min()\n",
    "    mean_bert_rev_len = flit_key_df['bert_review_len'].mean()\n",
    "    median_bert_rev_len = flit_key_df['bert_review_len'].median()\n",
    "\n",
    "    f.write('max_bert_rev_len :%s \\n'%(max_bert_rev_len))\n",
    "    f.write('min_bert_rev_len :%s \\n'%(min_bert_rev_len))\n",
    "    f.write('mean_bert_rev_len :%s \\n'%(mean_bert_rev_len))\n",
    "    f.write('median_bert_rev_len :%s \\n'%(median_bert_rev_len))\n",
    "    \n",
    "    f.write('\\n\\n\\n')\n",
    "    max_bert_summary_len = flit_key_df['bert_summary_len'].max()\n",
    "    min_bert_summary_len = flit_key_df['bert_summary_len'].min()\n",
    "    mean_bert_summary_len = flit_key_df['bert_summary_len'].mean()\n",
    "    median_bert_summary_len = flit_key_df['bert_summary_len'].median()\n",
    "\n",
    "    f.write('max_bert_summary_len :%s \\n'%(max_bert_summary_len))\n",
    "    f.write('min_bert_summary_len :%s \\n'%(min_bert_summary_len))\n",
    "    f.write('mean_bert_summary_len :%s \\n'%(mean_bert_summary_len))\n",
    "    f.write('median_bert_summary_len :%s \\n'%(median_bert_summary_len))\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "# plt.xlim(xmax = mean_rev_len)\n",
    "# plt.ylim(ymax = flit_key_df['lemm_review_len'].value_counts().max())\n",
    "\n",
    "flit_key_df['lemm_review_len'].value_counts().hist()\n",
    "plt.savefig('XLSX/statistic/review_len_%s_%s.png'%(category1,category2))\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "# plt.xlim(xmax = max_summary_len)\n",
    "# plt.ylim(ymax = flit_key_df['lemm_summary_len'].value_counts().max())\n",
    "flit_key_df['lemm_summary_len'].value_counts().hist()\n",
    "plt.savefig('XLSX/statistic/summary_len_%s_%s.png'%(category1,category2))\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "# plt.xlim(xmax = mean_keyword_num)\n",
    "flit_key_df['FOP_keywords_num'].value_counts().hist()\n",
    "plt.savefig('XLSX/statistic/FOP_keywords_num_%s_%s.png'%(category1,category2))\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "# flit_key_df['TextRank_keywords_num'].value_counts().hist()\n",
    "# plt.savefig('XLSX/statistic/TextRank_keywords_num_%s_%s.png'%(category1,category2))\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 製作record bin檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29115/29115 [00:10<00:00, 2881.53it/s]\n",
      "  9%|▉         | 333/3638 [00:00<00:00, 3320.43it/s] bin/category/train.bin finished... \n",
      "100%|██████████| 3638/3638 [00:01<00:00, 2827.53it/s]\n",
      "  8%|▊         | 276/3639 [00:00<00:01, 2756.34it/s] bin/category/test.bin finished... \n",
      "100%|██████████| 3639/3639 [00:01<00:00, 3359.15it/s] bin/category/valid.bin finished... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "if not os.path.exists('bin'):\n",
    "    shutil.rmtree('/bin', ignore_errors=True)\n",
    "\n",
    "if not os.path.exists('bin/category/chunked'):\n",
    "    os.makedirs('bin/category/chunked')\n",
    "\n",
    "makevocab = True\n",
    "if makevocab:\n",
    "    vocab_counter = collections.Counter()\n",
    "    \n",
    "# train_file\n",
    "flit_key_train_df = flit_key_df.iloc[:int(amount*0.8)]\n",
    "\n",
    "# test_file\n",
    "flit_key_test_df = flit_key_df.iloc[int(amount*0.8)+1:int(amount*0.9)]\n",
    "\n",
    "# vald_file\n",
    "flit_key_valid_df = flit_key_df.iloc[int(amount*0.9)+1:]\n",
    "sentence_start = \"<s>\"\n",
    "sentence_end = \"</s>\"\n",
    "\n",
    "\n",
    "def xlsx2bin(set_name,df):\n",
    "    sents = []\n",
    "    with open(\"bin/category/%s.bin\"%(set_name), 'wb') as file:\n",
    "        i = 0\n",
    "        for idx in tqdm(range(len(df))):\n",
    "            series = df.iloc[idx]\n",
    "            data_dict = series.to_dict()\n",
    "            review_ID , big_categories , small_categories , \\\n",
    "            orign_review , lemm_review , orign_summary , lemm_summary , \\\n",
    "            FOP_keywords ,TextRank_keywords , TextRank_summary = \\\n",
    "            data_dict['review_ID'],data_dict['big_categories'],data_dict['small_categories'], \\\n",
    "            data_dict['review'],data_dict['lemm_review'], data_dict['summary'],data_dict['lemm_summary'], \\\n",
    "            data_dict['FOP_keywords'] , data_dict['TextRank_keywords'] , data_dict['TextRank_summary']\n",
    "\n",
    "            '''\n",
    "            review_ID , big_categories , small_categories , \\\n",
    "            orign_review , lemm_review , orign_summary , lemm_summary , \\\n",
    "            bert_review , bert_summary ,FOP_keywords ,TextRank_keywords = \\\n",
    "            data_dict['review_ID'],data_dict['big_categories'],data_dict['small_categories'], \\\n",
    "            data_dict['review'],data_dict['lemm_review'], data_dict['summary'],data_dict['lemm_summary'], \\\n",
    "            data_dict['bert_review'], data_dict['bert_summary'] , data_dict['FOP_keywords'] ,data_dict['TextRank_keywords']\n",
    "            '''\n",
    "            \n",
    "#             print(FOP_keywords)\n",
    "\n",
    "            # save Embedding/word2Vec calculate sents\n",
    "#             for sent in nltk.sent_tokenize(lemm_review):\n",
    "#                 sent = sent.replace(\".\" ,\"\")\n",
    "#                 sents.append(str(sent).split()) # 切分词汇 \n",
    "\n",
    "#             for sent in nltk.sent_tokenize(lemm_summary):\n",
    "#                 sent = sent.replace(sentence_start ,\"\").replace(sentence_end ,\"\")\n",
    "#                 sents.append(str(sent).split()) # 切分词汇 \n",
    "\n",
    "            lemm_review = lemm_review.replace(\"\\n\",\"\")\n",
    "            lemm_summary = lemm_summary.replace(\"\\n\",\"\").replace(\".\",\" \")\n",
    "            # lemm_summary = sentence_start + ' '+ lemm_summary + ' ' + sentence_end\n",
    "#             print(lemm_summary)\n",
    "            # Write to tf.Example\n",
    "            tf_example = example_pb2.Example()\n",
    "            try:\n",
    "                tf_example.features.feature['orign_review'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(orign_review, encoding='utf-8')])\n",
    "\n",
    "                tf_example.features.feature['orign_summary'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(orign_summary, encoding='utf-8')])\n",
    "                \n",
    "                tf_example.features.feature['review'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(lemm_review, encoding='utf-8')])\n",
    "\n",
    "                tf_example.features.feature['summary'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(lemm_summary, encoding='utf-8')]) \n",
    "                '''    \n",
    "                tf_example.features.feature['bert_review'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(bert_review, encoding='utf-8')])\n",
    "\n",
    "                tf_example.features.feature['bert_summary'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(bert_summary, encoding='utf-8')])\n",
    "                '''\n",
    "                tf_example.features.feature['FOP_keywords'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(FOP_keywords, encoding='utf-8')]) \n",
    "            \n",
    "                tf_example.features.feature['TextRank_keywords'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(TextRank_keywords, encoding='utf-8')]) \n",
    "                \n",
    "                tf_example.features.feature['TextRank_summary'].bytes_list.value.extend(\n",
    "                    [tf.compat.as_bytes(TextRank_summary, encoding='utf-8')])\n",
    "\n",
    "                tf_example_str = tf_example.SerializeToString()\n",
    "                str_len = len(tf_example_str)  \n",
    "                file.write(struct.pack('q', str_len))\n",
    "                file.write(struct.pack('%ds' % str_len, tf_example_str))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    print(\" %s finished... \"%(file.name))\n",
    "    return sents\n",
    "    \n",
    "    \n",
    "sents1 = xlsx2bin('train',flit_key_train_df)\n",
    "sents2 = xlsx2bin('test',flit_key_test_df)\n",
    "sents3 = xlsx2bin('valid',flit_key_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bin/category/bin-info.txt\",'w',encoding='utf-8') as f :\n",
    "    f.write(\"train : %s\\n\"%(len(flit_key_train_df)))\n",
    "    f.write(\"test : %s\\n\"%(len(flit_key_test_df)))\n",
    "    f.write(\"valid : %s\\n\"%(len(flit_key_valid_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割record bin檔(1000為單位)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train data into chunks...\n",
      "Splitting valid data into chunks...\n",
      "Splitting test data into chunks...\n",
      "Saved chunked data in bin/category/chunked\n"
     ]
    }
   ],
   "source": [
    "def chunk_file(set_name, chunks_dir):\n",
    "    in_file = 'bin/category/%s.bin' % set_name\n",
    "    reader = open(in_file, \"rb\")\n",
    "    chunk = 0\n",
    "    finished = False\n",
    "    while not finished:\n",
    "#         chunk_fname = os.path.join('bin', '/%s/%s_%03d.bin' % (chunks_dir,set_name, chunk))  # new chunk\n",
    "        chunk_fname = '%s/%s/%s_%03d.bin' % (chunks_dir,set_name,set_name, chunk)\n",
    "        with open(chunk_fname, 'wb') as writer:\n",
    "            for _ in range(CHUNK_SIZE):\n",
    "                len_bytes = reader.read(8)\n",
    "                if not len_bytes:\n",
    "                    finished = True\n",
    "                    break\n",
    "                str_len = struct.unpack('q', len_bytes)[0]\n",
    "                example_str = struct.unpack('%ds' % str_len, reader.read(str_len))[0]\n",
    "                writer.write(struct.pack('q', str_len))\n",
    "                writer.write(struct.pack('%ds' % str_len, example_str))\n",
    "            chunk += 1\n",
    "\n",
    "\n",
    "def chunk_all(chunks_dir = 'bin/category/chunked'):\n",
    "    # Make a dir to hold the chunks\n",
    "    \n",
    "    # Chunk the data\n",
    "    for set_name in ['train', 'valid', 'test']:\n",
    "        if not os.path.isdir(os.path.join(chunks_dir,set_name)):\n",
    "            os.mkdir(os.path.join(chunks_dir,set_name))\n",
    "        print(\"Splitting %s data into chunks...\" % set_name)\n",
    "        chunk_file(set_name, chunks_dir)\n",
    "    print(\"Saved chunked data in %s\" % chunks_dir)\n",
    "    \n",
    "chunk_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_valid():\n",
    "    #Performing rouge evaluation on 1.9 lakh sentences takes lot of time. So, create mini validation set & test set by borrowing 15k samples each from these 1.9 lakh sentences\n",
    "    bin_valid_chuncks = os.listdir('bin/category/chunked/valid/')\n",
    "    bin_valid_chuncks.sort()\n",
    "    if not os.path.exists('bin/category/chunked/main_valid'):\n",
    "        os.makedirs('bin/category/chunked/main_valid')\n",
    "        \n",
    "    samples = random.sample(set(bin_valid_chuncks[:-1]), 2)      #Exclude last bin file; contains only 9k sentences\n",
    "    valid_chunk, test_chunk = samples[0], samples[1]\n",
    "    shutil.copyfile(os.path.join('bin/category/chunked/valid', valid_chunk), os.path.join(\"bin/category/chunked/main_valid\", \"valid_00.bin\"))\n",
    "    shutil.copyfile(os.path.join('bin/category/chunked/valid', test_chunk), os.path.join(\"bin/category/chunked/main_valid\", \"test_00.bin\"))\n",
    "main_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding/word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9%|▉         | 15182/165310 [00:06<01:14, 2017.16it/s]['.5']\n",
      " 20%|█▉        | 32320/165310 [00:14<00:52, 2534.02it/s]['.26']\n",
      " 50%|████▉     | 82252/165310 [00:37<00:40, 2075.00it/s]['.264']\n",
      " 64%|██████▍   | 106447/165310 [00:47<00:29, 1981.04it/s]['.5']\n",
      " 73%|███████▎  | 119965/165310 [00:53<00:16, 2752.63it/s]['.5']\n",
      "100%|██████████| 165310/165310 [01:12<00:00, 2290.87it/s]word2Vec training sentence finished...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [] # total sentence\n",
    "for idx in tqdm(range(len(orign_key_df))):\n",
    "    series = orign_key_df.iloc[idx]\n",
    "    data_dict = series.to_dict()\n",
    "    lemm_review_sents , lemm_summary  = data_dict['lemm_review'],data_dict['lemm_summary'] \n",
    "    try:\n",
    "        lemm_review_sents = eval(lemm_review_sents)\n",
    "        for sent in lemm_review_sents:\n",
    "            sent_tokens = sent.split(\" \")\n",
    "            tokens = [str(token) for token in sent.split() if (\" \" not in str(token))and (str(token) == '.' or str(token).isalpha())]\n",
    "    #         tokens = [str(token) for token in sent.split() if (\" \" not in str(token))]\n",
    "            sentences.append(tokens)   \n",
    "        \n",
    "            dot_tokens = [token for token in tokens if (token[0] == \".\" or token[-1] == \".\") and (len(token)>1)]\n",
    "            if len(dot_tokens) > 0 :print(dot_tokens)\n",
    "            \n",
    "        sentences.append([t for t in lemm_summary.split(\" \") if t not in [\"<s>\" , \"</s>\"]])\n",
    "        \n",
    "        dot_tokens = [token for token in lemm_summary.split(\" \") if (token[0] == \".\" or token[-1] == \".\") and (len(token)>1)]\n",
    "        if len(dot_tokens) > 0 :print(dot_tokens)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "print('word2Vec training sentence finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入 word2vec\n",
    "from gensim.models import word2vec\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsnooper\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "vocab_count = 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write vocab to file\n",
    "if not os.path.exists('Embedding/category/word2Vec'):\n",
    "    os.makedirs('Embedding/category/word2Vec')\n",
    "    \n",
    "if not os.path.exists(\"Embedding/category/word2Vec/word2Vec.300d.txt\"):\n",
    "\n",
    "    w2vec = word2vec.Word2Vec(sentences, size=300, min_count=2,max_vocab_size=None,iter=100,\n",
    "                              sorted_vocab=1,max_final_vocab=vocab_count)\n",
    "\n",
    "    \n",
    "\n",
    "    w2vec.wv.save_word2vec_format('Embedding/category/word2Vec/word2Vec.300d.txt', binary=False)\n",
    "\n",
    "    #保存模型，供日後使用\n",
    "    # w2vec.save(\"Embedding/word2Vec/word2vec.model\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = sents1 + sents2 + sents3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-01 11:54:30,931 : INFO : loading projection weights from Embedding/category/word2Vec/word2Vec.300d.txt\n",
      "2020-02-01 11:54:43,316 : INFO : loaded (46506, 300) matrix from Embedding/category/word2Vec/word2Vec.300d.txt\n",
      "2020-02-01 11:54:43,327 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vlc', 0.46921050548553467),\n",
       " ('editor', 0.44376611709594727),\n",
       " ('quicktime', 0.43098098039627075),\n",
       " ('windows', 0.41453486680984497),\n",
       " ('dvd', 0.4074060022830963),\n",
       " ('format', 0.40622010827064514),\n",
       " ('device', 0.40203574299812317),\n",
       " ('application', 0.39336585998535156),\n",
       " ('viewer', 0.3867083489894867),\n",
       " ('mkv', 0.3805641531944275)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型讀取方式\n",
    "# model = word2vec.Word2Vec.load(\"Embedding/word2Vec/word2vec.model\")\n",
    "\n",
    "wvmodel = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    'Embedding/category/word2Vec/word2Vec.300d.txt', binary=False, encoding='utf-8')\n",
    "\n",
    "wvmodel.most_similar(u\"player\", topn=10)\n",
    "# wvmodel.most_similar(['dvd','player','changer','machine','video'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"Embedding/category/word2Vec/word.vocab\"\n",
    "\n",
    "if not os.path.exists(vocab_file):\n",
    "    vocab_count = len(wvmodel.wv.index2entity)    \n",
    "\n",
    "    print(\"Writing vocab file...\")\n",
    "    with open(vocab_file, 'w',encoding='utf-8') as writer:\n",
    "        for word in wvmodel.wv.index2entity[:vocab_count]:\n",
    "            # print(word, w2vec.wv.vocab[word].count)\n",
    "            writer.write(word + ' ' + str(wvmodel.wv.vocab[word].count) + '\\n') # Output vocab count\n",
    "    print(\"Finished writing vocab file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take\n",
      "/home/eagleuser/.conda/envs/Leyan/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/eagleuser/.conda/envs/Leyan/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "word = wvmodel.wv.index2entity[25]\n",
    "vector = wvmodel.wv.vectors[25]\n",
    "print(word)\n",
    "# print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(46507, 300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from data_util.data import Vocab\n",
    "vocab_size = len(wvmodel.vocab) + 1\n",
    "\n",
    "\n",
    "vocab = Vocab('Embedding/category/word2Vec/word.vocab', vocab_size)\n",
    "\n",
    "embed_size = 300\n",
    "weight = torch.zeros(vocab_size, embed_size)\n",
    "\n",
    "for i in range(len(vocab._id_to_word.keys())):\n",
    "    try:\n",
    "        vocab_word = vocab._id_to_word[i+4]\n",
    "        w2vec_word = w2vec.wv.index2entity[i]\n",
    "    except Exception as e :\n",
    "        continue\n",
    "    if i + 4 > vocab_size: break\n",
    "#     print(vocab_word,w2vec_word)\n",
    "    weight[i+4, :] = torch.from_numpy(w2vec.wv.vectors[i])\n",
    "        \n",
    "embedding = torch.nn.Embedding.from_pretrained(weight)\n",
    "# requires_grad指定是否在训练过程中对词向量的权重进行微调\n",
    "embedding.weight.requires_grad = True\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2id('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding/glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "from glove import Corpus\n",
    "\n",
    "vocab_count = 50000\n",
    "# write vocab to file\n",
    "if not os.path.exists('Embedding/category/glove'):\n",
    "    os.makedirs('Embedding/category/glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Embedding/category/glove/glove.model\"):\n",
    "\n",
    "    corpus_model = Corpus()\n",
    "    corpus_model.fit(sentences, window=10)\n",
    "    #corpus_model.save('corpus.model')\n",
    "    print('Dict size: %s' % len(corpus_model.dictionary))\n",
    "    print('Collocations: %s' % corpus_model.matrix.nnz)\n",
    "    \n",
    "    glove = Glove(no_components=300, learning_rate=0.05)\n",
    "    glove.fit(corpus_model.matrix, epochs=100,\n",
    "              no_threads=10, verbose=True)\n",
    "    glove.add_dictionary(corpus_model.dictionary)\n",
    "    \n",
    "    glove.save('Embedding/category/glove/glove.model') # 存模型\n",
    "    corpus_model.save('Embedding/category/glove/corpus.model') # 存字典\n",
    "\n",
    "\n",
    "glove = Glove.load('Embedding/category/glove/glove.model')\n",
    "corpus_model = Corpus.load('Embedding/category/glove/corpus.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"Embedding/category/glove/word.vocab\"\n",
    "\n",
    "if not os.path.exists(vocab_file):\n",
    "#     vocab_count = len(glove.dictionary)    \n",
    "    vocab_count = 0\n",
    "    print(\"Writing vocab file...\")\n",
    "    with open(vocab_file, 'w',encoding='utf-8') as writer:\n",
    "        for word,idx in glove.dictionary.items():\n",
    "            if word in vocab._word_to_id.keys():\n",
    "                vocab_count += 1\n",
    "                writer.write(word + ' ' + str(idx) + '\\n') # Output vocab count\n",
    "    print(\"Finished writing vocab file %s\" %(vocab_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.word_vectors[glove.dictionary['.']].shape\n",
    "# vocab._word_to_id.keys()\n",
    "# len(glove.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(46503, 300)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(open('Embedding/category/glove/word.vocab').readlines())\n",
    "print(vocab_size)\n",
    "\n",
    "vocab = Vocab('Embedding/category/glove/word.vocab', vocab_size)\n",
    "embed_size = 300\n",
    "weight = torch.zeros(vocab_size, embed_size)\n",
    "\n",
    "for word,idx in glove.dictionary.items():\n",
    "    if word in vocab._word_to_id.keys():\n",
    "        wid = vocab.word2id(word) \n",
    "        vector = np.asarray(glove.word_vectors[glove.dictionary[word]], \"float32\")\n",
    "        weight[wid, :] = torch.from_numpy(vector)\n",
    "\n",
    "embedding = torch.nn.Embedding.from_pretrained(weight)\n",
    "# requires_grad指定是否在训练过程中对词向量的权重进行微调\n",
    "embedding.weight.requires_grad = True\n",
    "embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding/Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-01 11:54:51,211 : INFO : loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/eagleuser/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "2020-02-01 11:54:51,214 : INFO : extracting archive file /home/eagleuser/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpmpq97wx3\n",
      "2020-02-01 11:54:54,164 : INFO : Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# BERT\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, do_basic_tokenize=True)\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# model.eval()\n",
    "model.embeddings.word_embeddings\n",
    "\n",
    "\n",
    "# vocab = Vocab('Embedding/word2Vec/word2Vec.vocab', vocab_size)\n",
    "\n",
    "# embed_size = 300\n",
    "# weight = torch.zeros(vocab_size, embed_size)\n",
    "\n",
    "\n",
    "# embedding = torch.nn.Embedding.from_pretrained(weight)\n",
    "# # requires_grad指定是否在训练过程中对词向量的权重进行微调\n",
    "# embedding.weight.requires_grad = True\n",
    "# embedding        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook makeRecord.ipynb to script\n",
      "[NbConvertApp] Writing 31782 bytes to makeRecord.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script makeRecord.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
