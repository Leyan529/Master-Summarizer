{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 02:07:37.611906 140390137546560 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-06-01 02:07:38 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - logger已啟動\n",
      "I0601 02:07:38.668682 140390137546560 train_util.py:106] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config\n",
    "from utils.seq2seq import data\n",
    "\n",
    "from utils.seq2seq.batcher import *\n",
    "\n",
    "from utils.seq2seq.train_util import *\n",
    "from utils.seq2seq.rl_util import *\n",
    "from utils.seq2seq.initialize import loadCheckpoint, save_model\n",
    "from utils.seq2seq.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from translate.seq2seq_beam import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "eval_gpu = 0\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--copy', type=bool, default=True, help = 'True/False') # for transformer\n",
    "\n",
    "\n",
    "parser.add_argument('--model_type', type=str, default='seq2seq', choices=['seq2seq', 'transformer'])\n",
    "parser.add_argument('--train_rl', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_keys', \n",
    "                    help = 'POS_keys / DEP_keys / Noun_adj_keys / TextRank_keys')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=0.5)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=500)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=20)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=5)\n",
    "parser.add_argument('--max_epochs', type=int, default=15)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=5)\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default='', help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)\n",
    "\n",
    "eval_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-01 02:09:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - train : 469335, test : 52149\n",
      "I0601 02:09:02.008316 140390137546560 batcher.py:186] train : 469335, test : 52149\n",
      "2020-06-01 02:09:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - train batches : 29333, test batches : 3259\n",
      "I0601 02:09:02.607667 140390137546560 batcher.py:210] train batches : 29333, test batches : 3259\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)\n",
    "train_batches = len(iter(train_loader))\n",
    "test_batches = len(iter(validate_loader))\n",
    "save_steps = int(train_batches/250)*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.distributed as dist\n",
    "\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "# https://gist.github.com/thomwolf/7e2407fbd5945f07821adae3d9fd1312\n",
    "\n",
    "\n",
    "load_step = 0\n",
    "# model = Model(pre_train_emb=config.pre_train_emb, \n",
    "#               word_emb_type = config.word_emb_type, \n",
    "#               vocab = vocab)\n",
    "\n",
    "# # model = model.cuda()\n",
    "# optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# # optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "# load_model_path = config.save_model_path + '/%s/%s.tar' % (loggerName, config.load_ckpt)\n",
    "# if os.path.exists(load_model_path):\n",
    "#     model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)\n",
    "#     # 若偵測到model切換成eval\n",
    "#     eval_model = True\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(eval_gpu)\n",
    "    \n",
    "# else:    \n",
    "#     model.to('cuda:%s' % 0) #BCW\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/best/model.pkl' %(loggerName)\n",
    "model = torch.load(load_model_path)\n",
    "parallel_model = DataParallelModel(model) # Encapsulate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NLLLoss(nn.Module):\n",
    "#         \"\"\"\n",
    "#         With label smoothing,\n",
    "#         KL-divergence between q_{smoothed ground truth prob.}(w)\n",
    "#         and p_{prob. computed by model}(w) is minimized.\n",
    "#         \"\"\"\n",
    "#         def __init__(self, ignore_index):\n",
    "#             super(NLLLoss, self).__init__()\n",
    "# #             step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "#             self.NLL = nn.NLLLoss(ignore_index=ignore_index, reduction='sum')\n",
    "\n",
    "#         def forward(self, out, tar):  \n",
    "#             # target dimension[0] / 2\n",
    "#             # tar = target.contiguous().view(-1) \n",
    "#             # out = output.contiguous().view(target.size(0),-1)\n",
    "\n",
    "#             target = tar.contiguous().view(-1)\n",
    "#             output = out[:tar.size(0)]\n",
    "#             normalize = output.size(0) * output.size(1)\n",
    "#             output = output.contiguous().view(target.size(0),-1)\n",
    "#             loss = self.NLL(output, target) / normalize\n",
    "            \n",
    "#             return loss\n",
    "\n",
    "# if not eval_model:\n",
    "#     criterion = NLLLoss(ignore_index=PAD)\n",
    "#     parallel_model = DataParallelModel(model) # Encapsulate the model\n",
    "#     parallel_loss = DataParallelCriterion(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_sents(enc_out, inds, vocab, art_oovs):\n",
    "#     decoded_strs = []\n",
    "#     for i in range(len(enc_out)):\n",
    "#         id_list = inds[i].tolist() # 取出每個sample sentence 的word id list\n",
    "#         S = output2words(id_list, vocab, art_oovs[i]) #Generate sentence corresponding to sampled words\n",
    "#         try:\n",
    "#             end_idx = S.index(data.STOP_DECODING)\n",
    "#             S = S[:end_idx]\n",
    "#         except ValueError:\n",
    "#             S = S\n",
    "#         if len(S) < 2:          #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "#             S = [\"xxx\"]\n",
    "#         S = \" \".join(S)\n",
    "#         decoded_strs.append(S)\n",
    "#     return decoded_strs\n",
    "\n",
    "# # def merge_res(res):\n",
    "# #     ((inds1, log_probs1, enc_out1),(inds2, log_probs2, enc_out2)) = res\n",
    "# #     inds = T.cat([inds1, inds2], dim = 0).cpu()\n",
    "# #     enc_out = T.cat([enc_out1, enc_out2], dim = 0).cpu()\n",
    "# #     if type(log_probs1) != list:\n",
    "# #         log_probs = T.cat([log_probs1, log_probs2], dim = 0)\n",
    "# #         return inds, log_probs, enc_out\n",
    "# #     else:\n",
    "# #         return inds, _, enc_out\n",
    "\n",
    "# def train_one_rl(package, inputs):\n",
    "#     config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e,                                 max_dec_len, dec_batch, target_batch = package\n",
    "    \n",
    "#     rl_loss, batch_reward = parallel_model(config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e,                                 max_dec_len, dec_batch, target_batch, train_rl = True, art_oovs = inputs.art_oovs, original_abstract = inputs.original_abstract, vocab = vocab)\n",
    "#     rl_loss = nn.parallel.gather(rl_loss, 0).mean() \n",
    "#     return rl_loss, batch_reward\n",
    "\n",
    "# def train_one(package):\n",
    "#     model.train()\n",
    "#     config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e, \\\n",
    "#                                 max_dec_len, dec_batch, target_batch = package   \n",
    "\n",
    "#     pred_probs = parallel_model(config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e, \\\n",
    "#                                 max_dec_len, dec_batch, target_batch)\n",
    "#     target = target_batch\n",
    "#     loss = parallel_loss(config.mle_weight, pred_probs, target)\n",
    "    \n",
    "#     return loss, pred_probs\n",
    "\n",
    "# def write_res(inputs, batch_probs):\n",
    "#     decoded_sents = []\n",
    "#     for i, probs in enurmerate(batch_probs):\n",
    "#         sents = []\n",
    "#         for prob in probs:\n",
    "#             _id = T.max(probs, dim=1)[1]\n",
    "#             _id = _id.detach()\n",
    "#             sents.append(_id)\n",
    "#         decoded_sents.append(seq)\n",
    "            \n",
    "#     output2words()        \n",
    "#     article_sents = [article for article in inputs.original_article]\n",
    "#     ref_sents = [ref for ref in inputs.original_abstract]\n",
    "# #     decoded_sents = [summarize(article, words=30) for article in article_sents]\n",
    "# #     decoded_sents = [sent if len(sent) > 5 else \"xxx xxx xxx xxx xxx\" for sent in decoded_sents]\n",
    "        \n",
    "# #     article_sents, decoded_sents, keywords_list, \\\n",
    "# #     ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "# #     rouge_1, rouge_2, rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "# #                 keywords_list, ref_sents, long_seq_index, write = False)\n",
    "# #     avg_rouge_l.append(rouge_l)\n",
    "# #     acc_cost = time.time() - acc_st\n",
    "# #     avg_acc_cost.append(acc_cost)\n",
    "    \n",
    "#     return seq_sents\n",
    "\n",
    "# def get_package(inputs):\n",
    "#     enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "#         ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "#             get_input_from_batch(inputs, config, batch_first = True)\n",
    "\n",
    "#     dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "#         get_output_from_batch(inputs, config, batch_first = True) # Get input and target batchs for training decoder            \n",
    "\n",
    "#     max_enc_len = max(T.max(enc_lens,dim=0)).tolist()[0]    \n",
    "#     # ----------------------------------------------------\n",
    "#     package = (config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e, \\\n",
    "#                                 max_dec_len, dec_batch, target_batch)\n",
    "    \n",
    "#     inner_c = package[1] != max(package[4].tolist())[0]\n",
    "\n",
    "#     return inner_c, package\n",
    "\n",
    "\n",
    "# # for inputs in train_loader:  \n",
    "# #     # MLE test\n",
    "# #     # ----------------------------------------------------\n",
    "# #     # pred_probs = parallel_model(config, max_enc_len, enc_batch, enc_key_batch, enc_lens, enc_padding_mask, enc_key_mask, extra_zeros, enc_batch_extend_vocab, ct_e, \\\n",
    "# #     #                             max_dec_len, dec_batch, target_batch)\n",
    "# #     # # pass\n",
    "# #     # target = target_batch\n",
    "# #     # loss = parallel_loss(config.mle_weight, pred_probs, target)\n",
    "# #     loss = train_one(package)\n",
    "# # #     loss.backward() # Backward pass \n",
    "# # #     optimizer.step() # Optimizer step\n",
    "# #     print('loss : ',loss)\n",
    "# #     # pass\n",
    "# #     # ----------------------------------------------------   \n",
    "# #     if config.train_rl:\n",
    "# #         rl_loss, batch_reward = train_one_rl(package)\n",
    "# #         print('rl_loss : ',rl_loss, 'batch_reward : ',batch_reward)\n",
    "# #     else:\n",
    "# #         rl_loss = T.FloatTensor([0]).cuda()        \n",
    "    \n",
    "# #     (config.mle_weight * loss + config.rl_weight * rl_loss).backward() # Backward pass   \n",
    "# #     optimizer.step() # Optimizer step\n",
    "# #     optimizer.zero_grad() # 清空过往梯度 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @torch.no_grad()\n",
    "# @torch.autograd.no_grad()\n",
    "# def validate(validate_loader, config, model):\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "# #     batch = next(iter(validate_loader))\n",
    "#     val_num = len(iter(validate_loader))\n",
    "#     for idx, batch in enumerate(validate_loader):\n",
    "#         inner_c, package = get_package(batch)\n",
    "#         if inner_c: continue\n",
    "#         loss, _ = train_one(package)\n",
    "# #         loss = train_one(model, config, batch)\n",
    "#         losses.append(loss.item())\n",
    "# #         if idx>= val_num/40: break\n",
    "# #     model.train()\n",
    "#     avg_loss = sum(losses) / len(losses)\n",
    "#     return avg_loss\n",
    "\n",
    "# @torch.autograd.no_grad()\n",
    "# def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "#     if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "#         running_avg_loss = loss\n",
    "#     else:\n",
    "#         running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "#     running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "#     return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del parallel_model, parallel_loss\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from utils.seq2seq.write_result import total_evaulate, total_output\n",
    "\n",
    "@torch.autograd.no_grad()\n",
    "def decode_write_all(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(dataloader)\n",
    "    avg_rouge_1, avg_rouge_2, avg_rouge_l  = [], [], []\n",
    "    avg_self_bleu1, avg_self_bleu2, avg_self_bleu3, avg_self_bleu4 = [], [], [], []\n",
    "    avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4 = [], [], [], []\n",
    "    avg_meteor = []\n",
    "    outFrame = None\n",
    "    avg_time = 0\n",
    "        \n",
    "    for idx, inputs in enumerate(dataloader):\n",
    "        start = time.time() \n",
    "#         'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "            ct_e, enc_key_batch, enc_key_mask, enc_key_lens = get_input_from_batch(inputs, config, batch_first = True)\n",
    "        max_enc_len = max(T.max(enc_lens,dim=0)).tolist()[0] \n",
    "        \n",
    "        if (max_enc_len != max(enc_lens.tolist())[0]): continue\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens, max_enc_len)\n",
    "        \n",
    "#         'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                                enc_batch_extend_vocab, enc_key_batch, enc_key_mask, model, \n",
    "                                START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, ref_sents, long_seq_index = prepare_result(vocab, inputs, pred_ids)\n",
    "        cost = (time.time() - start)\n",
    "        avg_time += cost        \n",
    "\n",
    "        \n",
    "        rouge_1, rouge_2, rouge_l,             Bleu_1, Bleu_2, Bleu_3, Bleu_4, Meteor, batch_frame = total_evaulate(article_sents, keywords_list, decoded_sents, ref_sents)\n",
    "        \n",
    "        if idx %1000 ==0 and idx >0 : print(idx)\n",
    "        if idx == 0: outFrame = batch_frame\n",
    "        else: outFrame = pd.concat([outFrame, batch_frame], axis=0, ignore_index=True) \n",
    "        # ----------------------------------------------------\n",
    "        avg_rouge_1.extend(rouge_1)\n",
    "        avg_rouge_2.extend(rouge_2)\n",
    "        avg_rouge_l.extend(rouge_l)   \n",
    "        \n",
    "        # avg_self_bleu1.extend(self_Bleu_1)\n",
    "        # avg_self_bleu2.extend(self_Bleu_2)\n",
    "        # avg_self_bleu3.extend(self_Bleu_3)\n",
    "        # avg_self_bleu4.extend(self_Bleu_4)\n",
    "        \n",
    "        avg_bleu1.extend(Bleu_1)\n",
    "        avg_bleu2.extend(Bleu_2)\n",
    "        avg_bleu3.extend(Bleu_3)\n",
    "        avg_bleu4.extend(Bleu_4)\n",
    "        avg_meteor.extend(Meteor)\n",
    "        # ----------------------------------------------------    \n",
    "    avg_time = avg_time / (num * config.batch_size) \n",
    "    \n",
    "    avg_rouge_l, outFrame = total_output(15, mode, writerPath, outFrame, avg_time, avg_rouge_1, avg_rouge_2, avg_rouge_l,         avg_self_bleu1, avg_self_bleu2, avg_self_bleu3, avg_self_bleu4,         avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4, avg_meteor\n",
    "    )\n",
    "    \n",
    "    return avg_rouge_l, outFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # del parallel_model, parallel_loss\n",
    "\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from utils.seq2seq.write_result import total_evaulate, total_output\n",
    "\n",
    "# @torch.autograd.no_grad()\n",
    "# def decode(writer, dataloader, epoch):\n",
    "#     # 動態取batch\n",
    "#     num = len(dataloader)\n",
    "#     avg_rouge_1, avg_rouge_2, avg_rouge_l  = [], [], []\n",
    "#     avg_self_bleu1, avg_self_bleu2, avg_self_bleu3, avg_self_bleu4 = [], [], [], []\n",
    "#     avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4 = [], [], [], []\n",
    "#     avg_meteor = []\n",
    "#     outFrame = None\n",
    "#     avg_time = 0\n",
    "        \n",
    "#     for idx, inputs in enumerate(dataloader):\n",
    "#         start = time.time() \n",
    "# #         'Encoder data'\n",
    "#         enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "#             ct_e, enc_key_batch, enc_key_mask, enc_key_lens = get_input_from_batch(inputs, config, batch_first = True)\n",
    "#         max_enc_len = max(T.max(enc_lens,dim=0)).tolist()[0] \n",
    "        \n",
    "#         if (max_enc_len != max(enc_lens.tolist())[0]): continue\n",
    "\n",
    "#         enc_batch = parallel_model.module.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "#         enc_key_batch = parallel_model.module.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "#         enc_out, enc_hidden = parallel_model.module.encoder(enc_batch, enc_lens, max_enc_len)\n",
    "        \n",
    "# #         'Feed encoder data to predict'\n",
    "#         pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "#                                 enc_batch_extend_vocab, enc_key_batch, enc_key_mask, parallel_model.module, \n",
    "#                                 START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "#         article_sents, decoded_sents, keywords_list, ref_sents, long_seq_index = prepare_result(vocab, inputs, pred_ids)\n",
    "#         cost = (time.time() - start)\n",
    "#         avg_time += cost        \n",
    "\n",
    "        \n",
    "#         rouge_1, rouge_2, rouge_l,             Bleu_1, Bleu_2, Bleu_3, Bleu_4, Meteor, batch_frame = total_evaulate(article_sents, keywords_list, decoded_sents, ref_sents)\n",
    "        \n",
    "#         if idx %1000 ==0 and idx >0 : print(idx); \n",
    "#         if idx == 0: outFrame = batch_frame\n",
    "#         else: outFrame = pd.concat([outFrame, batch_frame], axis=0, ignore_index=True) \n",
    "#         # ----------------------------------------------------\n",
    "#         avg_rouge_1.extend(rouge_1)\n",
    "#         avg_rouge_2.extend(rouge_2)\n",
    "#         avg_rouge_l.extend(rouge_l)   \n",
    "        \n",
    "#         # avg_self_bleu1.extend(self_Bleu_1)\n",
    "#         # avg_self_bleu2.extend(self_Bleu_2)\n",
    "#         # avg_self_bleu3.extend(self_Bleu_3)\n",
    "#         # avg_self_bleu4.extend(self_Bleu_4)\n",
    "        \n",
    "#         avg_bleu1.extend(Bleu_1)\n",
    "#         avg_bleu2.extend(Bleu_2)\n",
    "#         avg_bleu3.extend(Bleu_3)\n",
    "#         avg_bleu4.extend(Bleu_4)\n",
    "#         avg_meteor.extend(Meteor)\n",
    "#         # ----------------------------------------------------    \n",
    "#     avg_time = avg_time / (num * config.batch_size)    \n",
    "    \n",
    "#     scalar_acc = {\n",
    "#         'rouge_1':sum(avg_rouge_1) / len(avg_rouge_1),\n",
    "#         'rouge_2':sum(avg_rouge_2) / len(avg_rouge_2),\n",
    "#         'rouge_l':sum(avg_rouge_l) / len(avg_rouge_l),\n",
    "        \n",
    "#         'bleu1':sum(avg_bleu1) / len(avg_bleu1),\n",
    "#         'bleu2':sum(avg_bleu2) / len(avg_bleu2),\n",
    "#         'bleu3':sum(avg_bleu3) / len(avg_bleu3),\n",
    "#         'bleu4':sum(avg_bleu4) / len(avg_bleu4),\n",
    "        \n",
    "#         'meteor':sum(avg_meteor) / len(avg_meteor)\n",
    "#     }\n",
    "    \n",
    "#     for scalar_name, accuracy in scalar_acc.items():\n",
    "#         if 'rouge' in scalar_name:\n",
    "#             writer.add_scalars('scalar/rouge',  \n",
    "#                {scalar_name: accuracy,\n",
    "#                }, epoch)\n",
    "#         elif 'bleu' in scalar_name:\n",
    "#             writer.add_scalars('scalar/bleu',  \n",
    "#                {scalar_name: accuracy,\n",
    "#                }, epoch)\n",
    "#         else:\n",
    "#             writer.add_scalars('scalar/meteor',  \n",
    "#                {scalar_name: accuracy,\n",
    "#                }, epoch)\n",
    "    \n",
    "#     # -----------------------------------------------------------\n",
    "#     total_output(epoch, 'test', writerPath, outFrame, avg_time, avg_rouge_1, avg_rouge_2, avg_rouge_l,                  avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4, avg_meteor\n",
    "#     )\n",
    "#     # -----------------------------------------------------------\n",
    "#     outFrame = outFrame.sort_values(by=['rouge_l'], ascending=False)\n",
    "#     big_frame = outFrame.head()\n",
    "#     small_frame = outFrame.tail()    \n",
    "#     # -----------------------------------------------------------\n",
    "#     i = 0\n",
    "#     for view_item in big_frame.to_dict('records'):\n",
    "#         writer.add_text('BigTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### rouge_l : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + str(view_item['rouge_l']), epoch)\n",
    "#         writer.add_text('BigTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### decoded : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['decoded'], epoch)\n",
    "#         writer.add_text('BigTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### reference : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['reference'], epoch)\n",
    "#         writer.add_text('BigTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### keywords : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['keywords'], epoch)\n",
    "#         writer.add_text('BigTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### article : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['article'], epoch)\n",
    "\n",
    "#         i += 1\n",
    "#     # -----------------------------------------------------------\n",
    "#     i = 0\n",
    "#     for view_item in small_frame.to_dict('records'):\n",
    "#         writer.add_text('SmallTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### rouge_l : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + str(view_item['rouge_l']), epoch)\n",
    "#         writer.add_text('SmallTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### decoded : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['decoded'], epoch)\n",
    "#         writer.add_text('SmallTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### reference : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['reference'], epoch)\n",
    "#         writer.add_text('SmallTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### keywords : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['keywords'], epoch)\n",
    "#         writer.add_text('SmallTest/epoch_%s/##%s' % (epoch, i),\n",
    "#                         \"### article : &nbsp;&nbsp;&nbsp;\\\n",
    "#                         \" + view_item['article'], epoch)\n",
    "#         i += 1\n",
    "#     return outFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# loss_st, loss_cost = 0,0\n",
    "# decode_st, decode_cost = 0,0\n",
    "# last_save_step = 0\n",
    "# from pytorchtools import EarlyStopping\n",
    "\n",
    "# print_step = 250\n",
    "# # save_steps = print_step\n",
    "# if not eval_model:\n",
    "\n",
    "#     write_train_para(writer, config)\n",
    "#     logger.info('------Training START--------')\n",
    "#     running_avg_loss, running_avg_rl_loss = 0, 0\n",
    "#     sum_total_reward = 0\n",
    "#     step = 0\n",
    "    \n",
    "#     # initialize the early_stopping object\n",
    "#     early_stopping = EarlyStopping(config, logger, vocab, loggerName, patience=3, verbose=True)\n",
    "#     try:\n",
    "#         for epoch in range((start_ep+1), config.max_epochs+1):\n",
    "#             for batch in train_loader:\n",
    "#                 step += 1; \n",
    "#                 loss_st = time.time()\n",
    "#                 inner_c, package = get_package(batch)\n",
    "#                 if inner_c: continue\n",
    "#                 parallel_model.module.train()\n",
    "#                 mle_loss, pred_probs = train_one(package)\n",
    "#                 if config.train_rl:\n",
    "#                     rl_loss, batch_reward = train_one_rl(package, batch)             \n",
    "\n",
    "#                     if step%print_step == 0 :\n",
    "#                         writer.add_scalars('scalar/RL_Loss',  \n",
    "#                            {'rl_loss': rl_loss\n",
    "#                            }, step)\n",
    "#                         writer.add_scalars('scalar/Reward',  \n",
    "#                            {'batch_reward': batch_reward\n",
    "#                            }, step)\n",
    "#     #                     logger.info('epoch %d: %d, RL_Loss = %f, batch_reward = %f'\n",
    "#     #                                     % (epoch, step, rl_loss, batch_reward))\n",
    "#                     sum_total_reward += batch_reward\n",
    "#                 else:\n",
    "#                     rl_loss = T.FloatTensor([0]).cuda()\n",
    "\n",
    "#                 (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "#                 '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "#                 if step % (config.gradient_accum) == 0: # gradient accumulation\n",
    "#         #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "#                     optimizer.step() # 根据累计的梯度更新网络参数\n",
    "#                     optimizer.zero_grad() # 清空过往梯度 \n",
    "#                 if step%print_step == 0 :\n",
    "#                     with T.autograd.no_grad():\n",
    "#                         train_batch_loss = mle_loss.item()\n",
    "#                         train_batch_rl_loss = rl_loss.item()\n",
    "# #                         val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "#                         running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "#                         running_avg_rl_loss = calc_running_avg_loss(train_batch_rl_loss, running_avg_rl_loss)\n",
    "#                         running_avg_reward = sum_total_reward / step\n",
    "# #                         if step % save_steps == 0:\n",
    "# #                             logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "# #                                         % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "#                         writer.add_scalars('scalar/Loss',  \n",
    "#                            {'train_batch_loss': train_batch_loss\n",
    "#                            }, step)\n",
    "#                         writer.add_scalars('scalar_avg/loss',  \n",
    "#                            {'train_avg_loss': running_avg_loss\n",
    "# #                             'test_avg_loss': val_avg_loss\n",
    "#                            }, step)\n",
    "#                         if running_avg_reward > 0:\n",
    "#     #                         logger.info('epoch %d: %d, running_avg_reward = %f'\n",
    "#     #                                 % (epoch, step, running_avg_reward))\n",
    "#                             writer.add_scalars('scalar_avg/Reward',  \n",
    "#                                {'running_avg_reward': running_avg_reward\n",
    "#                                }, step)\n",
    "#                         if running_avg_rl_loss != 0:\n",
    "#     #                         logger.info('epoch %d: %d, running_avg_rl_loss = %f'\n",
    "#     #                                 % (epoch, step, running_avg_rl_loss))\n",
    "#                             writer.add_scalars('scalar_avg/RL_Loss',  \n",
    "#                                {'running_avg_rl_loss': running_avg_rl_loss\n",
    "#                                }, step)\n",
    "                                                    \n",
    "                \n",
    "#                 if step % save_steps == 0:\n",
    "#                     parallel_model.module.eval()\n",
    "#                     logger.info('epoch : %s' % epoch)\n",
    "#                     val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "#                     logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "#                                         % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "#                     writer.add_scalars('scalar_avg/loss',  \n",
    "#                            {'train_avg_loss': running_avg_loss,\n",
    "#                             'test_avg_loss': val_avg_loss\n",
    "#                            }, step)\n",
    "#                     '''（讀取所儲存模型引數後，再進行並行化操作，否則無法利用之前的程式碼進行讀取）'''\n",
    "#                     save_model(config, logger, parallel_model, optimizer, step, vocab, val_avg_loss, \\\n",
    "#                                r_loss=0, title = loggerName)\n",
    "#                     loss_cost = time.time() - loss_st\n",
    "#                     logger.info('epoch %d|step %d| compute loss cost = %f ms'\n",
    "#                                     % (epoch, step, loss_cost))\n",
    "#                     writer.add_scalars('scalar_avg/epoch_loss',  \n",
    "#                        {'train_avg_loss': running_avg_loss,\n",
    "#                         'test_avg_loss': val_avg_loss\n",
    "#                        }, epoch)\n",
    "#                     last_save_step = step\n",
    "#                     test_outFrame = decode(writer, validate_loader, epoch)                   \n",
    "\n",
    "#             logger.info('-------------------------------------------------------------')\n",
    "\n",
    "#             if running_avg_reward > 0:\n",
    "#                 logger.info('epoch %d|step %d| running_avg_reward = %f'% (epoch, step, running_avg_reward))\n",
    "#             if running_avg_rl_loss != 0:\n",
    "#                 logger.info('epoch %d|step %d| running_avg_rl_loss = %f'% (epoch, step, running_avg_rl_loss))\n",
    "#             logger.info('-------------------------------------------------------------')\n",
    "\n",
    "#             early_stopping(parallel_model, optimizer, step, val_avg_loss) # update patience\n",
    "#             if early_stopping.early_stop:\n",
    "#                 logger.info(\"Early stopping epoch %s\"%(epoch))\n",
    "#                 break\n",
    "\n",
    "#     except Exception as e:\n",
    "#             print(e)\n",
    "#     else:\n",
    "#         logger.info(u'------Training SUCCESS--------')  \n",
    "#     finally:\n",
    "#         logger.info(u'------Training END--------')   \n",
    "#         logger.info(\"stopping epoch %s\"%(epoch))        \n",
    "#         logger.info(\"last_save_step %s\"%(last_save_step))  \n",
    "#         '''先將test_avg_acc調起來再decode train_'''\n",
    "#     #     train_avg_acc, train_outFrame = decode_write_all(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "# #         test_avg_acc, test_outFrame = decode_write_all(writer, logger, epoch, config, parallel_model.module, validate_loader, mode = 'test')\n",
    "#     #     logger.info('epoch %d: train_avg_acc = %f, test_avg_acc = %f' % (epoch, train_avg_acc, test_avg_acc)) \n",
    "# #         logger.info('epoch %d: test_avg_acc = %f' % (load_ep, test_avg_acc)) \n",
    "#         removeLogger(logger)\n",
    "\n",
    "# # else: # EVAL\n",
    "# #     load_ep = float(config.load_ckpt) / float(save_steps)\n",
    "# #     config.batch_size = 32\n",
    "# #     train_loader, validate_loader, vocab = getDataLoader(logger, config)\n",
    "# #     train_batches = len(iter(train_loader))\n",
    "# #     test_batches = len(iter(validate_loader))\n",
    "# # #     save_steps = int(train_batches/250)*250\n",
    "# #     model.cuda(eval_gpu) \n",
    "# #     model.eval()\n",
    "# #     '''先將test_avg_acc調起來再decode train_'''\n",
    "# # #     train_avg_acc, train_outFrame = decode_write_all(writer, logger, load_ep, config, model, train_loader, mode = 'train')\n",
    "# #     test_avg_acc, test_outFrame = decode_write_all(writer, logger, load_ep, config, model, validate_loader, mode = 'test')\n",
    "# # #     logger.info('epoch %d: train_avg_acc = %f, test_avg_acc = %f' % (load_ep, train_avg_acc, test_avg_acc)) \n",
    "# #     logger.info('epoch %d: test_avg_acc = %f' % (load_ep, test_avg_acc)) \n",
    "# #     removeLogger(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel_model\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-01 03:49:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: test_avg_acc = 0.392715\n",
      "I0601 03:49:25.281103 140390137546560 <ipython-input-10-1d5828c2ddf4>:8] epoch 15: test_avg_acc = 0.392715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test \n",
      " ['Accuracy result:\\n', '##-- Rouge --##\\n', 'testing_avg_rouge_1: 0.4188250392730259 \\n', 'testing_avg_rouge_2: 0.28948717761100906 \\n', 'testing_avg_rouge_l: 0.39271462020884523 \\n', '##-- SELF-BLEU --##\\n', 'testing_avg_self_bleu1: 0.3750028275916315 \\n', 'testing_avg_self_bleu2: 0.2681827919851197 \\n', 'testing_avg_self_bleu3: 0.22236819107464725 \\n', 'testing_avg_self_bleu4: 0.19078042918632868 \\n', '##-- BLEU --##\\n', 'testing_avg_bleu1: 0.3750028275916315 \\n', 'testing_avg_bleu2: 0.29353594356247364 \\n', 'testing_avg_bleu3: 0.25443417480269354 \\n', 'testing_avg_bleu4: 0.22362280452596373 \\n', '##-- Meteor --##\\n', 'testing_avg_meteor: 0.38326666155332306 \\n', 'Num : 52144 Execute Time: 0.10689771763383701 \\n']\n",
      "Index(['article', 'keywords', 'reference', 'decoded', 'rouge_1', 'rouge_2',\n",
      "       'rouge_l', 'self_Bleu_1', 'self_Bleu_2', 'self_Bleu_3', 'self_Bleu_4',\n",
      "       'Bleu_1', 'Bleu_2', 'Bleu_3', 'Bleu_4', 'Meteor', 'article_lens',\n",
      "       'ref_lens', 'overlap', 'overlap_percent', 'gen_type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge_1</th>\n",
       "      <th>article</th>\n",
       "      <th>reference</th>\n",
       "      <th>decoded</th>\n",
       "      <th>gen_type</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52128</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>this the best kids cup find and try plenty . i...</td>\n",
       "      <td>this is the best kid cup we find amazing custo...</td>\n",
       "      <td>this is the best kids cup find and try plenty of</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52142</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>the product come with two set direction . one ...</td>\n",
       "      <td>the direction that come with the machine are n...</td>\n",
       "      <td>the product come with two set of direction</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52122</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>this direct comparison ozark the utg which the...</td>\n",
       "      <td>this is direct comparison of ozark vs the utg</td>\n",
       "      <td>this is direct comparison ozark to the utg which</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52123</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this great video camera for the price . fairly...</td>\n",
       "      <td>this is great video camera for the price</td>\n",
       "      <td>this is great video camera for the price</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52121</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>have been play with this for one week the imag...</td>\n",
       "      <td>it was great tv until notice the screen unifor...</td>\n",
       "      <td>the color accuracy was great until notice ther...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52097</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>like car there are those who just want drive t...</td>\n",
       "      <td>excellent high end point and shoot camera</td>\n",
       "      <td>great point and shoot camera with lot of feature</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52105</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>have honest that have not see otterbox defende...</td>\n",
       "      <td>otterriffic experience poster child for poor s...</td>\n",
       "      <td>have the poster child for poor service have tr...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52127</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>this bluetooth mouse would great work flawless...</td>\n",
       "      <td>not fully compatible with mac os</td>\n",
       "      <td>great mouse but does not work with mac</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52084</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this very good phone system . there are many d...</td>\n",
       "      <td>this is very good phone system</td>\n",
       "      <td>this is very good phone system</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52092</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>purchased manduka eko natural tree rubber 5 mm...</td>\n",
       "      <td>manduka eko mm vs lululemon the mat mm</td>\n",
       "      <td>manduka natural tree rubber mm mat</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52095</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>purchase this phone april 2011 upgrade and mor...</td>\n",
       "      <td>unique style make it great transition phone</td>\n",
       "      <td>it is fast and easy to use and make great tran...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52048</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>this drain pump excellent replacement every re...</td>\n",
       "      <td>excellent replacement pump how to drain the tu...</td>\n",
       "      <td>this drain pump is excellent replacement every...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52062</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>the sony cli the perfect combination style fun...</td>\n",
       "      <td>excellent combination of style functionality a...</td>\n",
       "      <td>the perfect combination of functionality and p...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52033</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>first let mention that any have with this prod...</td>\n",
       "      <td>they are not terrible but they are mislead on ...</td>\n",
       "      <td>they do not terrible but they are mislead in t...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52044</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>this review the size large amazonbasic seat pa...</td>\n",
       "      <td>size large seat pack is much larger than the b...</td>\n",
       "      <td>this is very large seat pack easily the larges...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51997</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>first off will say this klipsch scala excellen...</td>\n",
       "      <td>not only great speaker one of the greatest pie...</td>\n",
       "      <td>will add that one of the greatest piece of ele...</td>\n",
       "      <td>Abs</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51971</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>read all the review before buy this . have hav...</td>\n",
       "      <td>try every suggestion in the review great box</td>\n",
       "      <td>get the cheaper replacement pee pad and they w...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51998</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>very nice gps very easy use really like the la...</td>\n",
       "      <td>very nice gps very easy to use</td>\n",
       "      <td>very nice gps very easy to use</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51957</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this really great price for large quantity goo...</td>\n",
       "      <td>this is really great price for large quantity ...</td>\n",
       "      <td>this is really great price for large quantity ...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51963</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>had couple these was the first monopod actuall...</td>\n",
       "      <td>when get the manfrotto think it was great it w...</td>\n",
       "      <td>thought was great was lot lighter than the old...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51941</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>this review the vomlite super bright lead bike...</td>\n",
       "      <td>this is review of the vomlite super bright lea...</td>\n",
       "      <td>this review is the vomlite super bright lead b...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51948</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>disclaimer receive this product discount excha...</td>\n",
       "      <td>poetic affinity series do not disappoint the u...</td>\n",
       "      <td>the look htc case poetic affinity is not disap...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>0.480000</td>\n",
       "      <td>have been japan time the last year and have fi...</td>\n",
       "      <td>great japanese sim card for convenience servic...</td>\n",
       "      <td>have find this prepaid sim card one of the bes...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51848</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>div class div input type hide name value class...</td>\n",
       "      <td>really nice aquarium kit especially for bettas</td>\n",
       "      <td>it is very nice aquarium aquarium kit</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51849</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>certify veteran the litter box war can say tha...</td>\n",
       "      <td>this is the best and least expensive to own au...</td>\n",
       "      <td>this is one of the hand down best least expens...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51832</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>this simply the best smartwatch available for ...</td>\n",
       "      <td>simply the best smartwatch for android on the ...</td>\n",
       "      <td>this is simply the best smartwatch available f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51855</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>wonderful amazing car camera pro have purchase...</td>\n",
       "      <td>wonderful amazing car camera</td>\n",
       "      <td>wonderful camera pro have purchase several car...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51834</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>lens breathing and other lens phenomena ill ma...</td>\n",
       "      <td>zoom make the lens pretty amazing find issue w...</td>\n",
       "      <td>the lens is pretty amazing find issue with cop...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51812</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>update 27oct11 this final review this product ...</td>\n",
       "      <td>wonderful when it work but malfunction break e...</td>\n",
       "      <td>the switch malfunction easily because it is re...</td>\n",
       "      <td>Abs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51808</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>purchased zywall vpn server replace older linu...</td>\n",
       "      <td>highly capable vpn server but difficult to set up</td>\n",
       "      <td>easy to set up and use with vpn</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>they are very cute adorable bootie but dog can...</td>\n",
       "      <td>they are very cute adorable bootie but my dog ...</td>\n",
       "      <td>they are very cute on adorable bootie but my d...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>work great . purchase this post therapy knee a...</td>\n",
       "      <td>work great purchase this to do post op therapy</td>\n",
       "      <td>work great purchase this post therapy knee after</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the first blue ray player purchase did not hav...</td>\n",
       "      <td>the first blue ray player purchase did not have</td>\n",
       "      <td>the first blue ray player purchase did not have</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the acrobird great for the medium size bird bu...</td>\n",
       "      <td>the acrobird is great for the medium size bird...</td>\n",
       "      <td>the acrobird is great for the medium size bird...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>seachem replenish increase the general hardnes...</td>\n",
       "      <td>easy to use will not turn water cloudy</td>\n",
       "      <td>easy to use and will not turn the water cloudy</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>say enough good thing about this experience . ...</td>\n",
       "      <td>can not say enough good thing about this tv ex...</td>\n",
       "      <td>say enough good thing about this experience</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>good design and like how easy remove and clean...</td>\n",
       "      <td>it is good design and like how easy it is to</td>\n",
       "      <td>good design and like how it is easy to</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>great well make light lot option lot light . e...</td>\n",
       "      <td>well make lantern with lot of option for lighting</td>\n",
       "      <td>great well make light lot of light</td>\n",
       "      <td>Abs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>good hollow plastic ball . the inside has many...</td>\n",
       "      <td>it is good hollow plastic ball</td>\n",
       "      <td>good hollow plastic ball the inside has many o...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>first co2 gun and its fcking awesome strong bl...</td>\n",
       "      <td>my first co bb gun and its fcking awesome stro...</td>\n",
       "      <td>first co2 gun and its fcking awesome it is strong</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>love the big tablet but what get not enough ti...</td>\n",
       "      <td>love the big tablet but what get me not enough</td>\n",
       "      <td>love the big tablet but what get not enough</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>was great service and the item work fine for d...</td>\n",
       "      <td>it was great service and the item is work fine...</td>\n",
       "      <td>was great service and the item work fine for m...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>the bag are too thin and the smell not contain...</td>\n",
       "      <td>are too thin and the smell is not contain like...</td>\n",
       "      <td>the bag are too thin and the smell is not cont...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>was very excited receive purchase until open t...</td>\n",
       "      <td>was very excited on receive my purchase until</td>\n",
       "      <td>was very excited to receive purchase until open</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>love this stuff for quick meal replacement . m...</td>\n",
       "      <td>love this stuff for quick meal replacement</td>\n",
       "      <td>love this stuff for my quick meal replacement</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>very good honey . use our coffee with some coc...</td>\n",
       "      <td>very good honey we use it in our coffee with</td>\n",
       "      <td>very good honey use it our coffee with some</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>very fine stone great for home brew low pressu...</td>\n",
       "      <td>very fine stone great for home brew</td>\n",
       "      <td>very fine stone great for home brew low pressu...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>this lens optically fantastic but manual focus...</td>\n",
       "      <td>this lens is optically fantastic but manual fo...</td>\n",
       "      <td>this lens is optically fantastic but manual fo...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the quality great but these pant are make for ...</td>\n",
       "      <td>the quality is great but these pant are make f...</td>\n",
       "      <td>the quality is great but these pant are make f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>very bad product reset all the time manual not...</td>\n",
       "      <td>very bad product reset all the time</td>\n",
       "      <td>very bad product reset all the time</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>have different type camp stove this far the be...</td>\n",
       "      <td>this is by far the best for bigger pan or skillet</td>\n",
       "      <td>have different type of camp stove this is by f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>awesome was look for waterproof raincoat and t...</td>\n",
       "      <td>awesome was look for waterproof raincoat</td>\n",
       "      <td>awesome was look for waterproof raincoat and this</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these are awesome fit true size and save dog f...</td>\n",
       "      <td>these are awesome fit true to size and save my</td>\n",
       "      <td>these are awesome fit true to size and save my</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>put nice edge this bad boy worth every pennie ...</td>\n",
       "      <td>put nice edge on this bad boy</td>\n",
       "      <td>put nice edge this is bad boy worth every</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>quality bag . weak point . love the zipper the...</td>\n",
       "      <td>love the zipper on the top of the bag</td>\n",
       "      <td>love the zipper on the top of the bag allow</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>good case but person sell describe that part t...</td>\n",
       "      <td>good case but person selling did not describe ...</td>\n",
       "      <td>good case but person sell it describe that part</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>shipping was time . the product does wonderful...</td>\n",
       "      <td>the product does wonderful job of retain the p...</td>\n",
       "      <td>the product does wonderful job of retain the p...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>awesome product you have ride shotgun mic . ch...</td>\n",
       "      <td>awesome product if you have ride shotgun mic</td>\n",
       "      <td>awesome product you have to ride shotgun</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21625 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rouge_1                                            article  \\\n",
       "52128  0.545455  this the best kids cup find and try plenty . i...   \n",
       "52142  0.470588  the product come with two set direction . one ...   \n",
       "52122  0.777778  this direct comparison ozark the utg which the...   \n",
       "52123  1.000000  this great video camera for the price . fairly...   \n",
       "52121  0.454545  have been play with this for one week the imag...   \n",
       "52097  0.500000  like car there are those who just want drive t...   \n",
       "52105  0.526316  have honest that have not see otterbox defende...   \n",
       "52127  0.428571  this bluetooth mouse would great work flawless...   \n",
       "52084  1.000000  this very good phone system . there are many d...   \n",
       "52092  0.461538  purchased manduka eko natural tree rubber 5 mm...   \n",
       "52095  0.421053  purchase this phone april 2011 upgrade and mor...   \n",
       "52048  0.444444  this drain pump excellent replacement every re...   \n",
       "52062  0.714286  the sony cli the perfect combination style fun...   \n",
       "52033  0.842105  first let mention that any have with this prod...   \n",
       "52044  0.428571  this review the size large amazonbasic seat pa...   \n",
       "51997  0.521739  first off will say this klipsch scala excellen...   \n",
       "51971  0.416667  read all the review before buy this . have hav...   \n",
       "51998  1.000000  very nice gps very easy use really like the la...   \n",
       "51957  1.000000  this really great price for large quantity goo...   \n",
       "51963  0.666667  had couple these was the first monopod actuall...   \n",
       "51941  0.956522  this review the vomlite super bright lead bike...   \n",
       "51948  0.571429  disclaimer receive this product discount excha...   \n",
       "51867  0.480000  have been japan time the last year and have fi...   \n",
       "51848  0.461538  div class div input type hide name value class...   \n",
       "51849  0.592593  certify veteran the litter box war can say tha...   \n",
       "51832  0.800000  this simply the best smartwatch available for ...   \n",
       "51855  0.500000  wonderful amazing car camera pro have purchase...   \n",
       "51834  0.761905  lens breathing and other lens phenomena ill ma...   \n",
       "51812  0.526316  update 27oct11 this final review this product ...   \n",
       "51808  0.470588  purchased zywall vpn server replace older linu...   \n",
       "...         ...                                                ...   \n",
       "285    0.888889  they are very cute adorable bootie but dog can...   \n",
       "286    0.705882  work great . purchase this post therapy knee a...   \n",
       "288    1.000000  the first blue ray player purchase did not hav...   \n",
       "289    1.000000  the acrobird great for the medium size bird bu...   \n",
       "290    1.000000  great camera and with everything that come wit...   \n",
       "291    0.888889  seachem replenish increase the general hardnes...   \n",
       "292    0.823529  say enough good thing about this experience . ...   \n",
       "270    1.000000  good design and like how easy remove and clean...   \n",
       "269    0.533333  great well make light lot option lot light . e...   \n",
       "257    0.533333  good hollow plastic ball . the inside has many...   \n",
       "248    0.666667  first co2 gun and its fcking awesome strong bl...   \n",
       "249    0.947368  love the big tablet but what get not enough ti...   \n",
       "250    0.869565  was great service and the item work fine for d...   \n",
       "251    0.960000  the bag are too thin and the smell not contain...   \n",
       "252    0.750000  was very excited receive purchase until open t...   \n",
       "253    0.933333  love this stuff for quick meal replacement . m...   \n",
       "254    0.842105  very good honey . use our coffee with some coc...   \n",
       "255    0.823529  very fine stone great for home brew low pressu...   \n",
       "256    0.956522  this lens optically fantastic but manual focus...   \n",
       "258    1.000000  the quality great but these pant are make for ...   \n",
       "268    1.000000  very bad product reset all the time manual not...   \n",
       "260    1.000000  lovely screen protector with easy bubble free ...   \n",
       "261    0.692308  have different type camp stove this far the be...   \n",
       "262    0.857143  awesome was look for waterproof raincoat and t...   \n",
       "263    1.000000  these are awesome fit true size and save dog f...   \n",
       "264    0.750000  put nice edge this bad boy worth every pennie ...   \n",
       "265    0.933333  quality bag . weak point . love the zipper the...   \n",
       "266    0.700000  good case but person sell describe that part t...   \n",
       "267    1.000000  shipping was time . the product does wonderful...   \n",
       "0      0.800000  awesome product you have ride shotgun mic . ch...   \n",
       "\n",
       "                                               reference  \\\n",
       "52128  this is the best kid cup we find amazing custo...   \n",
       "52142  the direction that come with the machine are n...   \n",
       "52122      this is direct comparison of ozark vs the utg   \n",
       "52123           this is great video camera for the price   \n",
       "52121  it was great tv until notice the screen unifor...   \n",
       "52097          excellent high end point and shoot camera   \n",
       "52105  otterriffic experience poster child for poor s...   \n",
       "52127                   not fully compatible with mac os   \n",
       "52084                     this is very good phone system   \n",
       "52092             manduka eko mm vs lululemon the mat mm   \n",
       "52095        unique style make it great transition phone   \n",
       "52048  excellent replacement pump how to drain the tu...   \n",
       "52062  excellent combination of style functionality a...   \n",
       "52033  they are not terrible but they are mislead on ...   \n",
       "52044  size large seat pack is much larger than the b...   \n",
       "51997  not only great speaker one of the greatest pie...   \n",
       "51971       try every suggestion in the review great box   \n",
       "51998                     very nice gps very easy to use   \n",
       "51957  this is really great price for large quantity ...   \n",
       "51963  when get the manfrotto think it was great it w...   \n",
       "51941  this is review of the vomlite super bright lea...   \n",
       "51948  poetic affinity series do not disappoint the u...   \n",
       "51867  great japanese sim card for convenience servic...   \n",
       "51848     really nice aquarium kit especially for bettas   \n",
       "51849  this is the best and least expensive to own au...   \n",
       "51832  simply the best smartwatch for android on the ...   \n",
       "51855                       wonderful amazing car camera   \n",
       "51834  zoom make the lens pretty amazing find issue w...   \n",
       "51812  wonderful when it work but malfunction break e...   \n",
       "51808  highly capable vpn server but difficult to set up   \n",
       "...                                                  ...   \n",
       "285    they are very cute adorable bootie but my dog ...   \n",
       "286       work great purchase this to do post op therapy   \n",
       "288      the first blue ray player purchase did not have   \n",
       "289    the acrobird is great for the medium size bird...   \n",
       "290    great camera and with everything that come wit...   \n",
       "291               easy to use will not turn water cloudy   \n",
       "292    can not say enough good thing about this tv ex...   \n",
       "270         it is good design and like how easy it is to   \n",
       "269    well make lantern with lot of option for lighting   \n",
       "257                       it is good hollow plastic ball   \n",
       "248    my first co bb gun and its fcking awesome stro...   \n",
       "249       love the big tablet but what get me not enough   \n",
       "250    it was great service and the item is work fine...   \n",
       "251    are too thin and the smell is not contain like...   \n",
       "252        was very excited on receive my purchase until   \n",
       "253           love this stuff for quick meal replacement   \n",
       "254         very good honey we use it in our coffee with   \n",
       "255                  very fine stone great for home brew   \n",
       "256    this lens is optically fantastic but manual fo...   \n",
       "258    the quality is great but these pant are make f...   \n",
       "268                  very bad product reset all the time   \n",
       "260    lovely screen protector with easy bubble free ...   \n",
       "261    this is by far the best for bigger pan or skillet   \n",
       "262             awesome was look for waterproof raincoat   \n",
       "263       these are awesome fit true to size and save my   \n",
       "264                        put nice edge on this bad boy   \n",
       "265                love the zipper on the top of the bag   \n",
       "266    good case but person selling did not describe ...   \n",
       "267    the product does wonderful job of retain the p...   \n",
       "0           awesome product if you have ride shotgun mic   \n",
       "\n",
       "                                                 decoded gen_type  overlap  \n",
       "52128   this is the best kids cup find and try plenty of      Ext        7  \n",
       "52142         the product come with two set of direction      Ext        7  \n",
       "52122   this is direct comparison ozark to the utg which      Ext        6  \n",
       "52123           this is great video camera for the price      Ext        7  \n",
       "52121  the color accuracy was great until notice ther...      Ext        8  \n",
       "52097   great point and shoot camera with lot of feature      Ext        5  \n",
       "52105  have the poster child for poor service have tr...      Ext        6  \n",
       "52127             great mouse but does not work with mac      Ext        4  \n",
       "52084                     this is very good phone system      Ext        5  \n",
       "52092                 manduka natural tree rubber mm mat      Ext        7  \n",
       "52095  it is fast and easy to use and make great tran...      Ext        5  \n",
       "52048  this drain pump is excellent replacement every...      Ext        6  \n",
       "52062  the perfect combination of functionality and p...      Ext        5  \n",
       "52033  they do not terrible but they are mislead in t...      Ext        8  \n",
       "52044  this is very large seat pack easily the larges...      Ext       12  \n",
       "51997  will add that one of the greatest piece of ele...      Abs        7  \n",
       "51971  get the cheaper replacement pee pad and they w...      Ext        5  \n",
       "51998                     very nice gps very easy to use      Ext        6  \n",
       "51957  this is really great price for large quantity ...      Ext       10  \n",
       "51963  thought was great was lot lighter than the old...      Ext       12  \n",
       "51941  this review is the vomlite super bright lead b...      Ext       10  \n",
       "51948  the look htc case poetic affinity is not disap...      Ext       10  \n",
       "51867  have find this prepaid sim card one of the bes...      Ext        8  \n",
       "51848              it is very nice aquarium aquarium kit      Ext        6  \n",
       "51849  this is one of the hand down best least expens...      Ext        9  \n",
       "51832  this is simply the best smartwatch available f...      Ext        8  \n",
       "51855  wonderful camera pro have purchase several car...      Ext        4  \n",
       "51834  the lens is pretty amazing find issue with cop...      Ext       10  \n",
       "51812  the switch malfunction easily because it is re...      Abs        4  \n",
       "51808                    easy to set up and use with vpn      Ext        5  \n",
       "...                                                  ...      ...      ...  \n",
       "285    they are very cute on adorable bootie but my d...      Ext       11  \n",
       "286     work great purchase this post therapy knee after      Ext        6  \n",
       "288      the first blue ray player purchase did not have      Ext        9  \n",
       "289    the acrobird is great for the medium size bird...      Ext       12  \n",
       "290    great camera and with everything that come wit...      Ext       10  \n",
       "291       easy to use and will not turn the water cloudy      Ext        7  \n",
       "292          say enough good thing about this experience      Ext        7  \n",
       "270               good design and like how it is easy to      Ext        6  \n",
       "269                   great well make light lot of light      Abs        4  \n",
       "257    good hollow plastic ball the inside has many o...      Ext        4  \n",
       "248    first co2 gun and its fcking awesome it is strong      Ext        8  \n",
       "249          love the big tablet but what get not enough      Ext        9  \n",
       "250    was great service and the item work fine for m...      Ext        9  \n",
       "251    the bag are too thin and the smell is not cont...      Ext       12  \n",
       "252      was very excited to receive purchase until open      Ext        6  \n",
       "253        love this stuff for my quick meal replacement      Ext        7  \n",
       "254          very good honey use it our coffee with some      Ext        7  \n",
       "255    very fine stone great for home brew low pressu...      Ext        7  \n",
       "256    this lens is optically fantastic but manual fo...      Ext       10  \n",
       "258    the quality is great but these pant are make f...      Ext       11  \n",
       "268                  very bad product reset all the time      Ext        7  \n",
       "260    lovely screen protector with easy bubble free ...      Ext        8  \n",
       "261    have different type of camp stove this is by f...      Ext        8  \n",
       "262    awesome was look for waterproof raincoat and this      Ext        6  \n",
       "263       these are awesome fit true to size and save my      Ext        8  \n",
       "264            put nice edge this is bad boy worth every      Ext        6  \n",
       "265          love the zipper on the top of the bag allow      Ext        7  \n",
       "266      good case but person sell it describe that part      Ext        7  \n",
       "267    the product does wonderful job of retain the p...      Ext       12  \n",
       "0               awesome product you have to ride shotgun      Ext        7  \n",
       "\n",
       "[21625 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.cuda(eval_gpu) \n",
    "print('parallel_model')\n",
    "parallel_model.module.eval()\n",
    "'''先將test_avg_acc調起來再decode train_'''\n",
    "#     train_avg_acc, train_outFrame = decode_write_all(writer, logger, load_ep, config, model, train_loader, mode = 'train')\n",
    "test_avg_acc, test_outFrame = decode_write_all(writer, logger, 15, config, parallel_model.module, validate_loader, mode = 'test')\n",
    "#     logger.info('epoch %d: train_avg_acc = %f, test_avg_acc = %f' % (load_ep, train_avg_acc, test_avg_acc)) \n",
    "logger.info('epoch %d: test_avg_acc = %f' % (15, test_avg_acc)) \n",
    "# removeLogger(logger)\n",
    "print(test_outFrame.columns)\n",
    "test_outFrame[test_outFrame[\"rouge_1\"]>=0.4][['rouge_1','article', 'reference', 'decoded', 'gen_type','overlap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-01 05:32:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: test_avg_acc = 0.392715\n",
      "I0601 05:32:42.508763 140390137546560 <ipython-input-11-229df890b1b7>:8] epoch 15: test_avg_acc = 0.392715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test \n",
      " ['Accuracy result:\\n', '##-- Rouge --##\\n', 'testing_avg_rouge_1: 0.4188250392730259 \\n', 'testing_avg_rouge_2: 0.28948717761100906 \\n', 'testing_avg_rouge_l: 0.39271462020884523 \\n', '##-- SELF-BLEU --##\\n', 'testing_avg_self_bleu1: 0.3750028275916315 \\n', 'testing_avg_self_bleu2: 0.2681827919851197 \\n', 'testing_avg_self_bleu3: 0.22236819107464725 \\n', 'testing_avg_self_bleu4: 0.19078042918632868 \\n', '##-- BLEU --##\\n', 'testing_avg_bleu1: 0.3750028275916315 \\n', 'testing_avg_bleu2: 0.29353594356247364 \\n', 'testing_avg_bleu3: 0.25443417480269354 \\n', 'testing_avg_bleu4: 0.22362280452596373 \\n', '##-- Meteor --##\\n', 'testing_avg_meteor: 0.38326666155332306 \\n', 'Num : 52144 Execute Time: 0.11446998279568021 \\n']\n",
      "Index(['article', 'keywords', 'reference', 'decoded', 'rouge_1', 'rouge_2',\n",
      "       'rouge_l', 'self_Bleu_1', 'self_Bleu_2', 'self_Bleu_3', 'self_Bleu_4',\n",
      "       'Bleu_1', 'Bleu_2', 'Bleu_3', 'Bleu_4', 'Meteor', 'article_lens',\n",
      "       'ref_lens', 'overlap', 'overlap_percent', 'gen_type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge_1</th>\n",
       "      <th>article</th>\n",
       "      <th>reference</th>\n",
       "      <th>decoded</th>\n",
       "      <th>gen_type</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52128</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>this the best kids cup find and try plenty . i...</td>\n",
       "      <td>this is the best kid cup we find amazing custo...</td>\n",
       "      <td>this is the best kids cup find and try plenty of</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52142</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>the product come with two set direction . one ...</td>\n",
       "      <td>the direction that come with the machine are n...</td>\n",
       "      <td>the product come with two set of direction</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52122</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>this direct comparison ozark the utg which the...</td>\n",
       "      <td>this is direct comparison of ozark vs the utg</td>\n",
       "      <td>this is direct comparison ozark to the utg which</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52123</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this great video camera for the price . fairly...</td>\n",
       "      <td>this is great video camera for the price</td>\n",
       "      <td>this is great video camera for the price</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52121</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>have been play with this for one week the imag...</td>\n",
       "      <td>it was great tv until notice the screen unifor...</td>\n",
       "      <td>the color accuracy was great until notice ther...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52097</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>like car there are those who just want drive t...</td>\n",
       "      <td>excellent high end point and shoot camera</td>\n",
       "      <td>great point and shoot camera with lot of feature</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52105</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>have honest that have not see otterbox defende...</td>\n",
       "      <td>otterriffic experience poster child for poor s...</td>\n",
       "      <td>have the poster child for poor service have tr...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52127</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>this bluetooth mouse would great work flawless...</td>\n",
       "      <td>not fully compatible with mac os</td>\n",
       "      <td>great mouse but does not work with mac</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52084</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this very good phone system . there are many d...</td>\n",
       "      <td>this is very good phone system</td>\n",
       "      <td>this is very good phone system</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52092</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>purchased manduka eko natural tree rubber 5 mm...</td>\n",
       "      <td>manduka eko mm vs lululemon the mat mm</td>\n",
       "      <td>manduka natural tree rubber mm mat</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52095</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>purchase this phone april 2011 upgrade and mor...</td>\n",
       "      <td>unique style make it great transition phone</td>\n",
       "      <td>it is fast and easy to use and make great tran...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52048</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>this drain pump excellent replacement every re...</td>\n",
       "      <td>excellent replacement pump how to drain the tu...</td>\n",
       "      <td>this drain pump is excellent replacement every...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52062</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>the sony cli the perfect combination style fun...</td>\n",
       "      <td>excellent combination of style functionality a...</td>\n",
       "      <td>the perfect combination of functionality and p...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52033</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>first let mention that any have with this prod...</td>\n",
       "      <td>they are not terrible but they are mislead on ...</td>\n",
       "      <td>they do not terrible but they are mislead in t...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52044</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>this review the size large amazonbasic seat pa...</td>\n",
       "      <td>size large seat pack is much larger than the b...</td>\n",
       "      <td>this is very large seat pack easily the larges...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51997</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>first off will say this klipsch scala excellen...</td>\n",
       "      <td>not only great speaker one of the greatest pie...</td>\n",
       "      <td>will add that one of the greatest piece of ele...</td>\n",
       "      <td>Abs</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51971</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>read all the review before buy this . have hav...</td>\n",
       "      <td>try every suggestion in the review great box</td>\n",
       "      <td>get the cheaper replacement pee pad and they w...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51998</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>very nice gps very easy use really like the la...</td>\n",
       "      <td>very nice gps very easy to use</td>\n",
       "      <td>very nice gps very easy to use</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51957</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>this really great price for large quantity goo...</td>\n",
       "      <td>this is really great price for large quantity ...</td>\n",
       "      <td>this is really great price for large quantity ...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51963</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>had couple these was the first monopod actuall...</td>\n",
       "      <td>when get the manfrotto think it was great it w...</td>\n",
       "      <td>thought was great was lot lighter than the old...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51941</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>this review the vomlite super bright lead bike...</td>\n",
       "      <td>this is review of the vomlite super bright lea...</td>\n",
       "      <td>this review is the vomlite super bright lead b...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51948</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>disclaimer receive this product discount excha...</td>\n",
       "      <td>poetic affinity series do not disappoint the u...</td>\n",
       "      <td>the look htc case poetic affinity is not disap...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>0.480000</td>\n",
       "      <td>have been japan time the last year and have fi...</td>\n",
       "      <td>great japanese sim card for convenience servic...</td>\n",
       "      <td>have find this prepaid sim card one of the bes...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51848</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>div class div input type hide name value class...</td>\n",
       "      <td>really nice aquarium kit especially for bettas</td>\n",
       "      <td>it is very nice aquarium aquarium kit</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51849</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>certify veteran the litter box war can say tha...</td>\n",
       "      <td>this is the best and least expensive to own au...</td>\n",
       "      <td>this is one of the hand down best least expens...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51832</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>this simply the best smartwatch available for ...</td>\n",
       "      <td>simply the best smartwatch for android on the ...</td>\n",
       "      <td>this is simply the best smartwatch available f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51855</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>wonderful amazing car camera pro have purchase...</td>\n",
       "      <td>wonderful amazing car camera</td>\n",
       "      <td>wonderful camera pro have purchase several car...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51834</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>lens breathing and other lens phenomena ill ma...</td>\n",
       "      <td>zoom make the lens pretty amazing find issue w...</td>\n",
       "      <td>the lens is pretty amazing find issue with cop...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51812</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>update 27oct11 this final review this product ...</td>\n",
       "      <td>wonderful when it work but malfunction break e...</td>\n",
       "      <td>the switch malfunction easily because it is re...</td>\n",
       "      <td>Abs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51808</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>purchased zywall vpn server replace older linu...</td>\n",
       "      <td>highly capable vpn server but difficult to set up</td>\n",
       "      <td>easy to set up and use with vpn</td>\n",
       "      <td>Ext</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>they are very cute adorable bootie but dog can...</td>\n",
       "      <td>they are very cute adorable bootie but my dog ...</td>\n",
       "      <td>they are very cute on adorable bootie but my d...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>work great . purchase this post therapy knee a...</td>\n",
       "      <td>work great purchase this to do post op therapy</td>\n",
       "      <td>work great purchase this post therapy knee after</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the first blue ray player purchase did not hav...</td>\n",
       "      <td>the first blue ray player purchase did not have</td>\n",
       "      <td>the first blue ray player purchase did not have</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the acrobird great for the medium size bird bu...</td>\n",
       "      <td>the acrobird is great for the medium size bird...</td>\n",
       "      <td>the acrobird is great for the medium size bird...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>great camera and with everything that come wit...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>seachem replenish increase the general hardnes...</td>\n",
       "      <td>easy to use will not turn water cloudy</td>\n",
       "      <td>easy to use and will not turn the water cloudy</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>say enough good thing about this experience . ...</td>\n",
       "      <td>can not say enough good thing about this tv ex...</td>\n",
       "      <td>say enough good thing about this experience</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>good design and like how easy remove and clean...</td>\n",
       "      <td>it is good design and like how easy it is to</td>\n",
       "      <td>good design and like how it is easy to</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>great well make light lot option lot light . e...</td>\n",
       "      <td>well make lantern with lot of option for lighting</td>\n",
       "      <td>great well make light lot of light</td>\n",
       "      <td>Abs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>good hollow plastic ball . the inside has many...</td>\n",
       "      <td>it is good hollow plastic ball</td>\n",
       "      <td>good hollow plastic ball the inside has many o...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>first co2 gun and its fcking awesome strong bl...</td>\n",
       "      <td>my first co bb gun and its fcking awesome stro...</td>\n",
       "      <td>first co2 gun and its fcking awesome it is strong</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>love the big tablet but what get not enough ti...</td>\n",
       "      <td>love the big tablet but what get me not enough</td>\n",
       "      <td>love the big tablet but what get not enough</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>was great service and the item work fine for d...</td>\n",
       "      <td>it was great service and the item is work fine...</td>\n",
       "      <td>was great service and the item work fine for m...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>the bag are too thin and the smell not contain...</td>\n",
       "      <td>are too thin and the smell is not contain like...</td>\n",
       "      <td>the bag are too thin and the smell is not cont...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>was very excited receive purchase until open t...</td>\n",
       "      <td>was very excited on receive my purchase until</td>\n",
       "      <td>was very excited to receive purchase until open</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>love this stuff for quick meal replacement . m...</td>\n",
       "      <td>love this stuff for quick meal replacement</td>\n",
       "      <td>love this stuff for my quick meal replacement</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>very good honey . use our coffee with some coc...</td>\n",
       "      <td>very good honey we use it in our coffee with</td>\n",
       "      <td>very good honey use it our coffee with some</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>very fine stone great for home brew low pressu...</td>\n",
       "      <td>very fine stone great for home brew</td>\n",
       "      <td>very fine stone great for home brew low pressu...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>this lens optically fantastic but manual focus...</td>\n",
       "      <td>this lens is optically fantastic but manual fo...</td>\n",
       "      <td>this lens is optically fantastic but manual fo...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>the quality great but these pant are make for ...</td>\n",
       "      <td>the quality is great but these pant are make f...</td>\n",
       "      <td>the quality is great but these pant are make f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>very bad product reset all the time manual not...</td>\n",
       "      <td>very bad product reset all the time</td>\n",
       "      <td>very bad product reset all the time</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>lovely screen protector with easy bubble free ...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>have different type camp stove this far the be...</td>\n",
       "      <td>this is by far the best for bigger pan or skillet</td>\n",
       "      <td>have different type of camp stove this is by f...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>awesome was look for waterproof raincoat and t...</td>\n",
       "      <td>awesome was look for waterproof raincoat</td>\n",
       "      <td>awesome was look for waterproof raincoat and this</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these are awesome fit true size and save dog f...</td>\n",
       "      <td>these are awesome fit true to size and save my</td>\n",
       "      <td>these are awesome fit true to size and save my</td>\n",
       "      <td>Ext</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>put nice edge this bad boy worth every pennie ...</td>\n",
       "      <td>put nice edge on this bad boy</td>\n",
       "      <td>put nice edge this is bad boy worth every</td>\n",
       "      <td>Ext</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>quality bag . weak point . love the zipper the...</td>\n",
       "      <td>love the zipper on the top of the bag</td>\n",
       "      <td>love the zipper on the top of the bag allow</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>good case but person sell describe that part t...</td>\n",
       "      <td>good case but person selling did not describe ...</td>\n",
       "      <td>good case but person sell it describe that part</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>shipping was time . the product does wonderful...</td>\n",
       "      <td>the product does wonderful job of retain the p...</td>\n",
       "      <td>the product does wonderful job of retain the p...</td>\n",
       "      <td>Ext</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>awesome product you have ride shotgun mic . ch...</td>\n",
       "      <td>awesome product if you have ride shotgun mic</td>\n",
       "      <td>awesome product you have to ride shotgun</td>\n",
       "      <td>Ext</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21625 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rouge_1                                            article  \\\n",
       "52128  0.545455  this the best kids cup find and try plenty . i...   \n",
       "52142  0.470588  the product come with two set direction . one ...   \n",
       "52122  0.777778  this direct comparison ozark the utg which the...   \n",
       "52123  1.000000  this great video camera for the price . fairly...   \n",
       "52121  0.454545  have been play with this for one week the imag...   \n",
       "52097  0.500000  like car there are those who just want drive t...   \n",
       "52105  0.526316  have honest that have not see otterbox defende...   \n",
       "52127  0.428571  this bluetooth mouse would great work flawless...   \n",
       "52084  1.000000  this very good phone system . there are many d...   \n",
       "52092  0.461538  purchased manduka eko natural tree rubber 5 mm...   \n",
       "52095  0.421053  purchase this phone april 2011 upgrade and mor...   \n",
       "52048  0.444444  this drain pump excellent replacement every re...   \n",
       "52062  0.714286  the sony cli the perfect combination style fun...   \n",
       "52033  0.842105  first let mention that any have with this prod...   \n",
       "52044  0.428571  this review the size large amazonbasic seat pa...   \n",
       "51997  0.521739  first off will say this klipsch scala excellen...   \n",
       "51971  0.416667  read all the review before buy this . have hav...   \n",
       "51998  1.000000  very nice gps very easy use really like the la...   \n",
       "51957  1.000000  this really great price for large quantity goo...   \n",
       "51963  0.666667  had couple these was the first monopod actuall...   \n",
       "51941  0.956522  this review the vomlite super bright lead bike...   \n",
       "51948  0.571429  disclaimer receive this product discount excha...   \n",
       "51867  0.480000  have been japan time the last year and have fi...   \n",
       "51848  0.461538  div class div input type hide name value class...   \n",
       "51849  0.592593  certify veteran the litter box war can say tha...   \n",
       "51832  0.800000  this simply the best smartwatch available for ...   \n",
       "51855  0.500000  wonderful amazing car camera pro have purchase...   \n",
       "51834  0.761905  lens breathing and other lens phenomena ill ma...   \n",
       "51812  0.526316  update 27oct11 this final review this product ...   \n",
       "51808  0.470588  purchased zywall vpn server replace older linu...   \n",
       "...         ...                                                ...   \n",
       "285    0.888889  they are very cute adorable bootie but dog can...   \n",
       "286    0.705882  work great . purchase this post therapy knee a...   \n",
       "288    1.000000  the first blue ray player purchase did not hav...   \n",
       "289    1.000000  the acrobird great for the medium size bird bu...   \n",
       "290    1.000000  great camera and with everything that come wit...   \n",
       "291    0.888889  seachem replenish increase the general hardnes...   \n",
       "292    0.823529  say enough good thing about this experience . ...   \n",
       "270    1.000000  good design and like how easy remove and clean...   \n",
       "269    0.533333  great well make light lot option lot light . e...   \n",
       "257    0.533333  good hollow plastic ball . the inside has many...   \n",
       "248    0.666667  first co2 gun and its fcking awesome strong bl...   \n",
       "249    0.947368  love the big tablet but what get not enough ti...   \n",
       "250    0.869565  was great service and the item work fine for d...   \n",
       "251    0.960000  the bag are too thin and the smell not contain...   \n",
       "252    0.750000  was very excited receive purchase until open t...   \n",
       "253    0.933333  love this stuff for quick meal replacement . m...   \n",
       "254    0.842105  very good honey . use our coffee with some coc...   \n",
       "255    0.823529  very fine stone great for home brew low pressu...   \n",
       "256    0.956522  this lens optically fantastic but manual focus...   \n",
       "258    1.000000  the quality great but these pant are make for ...   \n",
       "268    1.000000  very bad product reset all the time manual not...   \n",
       "260    1.000000  lovely screen protector with easy bubble free ...   \n",
       "261    0.692308  have different type camp stove this far the be...   \n",
       "262    0.857143  awesome was look for waterproof raincoat and t...   \n",
       "263    1.000000  these are awesome fit true size and save dog f...   \n",
       "264    0.750000  put nice edge this bad boy worth every pennie ...   \n",
       "265    0.933333  quality bag . weak point . love the zipper the...   \n",
       "266    0.700000  good case but person sell describe that part t...   \n",
       "267    1.000000  shipping was time . the product does wonderful...   \n",
       "0      0.800000  awesome product you have ride shotgun mic . ch...   \n",
       "\n",
       "                                               reference  \\\n",
       "52128  this is the best kid cup we find amazing custo...   \n",
       "52142  the direction that come with the machine are n...   \n",
       "52122      this is direct comparison of ozark vs the utg   \n",
       "52123           this is great video camera for the price   \n",
       "52121  it was great tv until notice the screen unifor...   \n",
       "52097          excellent high end point and shoot camera   \n",
       "52105  otterriffic experience poster child for poor s...   \n",
       "52127                   not fully compatible with mac os   \n",
       "52084                     this is very good phone system   \n",
       "52092             manduka eko mm vs lululemon the mat mm   \n",
       "52095        unique style make it great transition phone   \n",
       "52048  excellent replacement pump how to drain the tu...   \n",
       "52062  excellent combination of style functionality a...   \n",
       "52033  they are not terrible but they are mislead on ...   \n",
       "52044  size large seat pack is much larger than the b...   \n",
       "51997  not only great speaker one of the greatest pie...   \n",
       "51971       try every suggestion in the review great box   \n",
       "51998                     very nice gps very easy to use   \n",
       "51957  this is really great price for large quantity ...   \n",
       "51963  when get the manfrotto think it was great it w...   \n",
       "51941  this is review of the vomlite super bright lea...   \n",
       "51948  poetic affinity series do not disappoint the u...   \n",
       "51867  great japanese sim card for convenience servic...   \n",
       "51848     really nice aquarium kit especially for bettas   \n",
       "51849  this is the best and least expensive to own au...   \n",
       "51832  simply the best smartwatch for android on the ...   \n",
       "51855                       wonderful amazing car camera   \n",
       "51834  zoom make the lens pretty amazing find issue w...   \n",
       "51812  wonderful when it work but malfunction break e...   \n",
       "51808  highly capable vpn server but difficult to set up   \n",
       "...                                                  ...   \n",
       "285    they are very cute adorable bootie but my dog ...   \n",
       "286       work great purchase this to do post op therapy   \n",
       "288      the first blue ray player purchase did not have   \n",
       "289    the acrobird is great for the medium size bird...   \n",
       "290    great camera and with everything that come wit...   \n",
       "291               easy to use will not turn water cloudy   \n",
       "292    can not say enough good thing about this tv ex...   \n",
       "270         it is good design and like how easy it is to   \n",
       "269    well make lantern with lot of option for lighting   \n",
       "257                       it is good hollow plastic ball   \n",
       "248    my first co bb gun and its fcking awesome stro...   \n",
       "249       love the big tablet but what get me not enough   \n",
       "250    it was great service and the item is work fine...   \n",
       "251    are too thin and the smell is not contain like...   \n",
       "252        was very excited on receive my purchase until   \n",
       "253           love this stuff for quick meal replacement   \n",
       "254         very good honey we use it in our coffee with   \n",
       "255                  very fine stone great for home brew   \n",
       "256    this lens is optically fantastic but manual fo...   \n",
       "258    the quality is great but these pant are make f...   \n",
       "268                  very bad product reset all the time   \n",
       "260    lovely screen protector with easy bubble free ...   \n",
       "261    this is by far the best for bigger pan or skillet   \n",
       "262             awesome was look for waterproof raincoat   \n",
       "263       these are awesome fit true to size and save my   \n",
       "264                        put nice edge on this bad boy   \n",
       "265                love the zipper on the top of the bag   \n",
       "266    good case but person selling did not describe ...   \n",
       "267    the product does wonderful job of retain the p...   \n",
       "0           awesome product if you have ride shotgun mic   \n",
       "\n",
       "                                                 decoded gen_type  overlap  \n",
       "52128   this is the best kids cup find and try plenty of      Ext        7  \n",
       "52142         the product come with two set of direction      Ext        7  \n",
       "52122   this is direct comparison ozark to the utg which      Ext        6  \n",
       "52123           this is great video camera for the price      Ext        7  \n",
       "52121  the color accuracy was great until notice ther...      Ext        8  \n",
       "52097   great point and shoot camera with lot of feature      Ext        5  \n",
       "52105  have the poster child for poor service have tr...      Ext        6  \n",
       "52127             great mouse but does not work with mac      Ext        4  \n",
       "52084                     this is very good phone system      Ext        5  \n",
       "52092                 manduka natural tree rubber mm mat      Ext        7  \n",
       "52095  it is fast and easy to use and make great tran...      Ext        5  \n",
       "52048  this drain pump is excellent replacement every...      Ext        6  \n",
       "52062  the perfect combination of functionality and p...      Ext        5  \n",
       "52033  they do not terrible but they are mislead in t...      Ext        8  \n",
       "52044  this is very large seat pack easily the larges...      Ext       12  \n",
       "51997  will add that one of the greatest piece of ele...      Abs        7  \n",
       "51971  get the cheaper replacement pee pad and they w...      Ext        5  \n",
       "51998                     very nice gps very easy to use      Ext        6  \n",
       "51957  this is really great price for large quantity ...      Ext       10  \n",
       "51963  thought was great was lot lighter than the old...      Ext       12  \n",
       "51941  this review is the vomlite super bright lead b...      Ext       10  \n",
       "51948  the look htc case poetic affinity is not disap...      Ext       10  \n",
       "51867  have find this prepaid sim card one of the bes...      Ext        8  \n",
       "51848              it is very nice aquarium aquarium kit      Ext        6  \n",
       "51849  this is one of the hand down best least expens...      Ext        9  \n",
       "51832  this is simply the best smartwatch available f...      Ext        8  \n",
       "51855  wonderful camera pro have purchase several car...      Ext        4  \n",
       "51834  the lens is pretty amazing find issue with cop...      Ext       10  \n",
       "51812  the switch malfunction easily because it is re...      Abs        4  \n",
       "51808                    easy to set up and use with vpn      Ext        5  \n",
       "...                                                  ...      ...      ...  \n",
       "285    they are very cute on adorable bootie but my d...      Ext       11  \n",
       "286     work great purchase this post therapy knee after      Ext        6  \n",
       "288      the first blue ray player purchase did not have      Ext        9  \n",
       "289    the acrobird is great for the medium size bird...      Ext       12  \n",
       "290    great camera and with everything that come wit...      Ext       10  \n",
       "291       easy to use and will not turn the water cloudy      Ext        7  \n",
       "292          say enough good thing about this experience      Ext        7  \n",
       "270               good design and like how it is easy to      Ext        6  \n",
       "269                   great well make light lot of light      Abs        4  \n",
       "257    good hollow plastic ball the inside has many o...      Ext        4  \n",
       "248    first co2 gun and its fcking awesome it is strong      Ext        8  \n",
       "249          love the big tablet but what get not enough      Ext        9  \n",
       "250    was great service and the item work fine for m...      Ext        9  \n",
       "251    the bag are too thin and the smell is not cont...      Ext       12  \n",
       "252      was very excited to receive purchase until open      Ext        6  \n",
       "253        love this stuff for my quick meal replacement      Ext        7  \n",
       "254          very good honey use it our coffee with some      Ext        7  \n",
       "255    very fine stone great for home brew low pressu...      Ext        7  \n",
       "256    this lens is optically fantastic but manual fo...      Ext       10  \n",
       "258    the quality is great but these pant are make f...      Ext       11  \n",
       "268                  very bad product reset all the time      Ext        7  \n",
       "260    lovely screen protector with easy bubble free ...      Ext        8  \n",
       "261    have different type of camp stove this is by f...      Ext        8  \n",
       "262    awesome was look for waterproof raincoat and this      Ext        6  \n",
       "263       these are awesome fit true to size and save my      Ext        8  \n",
       "264            put nice edge this is bad boy worth every      Ext        6  \n",
       "265          love the zipper on the top of the bag allow      Ext        7  \n",
       "266      good case but person sell it describe that part      Ext        7  \n",
       "267    the product does wonderful job of retain the p...      Ext       12  \n",
       "0               awesome product you have to ride shotgun      Ext        7  \n",
       "\n",
       "[21625 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('model')\n",
    "model.cuda(eval_gpu) \n",
    "model.eval()\n",
    "'''先將test_avg_acc調起來再decode train_'''\n",
    "#     train_avg_acc, train_outFrame = decode_write_all(writer, logger, load_ep, config, model, train_loader, mode = 'train')\n",
    "test_avg_acc, test_outFrame = decode_write_all(writer, logger, 15, config, model, validate_loader, mode = 'test')\n",
    "#     logger.info('epoch %d: train_avg_acc = %f, test_avg_acc = %f' % (load_ep, train_avg_acc, test_avg_acc)) \n",
    "logger.info('epoch %d: test_avg_acc = %f' % (15, test_avg_acc)) \n",
    "# removeLogger(logger)\n",
    "print(test_outFrame.columns)\n",
    "test_outFrame[test_outFrame[\"rouge_1\"]>=0.4][['rouge_1','article', 'reference', 'decoded', 'gen_type','overlap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_16 epoch_6\n",
    "# testing_avg_rouge_1: 0.3873426628114616 \\n', \n",
    "# 'testing_avg_rouge_2: 0.25943944916828854 \\n', \n",
    "# 'testing_avg_rouge_l: 0.3614074094052472 \\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('Leyan': conda)",
   "language": "python",
   "name": "python36764bitleyancondaa378f3cedbcc4b3f906a2276b3eef765"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
