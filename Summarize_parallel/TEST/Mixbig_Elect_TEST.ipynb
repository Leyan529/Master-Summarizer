{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "from utils import config\n",
    "data_type = 'Mixbig_Elect_30'\n",
    "config.Data_path = '../Test-Data/%s/'%(data_type)\n",
    "from utils.seq2seq.batcher import *\n",
    "from utils.seq2seq.train_util import *\n",
    "from translate.seq2seq_beam import *\n",
    "from utils.seq2seq.write_result import *\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--copy', type=bool, default=True, help = 'True/False') # for transformer\n",
    "\n",
    "parser.add_argument('--model_type', type=str, default='seq2seq', choices=['seq2seq', 'transformer'])\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_keys', \n",
    "                    help = 'POS_keys / DEP_keys / Noun_adj_keys / TextRank_keys')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=500)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=20)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=5)\n",
    "parser.add_argument('--max_epochs', type=int, default=15)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/eagleuser/Users/leyan/Summarize_parallel/Train-Data/Mix6_mainCat_Ekphrasis/Embedding/word2Vec/word.vocab'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(data_type):\n",
    "    os.makedirs(data_type)\n",
    "\n",
    "\n",
    "config.word_emb_path = config.word_emb_path.replace('Test-Data/Mixbig_Elect_30','Train-Data/Mix6_mainCat_Ekphrasis')\n",
    "config.vocab_path = config.vocab_path.replace('Test-Data/Mixbig_Elect_30','Train-Data/Mix6_mainCat_Ekphrasis')\n",
    "os.path.abspath(config.vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 19:04:31 - Pointer_generator_word2Vec_TEST - INFO: - logger已啟動\n"
     ]
    }
   ],
   "source": [
    "loggerName, writerPath = getName(config)   \n",
    "loggerName = loggerName + \"_TEST\"\n",
    "# writerPath = writerPath.replace('Pointer-Generator','Pointer_less_Intra_dec')\n",
    "\n",
    "logger = getLogger(loggerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 19:08:10 - Pointer_generator_word2Vec_TEST - INFO: - train : 491432, test : 54604\n",
      "2020-07-03 19:08:10 - Pointer_generator_word2Vec_TEST - INFO: - train batches : 491432, test batches : 54604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.seq2seq.data.Vocab at 0x7f2531711fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, validate_loader, vocab = getDataLoader(logger, config)\n",
    "# train_batches = len(iter(train_loader))\n",
    "test_batches = len(iter(validate_loader))\n",
    "# save_steps = int(train_batches/250)*250\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG-less.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 19:08:14.203657 139797938509632 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "/home/eagleuser/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "I0703 19:08:15.370535 139797938509632 utils_any2vec.py:341] loading projection weights from /home/eagleuser/Users/leyan//Train-Data/Mix6_mainCat_Ekphrasis/Embedding/word2Vec/word2Vec.300d.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eagleuser/Users/leyan//Train-Data/Mix6_mainCat_Ekphrasis/Embedding/word2Vec/word2Vec.300d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 19:08:26.209514 139797938509632 utils_any2vec.py:405] loaded (48560, 300) matrix from /home/eagleuser/Users/leyan//Train-Data/Mix6_mainCat_Ekphrasis/Embedding/word2Vec/word2Vec.300d.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(300, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (reduce_h): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (reduce_c): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (enc_attention): MultiHeadedAttention(\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (dec_attention): decoder_attention()\n",
       "    (x_context): Linear(in_features=1324, out_features=300, bias=True)\n",
       "    (x_key_context): Linear(in_features=1624, out_features=300, bias=True)\n",
       "    (lstm): LSTMCell(300, 512)\n",
       "    (p_gen_linear): Linear(in_features=2860, out_features=1, bias=True)\n",
       "    (p_gen_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (V): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (V1): Linear(in_features=512, out_features=50000, bias=True)\n",
       "  )\n",
       "  (embeds): Embedding(50000, 300)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model_path = 'PG-less.tar'  \n",
    "\n",
    "\n",
    "import torch as T\n",
    "\n",
    "T.backends.cudnn.benchmark = True \n",
    "checkpoint = T.load(load_model_path)\n",
    "# vocab = checkpoint['vocab']\n",
    "print(load_model_path)\n",
    "\n",
    "from create_model.pointer_less import Model \n",
    "\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writerPath = './'\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def decode(dataloader, epoch = 0):\n",
    "    # 動態取batch\n",
    "    num = len(dataloader)\n",
    "    outFrame = None\n",
    "    avg_time = 0\n",
    "    total_scores = dict()   \n",
    "    idx = 0 \n",
    "    for _, inputs in enumerate(dataloader):\n",
    "        start = time.time() \n",
    "        # 'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage,             ct_e, enc_key_batch, enc_key_mask, enc_key_lens = get_input_from_batch(inputs, config, batch_first = True)\n",
    "        max_enc_len = max(T.max(enc_lens,dim=0)).tolist()[0] \n",
    "        \n",
    "        if (max_enc_len != max(enc_lens.tolist())[0]): continue\n",
    "        if len(enc_key_batch[0]) == 0: enc_key_batch = T.LongTensor([0]).cuda()\n",
    "#         print(enc_key_batch[0],len(enc_key_batch[0]))\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens, max_enc_len)\n",
    "        \n",
    "        # 'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                                enc_batch_extend_vocab, enc_key_batch, enc_key_mask, model, \n",
    "                                START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, ref_sents, long_seq_index = prepare_result(vocab, inputs, pred_ids)\n",
    "        cost = (time.time() - start)\n",
    "        avg_time += cost        \n",
    "\n",
    "        multi_scores, batch_frame = total_evaulate(article_sents, keywords_list, decoded_sents, ref_sents)\n",
    "        review_IDS = [review_ID for review_ID in inputs.review_IDS]\n",
    "        batch_frame['review_ID'] = review_IDS        \n",
    "        if idx %1000 ==0 and idx >0 : \n",
    "            print(idx); \n",
    "        if idx == 0: \n",
    "            outFrame = batch_frame; \n",
    "            total_scores = multi_scores\n",
    "        else: \n",
    "            outFrame = pd.concat([outFrame, batch_frame], axis=0, ignore_index=True) \n",
    "            for key, scores in total_scores.items():\n",
    "                scores.extend(multi_scores[key])\n",
    "                total_scores[key] = scores\n",
    "        idx += 1\n",
    "        # ----------------------------------------------------    \n",
    "    avg_time = avg_time / (num * config.batch_size)    \n",
    "\n",
    "    scalar_acc = {}\n",
    "    num = 0\n",
    "    for key, scores in total_scores.items():\n",
    "        num = len(scores)\n",
    "        scalar_acc[key] = sum(scores)/len(scores)    \n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    total_output(epoch, 'test', writerPath, outFrame, avg_time, num , scalar_acc\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "    outFrame = outFrame.sort_values(by=['rouge_l'], ascending=False)\n",
    "    big_frame = outFrame.head()\n",
    "    small_frame = outFrame.tail()    \n",
    "    # -----------------------------------------------------------\n",
    "    \n",
    "    return outFrame, scalar_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "test \n",
      " ['Accuracy result:\\n', '##-- Rouge-1 --##\\n', 'testing_rouge_1_p: 0.1799647273455593 \\n', 'testing_rouge_1_r: 0.17887940021151855 \\n', 'testing_rouge_1_f: 0.1717402512585566 \\n', '##-- Rouge-2 --##\\n', 'testing_rouge_2_p: 0.04837252521019476 \\n', 'testing_rouge_2_r: 0.049107616007987825 \\n', 'testing_rouge_2_f: 0.046838219143360026 \\n', '##-- Rouge-l --##\\n', 'testing_rouge_l_p: 0.16109900861546503 \\n', 'testing_rouge_l_r: 0.15915568388083812 \\n', 'testing_rouge_l_f: 0.1437934898521938 \\n', '##-- BLEU --##\\n', 'testing_bleu_1: 0.13791245809169153 \\n', 'testing_bleu_2: 0.047800219108112635 \\n', 'testing_bleu_3: 0.03325125095974862 \\n', 'testing_bleu_4: 0.027189135721829308 \\n', '##-- Meteor --##\\n', 'testing_meteor: 0.1258603759712392 \\n', 'Num : 54604 Execute Time: 0.5614654705748174 \\n']\n"
     ]
    }
   ],
   "source": [
    "test_outFrame, scalar_acc = decode(validate_loader)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge_1_p': 0.1799647273455593,\n",
       " 'rouge_1_r': 0.17887940021151855,\n",
       " 'rouge_1_f': 0.1717402512585566,\n",
       " 'rouge_2_p': 0.04837252521019476,\n",
       " 'rouge_2_r': 0.049107616007987825,\n",
       " 'rouge_2_f': 0.046838219143360026,\n",
       " 'rouge_l_p': 0.16109900861546503,\n",
       " 'rouge_l_r': 0.15915568388083812,\n",
       " 'rouge_l_f': 0.1437934898521938,\n",
       " 'bleu_1': 0.13791245809169153,\n",
       " 'bleu_2': 0.047800219108112635,\n",
       " 'bleu_3': 0.03325125095974862,\n",
       " 'bleu_4': 0.027189135721829308,\n",
       " 'meteor': 0.1258603759712392}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixbig_Elect_30/output.xlsx Write finished\n"
     ]
    }
   ],
   "source": [
    "path = '%s/output.xlsx'%(data_type)\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "#THIS\n",
    "writer.book.use_zip64()\n",
    "test_outFrame.to_excel(writer, index = False)\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "writer.close()\n",
    "print(path + \" Write finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '%s/res.txt'%(data_type)\n",
    "with open(path,'w',encoding='utf-8') as f:\n",
    "    for k ,v in scalar_acc.items():\n",
    "        f.write(k + ' : ' + str(v) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('Leyan': conda)",
   "language": "python",
   "name": "python36764bitleyancondaa378f3cedbcc4b3f906a2276b3eef765"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
