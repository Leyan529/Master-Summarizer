{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0414 15:40:57.107887 140122325395264 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-14 15:40:57 - Pointer_generator_FastText_Intra_Atten - INFO: - logger已啟動\n",
      "I0414 15:40:57.955201 140122325395264 train_util.py:146] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.rl_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "from utils.rl_util import *\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--copy', type=bool, default=True, help = 'True/False') # for transformer\n",
    "\n",
    "parser.add_argument('--transformer', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='FastText', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 15:42:14 - Pointer_generator_FastText_Intra_Atten - INFO: - train : 504075, test : 56009\n",
      "I0414 15:42:14.216642 140122325395264 batcher.py:171] train : 504075, test : 56009\n",
      "2020-04-14 15:42:14 - Pointer_generator_FastText_Intra_Atten - INFO: - train batches : 63010, test batches : 7002\n",
      "I0414 15:42:14.667210 140122325395264 batcher.py:182] train batches : 63010, test batches : 7002\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0414 15:42:15.163486 140122325395264 utils_any2vec.py:341] loading projection weights from ../Train-Data/Mix6_mainCat/Embedding/FastText/FastText.300d.txt\n",
      "I0414 15:44:45.283813 140122325395264 utils_any2vec.py:405] loaded (699274, 300) matrix from ../Train-Data/Mix6_mainCat/Embedding/FastText/FastText.300d.txt\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    " \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > config.gound_truth_prob)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = model.embeds(x_t)  \n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * UNKNOWN_TOKEN  # Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "    enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    'Feed encoder data to predict'\n",
    "    pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                           enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                           START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                               enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                               START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(model, config, batch, greedy):    \n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param article_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "        \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        s_t = enc_hidden                                                                            #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []                       # Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []       # Stores padding masks of generated samples\n",
    "        log_probs = []                                                                              #Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "        # Generate RL tokens and compute rl-log-loss\n",
    "        # ----------------------------------------------------------------------\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = model.embeds(x_t)\n",
    "            \n",
    "            probs, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            \n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs) # 建立以參數probs為標準的類別分佈\n",
    "                # perform multinomial sampling\n",
    "                x_t = multi_dist.sample()  # 將下一個時間點的x_t，視為下一個action   \n",
    "                # 使用log_prob实施梯度方法 Policy Gradient，构造一个等价類別分佈的损失函数\n",
    "                log_prob = multi_dist.log_prob(x_t)  \n",
    "                log_probs.append(log_prob) #\n",
    "            else:\n",
    "                # perform greedy sampling distribution\n",
    "                _, x_t = T.max(probs, dim=1)  # 因greedy以機率最大進行取樣，視為其中一個action   \n",
    "            x_t = x_t.detach() # detach返回的 Variable 永远不会需要梯度\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "            mask[(mask == 1) + (x_t == END) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "            is_oov = (x_t>=config.vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n",
    "            x_t = (1-is_oov)*x_t + (is_oov)*UNKNOWN_TOKEN                                             #Replace OOVs with [UNK] token\n",
    "        # -----------------------------------End loop -----------------------------------\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n",
    "            log_probs = T.stack(log_probs, dim=1) # 在第1个维度上stack, 增加新的维度进行堆叠\n",
    "            log_probs = log_probs * decoder_padding_mask # 遮罩掉為[END] or [STOP]不計算損失           #Not considering sampled words with padding mask = 0\n",
    "            lens = T.sum(decoder_padding_mask, dim=1) # 計算每個sample words生成的總長度               #Length of sampled sentence\n",
    "            log_probs = T.sum(log_probs, dim=1) / lens  # 計算平均的每個句子的log loss # (bs,1)        #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy() # 取出每個sample sentence 的word id list\n",
    "            S = output2words(id_list, vocab, batch.art_oovs[i]) #Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:          #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "        return decoded_strs, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_RL(model, config, batch):\n",
    "    # Self-Critical sequence training(SCST)\n",
    "    sample_sents, RL_log_probs = RL(model, config, batch, greedy=False)   # multinomial sampling\n",
    "    with T.autograd.no_grad():        \n",
    "        greedy_sents, _ = RL(model, config, batch, greedy=True)  # greedy sampling\n",
    "\n",
    "    sample_reward = reward_function(sample_sents, batch.original_abstract) # r(w^s):通过根据概率来随机sample词生成句子的reward值\n",
    "    baseline_reward = reward_function(greedy_sents, batch.original_abstract) # r(w^):测试阶段使用greedy decoding取概率最大的词来生成句子的reward值\n",
    "\n",
    "    batch_reward = T.mean(sample_reward).item()\n",
    "    #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "    rl_loss = -(sample_reward - baseline_reward) * RL_log_probs  # SCST梯度計算公式     \n",
    "    rl_loss = T.mean(rl_loss)  \n",
    "    '''\n",
    "    公式的意思就是：对于如果当前sample到的词比测试阶段生成的词好，那么在这次词的维度上，整个式子的值就是负的（因为后面那一项一定为负），\n",
    "    这样梯度就会上升，从而提高这个词的分数st；而对于其他词，后面那一项为正，梯度就会下降，从而降低其他词的分数\n",
    "    '''                 \n",
    "    return rl_loss, batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 15:44:48 - Pointer_generator_FastText_Intra_Atten - INFO: - ------Training START--------\n",
      "I0414 15:44:48.975535 140122325395264 <ipython-input-11-2ac8b23ec35d>:2] ------Training START--------\n",
      "2020-04-14 15:55:28 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 1000, training batch loss = 3.700423, running_avg_loss loss = 3.700423, validation loss = 4.032388\n",
      "I0414 15:55:28.117088 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 1000, training batch loss = 3.700423, running_avg_loss loss = 3.700423, validation loss = 4.032388\n",
      "2020-04-14 15:55:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 1000, train_rouge_l_f = 0.326313, test_rouge_l_f = 0.274836\n",
      "I0414 15:55:36.695621 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 1000, train_rouge_l_f = 0.326313, test_rouge_l_f = 0.274836\n",
      "2020-04-14 16:06:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 2000, training batch loss = 3.067930, running_avg_loss loss = 3.694098, validation loss = 3.562637\n",
      "I0414 16:06:19.874293 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 2000, training batch loss = 3.067930, running_avg_loss loss = 3.694098, validation loss = 3.562637\n",
      "2020-04-14 16:06:35 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 2000, train_rouge_l_f = 0.443565, test_rouge_l_f = 0.184961\n",
      "I0414 16:06:35.381519 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 2000, train_rouge_l_f = 0.443565, test_rouge_l_f = 0.184961\n",
      "2020-04-14 16:17:17 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 3000, training batch loss = 3.025420, running_avg_loss loss = 3.687411, validation loss = 3.341888\n",
      "I0414 16:17:17.096156 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 3000, training batch loss = 3.025420, running_avg_loss loss = 3.687411, validation loss = 3.341888\n",
      "2020-04-14 16:17:25 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 3000, train_rouge_l_f = 0.328396, test_rouge_l_f = 0.254051\n",
      "I0414 16:17:25.811821 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 3000, train_rouge_l_f = 0.328396, test_rouge_l_f = 0.254051\n",
      "2020-04-14 16:28:03 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 4000, training batch loss = 3.310168, running_avg_loss loss = 3.683639, validation loss = 3.232322\n",
      "I0414 16:28:03.454324 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 4000, training batch loss = 3.310168, running_avg_loss loss = 3.683639, validation loss = 3.232322\n",
      "2020-04-14 16:28:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 4000, train_rouge_l_f = 0.190987, test_rouge_l_f = 0.121721\n",
      "I0414 16:28:13.636102 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 4000, train_rouge_l_f = 0.190987, test_rouge_l_f = 0.121721\n",
      "2020-04-14 16:38:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 5000, training batch loss = 3.258047, running_avg_loss loss = 3.679383, validation loss = 3.165454\n",
      "I0414 16:38:56.507697 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 5000, training batch loss = 3.258047, running_avg_loss loss = 3.679383, validation loss = 3.165454\n",
      "2020-04-14 16:38:56 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 5000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0005000.tar...\n",
      "I0414 16:38:56.509649 140122325395264 initialize.py:225] Saving model step 5000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0005000.tar...\n",
      "2020-04-14 16:38:58 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 5000, train_rouge_l_f = 0.348810, test_rouge_l_f = 0.643184\n",
      "I0414 16:38:58.537941 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 5000, train_rouge_l_f = 0.348810, test_rouge_l_f = 0.643184\n",
      "2020-04-14 16:49:43 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 6000, training batch loss = 2.250496, running_avg_loss loss = 3.665094, validation loss = 3.073654\n",
      "I0414 16:49:43.428370 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 6000, training batch loss = 2.250496, running_avg_loss loss = 3.665094, validation loss = 3.073654\n",
      "2020-04-14 16:49:51 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 6000, train_rouge_l_f = 0.569405, test_rouge_l_f = 0.284338\n",
      "I0414 16:49:51.891212 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 6000, train_rouge_l_f = 0.569405, test_rouge_l_f = 0.284338\n",
      "2020-04-14 17:00:35 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 7000, training batch loss = 3.286436, running_avg_loss loss = 3.661307, validation loss = 3.024178\n",
      "I0414 17:00:35.949529 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 7000, training batch loss = 3.286436, running_avg_loss loss = 3.661307, validation loss = 3.024178\n",
      "2020-04-14 17:00:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 7000, train_rouge_l_f = 0.318123, test_rouge_l_f = 0.599446\n",
      "I0414 17:00:40.563965 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 7000, train_rouge_l_f = 0.318123, test_rouge_l_f = 0.599446\n",
      "2020-04-14 17:11:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 8000, training batch loss = 2.834282, running_avg_loss loss = 3.653037, validation loss = 2.992452\n",
      "I0414 17:11:19.830134 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 8000, training batch loss = 2.834282, running_avg_loss loss = 3.653037, validation loss = 2.992452\n",
      "2020-04-14 17:11:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 8000, train_rouge_l_f = 0.527856, test_rouge_l_f = 0.824279\n",
      "I0414 17:11:22.282077 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 8000, train_rouge_l_f = 0.527856, test_rouge_l_f = 0.824279\n",
      "2020-04-14 17:21:55 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 9000, training batch loss = 2.384845, running_avg_loss loss = 3.640355, validation loss = 2.961546\n",
      "I0414 17:21:55.664594 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 9000, training batch loss = 2.384845, running_avg_loss loss = 3.640355, validation loss = 2.961546\n",
      "2020-04-14 17:22:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 9000, train_rouge_l_f = 0.428330, test_rouge_l_f = 0.288827\n",
      "I0414 17:22:05.727704 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 9000, train_rouge_l_f = 0.428330, test_rouge_l_f = 0.288827\n",
      "2020-04-14 17:32:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 10000, training batch loss = 3.837723, running_avg_loss loss = 3.642329, validation loss = 2.932536\n",
      "I0414 17:32:36.529457 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 10000, training batch loss = 3.837723, running_avg_loss loss = 3.642329, validation loss = 2.932536\n",
      "2020-04-14 17:32:36 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 10000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0010000.tar...\n",
      "I0414 17:32:36.532016 140122325395264 initialize.py:225] Saving model step 10000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0010000.tar...\n",
      "2020-04-14 17:32:47 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 10000, train_rouge_l_f = 0.288763, test_rouge_l_f = 0.135315\n",
      "I0414 17:32:47.311506 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 10000, train_rouge_l_f = 0.288763, test_rouge_l_f = 0.135315\n",
      "2020-04-14 17:43:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 11000, training batch loss = 3.088561, running_avg_loss loss = 3.636791, validation loss = 2.904096\n",
      "I0414 17:43:19.183764 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 11000, training batch loss = 3.088561, running_avg_loss loss = 3.636791, validation loss = 2.904096\n",
      "2020-04-14 17:43:32 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 11000, train_rouge_l_f = 0.410305, test_rouge_l_f = 0.188035\n",
      "I0414 17:43:32.833380 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 11000, train_rouge_l_f = 0.410305, test_rouge_l_f = 0.188035\n",
      "2020-04-14 17:54:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 12000, training batch loss = 2.888797, running_avg_loss loss = 3.629311, validation loss = 2.895642\n",
      "I0414 17:54:13.066899 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 12000, training batch loss = 2.888797, running_avg_loss loss = 3.629311, validation loss = 2.895642\n",
      "2020-04-14 17:54:14 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 12000, train_rouge_l_f = 0.527106, test_rouge_l_f = 0.861692\n",
      "I0414 17:54:14.325960 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 12000, train_rouge_l_f = 0.527106, test_rouge_l_f = 0.861692\n",
      "2020-04-14 18:04:43 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 13000, training batch loss = 1.777686, running_avg_loss loss = 3.610795, validation loss = 2.870845\n",
      "I0414 18:04:43.274406 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 13000, training batch loss = 1.777686, running_avg_loss loss = 3.610795, validation loss = 2.870845\n",
      "2020-04-14 18:04:54 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 13000, train_rouge_l_f = 0.667971, test_rouge_l_f = 0.146164\n",
      "I0414 18:04:54.955221 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 13000, train_rouge_l_f = 0.667971, test_rouge_l_f = 0.146164\n",
      "2020-04-14 18:15:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 14000, training batch loss = 2.429003, running_avg_loss loss = 3.598977, validation loss = 2.849531\n",
      "I0414 18:15:30.482595 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 14000, training batch loss = 2.429003, running_avg_loss loss = 3.598977, validation loss = 2.849531\n",
      "2020-04-14 18:15:41 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 14000, train_rouge_l_f = 0.399480, test_rouge_l_f = 0.244467\n",
      "I0414 18:15:41.976068 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 14000, train_rouge_l_f = 0.399480, test_rouge_l_f = 0.244467\n",
      "2020-04-14 18:26:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 15000, training batch loss = 3.351235, running_avg_loss loss = 3.596500, validation loss = 2.823883\n",
      "I0414 18:26:04.892698 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 15000, training batch loss = 3.351235, running_avg_loss loss = 3.596500, validation loss = 2.823883\n",
      "2020-04-14 18:26:04 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 15000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0015000.tar...\n",
      "I0414 18:26:04.895337 140122325395264 initialize.py:225] Saving model step 15000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0015000.tar...\n",
      "2020-04-14 18:26:07 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 15000, train_rouge_l_f = 0.350031, test_rouge_l_f = 0.542094\n",
      "I0414 18:26:07.588542 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 15000, train_rouge_l_f = 0.350031, test_rouge_l_f = 0.542094\n",
      "2020-04-14 18:36:39 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 16000, training batch loss = 2.572422, running_avg_loss loss = 3.586259, validation loss = 2.814905\n",
      "I0414 18:36:39.259306 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 16000, training batch loss = 2.572422, running_avg_loss loss = 3.586259, validation loss = 2.814905\n",
      "2020-04-14 18:36:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 16000, train_rouge_l_f = 0.430400, test_rouge_l_f = 0.687142\n",
      "I0414 18:36:40.499212 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 16000, train_rouge_l_f = 0.430400, test_rouge_l_f = 0.687142\n",
      "2020-04-14 18:47:11 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 17000, training batch loss = 3.565994, running_avg_loss loss = 3.586056, validation loss = 2.794435\n",
      "I0414 18:47:11.996563 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 17000, training batch loss = 3.565994, running_avg_loss loss = 3.586056, validation loss = 2.794435\n",
      "2020-04-14 18:47:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 17000, train_rouge_l_f = 0.321414, test_rouge_l_f = 0.338016\n",
      "I0414 18:47:19.017200 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 17000, train_rouge_l_f = 0.321414, test_rouge_l_f = 0.338016\n",
      "2020-04-14 18:57:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 18000, training batch loss = 2.940698, running_avg_loss loss = 3.579603, validation loss = 2.787336\n",
      "I0414 18:57:49.628655 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 18000, training batch loss = 2.940698, running_avg_loss loss = 3.579603, validation loss = 2.787336\n",
      "2020-04-14 18:57:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 18000, train_rouge_l_f = 0.497318, test_rouge_l_f = 0.238422\n",
      "I0414 18:57:56.922235 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 18000, train_rouge_l_f = 0.497318, test_rouge_l_f = 0.238422\n",
      "2020-04-14 19:08:23 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 19000, training batch loss = 2.269442, running_avg_loss loss = 3.566501, validation loss = 2.769426\n",
      "I0414 19:08:23.579566 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 19000, training batch loss = 2.269442, running_avg_loss loss = 3.566501, validation loss = 2.769426\n",
      "2020-04-14 19:08:28 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 19000, train_rouge_l_f = 0.476217, test_rouge_l_f = 0.415796\n",
      "I0414 19:08:28.217918 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 19000, train_rouge_l_f = 0.476217, test_rouge_l_f = 0.415796\n",
      "2020-04-14 19:18:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 20000, training batch loss = 2.202602, running_avg_loss loss = 3.552862, validation loss = 2.761258\n",
      "I0414 19:18:52.741222 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 20000, training batch loss = 2.202602, running_avg_loss loss = 3.552862, validation loss = 2.761258\n",
      "2020-04-14 19:18:52 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 20000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0020000.tar...\n",
      "I0414 19:18:52.743831 140122325395264 initialize.py:225] Saving model step 20000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0020000.tar...\n",
      "2020-04-14 19:19:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 20000, train_rouge_l_f = 0.669248, test_rouge_l_f = 0.288243\n",
      "I0414 19:19:04.622218 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 20000, train_rouge_l_f = 0.669248, test_rouge_l_f = 0.288243\n",
      "2020-04-14 19:29:32 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 21000, training batch loss = 3.008939, running_avg_loss loss = 3.547423, validation loss = 2.749662\n",
      "I0414 19:29:32.987779 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 21000, training batch loss = 3.008939, running_avg_loss loss = 3.547423, validation loss = 2.749662\n",
      "2020-04-14 19:29:34 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 21000, train_rouge_l_f = 0.261678, test_rouge_l_f = 0.647994\n",
      "I0414 19:29:34.326016 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 21000, train_rouge_l_f = 0.261678, test_rouge_l_f = 0.647994\n",
      "2020-04-14 19:40:34 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 22000, training batch loss = 2.487706, running_avg_loss loss = 3.536826, validation loss = 2.734104\n",
      "I0414 19:40:34.909357 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 22000, training batch loss = 2.487706, running_avg_loss loss = 3.536826, validation loss = 2.734104\n",
      "2020-04-14 19:40:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 22000, train_rouge_l_f = 0.440589, test_rouge_l_f = 0.315806\n",
      "I0414 19:40:40.449193 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 22000, train_rouge_l_f = 0.440589, test_rouge_l_f = 0.315806\n",
      "2020-04-14 19:51:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 23000, training batch loss = 1.027203, running_avg_loss loss = 3.511730, validation loss = 2.723354\n",
      "I0414 19:51:05.124951 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 23000, training batch loss = 1.027203, running_avg_loss loss = 3.511730, validation loss = 2.723354\n",
      "2020-04-14 19:51:10 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 23000, train_rouge_l_f = 0.668600, test_rouge_l_f = 0.311270\n",
      "I0414 19:51:10.613281 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 23000, train_rouge_l_f = 0.668600, test_rouge_l_f = 0.311270\n",
      "2020-04-14 20:01:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 24000, training batch loss = 2.453714, running_avg_loss loss = 3.501149, validation loss = 2.731385\n",
      "I0414 20:01:36.860326 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 24000, training batch loss = 2.453714, running_avg_loss loss = 3.501149, validation loss = 2.731385\n",
      "2020-04-14 20:01:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 24000, train_rouge_l_f = 0.471336, test_rouge_l_f = 0.511876\n",
      "I0414 20:01:40.496907 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 24000, train_rouge_l_f = 0.471336, test_rouge_l_f = 0.511876\n",
      "2020-04-14 20:12:11 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 25000, training batch loss = 3.136842, running_avg_loss loss = 3.497506, validation loss = 2.708957\n",
      "I0414 20:12:11.963340 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 25000, training batch loss = 3.136842, running_avg_loss loss = 3.497506, validation loss = 2.708957\n",
      "2020-04-14 20:12:11 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 25000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0025000.tar...\n",
      "I0414 20:12:11.966585 140122325395264 initialize.py:225] Saving model step 25000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0025000.tar...\n",
      "2020-04-14 20:12:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 25000, train_rouge_l_f = 0.384005, test_rouge_l_f = 0.705920\n",
      "I0414 20:12:13.995309 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 25000, train_rouge_l_f = 0.384005, test_rouge_l_f = 0.705920\n",
      "2020-04-14 20:22:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 26000, training batch loss = 2.179371, running_avg_loss loss = 3.484325, validation loss = 2.700802\n",
      "I0414 20:22:52.386948 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 26000, training batch loss = 2.179371, running_avg_loss loss = 3.484325, validation loss = 2.700802\n",
      "2020-04-14 20:23:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 26000, train_rouge_l_f = 0.388530, test_rouge_l_f = 0.451393\n",
      "I0414 20:23:04.159291 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 26000, train_rouge_l_f = 0.388530, test_rouge_l_f = 0.451393\n",
      "2020-04-14 20:33:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 27000, training batch loss = 1.918583, running_avg_loss loss = 3.468668, validation loss = 2.702455\n",
      "I0414 20:33:56.785972 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 27000, training batch loss = 1.918583, running_avg_loss loss = 3.468668, validation loss = 2.702455\n",
      "2020-04-14 20:33:59 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 27000, train_rouge_l_f = 0.500002, test_rouge_l_f = 0.646533\n",
      "I0414 20:33:59.676620 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 27000, train_rouge_l_f = 0.500002, test_rouge_l_f = 0.646533\n",
      "2020-04-14 20:44:25 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 28000, training batch loss = 2.773985, running_avg_loss loss = 3.461721, validation loss = 2.688084\n",
      "I0414 20:44:25.778992 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 28000, training batch loss = 2.773985, running_avg_loss loss = 3.461721, validation loss = 2.688084\n",
      "2020-04-14 20:44:29 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 28000, train_rouge_l_f = 0.465008, test_rouge_l_f = 0.759773\n",
      "I0414 20:44:29.989890 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 28000, train_rouge_l_f = 0.465008, test_rouge_l_f = 0.759773\n",
      "2020-04-14 20:55:07 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 29000, training batch loss = 2.385686, running_avg_loss loss = 3.450960, validation loss = 2.673346\n",
      "I0414 20:55:07.134702 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 29000, training batch loss = 2.385686, running_avg_loss loss = 3.450960, validation loss = 2.673346\n",
      "2020-04-14 20:55:11 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 29000, train_rouge_l_f = 0.496262, test_rouge_l_f = 0.479194\n",
      "I0414 20:55:11.924828 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 29000, train_rouge_l_f = 0.496262, test_rouge_l_f = 0.479194\n",
      "2020-04-14 21:06:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 30000, training batch loss = 1.813506, running_avg_loss loss = 3.434586, validation loss = 2.687032\n",
      "I0414 21:06:04.445885 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 30000, training batch loss = 1.813506, running_avg_loss loss = 3.434586, validation loss = 2.687032\n",
      "2020-04-14 21:06:04 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 30000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0030000.tar...\n",
      "I0414 21:06:04.448493 140122325395264 initialize.py:225] Saving model step 30000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0030000.tar...\n",
      "2020-04-14 21:06:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 30000, train_rouge_l_f = 0.497894, test_rouge_l_f = 0.499646\n",
      "I0414 21:06:13.252896 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 30000, train_rouge_l_f = 0.497894, test_rouge_l_f = 0.499646\n",
      "2020-04-14 21:16:54 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 31000, training batch loss = 2.091586, running_avg_loss loss = 3.421156, validation loss = 2.658894\n",
      "I0414 21:16:54.909549 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 31000, training batch loss = 2.091586, running_avg_loss loss = 3.421156, validation loss = 2.658894\n",
      "2020-04-14 21:16:59 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 31000, train_rouge_l_f = 0.526502, test_rouge_l_f = 0.413886\n",
      "I0414 21:16:59.825206 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 31000, train_rouge_l_f = 0.526502, test_rouge_l_f = 0.413886\n",
      "2020-04-14 21:27:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 32000, training batch loss = 2.770202, running_avg_loss loss = 3.414646, validation loss = 2.656566\n",
      "I0414 21:27:30.453100 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 32000, training batch loss = 2.770202, running_avg_loss loss = 3.414646, validation loss = 2.656566\n",
      "2020-04-14 21:27:43 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 32000, train_rouge_l_f = 0.593354, test_rouge_l_f = 0.073737\n",
      "I0414 21:27:43.001329 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 32000, train_rouge_l_f = 0.593354, test_rouge_l_f = 0.073737\n",
      "2020-04-14 21:38:14 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 33000, training batch loss = 2.895934, running_avg_loss loss = 3.409459, validation loss = 2.649754\n",
      "I0414 21:38:14.354372 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 33000, training batch loss = 2.895934, running_avg_loss loss = 3.409459, validation loss = 2.649754\n",
      "2020-04-14 21:38:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 33000, train_rouge_l_f = 0.522710, test_rouge_l_f = 0.468991\n",
      "I0414 21:38:22.000263 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 33000, train_rouge_l_f = 0.522710, test_rouge_l_f = 0.468991\n",
      "2020-04-14 21:48:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 34000, training batch loss = 2.002759, running_avg_loss loss = 3.395392, validation loss = 2.643728\n",
      "I0414 21:48:52.359307 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 34000, training batch loss = 2.002759, running_avg_loss loss = 3.395392, validation loss = 2.643728\n",
      "2020-04-14 21:49:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 34000, train_rouge_l_f = 0.519469, test_rouge_l_f = 0.177739\n",
      "I0414 21:49:04.026249 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 34000, train_rouge_l_f = 0.519469, test_rouge_l_f = 0.177739\n",
      "2020-04-14 21:59:41 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 35000, training batch loss = 2.154672, running_avg_loss loss = 3.382985, validation loss = 2.639445\n",
      "I0414 21:59:41.939026 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 35000, training batch loss = 2.154672, running_avg_loss loss = 3.382985, validation loss = 2.639445\n",
      "2020-04-14 21:59:41 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 35000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0035000.tar...\n",
      "I0414 21:59:41.942099 140122325395264 initialize.py:225] Saving model step 35000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0035000.tar...\n",
      "2020-04-14 21:59:54 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 35000, train_rouge_l_f = 0.519905, test_rouge_l_f = 0.267395\n",
      "I0414 21:59:54.274324 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 35000, train_rouge_l_f = 0.519905, test_rouge_l_f = 0.267395\n",
      "2020-04-14 22:10:27 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 36000, training batch loss = 2.019283, running_avg_loss loss = 3.369348, validation loss = 2.635671\n",
      "I0414 22:10:27.775486 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 36000, training batch loss = 2.019283, running_avg_loss loss = 3.369348, validation loss = 2.635671\n",
      "2020-04-14 22:10:37 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 36000, train_rouge_l_f = 0.521927, test_rouge_l_f = 0.316688\n",
      "I0414 22:10:37.162490 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 36000, train_rouge_l_f = 0.521927, test_rouge_l_f = 0.316688\n",
      "2020-04-14 22:21:14 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 37000, training batch loss = 2.132838, running_avg_loss loss = 3.356983, validation loss = 2.625293\n",
      "I0414 22:21:14.587180 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 37000, training batch loss = 2.132838, running_avg_loss loss = 3.356983, validation loss = 2.625293\n",
      "2020-04-14 22:21:27 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 37000, train_rouge_l_f = 0.475523, test_rouge_l_f = 0.147902\n",
      "I0414 22:21:27.443605 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 37000, train_rouge_l_f = 0.475523, test_rouge_l_f = 0.147902\n",
      "2020-04-14 22:31:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 38000, training batch loss = 2.016916, running_avg_loss loss = 3.343582, validation loss = 2.635296\n",
      "I0414 22:31:56.718225 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 38000, training batch loss = 2.016916, running_avg_loss loss = 3.343582, validation loss = 2.635296\n",
      "2020-04-14 22:32:10 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 38000, train_rouge_l_f = 0.512659, test_rouge_l_f = 0.193047\n",
      "I0414 22:32:10.175643 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 38000, train_rouge_l_f = 0.512659, test_rouge_l_f = 0.193047\n",
      "2020-04-14 22:42:41 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 39000, training batch loss = 2.714736, running_avg_loss loss = 3.337294, validation loss = 2.617320\n",
      "I0414 22:42:41.109485 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 39000, training batch loss = 2.714736, running_avg_loss loss = 3.337294, validation loss = 2.617320\n",
      "2020-04-14 22:42:50 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 39000, train_rouge_l_f = 0.309646, test_rouge_l_f = 0.204252\n",
      "I0414 22:42:50.360285 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 39000, train_rouge_l_f = 0.309646, test_rouge_l_f = 0.204252\n",
      "2020-04-14 22:53:20 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 40000, training batch loss = 2.339951, running_avg_loss loss = 3.327320, validation loss = 2.614461\n",
      "I0414 22:53:20.869368 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 40000, training batch loss = 2.339951, running_avg_loss loss = 3.327320, validation loss = 2.614461\n",
      "2020-04-14 22:53:20 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 40000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0040000.tar...\n",
      "I0414 22:53:20.872295 140122325395264 initialize.py:225] Saving model step 40000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0040000.tar...\n",
      "2020-04-14 22:53:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 40000, train_rouge_l_f = 0.372020, test_rouge_l_f = 0.213887\n",
      "I0414 22:53:30.515062 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 40000, train_rouge_l_f = 0.372020, test_rouge_l_f = 0.213887\n",
      "2020-04-14 23:04:07 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 41000, training batch loss = 3.715479, running_avg_loss loss = 3.331202, validation loss = 2.615456\n",
      "I0414 23:04:07.342651 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 41000, training batch loss = 3.715479, running_avg_loss loss = 3.331202, validation loss = 2.615456\n",
      "2020-04-14 23:04:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 41000, train_rouge_l_f = 0.259027, test_rouge_l_f = 0.179478\n",
      "I0414 23:04:19.723629 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 41000, train_rouge_l_f = 0.259027, test_rouge_l_f = 0.179478\n",
      "2020-04-14 23:14:43 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 42000, training batch loss = 2.933347, running_avg_loss loss = 3.327223, validation loss = 2.608829\n",
      "I0414 23:14:43.623577 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 42000, training batch loss = 2.933347, running_avg_loss loss = 3.327223, validation loss = 2.608829\n",
      "2020-04-14 23:14:48 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 42000, train_rouge_l_f = 0.427303, test_rouge_l_f = 0.363470\n",
      "I0414 23:14:48.809160 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 42000, train_rouge_l_f = 0.427303, test_rouge_l_f = 0.363470\n",
      "2020-04-14 23:25:47 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 43000, training batch loss = 1.034696, running_avg_loss loss = 3.304298, validation loss = 2.601306\n",
      "I0414 23:25:47.044664 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 43000, training batch loss = 1.034696, running_avg_loss loss = 3.304298, validation loss = 2.601306\n",
      "2020-04-14 23:25:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 43000, train_rouge_l_f = 0.753251, test_rouge_l_f = 0.292637\n",
      "I0414 23:25:56.678856 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 43000, train_rouge_l_f = 0.753251, test_rouge_l_f = 0.292637\n",
      "2020-04-14 23:36:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 44000, training batch loss = 2.862782, running_avg_loss loss = 3.299883, validation loss = 2.603563\n",
      "I0414 23:36:45.660783 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 44000, training batch loss = 2.862782, running_avg_loss loss = 3.299883, validation loss = 2.603563\n",
      "2020-04-14 23:36:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 44000, train_rouge_l_f = 0.395518, test_rouge_l_f = 0.528118\n",
      "I0414 23:36:49.106549 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 44000, train_rouge_l_f = 0.395518, test_rouge_l_f = 0.528118\n",
      "2020-04-14 23:47:37 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 45000, training batch loss = 2.299736, running_avg_loss loss = 3.289881, validation loss = 2.609281\n",
      "I0414 23:47:37.163140 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 45000, training batch loss = 2.299736, running_avg_loss loss = 3.289881, validation loss = 2.609281\n",
      "2020-04-14 23:47:37 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 45000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0045000.tar...\n",
      "I0414 23:47:37.165875 140122325395264 initialize.py:225] Saving model step 45000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0045000.tar...\n",
      "2020-04-14 23:47:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 45000, train_rouge_l_f = 0.478353, test_rouge_l_f = 0.054046\n",
      "I0414 23:47:52.091278 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 45000, train_rouge_l_f = 0.478353, test_rouge_l_f = 0.054046\n",
      "2020-04-14 23:58:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 46000, training batch loss = 2.718278, running_avg_loss loss = 3.284165, validation loss = 2.594667\n",
      "I0414 23:58:40.546971 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 46000, training batch loss = 2.718278, running_avg_loss loss = 3.284165, validation loss = 2.594667\n",
      "2020-04-14 23:58:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 46000, train_rouge_l_f = 0.482798, test_rouge_l_f = 0.431538\n",
      "I0414 23:58:49.292664 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 46000, train_rouge_l_f = 0.482798, test_rouge_l_f = 0.431538\n",
      "2020-04-15 00:09:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 47000, training batch loss = 2.174603, running_avg_loss loss = 3.273070, validation loss = 2.587821\n",
      "I0415 00:09:45.568362 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 47000, training batch loss = 2.174603, running_avg_loss loss = 3.273070, validation loss = 2.587821\n",
      "2020-04-15 00:09:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 47000, train_rouge_l_f = 0.640931, test_rouge_l_f = 0.401760\n",
      "I0415 00:09:52.134635 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 47000, train_rouge_l_f = 0.640931, test_rouge_l_f = 0.401760\n",
      "2020-04-15 00:20:31 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 48000, training batch loss = 2.774493, running_avg_loss loss = 3.268084, validation loss = 2.580007\n",
      "I0415 00:20:31.296277 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 48000, training batch loss = 2.774493, running_avg_loss loss = 3.268084, validation loss = 2.580007\n",
      "2020-04-15 00:20:37 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 48000, train_rouge_l_f = 0.460337, test_rouge_l_f = 0.504508\n",
      "I0415 00:20:37.527356 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 48000, train_rouge_l_f = 0.460337, test_rouge_l_f = 0.504508\n",
      "2020-04-15 00:31:09 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 49000, training batch loss = 2.422728, running_avg_loss loss = 3.259630, validation loss = 2.580533\n",
      "I0415 00:31:09.726199 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 49000, training batch loss = 2.422728, running_avg_loss loss = 3.259630, validation loss = 2.580533\n",
      "2020-04-15 00:31:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 49000, train_rouge_l_f = 0.322328, test_rouge_l_f = 0.193467\n",
      "I0415 00:31:19.852406 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 49000, train_rouge_l_f = 0.322328, test_rouge_l_f = 0.193467\n",
      "2020-04-15 00:41:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 50000, training batch loss = 1.546175, running_avg_loss loss = 3.242496, validation loss = 2.576206\n",
      "I0415 00:41:56.438323 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 50000, training batch loss = 1.546175, running_avg_loss loss = 3.242496, validation loss = 2.576206\n",
      "2020-04-15 00:41:56 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 50000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0050000.tar...\n",
      "I0415 00:41:56.440794 140122325395264 initialize.py:225] Saving model step 50000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0050000.tar...\n",
      "2020-04-15 00:42:01 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 50000, train_rouge_l_f = 0.683741, test_rouge_l_f = 0.663318\n",
      "I0415 00:42:01.506177 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 50000, train_rouge_l_f = 0.683741, test_rouge_l_f = 0.663318\n",
      "2020-04-15 00:52:42 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 51000, training batch loss = 3.190288, running_avg_loss loss = 3.241974, validation loss = 2.577798\n",
      "I0415 00:52:42.062053 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 51000, training batch loss = 3.190288, running_avg_loss loss = 3.241974, validation loss = 2.577798\n",
      "2020-04-15 00:52:53 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 51000, train_rouge_l_f = 0.326121, test_rouge_l_f = 0.231320\n",
      "I0415 00:52:53.689227 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 51000, train_rouge_l_f = 0.326121, test_rouge_l_f = 0.231320\n",
      "2020-04-15 01:03:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 52000, training batch loss = 1.922616, running_avg_loss loss = 3.228780, validation loss = 2.577981\n",
      "I0415 01:03:30.909390 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 52000, training batch loss = 1.922616, running_avg_loss loss = 3.228780, validation loss = 2.577981\n",
      "2020-04-15 01:03:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 52000, train_rouge_l_f = 0.493326, test_rouge_l_f = 0.450546\n",
      "I0415 01:03:38.970114 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 52000, train_rouge_l_f = 0.493326, test_rouge_l_f = 0.450546\n",
      "2020-04-15 01:14:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 53000, training batch loss = 2.652678, running_avg_loss loss = 3.223019, validation loss = 2.564073\n",
      "I0415 01:14:22.721012 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 53000, training batch loss = 2.652678, running_avg_loss loss = 3.223019, validation loss = 2.564073\n",
      "2020-04-15 01:14:24 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 53000, train_rouge_l_f = 0.292416, test_rouge_l_f = 0.808733\n",
      "I0415 01:14:24.846000 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 53000, train_rouge_l_f = 0.292416, test_rouge_l_f = 0.808733\n",
      "2020-04-15 01:25:07 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 54000, training batch loss = 1.714003, running_avg_loss loss = 3.207929, validation loss = 2.568769\n",
      "I0415 01:25:07.038184 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 54000, training batch loss = 1.714003, running_avg_loss loss = 3.207929, validation loss = 2.568769\n",
      "2020-04-15 01:25:09 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 54000, train_rouge_l_f = 0.636777, test_rouge_l_f = 0.704864\n",
      "I0415 01:25:09.328892 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 54000, train_rouge_l_f = 0.636777, test_rouge_l_f = 0.704864\n",
      "2020-04-15 01:35:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 55000, training batch loss = 1.971014, running_avg_loss loss = 3.195560, validation loss = 2.570012\n",
      "I0415 01:35:56.066651 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 55000, training batch loss = 1.971014, running_avg_loss loss = 3.195560, validation loss = 2.570012\n",
      "2020-04-15 01:35:56 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 55000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0055000.tar...\n",
      "I0415 01:35:56.068457 140122325395264 initialize.py:225] Saving model step 55000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0055000.tar...\n",
      "2020-04-15 01:36:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 55000, train_rouge_l_f = 0.576229, test_rouge_l_f = 0.392395\n",
      "I0415 01:36:04.872634 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 55000, train_rouge_l_f = 0.576229, test_rouge_l_f = 0.392395\n",
      "2020-04-15 01:46:50 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 56000, training batch loss = 2.204722, running_avg_loss loss = 3.185651, validation loss = 2.568408\n",
      "I0415 01:46:50.865008 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 56000, training batch loss = 2.204722, running_avg_loss loss = 3.185651, validation loss = 2.568408\n",
      "2020-04-15 01:46:53 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 56000, train_rouge_l_f = 0.484234, test_rouge_l_f = 0.724993\n",
      "I0415 01:46:53.021077 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 56000, train_rouge_l_f = 0.484234, test_rouge_l_f = 0.724993\n",
      "2020-04-15 01:57:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 57000, training batch loss = 2.818650, running_avg_loss loss = 3.181981, validation loss = 2.559021\n",
      "I0415 01:57:38.028142 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 57000, training batch loss = 2.818650, running_avg_loss loss = 3.181981, validation loss = 2.559021\n",
      "2020-04-15 01:57:44 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 57000, train_rouge_l_f = 0.341362, test_rouge_l_f = 0.404283\n",
      "I0415 01:57:44.919541 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 57000, train_rouge_l_f = 0.341362, test_rouge_l_f = 0.404283\n",
      "2020-04-15 02:08:27 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 58000, training batch loss = 2.150445, running_avg_loss loss = 3.171666, validation loss = 2.557674\n",
      "I0415 02:08:27.184278 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 58000, training batch loss = 2.150445, running_avg_loss loss = 3.171666, validation loss = 2.557674\n",
      "2020-04-15 02:08:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 58000, train_rouge_l_f = 0.607880, test_rouge_l_f = 0.322028\n",
      "I0415 02:08:38.252778 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 58000, train_rouge_l_f = 0.607880, test_rouge_l_f = 0.322028\n",
      "2020-04-15 02:19:11 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 59000, training batch loss = 3.259830, running_avg_loss loss = 3.172548, validation loss = 2.559809\n",
      "I0415 02:19:11.566536 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 59000, training batch loss = 3.259830, running_avg_loss loss = 3.172548, validation loss = 2.559809\n",
      "2020-04-15 02:19:28 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 59000, train_rouge_l_f = 0.323287, test_rouge_l_f = 0.268714\n",
      "I0415 02:19:28.806593 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 59000, train_rouge_l_f = 0.323287, test_rouge_l_f = 0.268714\n",
      "2020-04-15 02:30:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 60000, training batch loss = 2.295190, running_avg_loss loss = 3.163774, validation loss = 2.544820\n",
      "I0415 02:30:04.108617 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 60000, training batch loss = 2.295190, running_avg_loss loss = 3.163774, validation loss = 2.544820\n",
      "2020-04-15 02:30:04 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 60000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0060000.tar...\n",
      "I0415 02:30:04.111750 140122325395264 initialize.py:225] Saving model step 60000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0060000.tar...\n",
      "2020-04-15 02:30:09 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 60000, train_rouge_l_f = 0.380164, test_rouge_l_f = 0.537392\n",
      "I0415 02:30:09.929315 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 60000, train_rouge_l_f = 0.380164, test_rouge_l_f = 0.537392\n",
      "2020-04-15 02:40:53 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 61000, training batch loss = 1.667933, running_avg_loss loss = 3.148816, validation loss = 2.542068\n",
      "I0415 02:40:53.214531 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 61000, training batch loss = 1.667933, running_avg_loss loss = 3.148816, validation loss = 2.542068\n",
      "2020-04-15 02:41:03 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 61000, train_rouge_l_f = 0.546918, test_rouge_l_f = 0.500530\n",
      "I0415 02:41:03.851684 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 61000, train_rouge_l_f = 0.546918, test_rouge_l_f = 0.500530\n",
      "2020-04-15 02:51:48 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 62000, training batch loss = 3.557278, running_avg_loss loss = 3.152900, validation loss = 2.536957\n",
      "I0415 02:51:48.387080 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 62000, training batch loss = 3.557278, running_avg_loss loss = 3.152900, validation loss = 2.536957\n",
      "2020-04-15 02:51:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 62000, train_rouge_l_f = 0.495487, test_rouge_l_f = 0.137164\n",
      "I0415 02:51:56.067379 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 62000, train_rouge_l_f = 0.495487, test_rouge_l_f = 0.137164\n",
      "2020-04-15 03:02:37 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 63000, training batch loss = 2.631787, running_avg_loss loss = 3.147689, validation loss = 2.542577\n",
      "I0415 03:02:37.799640 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 0: 63000, training batch loss = 2.631787, running_avg_loss loss = 3.147689, validation loss = 2.542577\n",
      "2020-04-15 03:02:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 63000, train_rouge_l_f = 0.509723, test_rouge_l_f = 0.628292\n",
      "I0415 03:02:38.813225 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 0: 63000, train_rouge_l_f = 0.509723, test_rouge_l_f = 0.628292\n",
      "2020-04-15 14:39:27 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 0: 63010, test_avg_acc = 0.443298, test_avg_acc = 0.440927\n",
      "I0415 14:39:27.233246 140122325395264 <ipython-input-11-2ac8b23ec35d>:72] epoch 0: 63010, test_avg_acc = 0.443298, test_avg_acc = 0.440927\n",
      "2020-04-15 14:50:01 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 64000, training batch loss = 1.527370, running_avg_loss loss = 3.131486, validation loss = 2.537527\n",
      "I0415 14:50:01.823611 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 64000, training batch loss = 1.527370, running_avg_loss loss = 3.131486, validation loss = 2.537527\n",
      "2020-04-15 14:50:10 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 64000, train_rouge_l_f = 0.699438, test_rouge_l_f = 0.475701\n",
      "I0415 14:50:10.990290 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 64000, train_rouge_l_f = 0.699438, test_rouge_l_f = 0.475701\n",
      "2020-04-15 15:01:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 65000, training batch loss = 1.807153, running_avg_loss loss = 3.118243, validation loss = 2.535765\n",
      "I0415 15:01:04.792439 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 65000, training batch loss = 1.807153, running_avg_loss loss = 3.118243, validation loss = 2.535765\n",
      "2020-04-15 15:01:04 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 65000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0065000.tar...\n",
      "I0415 15:01:04.795125 140122325395264 initialize.py:225] Saving model step 65000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0065000.tar...\n",
      "2020-04-15 15:01:09 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 65000, train_rouge_l_f = 0.617701, test_rouge_l_f = 0.443533\n",
      "I0415 15:01:09.564557 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 65000, train_rouge_l_f = 0.617701, test_rouge_l_f = 0.443533\n",
      "2020-04-15 15:11:40 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 66000, training batch loss = 3.112923, running_avg_loss loss = 3.118190, validation loss = 2.532523\n",
      "I0415 15:11:40.037302 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 66000, training batch loss = 3.112923, running_avg_loss loss = 3.118190, validation loss = 2.532523\n",
      "2020-04-15 15:11:48 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 66000, train_rouge_l_f = 0.237511, test_rouge_l_f = 0.294798\n",
      "I0415 15:11:48.231399 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 66000, train_rouge_l_f = 0.237511, test_rouge_l_f = 0.294798\n",
      "2020-04-15 15:22:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 67000, training batch loss = 3.481249, running_avg_loss loss = 3.121820, validation loss = 2.531219\n",
      "I0415 15:22:13.868248 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 67000, training batch loss = 3.481249, running_avg_loss loss = 3.121820, validation loss = 2.531219\n",
      "2020-04-15 15:22:17 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 67000, train_rouge_l_f = 0.301734, test_rouge_l_f = 0.461641\n",
      "I0415 15:22:17.777936 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 67000, train_rouge_l_f = 0.301734, test_rouge_l_f = 0.461641\n",
      "2020-04-15 15:32:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 68000, training batch loss = 2.750279, running_avg_loss loss = 3.118105, validation loss = 2.530531\n",
      "I0415 15:32:49.295740 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 68000, training batch loss = 2.750279, running_avg_loss loss = 3.118105, validation loss = 2.530531\n",
      "2020-04-15 15:32:59 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 68000, train_rouge_l_f = 0.372003, test_rouge_l_f = 0.103417\n",
      "I0415 15:32:59.144420 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 68000, train_rouge_l_f = 0.372003, test_rouge_l_f = 0.103417\n",
      "2020-04-15 15:43:28 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 69000, training batch loss = 2.718658, running_avg_loss loss = 3.114110, validation loss = 2.526646\n",
      "I0415 15:43:28.088556 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 69000, training batch loss = 2.718658, running_avg_loss loss = 3.114110, validation loss = 2.526646\n",
      "2020-04-15 15:43:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 69000, train_rouge_l_f = 0.567122, test_rouge_l_f = 0.601071\n",
      "I0415 15:43:30.545579 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 69000, train_rouge_l_f = 0.567122, test_rouge_l_f = 0.601071\n",
      "2020-04-15 15:53:58 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 70000, training batch loss = 2.078076, running_avg_loss loss = 3.103750, validation loss = 2.526824\n",
      "I0415 15:53:58.985372 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 70000, training batch loss = 2.078076, running_avg_loss loss = 3.103750, validation loss = 2.526824\n",
      "2020-04-15 15:53:58 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 70000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0070000.tar...\n",
      "I0415 15:53:58.987508 140122325395264 initialize.py:225] Saving model step 70000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0070000.tar...\n",
      "2020-04-15 15:54:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 70000, train_rouge_l_f = 0.475465, test_rouge_l_f = 0.295878\n",
      "I0415 15:54:05.466481 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 70000, train_rouge_l_f = 0.475465, test_rouge_l_f = 0.295878\n",
      "2020-04-15 16:04:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 71000, training batch loss = 2.384993, running_avg_loss loss = 3.096562, validation loss = 2.517554\n",
      "I0415 16:04:38.764506 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 71000, training batch loss = 2.384993, running_avg_loss loss = 3.096562, validation loss = 2.517554\n",
      "2020-04-15 16:04:43 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 71000, train_rouge_l_f = 0.384219, test_rouge_l_f = 0.676313\n",
      "I0415 16:04:43.487689 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 71000, train_rouge_l_f = 0.384219, test_rouge_l_f = 0.676313\n",
      "2020-04-15 16:15:16 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 72000, training batch loss = 3.128329, running_avg_loss loss = 3.096880, validation loss = 2.522551\n",
      "I0415 16:15:16.774455 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 72000, training batch loss = 3.128329, running_avg_loss loss = 3.096880, validation loss = 2.522551\n",
      "2020-04-15 16:15:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 72000, train_rouge_l_f = 0.393984, test_rouge_l_f = 0.389595\n",
      "I0415 16:15:22.376635 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 72000, train_rouge_l_f = 0.393984, test_rouge_l_f = 0.389595\n",
      "2020-04-15 16:25:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 73000, training batch loss = 3.621391, running_avg_loss loss = 3.102125, validation loss = 2.513297\n",
      "I0415 16:25:56.486247 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 73000, training batch loss = 3.621391, running_avg_loss loss = 3.102125, validation loss = 2.513297\n",
      "2020-04-15 16:26:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 73000, train_rouge_l_f = 0.270253, test_rouge_l_f = 0.375658\n",
      "I0415 16:26:05.112416 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 73000, train_rouge_l_f = 0.270253, test_rouge_l_f = 0.375658\n",
      "2020-04-15 16:36:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 74000, training batch loss = 2.986992, running_avg_loss loss = 3.100974, validation loss = 2.514560\n",
      "I0415 16:36:36.579261 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 74000, training batch loss = 2.986992, running_avg_loss loss = 3.100974, validation loss = 2.514560\n",
      "2020-04-15 16:36:46 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 74000, train_rouge_l_f = 0.481044, test_rouge_l_f = 0.203036\n",
      "I0415 16:36:46.830736 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 74000, train_rouge_l_f = 0.481044, test_rouge_l_f = 0.203036\n",
      "2020-04-15 16:47:14 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 75000, training batch loss = 2.941814, running_avg_loss loss = 3.099382, validation loss = 2.512055\n",
      "I0415 16:47:14.596692 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 75000, training batch loss = 2.941814, running_avg_loss loss = 3.099382, validation loss = 2.512055\n",
      "2020-04-15 16:47:14 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 75000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0075000.tar...\n",
      "I0415 16:47:14.599639 140122325395264 initialize.py:225] Saving model step 75000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0075000.tar...\n",
      "2020-04-15 16:47:18 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 75000, train_rouge_l_f = 0.253289, test_rouge_l_f = 0.754998\n",
      "I0415 16:47:18.739052 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 75000, train_rouge_l_f = 0.253289, test_rouge_l_f = 0.754998\n",
      "2020-04-15 16:57:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 76000, training batch loss = 2.615612, running_avg_loss loss = 3.094544, validation loss = 2.518859\n",
      "I0415 16:57:45.918480 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 76000, training batch loss = 2.615612, running_avg_loss loss = 3.094544, validation loss = 2.518859\n",
      "2020-04-15 16:57:50 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 76000, train_rouge_l_f = 0.457624, test_rouge_l_f = 0.796911\n",
      "I0415 16:57:50.417980 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 76000, train_rouge_l_f = 0.457624, test_rouge_l_f = 0.796911\n",
      "2020-04-15 17:08:24 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 77000, training batch loss = 2.156705, running_avg_loss loss = 3.085166, validation loss = 2.516456\n",
      "I0415 17:08:24.292390 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 77000, training batch loss = 2.156705, running_avg_loss loss = 3.085166, validation loss = 2.516456\n",
      "2020-04-15 17:08:31 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 77000, train_rouge_l_f = 0.475374, test_rouge_l_f = 0.295320\n",
      "I0415 17:08:31.155301 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 77000, train_rouge_l_f = 0.475374, test_rouge_l_f = 0.295320\n",
      "2020-04-15 17:19:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 78000, training batch loss = 2.189734, running_avg_loss loss = 3.076212, validation loss = 2.511598\n",
      "I0415 17:19:05.795754 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 78000, training batch loss = 2.189734, running_avg_loss loss = 3.076212, validation loss = 2.511598\n",
      "2020-04-15 17:19:12 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 78000, train_rouge_l_f = 0.516935, test_rouge_l_f = 0.473456\n",
      "I0415 17:19:12.900853 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 78000, train_rouge_l_f = 0.516935, test_rouge_l_f = 0.473456\n",
      "2020-04-15 17:29:53 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 79000, training batch loss = 2.471739, running_avg_loss loss = 3.070167, validation loss = 2.508782\n",
      "I0415 17:29:53.196592 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 79000, training batch loss = 2.471739, running_avg_loss loss = 3.070167, validation loss = 2.508782\n",
      "2020-04-15 17:29:57 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 79000, train_rouge_l_f = 0.563026, test_rouge_l_f = 0.478974\n",
      "I0415 17:29:57.637293 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 79000, train_rouge_l_f = 0.563026, test_rouge_l_f = 0.478974\n",
      "2020-04-15 17:40:33 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 80000, training batch loss = 3.441019, running_avg_loss loss = 3.073876, validation loss = 2.508175\n",
      "I0415 17:40:33.680074 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 80000, training batch loss = 3.441019, running_avg_loss loss = 3.073876, validation loss = 2.508175\n",
      "2020-04-15 17:40:33 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 80000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0080000.tar...\n",
      "I0415 17:40:33.683061 140122325395264 initialize.py:225] Saving model step 80000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0080000.tar...\n",
      "2020-04-15 17:40:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 80000, train_rouge_l_f = 0.287329, test_rouge_l_f = 0.323300\n",
      "I0415 17:40:45.662815 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 80000, train_rouge_l_f = 0.287329, test_rouge_l_f = 0.323300\n",
      "2020-04-15 17:51:23 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 81000, training batch loss = 1.700206, running_avg_loss loss = 3.060139, validation loss = 2.511726\n",
      "I0415 17:51:23.860356 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 81000, training batch loss = 1.700206, running_avg_loss loss = 3.060139, validation loss = 2.511726\n",
      "2020-04-15 17:51:30 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 81000, train_rouge_l_f = 0.486939, test_rouge_l_f = 0.478847\n",
      "I0415 17:51:30.751306 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 81000, train_rouge_l_f = 0.486939, test_rouge_l_f = 0.478847\n",
      "2020-04-15 18:02:01 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 82000, training batch loss = 2.347234, running_avg_loss loss = 3.053010, validation loss = 2.499012\n",
      "I0415 18:02:01.315250 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 82000, training batch loss = 2.347234, running_avg_loss loss = 3.053010, validation loss = 2.499012\n",
      "2020-04-15 18:02:09 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 82000, train_rouge_l_f = 0.495574, test_rouge_l_f = 0.146946\n",
      "I0415 18:02:09.418368 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 82000, train_rouge_l_f = 0.495574, test_rouge_l_f = 0.146946\n",
      "2020-04-15 18:12:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 83000, training batch loss = 2.452464, running_avg_loss loss = 3.047004, validation loss = 2.499655\n",
      "I0415 18:12:49.600206 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 83000, training batch loss = 2.452464, running_avg_loss loss = 3.047004, validation loss = 2.499655\n",
      "2020-04-15 18:12:51 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 83000, train_rouge_l_f = 0.450880, test_rouge_l_f = 0.837741\n",
      "I0415 18:12:51.410472 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 83000, train_rouge_l_f = 0.450880, test_rouge_l_f = 0.837741\n",
      "2020-04-15 18:23:33 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 84000, training batch loss = 3.096828, running_avg_loss loss = 3.047503, validation loss = 2.503758\n",
      "I0415 18:23:33.561125 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 84000, training batch loss = 3.096828, running_avg_loss loss = 3.047503, validation loss = 2.503758\n",
      "2020-04-15 18:23:42 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 84000, train_rouge_l_f = 0.297790, test_rouge_l_f = 0.306929\n",
      "I0415 18:23:42.637959 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 84000, train_rouge_l_f = 0.297790, test_rouge_l_f = 0.306929\n",
      "2020-04-15 18:34:26 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 85000, training batch loss = 1.931574, running_avg_loss loss = 3.036343, validation loss = 2.494078\n",
      "I0415 18:34:26.843475 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 85000, training batch loss = 1.931574, running_avg_loss loss = 3.036343, validation loss = 2.494078\n",
      "2020-04-15 18:34:26 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 85000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0085000.tar...\n",
      "I0415 18:34:26.846315 140122325395264 initialize.py:225] Saving model step 85000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0085000.tar...\n",
      "2020-04-15 18:34:31 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 85000, train_rouge_l_f = 0.541445, test_rouge_l_f = 0.593386\n",
      "I0415 18:34:31.613975 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 85000, train_rouge_l_f = 0.541445, test_rouge_l_f = 0.593386\n",
      "2020-04-15 18:45:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 86000, training batch loss = 1.872072, running_avg_loss loss = 3.024701, validation loss = 2.496421\n",
      "I0415 18:45:19.895910 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 86000, training batch loss = 1.872072, running_avg_loss loss = 3.024701, validation loss = 2.496421\n",
      "2020-04-15 18:45:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 86000, train_rouge_l_f = 0.459998, test_rouge_l_f = 0.834566\n",
      "I0415 18:45:22.667486 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 86000, train_rouge_l_f = 0.459998, test_rouge_l_f = 0.834566\n",
      "2020-04-15 18:56:07 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 87000, training batch loss = 3.088289, running_avg_loss loss = 3.025336, validation loss = 2.492257\n",
      "I0415 18:56:07.946273 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 87000, training batch loss = 3.088289, running_avg_loss loss = 3.025336, validation loss = 2.492257\n",
      "2020-04-15 18:56:22 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 87000, train_rouge_l_f = 0.376616, test_rouge_l_f = 0.295803\n",
      "I0415 18:56:22.702942 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 87000, train_rouge_l_f = 0.376616, test_rouge_l_f = 0.295803\n",
      "2020-04-15 19:07:02 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 88000, training batch loss = 2.857844, running_avg_loss loss = 3.023662, validation loss = 2.495924\n",
      "I0415 19:07:02.335690 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 88000, training batch loss = 2.857844, running_avg_loss loss = 3.023662, validation loss = 2.495924\n",
      "2020-04-15 19:07:15 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 88000, train_rouge_l_f = 0.368170, test_rouge_l_f = 0.210296\n",
      "I0415 19:07:15.013715 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 88000, train_rouge_l_f = 0.368170, test_rouge_l_f = 0.210296\n",
      "2020-04-15 19:18:01 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 89000, training batch loss = 1.898851, running_avg_loss loss = 3.012413, validation loss = 2.490421\n",
      "I0415 19:18:01.607117 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 89000, training batch loss = 1.898851, running_avg_loss loss = 3.012413, validation loss = 2.490421\n",
      "2020-04-15 19:18:14 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 89000, train_rouge_l_f = 0.560043, test_rouge_l_f = 0.182398\n",
      "I0415 19:18:14.590224 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 89000, train_rouge_l_f = 0.560043, test_rouge_l_f = 0.182398\n",
      "2020-04-15 19:28:58 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 90000, training batch loss = 2.078251, running_avg_loss loss = 3.003072, validation loss = 2.486189\n",
      "I0415 19:28:58.215387 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 90000, training batch loss = 2.078251, running_avg_loss loss = 3.003072, validation loss = 2.486189\n",
      "2020-04-15 19:28:58 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 90000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0090000.tar...\n",
      "I0415 19:28:58.218272 140122325395264 initialize.py:225] Saving model step 90000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0090000.tar...\n",
      "2020-04-15 19:29:04 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 90000, train_rouge_l_f = 0.499874, test_rouge_l_f = 0.360307\n",
      "I0415 19:29:04.661204 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 90000, train_rouge_l_f = 0.499874, test_rouge_l_f = 0.360307\n",
      "2020-04-15 19:39:47 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 91000, training batch loss = 2.116970, running_avg_loss loss = 2.994211, validation loss = 2.489334\n",
      "I0415 19:39:47.055574 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 91000, training batch loss = 2.116970, running_avg_loss loss = 2.994211, validation loss = 2.489334\n",
      "2020-04-15 19:39:52 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 91000, train_rouge_l_f = 0.495096, test_rouge_l_f = 0.588949\n",
      "I0415 19:39:52.567072 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 91000, train_rouge_l_f = 0.495096, test_rouge_l_f = 0.588949\n",
      "2020-04-15 19:50:38 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 92000, training batch loss = 3.056051, running_avg_loss loss = 2.994829, validation loss = 2.484762\n",
      "I0415 19:50:38.468613 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 92000, training batch loss = 3.056051, running_avg_loss loss = 2.994829, validation loss = 2.484762\n",
      "2020-04-15 19:50:41 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 92000, train_rouge_l_f = 0.219350, test_rouge_l_f = 0.736532\n",
      "I0415 19:50:41.297790 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 92000, train_rouge_l_f = 0.219350, test_rouge_l_f = 0.736532\n",
      "2020-04-15 20:01:21 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 93000, training batch loss = 3.788924, running_avg_loss loss = 3.002770, validation loss = 2.496817\n",
      "I0415 20:01:21.366337 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 93000, training batch loss = 3.788924, running_avg_loss loss = 3.002770, validation loss = 2.496817\n",
      "2020-04-15 20:01:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 93000, train_rouge_l_f = 0.248873, test_rouge_l_f = 0.327080\n",
      "I0415 20:01:36.773718 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 93000, train_rouge_l_f = 0.248873, test_rouge_l_f = 0.327080\n",
      "2020-04-15 20:12:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 94000, training batch loss = 1.968640, running_avg_loss loss = 2.992429, validation loss = 2.484632\n",
      "I0415 20:12:19.262908 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 94000, training batch loss = 1.968640, running_avg_loss loss = 2.992429, validation loss = 2.484632\n",
      "2020-04-15 20:12:25 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 94000, train_rouge_l_f = 0.560803, test_rouge_l_f = 0.162666\n",
      "I0415 20:12:25.798852 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 94000, train_rouge_l_f = 0.560803, test_rouge_l_f = 0.162666\n",
      "2020-04-15 20:23:05 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 95000, training batch loss = 2.515164, running_avg_loss loss = 2.987656, validation loss = 2.478460\n",
      "I0415 20:23:05.192694 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 95000, training batch loss = 2.515164, running_avg_loss loss = 2.987656, validation loss = 2.478460\n",
      "2020-04-15 20:23:05 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 95000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0095000.tar...\n",
      "I0415 20:23:05.194960 140122325395264 initialize.py:225] Saving model step 95000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0095000.tar...\n",
      "2020-04-15 20:23:20 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 95000, train_rouge_l_f = 0.423589, test_rouge_l_f = 0.120767\n",
      "I0415 20:23:20.622568 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 95000, train_rouge_l_f = 0.423589, test_rouge_l_f = 0.120767\n",
      "2020-04-15 20:34:08 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 96000, training batch loss = 2.839410, running_avg_loss loss = 2.986174, validation loss = 2.478857\n",
      "I0415 20:34:08.498384 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 96000, training batch loss = 2.839410, running_avg_loss loss = 2.986174, validation loss = 2.478857\n",
      "2020-04-15 20:34:19 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 96000, train_rouge_l_f = 0.275745, test_rouge_l_f = 0.542972\n",
      "I0415 20:34:19.630038 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 96000, train_rouge_l_f = 0.275745, test_rouge_l_f = 0.542972\n",
      "2020-04-15 20:44:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 97000, training batch loss = 3.321285, running_avg_loss loss = 2.989525, validation loss = 2.476648\n",
      "I0415 20:44:49.435775 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 97000, training batch loss = 3.321285, running_avg_loss loss = 2.989525, validation loss = 2.476648\n",
      "2020-04-15 20:45:03 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 97000, train_rouge_l_f = 0.289574, test_rouge_l_f = 0.282419\n",
      "I0415 20:45:03.518748 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 97000, train_rouge_l_f = 0.289574, test_rouge_l_f = 0.282419\n",
      "2020-04-15 20:55:41 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 98000, training batch loss = 2.047023, running_avg_loss loss = 2.980100, validation loss = 2.480331\n",
      "I0415 20:55:41.640464 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 98000, training batch loss = 2.047023, running_avg_loss loss = 2.980100, validation loss = 2.480331\n",
      "2020-04-15 20:55:47 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 98000, train_rouge_l_f = 0.575879, test_rouge_l_f = 0.436242\n",
      "I0415 20:55:47.064751 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 98000, train_rouge_l_f = 0.575879, test_rouge_l_f = 0.436242\n",
      "2020-04-15 21:06:33 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 99000, training batch loss = 3.091215, running_avg_loss loss = 2.981211, validation loss = 2.477271\n",
      "I0415 21:06:33.034454 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 99000, training batch loss = 3.091215, running_avg_loss loss = 2.981211, validation loss = 2.477271\n",
      "2020-04-15 21:06:46 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 99000, train_rouge_l_f = 0.199705, test_rouge_l_f = 0.562853\n",
      "I0415 21:06:46.107228 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 99000, train_rouge_l_f = 0.199705, test_rouge_l_f = 0.562853\n",
      "2020-04-15 21:17:36 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 100000, training batch loss = 2.079273, running_avg_loss loss = 2.972192, validation loss = 2.471572\n",
      "I0415 21:17:36.843335 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 100000, training batch loss = 2.079273, running_avg_loss loss = 2.972192, validation loss = 2.471572\n",
      "2020-04-15 21:17:36 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 100000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0100000.tar...\n",
      "I0415 21:17:36.846692 140122325395264 initialize.py:225] Saving model step 100000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0100000.tar...\n",
      "2020-04-15 21:17:48 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 100000, train_rouge_l_f = 0.475992, test_rouge_l_f = 0.234209\n",
      "I0415 21:17:48.340162 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 100000, train_rouge_l_f = 0.475992, test_rouge_l_f = 0.234209\n",
      "2020-04-15 21:28:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 101000, training batch loss = 2.677508, running_avg_loss loss = 2.969245, validation loss = 2.471180\n",
      "I0415 21:28:45.950560 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 101000, training batch loss = 2.677508, running_avg_loss loss = 2.969245, validation loss = 2.471180\n",
      "2020-04-15 21:28:49 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 101000, train_rouge_l_f = 0.495692, test_rouge_l_f = 0.493395\n",
      "I0415 21:28:49.607175 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 101000, train_rouge_l_f = 0.495692, test_rouge_l_f = 0.493395\n",
      "2020-04-15 21:39:28 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 102000, training batch loss = 2.594310, running_avg_loss loss = 2.965495, validation loss = 2.471199\n",
      "I0415 21:39:28.282194 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 102000, training batch loss = 2.594310, running_avg_loss loss = 2.965495, validation loss = 2.471199\n",
      "2020-04-15 21:39:37 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 102000, train_rouge_l_f = 0.515028, test_rouge_l_f = 0.493014\n",
      "I0415 21:39:37.980557 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 102000, train_rouge_l_f = 0.515028, test_rouge_l_f = 0.493014\n",
      "2020-04-15 21:50:08 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 103000, training batch loss = 3.743615, running_avg_loss loss = 2.973277, validation loss = 2.474587\n",
      "I0415 21:50:08.405059 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 103000, training batch loss = 3.743615, running_avg_loss loss = 2.973277, validation loss = 2.474587\n",
      "2020-04-15 21:50:13 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 103000, train_rouge_l_f = 0.156725, test_rouge_l_f = 0.570970\n",
      "I0415 21:50:13.629496 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 103000, train_rouge_l_f = 0.156725, test_rouge_l_f = 0.570970\n",
      "2020-04-15 22:00:58 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 104000, training batch loss = 2.890864, running_avg_loss loss = 2.972452, validation loss = 2.468647\n",
      "I0415 22:00:58.238112 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 104000, training batch loss = 2.890864, running_avg_loss loss = 2.972452, validation loss = 2.468647\n",
      "2020-04-15 22:01:08 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 104000, train_rouge_l_f = 0.428147, test_rouge_l_f = 0.118287\n",
      "I0415 22:01:08.579385 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 104000, train_rouge_l_f = 0.428147, test_rouge_l_f = 0.118287\n",
      "2020-04-15 22:11:56 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 105000, training batch loss = 2.376171, running_avg_loss loss = 2.966490, validation loss = 2.467093\n",
      "I0415 22:11:56.040704 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 105000, training batch loss = 2.376171, running_avg_loss loss = 2.966490, validation loss = 2.467093\n",
      "2020-04-15 22:11:56 - Pointer_generator_FastText_Intra_Atten - INFO: - Saving model step 105000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0105000.tar...\n",
      "I0415 22:11:56.043426 140122325395264 initialize.py:225] Saving model step 105000 to model/saved_models/Pointer_generator_FastText_Intra_Atten/0105000.tar...\n",
      "2020-04-15 22:11:59 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 105000, train_rouge_l_f = 0.462658, test_rouge_l_f = 0.511451\n",
      "I0415 22:11:59.113847 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 105000, train_rouge_l_f = 0.462658, test_rouge_l_f = 0.511451\n",
      "2020-04-15 22:22:48 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 106000, training batch loss = 1.267884, running_avg_loss loss = 2.949504, validation loss = 2.470989\n",
      "I0415 22:22:48.943438 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 106000, training batch loss = 1.267884, running_avg_loss loss = 2.949504, validation loss = 2.470989\n",
      "2020-04-15 22:22:51 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 106000, train_rouge_l_f = 0.647495, test_rouge_l_f = 0.571378\n",
      "I0415 22:22:51.799024 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 106000, train_rouge_l_f = 0.647495, test_rouge_l_f = 0.571378\n",
      "2020-04-15 22:33:45 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 107000, training batch loss = 2.845093, running_avg_loss loss = 2.948460, validation loss = 2.463996\n",
      "I0415 22:33:45.642143 140122325395264 <ipython-input-11-2ac8b23ec35d>:41] epoch 1: 107000, training batch loss = 2.845093, running_avg_loss loss = 2.948460, validation loss = 2.463996\n",
      "2020-04-15 22:33:51 - Pointer_generator_FastText_Intra_Atten - INFO: - epoch 1: 107000, train_rouge_l_f = 0.470613, test_rouge_l_f = 0.539291\n",
      "I0415 22:33:51.778013 140122325395264 <ipython-input-11-2ac8b23ec35d>:68] epoch 1: 107000, train_rouge_l_f = 0.470613, test_rouge_l_f = 0.539291\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "sum_total_reward = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            mle_loss = train_one(model, config, batch)\n",
    "            if config.train_rl:\n",
    "                rl_loss, batch_reward = train_one_RL(model, config, batch)             \n",
    "                writer.add_scalars('scalar/RL_Loss',  \n",
    "                       {'rl_loss': rl_loss\n",
    "                       }, step)\n",
    "                writer.add_scalars('scalar/Reward',  \n",
    "                       {'batch_reward': batch_reward\n",
    "                       }, step)\n",
    "                \n",
    "                if step%1000 == 0 :\n",
    "                    logger.info('epoch %d: %d, RL_Loss = %f, batch_reward = %f'\n",
    "                                    % (epoch, step, rl_loss, batch_reward))\n",
    "                sum_total_reward += batch_reward\n",
    "            else:\n",
    "                rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % (config.gradient_accum) == 0: # gradient accumulation\n",
    "    #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "                optimizer.step() # 根据累计的梯度更新网络参数\n",
    "                optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    running_avg_reward = sum_total_reward / step\n",
    "                    logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "                    if running_avg_reward > 0:\n",
    "                        logger.info('epoch %d: %d, running_avg_reward = %f'\n",
    "                                % (epoch, step, running_avg_reward))\n",
    "                        writer.add_scalars('scalar_avg/Reward',  \n",
    "                           {'running_avg_reward': running_avg_reward\n",
    "                           }, step)\n",
    "\n",
    "            if step%5000 == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                           r_loss=0, title = loggerName)\n",
    "            if step%1000 == 0 and step > 0:\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "        logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')                \n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
