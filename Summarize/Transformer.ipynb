{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0409 01:38:59.294201 140206455236416 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-09 01:39:00 - Transformer_word2Vec - INFO: - logger已啟動\n",
      "I0409 01:39:00.136677 140206455236416 train_util.py:92] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.transormer_beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--transformer', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=6)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=512)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=False)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "config.rl_weight = 1 - config.mle_weight\n",
    "\n",
    "if not config.transformer:\n",
    "    loggerName = 'Pointer_generator_%s' % (config.word_emb_type)\n",
    "else:\n",
    "    loggerName = 'Transformer_%s' % (config.word_emb_type)\n",
    "    \n",
    "if config.intra_encoder and config.intra_decoder and True :\n",
    "    loggerName = loggerName + '_Intra_Atten'\n",
    "if config.key_attention:\n",
    "    loggerName = loggerName + '_Key_Atten'\n",
    "    \n",
    "logger = getLogger(loggerName) \n",
    "\n",
    "if not config.transformer:\n",
    "    writer = SummaryWriter('runs/Pointer-Generator/%s/exp' % config.word_emb_type)\n",
    "else:\n",
    "    writer = SummaryWriter('runs/Transformer/%s/exp' % config.word_emb_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-09 01:39:05 - Transformer_word2Vec - INFO: - train : 37771, test : 4197\n",
      "I0409 01:39:05.943351 140206455236416 batcher.py:171] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab,config=config)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, _, \\\n",
    "        _, _, _, _= \\\n",
    "            get_input_from_batch(batch, config, batch_first = False)\n",
    "       \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = False) # Get input and target batchs for training decoder\n",
    "\n",
    "        pred = model(enc_batch, dec_batch, enc_padding_mask, dec_padding_mask, enc_batch_extend_vocab, extra_zeros)\n",
    "#         loss = model.label_smoothing_loss(pred, target_batch)\n",
    "        loss = model.nll_loss(pred, target_batch, dec_lens)\n",
    "#         print(loss)#         \n",
    "        # >>>>>>>> DEBUG Session <<<<<<<<<\n",
    "#         print('------------------------------------')\n",
    "#         print(\"ENC\\n\")\n",
    "#         print(enc_batch.shape)\n",
    "#         print(\"DEC\\n\")\n",
    "#         print(dec_batch.shape)\n",
    "        # print(\"TGT\\n\")\n",
    "        # print(target_batch.shape)\n",
    "        # print(\"ENCP\\n\")\n",
    "        # print(enc_padding_mask.shape)\n",
    "        # print(\"DECP\\n\")\n",
    "        # print(dec_padding_mask.shape)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    model.eval()\n",
    "    config.is_predicting = True\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "\n",
    "    pred_ids = beam_search(config, batch, model, START, END, UNKNOWN_TOKEN)\n",
    "    config.is_predicting = False\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "#     print(prepare_result(vocab, batch, pred_ids))\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    model.eval()\n",
    "    config.is_predicting = True\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        pred_ids = beam_search(config, batch, model, START, END, UNKNOWN_TOKEN)\n",
    "        config.is_predicting = False\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'testing_avg_acc': avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-09 01:39:09 - Transformer_word2Vec - INFO: - ------Training START--------\n",
      "I0409 01:39:09.021363 140206455236416 <ipython-input-9-86ea97d748bc>:2] ------Training START--------\n",
      "2020-04-09 01:41:24 - Transformer_word2Vec - INFO: - epoch 0: 1000, training batch loss = 5.593308, running_avg_loss loss = 5.593308, validation loss = 5.092603\n",
      "I0409 01:41:24.982884 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 0: 1000, training batch loss = 5.593308, running_avg_loss loss = 5.593308, validation loss = 5.092603\n",
      "2020-04-09 01:41:25 - Transformer_word2Vec - INFO: - epoch 0: 1000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.000000\n",
      "I0409 01:41:25.183252 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 0: 1000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.000000\n",
      "2020-04-09 01:43:37 - Transformer_word2Vec - INFO: - epoch 0: 2000, training batch loss = 4.691309, running_avg_loss loss = 5.584288, validation loss = 4.805816\n",
      "I0409 01:43:37.971808 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 0: 2000, training batch loss = 4.691309, running_avg_loss loss = 5.584288, validation loss = 4.805816\n",
      "2020-04-09 01:43:38 - Transformer_word2Vec - INFO: - epoch 0: 2000, train_rouge_l_f = 0.189720, test_rouge_l_f = 0.160166\n",
      "I0409 01:43:38.542367 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 0: 2000, train_rouge_l_f = 0.189720, test_rouge_l_f = 0.160166\n",
      "2020-04-09 01:45:45 - Transformer_word2Vec - INFO: - epoch 0: 3000, training batch loss = 5.290616, running_avg_loss loss = 5.581351, validation loss = 4.636622\n",
      "I0409 01:45:45.883211 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 0: 3000, training batch loss = 5.290616, running_avg_loss loss = 5.581351, validation loss = 4.636622\n",
      "2020-04-09 01:45:46 - Transformer_word2Vec - INFO: - epoch 0: 3000, train_rouge_l_f = 0.038848, test_rouge_l_f = 0.105754\n",
      "I0409 01:45:46.563569 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 0: 3000, train_rouge_l_f = 0.038848, test_rouge_l_f = 0.105754\n",
      "2020-04-09 01:47:51 - Transformer_word2Vec - INFO: - epoch 0: 4000, training batch loss = 4.404704, running_avg_loss loss = 5.569585, validation loss = 4.541668\n",
      "I0409 01:47:51.325885 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 0: 4000, training batch loss = 4.404704, running_avg_loss loss = 5.569585, validation loss = 4.541668\n",
      "2020-04-09 01:47:52 - Transformer_word2Vec - INFO: - epoch 0: 4000, train_rouge_l_f = 0.118013, test_rouge_l_f = 0.122545\n",
      "I0409 01:47:52.152434 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 0: 4000, train_rouge_l_f = 0.118013, test_rouge_l_f = 0.122545\n",
      "2020-04-09 01:49:49 - Transformer_word2Vec - INFO: - epoch 0: 4722, test_avg_acc = 0.110855\n",
      "I0409 01:49:49.220238 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 0: 4722, test_avg_acc = 0.110855\n",
      "2020-04-09 01:50:29 - Transformer_word2Vec - INFO: - epoch 1: 5000, training batch loss = 4.382577, running_avg_loss loss = 5.557715, validation loss = 4.477324\n",
      "I0409 01:50:29.762105 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 1: 5000, training batch loss = 4.382577, running_avg_loss loss = 5.557715, validation loss = 4.477324\n",
      "2020-04-09 01:50:29 - Transformer_word2Vec - INFO: - Saving model step 5000 to model/saved_models/Transformer_word2Vec/0005000.tar...\n",
      "I0409 01:50:29.763823 140206455236416 initialize.py:226] Saving model step 5000 to model/saved_models/Transformer_word2Vec/0005000.tar...\n",
      "2020-04-09 01:50:34 - Transformer_word2Vec - INFO: - epoch 1: 5000, train_rouge_l_f = 0.114246, test_rouge_l_f = 0.168650\n",
      "I0409 01:50:34.684712 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 1: 5000, train_rouge_l_f = 0.114246, test_rouge_l_f = 0.168650\n",
      "2020-04-09 01:52:43 - Transformer_word2Vec - INFO: - epoch 1: 6000, training batch loss = 4.253471, running_avg_loss loss = 5.544672, validation loss = 4.435162\n",
      "I0409 01:52:43.959850 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 1: 6000, training batch loss = 4.253471, running_avg_loss loss = 5.544672, validation loss = 4.435162\n",
      "2020-04-09 01:52:44 - Transformer_word2Vec - INFO: - epoch 1: 6000, train_rouge_l_f = 0.084821, test_rouge_l_f = 0.099513\n",
      "I0409 01:52:44.802075 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 1: 6000, train_rouge_l_f = 0.084821, test_rouge_l_f = 0.099513\n",
      "2020-04-09 01:54:52 - Transformer_word2Vec - INFO: - epoch 1: 7000, training batch loss = 4.105987, running_avg_loss loss = 5.530285, validation loss = 4.394160\n",
      "I0409 01:54:52.973219 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 1: 7000, training batch loss = 4.105987, running_avg_loss loss = 5.530285, validation loss = 4.394160\n",
      "2020-04-09 01:54:53 - Transformer_word2Vec - INFO: - epoch 1: 7000, train_rouge_l_f = 0.085055, test_rouge_l_f = 0.087743\n",
      "I0409 01:54:53.824110 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 1: 7000, train_rouge_l_f = 0.085055, test_rouge_l_f = 0.087743\n",
      "2020-04-09 01:57:04 - Transformer_word2Vec - INFO: - epoch 1: 8000, training batch loss = 3.635736, running_avg_loss loss = 5.511340, validation loss = 4.366852\n",
      "I0409 01:57:04.794781 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 1: 8000, training batch loss = 3.635736, running_avg_loss loss = 5.511340, validation loss = 4.366852\n",
      "2020-04-09 01:57:05 - Transformer_word2Vec - INFO: - epoch 1: 8000, train_rouge_l_f = 0.070857, test_rouge_l_f = 0.083959\n",
      "I0409 01:57:05.145559 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 1: 8000, train_rouge_l_f = 0.070857, test_rouge_l_f = 0.083959\n",
      "2020-04-09 01:59:17 - Transformer_word2Vec - INFO: - epoch 1: 9000, training batch loss = 4.250844, running_avg_loss loss = 5.498735, validation loss = 4.326875\n",
      "I0409 01:59:17.482441 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 1: 9000, training batch loss = 4.250844, running_avg_loss loss = 5.498735, validation loss = 4.326875\n",
      "2020-04-09 01:59:18 - Transformer_word2Vec - INFO: - epoch 1: 9000, train_rouge_l_f = 0.071898, test_rouge_l_f = 0.160536\n",
      "I0409 01:59:18.299408 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 1: 9000, train_rouge_l_f = 0.071898, test_rouge_l_f = 0.160536\n",
      "2020-04-09 02:00:45 - Transformer_word2Vec - INFO: - epoch 1: 9444, test_avg_acc = 0.110855\n",
      "I0409 02:00:45.676488 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 1: 9444, test_avg_acc = 0.110855\n",
      "2020-04-09 02:02:03 - Transformer_word2Vec - INFO: - epoch 2: 10000, training batch loss = 4.398422, running_avg_loss loss = 5.487732, validation loss = 4.320815\n",
      "I0409 02:02:03.215885 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 2: 10000, training batch loss = 4.398422, running_avg_loss loss = 5.487732, validation loss = 4.320815\n",
      "2020-04-09 02:02:03 - Transformer_word2Vec - INFO: - Saving model step 10000 to model/saved_models/Transformer_word2Vec/0010000.tar...\n",
      "I0409 02:02:03.218999 140206455236416 initialize.py:226] Saving model step 10000 to model/saved_models/Transformer_word2Vec/0010000.tar...\n",
      "2020-04-09 02:02:07 - Transformer_word2Vec - INFO: - epoch 2: 10000, train_rouge_l_f = 0.071976, test_rouge_l_f = 0.022326\n",
      "I0409 02:02:07.563446 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 2: 10000, train_rouge_l_f = 0.071976, test_rouge_l_f = 0.022326\n",
      "2020-04-09 02:04:17 - Transformer_word2Vec - INFO: - epoch 2: 11000, training batch loss = 3.719314, running_avg_loss loss = 5.470048, validation loss = 4.306726\n",
      "I0409 02:04:17.543693 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 2: 11000, training batch loss = 3.719314, running_avg_loss loss = 5.470048, validation loss = 4.306726\n",
      "2020-04-09 02:04:17 - Transformer_word2Vec - INFO: - epoch 2: 11000, train_rouge_l_f = 0.110186, test_rouge_l_f = 0.189067\n",
      "I0409 02:04:17.751109 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 2: 11000, train_rouge_l_f = 0.110186, test_rouge_l_f = 0.189067\n",
      "2020-04-09 02:06:31 - Transformer_word2Vec - INFO: - epoch 2: 12000, training batch loss = 4.416232, running_avg_loss loss = 5.459510, validation loss = 4.290775\n",
      "I0409 02:06:31.219853 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 2: 12000, training batch loss = 4.416232, running_avg_loss loss = 5.459510, validation loss = 4.290775\n",
      "2020-04-09 02:06:32 - Transformer_word2Vec - INFO: - epoch 2: 12000, train_rouge_l_f = 0.092640, test_rouge_l_f = 0.240985\n",
      "I0409 02:06:32.095568 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 2: 12000, train_rouge_l_f = 0.092640, test_rouge_l_f = 0.240985\n",
      "2020-04-09 02:08:43 - Transformer_word2Vec - INFO: - epoch 2: 13000, training batch loss = 3.658312, running_avg_loss loss = 5.441498, validation loss = 4.277055\n",
      "I0409 02:08:43.479510 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 2: 13000, training batch loss = 3.658312, running_avg_loss loss = 5.441498, validation loss = 4.277055\n",
      "2020-04-09 02:08:43 - Transformer_word2Vec - INFO: - epoch 2: 13000, train_rouge_l_f = 0.099808, test_rouge_l_f = 0.064753\n",
      "I0409 02:08:43.948799 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 2: 13000, train_rouge_l_f = 0.099808, test_rouge_l_f = 0.064753\n",
      "2020-04-09 02:10:53 - Transformer_word2Vec - INFO: - epoch 2: 14000, training batch loss = 3.740405, running_avg_loss loss = 5.424487, validation loss = 4.259644\n",
      "I0409 02:10:53.114775 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 2: 14000, training batch loss = 3.740405, running_avg_loss loss = 5.424487, validation loss = 4.259644\n",
      "2020-04-09 02:10:54 - Transformer_word2Vec - INFO: - epoch 2: 14000, train_rouge_l_f = 0.051857, test_rouge_l_f = 0.240985\n",
      "I0409 02:10:54.004322 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 2: 14000, train_rouge_l_f = 0.051857, test_rouge_l_f = 0.240985\n",
      "2020-04-09 02:12:01 - Transformer_word2Vec - INFO: - epoch 2: 14166, test_avg_acc = 0.054907\n",
      "I0409 02:12:01.616426 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 2: 14166, test_avg_acc = 0.054907\n",
      "2020-04-09 02:13:50 - Transformer_word2Vec - INFO: - epoch 3: 15000, training batch loss = 3.476381, running_avg_loss loss = 5.405006, validation loss = 4.273051\n",
      "I0409 02:13:50.921725 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 3: 15000, training batch loss = 3.476381, running_avg_loss loss = 5.405006, validation loss = 4.273051\n",
      "2020-04-09 02:13:50 - Transformer_word2Vec - INFO: - Saving model step 15000 to model/saved_models/Transformer_word2Vec/0015000.tar...\n",
      "I0409 02:13:50.924495 140206455236416 initialize.py:226] Saving model step 15000 to model/saved_models/Transformer_word2Vec/0015000.tar...\n",
      "2020-04-09 02:13:55 - Transformer_word2Vec - INFO: - epoch 3: 15000, train_rouge_l_f = 0.114087, test_rouge_l_f = 0.070041\n",
      "I0409 02:13:55.609784 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 3: 15000, train_rouge_l_f = 0.114087, test_rouge_l_f = 0.070041\n",
      "2020-04-09 02:16:03 - Transformer_word2Vec - INFO: - epoch 3: 16000, training batch loss = 4.151455, running_avg_loss loss = 5.392470, validation loss = 4.268984\n",
      "I0409 02:16:03.372987 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 3: 16000, training batch loss = 4.151455, running_avg_loss loss = 5.392470, validation loss = 4.268984\n",
      "2020-04-09 02:16:04 - Transformer_word2Vec - INFO: - epoch 3: 16000, train_rouge_l_f = 0.044643, test_rouge_l_f = 0.078758\n",
      "I0409 02:16:04.276371 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 3: 16000, train_rouge_l_f = 0.044643, test_rouge_l_f = 0.078758\n",
      "2020-04-09 02:18:19 - Transformer_word2Vec - INFO: - epoch 3: 17000, training batch loss = 3.603441, running_avg_loss loss = 5.374580, validation loss = 4.271537\n",
      "I0409 02:18:19.334448 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 3: 17000, training batch loss = 3.603441, running_avg_loss loss = 5.374580, validation loss = 4.271537\n",
      "2020-04-09 02:18:20 - Transformer_word2Vec - INFO: - epoch 3: 17000, train_rouge_l_f = 0.021313, test_rouge_l_f = 0.089744\n",
      "I0409 02:18:20.531659 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 3: 17000, train_rouge_l_f = 0.021313, test_rouge_l_f = 0.089744\n",
      "2020-04-09 02:20:29 - Transformer_word2Vec - INFO: - epoch 3: 18000, training batch loss = 4.277780, running_avg_loss loss = 5.363612, validation loss = 4.257713\n",
      "I0409 02:20:29.557957 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 3: 18000, training batch loss = 4.277780, running_avg_loss loss = 5.363612, validation loss = 4.257713\n",
      "2020-04-09 02:20:29 - Transformer_word2Vec - INFO: - epoch 3: 18000, train_rouge_l_f = 0.062775, test_rouge_l_f = 0.167591\n",
      "I0409 02:20:29.895068 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 3: 18000, train_rouge_l_f = 0.062775, test_rouge_l_f = 0.167591\n",
      "2020-04-09 02:22:54 - Transformer_word2Vec - INFO: - epoch 3: 18888, test_avg_acc = 0.110855\n",
      "I0409 02:22:54.104254 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 3: 18888, test_avg_acc = 0.110855\n",
      "2020-04-09 02:23:17 - Transformer_word2Vec - INFO: - epoch 4: 19000, training batch loss = 3.269502, running_avg_loss loss = 5.342671, validation loss = 4.265153\n",
      "I0409 02:23:17.124196 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 4: 19000, training batch loss = 3.269502, running_avg_loss loss = 5.342671, validation loss = 4.265153\n",
      "2020-04-09 02:23:17 - Transformer_word2Vec - INFO: - epoch 4: 19000, train_rouge_l_f = 0.124532, test_rouge_l_f = 0.146866\n",
      "I0409 02:23:17.420770 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 4: 19000, train_rouge_l_f = 0.124532, test_rouge_l_f = 0.146866\n",
      "2020-04-09 02:25:26 - Transformer_word2Vec - INFO: - epoch 4: 20000, training batch loss = 3.966846, running_avg_loss loss = 5.328912, validation loss = 4.303166\n",
      "I0409 02:25:26.672696 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 4: 20000, training batch loss = 3.966846, running_avg_loss loss = 5.328912, validation loss = 4.303166\n",
      "2020-04-09 02:25:26 - Transformer_word2Vec - INFO: - Saving model step 20000 to model/saved_models/Transformer_word2Vec/0020000.tar...\n",
      "I0409 02:25:26.676651 140206455236416 initialize.py:226] Saving model step 20000 to model/saved_models/Transformer_word2Vec/0020000.tar...\n",
      "2020-04-09 02:25:30 - Transformer_word2Vec - INFO: - epoch 4: 20000, train_rouge_l_f = 0.043682, test_rouge_l_f = 0.109203\n",
      "I0409 02:25:30.833972 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 4: 20000, train_rouge_l_f = 0.043682, test_rouge_l_f = 0.109203\n",
      "2020-04-09 02:27:38 - Transformer_word2Vec - INFO: - epoch 4: 21000, training batch loss = 3.443040, running_avg_loss loss = 5.310054, validation loss = 4.304486\n",
      "I0409 02:27:38.496745 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 4: 21000, training batch loss = 3.443040, running_avg_loss loss = 5.310054, validation loss = 4.304486\n",
      "2020-04-09 02:27:39 - Transformer_word2Vec - INFO: - epoch 4: 21000, train_rouge_l_f = 0.030544, test_rouge_l_f = 0.091717\n",
      "I0409 02:27:39.403291 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 4: 21000, train_rouge_l_f = 0.030544, test_rouge_l_f = 0.091717\n",
      "2020-04-09 02:29:51 - Transformer_word2Vec - INFO: - epoch 4: 22000, training batch loss = 3.175136, running_avg_loss loss = 5.288704, validation loss = 4.291364\n",
      "I0409 02:29:51.231825 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 4: 22000, training batch loss = 3.175136, running_avg_loss loss = 5.288704, validation loss = 4.291364\n",
      "2020-04-09 02:29:51 - Transformer_word2Vec - INFO: - epoch 4: 22000, train_rouge_l_f = 0.069172, test_rouge_l_f = 0.010657\n",
      "I0409 02:29:51.925370 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 4: 22000, train_rouge_l_f = 0.069172, test_rouge_l_f = 0.010657\n",
      "2020-04-09 02:32:06 - Transformer_word2Vec - INFO: - epoch 4: 23000, training batch loss = 3.544068, running_avg_loss loss = 5.271258, validation loss = 4.291619\n",
      "I0409 02:32:06.457237 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 4: 23000, training batch loss = 3.544068, running_avg_loss loss = 5.271258, validation loss = 4.291619\n",
      "2020-04-09 02:32:06 - Transformer_word2Vec - INFO: - epoch 4: 23000, train_rouge_l_f = 0.074642, test_rouge_l_f = 0.219327\n",
      "I0409 02:32:06.685332 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 4: 23000, train_rouge_l_f = 0.074642, test_rouge_l_f = 0.219327\n",
      "2020-04-09 02:34:07 - Transformer_word2Vec - INFO: - epoch 4: 23610, test_avg_acc = 0.052112\n",
      "I0409 02:34:07.065701 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 4: 23610, test_avg_acc = 0.052112\n",
      "2020-04-09 02:35:04 - Transformer_word2Vec - INFO: - epoch 5: 24000, training batch loss = 3.140242, running_avg_loss loss = 5.249948, validation loss = 4.333098\n",
      "I0409 02:35:04.632256 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 5: 24000, training batch loss = 3.140242, running_avg_loss loss = 5.249948, validation loss = 4.333098\n",
      "2020-04-09 02:35:05 - Transformer_word2Vec - INFO: - epoch 5: 24000, train_rouge_l_f = 0.195520, test_rouge_l_f = 0.201482\n",
      "I0409 02:35:05.406676 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 5: 24000, train_rouge_l_f = 0.195520, test_rouge_l_f = 0.201482\n",
      "2020-04-09 02:37:14 - Transformer_word2Vec - INFO: - epoch 5: 25000, training batch loss = 2.937174, running_avg_loss loss = 5.226820, validation loss = 4.351175\n",
      "I0409 02:37:14.244057 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 5: 25000, training batch loss = 2.937174, running_avg_loss loss = 5.226820, validation loss = 4.351175\n",
      "2020-04-09 02:37:14 - Transformer_word2Vec - INFO: - Saving model step 25000 to model/saved_models/Transformer_word2Vec/0025000.tar...\n",
      "I0409 02:37:14.247010 140206455236416 initialize.py:226] Saving model step 25000 to model/saved_models/Transformer_word2Vec/0025000.tar...\n",
      "2020-04-09 02:37:18 - Transformer_word2Vec - INFO: - epoch 5: 25000, train_rouge_l_f = 0.095773, test_rouge_l_f = 0.075918\n",
      "I0409 02:37:18.883955 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 5: 25000, train_rouge_l_f = 0.095773, test_rouge_l_f = 0.075918\n",
      "2020-04-09 02:39:23 - Transformer_word2Vec - INFO: - epoch 5: 26000, training batch loss = 2.927565, running_avg_loss loss = 5.203828, validation loss = 4.370053\n",
      "I0409 02:39:23.724284 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 5: 26000, training batch loss = 2.927565, running_avg_loss loss = 5.203828, validation loss = 4.370053\n",
      "2020-04-09 02:39:24 - Transformer_word2Vec - INFO: - epoch 5: 26000, train_rouge_l_f = 0.179464, test_rouge_l_f = 0.117850\n",
      "I0409 02:39:24.838902 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 5: 26000, train_rouge_l_f = 0.179464, test_rouge_l_f = 0.117850\n",
      "2020-04-09 02:41:37 - Transformer_word2Vec - INFO: - epoch 5: 27000, training batch loss = 3.148721, running_avg_loss loss = 5.183277, validation loss = 4.359519\n",
      "I0409 02:41:37.429085 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 5: 27000, training batch loss = 3.148721, running_avg_loss loss = 5.183277, validation loss = 4.359519\n",
      "2020-04-09 02:41:38 - Transformer_word2Vec - INFO: - epoch 5: 27000, train_rouge_l_f = 0.164108, test_rouge_l_f = 0.167699\n",
      "I0409 02:41:38.302551 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 5: 27000, train_rouge_l_f = 0.164108, test_rouge_l_f = 0.167699\n",
      "2020-04-09 02:43:54 - Transformer_word2Vec - INFO: - epoch 5: 28000, training batch loss = 3.348070, running_avg_loss loss = 5.164925, validation loss = 4.358124\n",
      "I0409 02:43:54.254761 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 5: 28000, training batch loss = 3.348070, running_avg_loss loss = 5.164925, validation loss = 4.358124\n",
      "2020-04-09 02:43:54 - Transformer_word2Vec - INFO: - epoch 5: 28000, train_rouge_l_f = 0.083650, test_rouge_l_f = 0.083899\n",
      "I0409 02:43:54.540823 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 5: 28000, train_rouge_l_f = 0.083650, test_rouge_l_f = 0.083899\n",
      "2020-04-09 02:45:09 - Transformer_word2Vec - INFO: - epoch 5: 28332, test_avg_acc = 0.110855\n",
      "I0409 02:45:09.090697 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 5: 28332, test_avg_acc = 0.110855\n",
      "2020-04-09 02:46:40 - Transformer_word2Vec - INFO: - epoch 6: 29000, training batch loss = 2.627836, running_avg_loss loss = 5.139554, validation loss = 4.440188\n",
      "I0409 02:46:40.986696 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 6: 29000, training batch loss = 2.627836, running_avg_loss loss = 5.139554, validation loss = 4.440188\n",
      "2020-04-09 02:46:41 - Transformer_word2Vec - INFO: - epoch 6: 29000, train_rouge_l_f = 0.169716, test_rouge_l_f = 0.066180\n",
      "I0409 02:46:41.152899 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 6: 29000, train_rouge_l_f = 0.169716, test_rouge_l_f = 0.066180\n",
      "2020-04-09 02:48:53 - Transformer_word2Vec - INFO: - epoch 6: 30000, training batch loss = 2.844612, running_avg_loss loss = 5.116604, validation loss = 4.474594\n",
      "I0409 02:48:53.381426 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 6: 30000, training batch loss = 2.844612, running_avg_loss loss = 5.116604, validation loss = 4.474594\n",
      "2020-04-09 02:48:53 - Transformer_word2Vec - INFO: - Saving model step 30000 to model/saved_models/Transformer_word2Vec/0030000.tar...\n",
      "I0409 02:48:53.385567 140206455236416 initialize.py:226] Saving model step 30000 to model/saved_models/Transformer_word2Vec/0030000.tar...\n",
      "2020-04-09 02:48:57 - Transformer_word2Vec - INFO: - epoch 6: 30000, train_rouge_l_f = 0.064968, test_rouge_l_f = 0.023148\n",
      "I0409 02:48:57.622075 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 6: 30000, train_rouge_l_f = 0.064968, test_rouge_l_f = 0.023148\n",
      "2020-04-09 02:51:09 - Transformer_word2Vec - INFO: - epoch 6: 31000, training batch loss = 3.082437, running_avg_loss loss = 5.096263, validation loss = 4.480772\n",
      "I0409 02:51:09.000736 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 6: 31000, training batch loss = 3.082437, running_avg_loss loss = 5.096263, validation loss = 4.480772\n",
      "2020-04-09 02:51:09 - Transformer_word2Vec - INFO: - epoch 6: 31000, train_rouge_l_f = 0.009437, test_rouge_l_f = 0.050331\n",
      "I0409 02:51:09.487200 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 6: 31000, train_rouge_l_f = 0.009437, test_rouge_l_f = 0.050331\n",
      "2020-04-09 02:53:25 - Transformer_word2Vec - INFO: - epoch 6: 32000, training batch loss = 3.400849, running_avg_loss loss = 5.079308, validation loss = 4.476096\n",
      "I0409 02:53:25.285651 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 6: 32000, training batch loss = 3.400849, running_avg_loss loss = 5.079308, validation loss = 4.476096\n",
      "2020-04-09 02:53:25 - Transformer_word2Vec - INFO: - epoch 6: 32000, train_rouge_l_f = 0.048406, test_rouge_l_f = 0.051668\n",
      "I0409 02:53:25.546445 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 6: 32000, train_rouge_l_f = 0.048406, test_rouge_l_f = 0.051668\n",
      "2020-04-09 02:55:44 - Transformer_word2Vec - INFO: - epoch 6: 33000, training batch loss = 3.334023, running_avg_loss loss = 5.061856, validation loss = 4.466164\n",
      "I0409 02:55:44.836591 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 6: 33000, training batch loss = 3.334023, running_avg_loss loss = 5.061856, validation loss = 4.466164\n",
      "2020-04-09 02:55:45 - Transformer_word2Vec - INFO: - epoch 6: 33000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.083333\n",
      "I0409 02:55:45.620258 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 6: 33000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.083333\n",
      "2020-04-09 02:56:41 - Transformer_word2Vec - INFO: - epoch 6: 33054, test_avg_acc = 0.068049\n",
      "I0409 02:56:41.149027 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 6: 33054, test_avg_acc = 0.068049\n",
      "2020-04-09 02:58:43 - Transformer_word2Vec - INFO: - epoch 7: 34000, training batch loss = 2.787200, running_avg_loss loss = 5.039109, validation loss = 4.589467\n",
      "I0409 02:58:43.540928 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 7: 34000, training batch loss = 2.787200, running_avg_loss loss = 5.039109, validation loss = 4.589467\n",
      "2020-04-09 02:58:44 - Transformer_word2Vec - INFO: - epoch 7: 34000, train_rouge_l_f = 0.150353, test_rouge_l_f = 0.089744\n",
      "I0409 02:58:44.761368 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 7: 34000, train_rouge_l_f = 0.150353, test_rouge_l_f = 0.089744\n",
      "2020-04-09 03:00:58 - Transformer_word2Vec - INFO: - epoch 7: 35000, training batch loss = 2.599977, running_avg_loss loss = 5.014718, validation loss = 4.605015\n",
      "I0409 03:00:58.917343 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 7: 35000, training batch loss = 2.599977, running_avg_loss loss = 5.014718, validation loss = 4.605015\n",
      "2020-04-09 03:00:58 - Transformer_word2Vec - INFO: - Saving model step 35000 to model/saved_models/Transformer_word2Vec/0035000.tar...\n",
      "I0409 03:00:58.919945 140206455236416 initialize.py:226] Saving model step 35000 to model/saved_models/Transformer_word2Vec/0035000.tar...\n",
      "2020-04-09 03:01:03 - Transformer_word2Vec - INFO: - epoch 7: 35000, train_rouge_l_f = 0.113778, test_rouge_l_f = 0.117152\n",
      "I0409 03:01:03.443113 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 7: 35000, train_rouge_l_f = 0.113778, test_rouge_l_f = 0.117152\n",
      "2020-04-09 03:03:18 - Transformer_word2Vec - INFO: - epoch 7: 36000, training batch loss = 3.056621, running_avg_loss loss = 4.995137, validation loss = 4.608856\n",
      "I0409 03:03:18.656241 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 7: 36000, training batch loss = 3.056621, running_avg_loss loss = 4.995137, validation loss = 4.608856\n",
      "2020-04-09 03:03:18 - Transformer_word2Vec - INFO: - epoch 7: 36000, train_rouge_l_f = 0.115285, test_rouge_l_f = 0.172540\n",
      "I0409 03:03:18.908593 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 7: 36000, train_rouge_l_f = 0.115285, test_rouge_l_f = 0.172540\n",
      "2020-04-09 03:05:33 - Transformer_word2Vec - INFO: - epoch 7: 37000, training batch loss = 3.063001, running_avg_loss loss = 4.975815, validation loss = 4.601673\n",
      "I0409 03:05:33.537300 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 7: 37000, training batch loss = 3.063001, running_avg_loss loss = 4.975815, validation loss = 4.601673\n",
      "2020-04-09 03:05:34 - Transformer_word2Vec - INFO: - epoch 7: 37000, train_rouge_l_f = 0.046429, test_rouge_l_f = 0.115179\n",
      "I0409 03:05:34.299397 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 7: 37000, train_rouge_l_f = 0.046429, test_rouge_l_f = 0.115179\n",
      "2020-04-09 03:07:40 - Transformer_word2Vec - INFO: - epoch 7: 37776, test_avg_acc = 0.089532\n",
      "I0409 03:07:40.700057 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 7: 37776, test_avg_acc = 0.089532\n",
      "2020-04-09 03:08:19 - Transformer_word2Vec - INFO: - epoch 8: 38000, training batch loss = 2.129611, running_avg_loss loss = 4.947353, validation loss = 4.675343\n",
      "I0409 03:08:19.216061 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 8: 38000, training batch loss = 2.129611, running_avg_loss loss = 4.947353, validation loss = 4.675343\n",
      "2020-04-09 03:08:19 - Transformer_word2Vec - INFO: - epoch 8: 38000, train_rouge_l_f = 0.116103, test_rouge_l_f = 0.126470\n",
      "I0409 03:08:19.420182 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 8: 38000, train_rouge_l_f = 0.116103, test_rouge_l_f = 0.126470\n",
      "2020-04-09 03:10:27 - Transformer_word2Vec - INFO: - epoch 8: 39000, training batch loss = 2.903241, running_avg_loss loss = 4.926912, validation loss = 4.768984\n",
      "I0409 03:10:27.792560 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 8: 39000, training batch loss = 2.903241, running_avg_loss loss = 4.926912, validation loss = 4.768984\n",
      "2020-04-09 03:10:28 - Transformer_word2Vec - INFO: - epoch 8: 39000, train_rouge_l_f = 0.088556, test_rouge_l_f = 0.175514\n",
      "I0409 03:10:28.081188 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 8: 39000, train_rouge_l_f = 0.088556, test_rouge_l_f = 0.175514\n",
      "2020-04-09 03:12:39 - Transformer_word2Vec - INFO: - epoch 8: 40000, training batch loss = 2.362212, running_avg_loss loss = 4.901265, validation loss = 4.731942\n",
      "I0409 03:12:39.505924 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 8: 40000, training batch loss = 2.362212, running_avg_loss loss = 4.901265, validation loss = 4.731942\n",
      "2020-04-09 03:12:39 - Transformer_word2Vec - INFO: - Saving model step 40000 to model/saved_models/Transformer_word2Vec/0040000.tar...\n",
      "I0409 03:12:39.509664 140206455236416 initialize.py:226] Saving model step 40000 to model/saved_models/Transformer_word2Vec/0040000.tar...\n",
      "2020-04-09 03:12:44 - Transformer_word2Vec - INFO: - epoch 8: 40000, train_rouge_l_f = 0.116985, test_rouge_l_f = 0.156383\n",
      "I0409 03:12:44.543522 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 8: 40000, train_rouge_l_f = 0.116985, test_rouge_l_f = 0.156383\n",
      "2020-04-09 03:14:56 - Transformer_word2Vec - INFO: - epoch 8: 41000, training batch loss = 2.367791, running_avg_loss loss = 4.875930, validation loss = 4.759556\n",
      "I0409 03:14:56.414595 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 8: 41000, training batch loss = 2.367791, running_avg_loss loss = 4.875930, validation loss = 4.759556\n",
      "2020-04-09 03:14:56 - Transformer_word2Vec - INFO: - epoch 8: 41000, train_rouge_l_f = 0.049639, test_rouge_l_f = 0.119030\n",
      "I0409 03:14:56.693966 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 8: 41000, train_rouge_l_f = 0.049639, test_rouge_l_f = 0.119030\n",
      "2020-04-09 03:17:06 - Transformer_word2Vec - INFO: - epoch 8: 42000, training batch loss = 2.482916, running_avg_loss loss = 4.852000, validation loss = 4.770159\n",
      "I0409 03:17:06.054455 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 8: 42000, training batch loss = 2.482916, running_avg_loss loss = 4.852000, validation loss = 4.770159\n",
      "2020-04-09 03:17:06 - Transformer_word2Vec - INFO: - epoch 8: 42000, train_rouge_l_f = 0.015617, test_rouge_l_f = 0.040865\n",
      "I0409 03:17:06.390540 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 8: 42000, train_rouge_l_f = 0.015617, test_rouge_l_f = 0.040865\n",
      "2020-04-09 03:18:39 - Transformer_word2Vec - INFO: - epoch 8: 42498, test_avg_acc = 0.089084\n",
      "I0409 03:18:39.136028 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 8: 42498, test_avg_acc = 0.089084\n",
      "2020-04-09 03:19:48 - Transformer_word2Vec - INFO: - epoch 9: 43000, training batch loss = 2.045001, running_avg_loss loss = 4.823930, validation loss = 4.859297\n",
      "I0409 03:19:48.652066 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 9: 43000, training batch loss = 2.045001, running_avg_loss loss = 4.823930, validation loss = 4.859297\n",
      "2020-04-09 03:19:48 - Transformer_word2Vec - INFO: - epoch 9: 43000, train_rouge_l_f = 0.109686, test_rouge_l_f = 0.095847\n",
      "I0409 03:19:48.840985 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 9: 43000, train_rouge_l_f = 0.109686, test_rouge_l_f = 0.095847\n",
      "2020-04-09 03:21:58 - Transformer_word2Vec - INFO: - epoch 9: 44000, training batch loss = 2.116491, running_avg_loss loss = 4.796856, validation loss = 4.927077\n",
      "I0409 03:21:58.959597 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 9: 44000, training batch loss = 2.116491, running_avg_loss loss = 4.796856, validation loss = 4.927077\n",
      "2020-04-09 03:21:59 - Transformer_word2Vec - INFO: - epoch 9: 44000, train_rouge_l_f = 0.163722, test_rouge_l_f = 0.115500\n",
      "I0409 03:21:59.537351 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 9: 44000, train_rouge_l_f = 0.163722, test_rouge_l_f = 0.115500\n",
      "2020-04-09 03:24:10 - Transformer_word2Vec - INFO: - epoch 9: 45000, training batch loss = 2.101972, running_avg_loss loss = 4.769907, validation loss = 4.933370\n",
      "I0409 03:24:10.736386 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 9: 45000, training batch loss = 2.101972, running_avg_loss loss = 4.769907, validation loss = 4.933370\n",
      "2020-04-09 03:24:10 - Transformer_word2Vec - INFO: - Saving model step 45000 to model/saved_models/Transformer_word2Vec/0045000.tar...\n",
      "I0409 03:24:10.739183 140206455236416 initialize.py:226] Saving model step 45000 to model/saved_models/Transformer_word2Vec/0045000.tar...\n",
      "2020-04-09 03:24:14 - Transformer_word2Vec - INFO: - epoch 9: 45000, train_rouge_l_f = 0.033291, test_rouge_l_f = 0.057542\n",
      "I0409 03:24:14.996661 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 9: 45000, train_rouge_l_f = 0.033291, test_rouge_l_f = 0.057542\n",
      "2020-04-09 03:26:25 - Transformer_word2Vec - INFO: - epoch 9: 46000, training batch loss = 2.490346, running_avg_loss loss = 4.747111, validation loss = 4.898014\n",
      "I0409 03:26:25.609077 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 9: 46000, training batch loss = 2.490346, running_avg_loss loss = 4.747111, validation loss = 4.898014\n",
      "2020-04-09 03:26:26 - Transformer_word2Vec - INFO: - epoch 9: 46000, train_rouge_l_f = 0.060026, test_rouge_l_f = 0.294914\n",
      "I0409 03:26:26.025853 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 9: 46000, train_rouge_l_f = 0.060026, test_rouge_l_f = 0.294914\n",
      "2020-04-09 03:28:36 - Transformer_word2Vec - INFO: - epoch 9: 47000, training batch loss = 2.334085, running_avg_loss loss = 4.722981, validation loss = 4.930702\n",
      "I0409 03:28:36.518372 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 9: 47000, training batch loss = 2.334085, running_avg_loss loss = 4.722981, validation loss = 4.930702\n",
      "2020-04-09 03:28:37 - Transformer_word2Vec - INFO: - epoch 9: 47000, train_rouge_l_f = 0.095722, test_rouge_l_f = 0.065944\n",
      "I0409 03:28:37.014298 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 9: 47000, train_rouge_l_f = 0.095722, test_rouge_l_f = 0.065944\n",
      "2020-04-09 03:29:36 - Transformer_word2Vec - INFO: - epoch 9: 47220, test_avg_acc = 0.110855\n",
      "I0409 03:29:36.515269 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 9: 47220, test_avg_acc = 0.110855\n",
      "2020-04-09 03:31:20 - Transformer_word2Vec - INFO: - epoch 10: 48000, training batch loss = 1.972965, running_avg_loss loss = 4.695481, validation loss = 5.030801\n",
      "I0409 03:31:20.589496 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 10: 48000, training batch loss = 1.972965, running_avg_loss loss = 4.695481, validation loss = 5.030801\n",
      "2020-04-09 03:31:21 - Transformer_word2Vec - INFO: - epoch 10: 48000, train_rouge_l_f = 0.051270, test_rouge_l_f = 0.000000\n",
      "I0409 03:31:21.111800 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 10: 48000, train_rouge_l_f = 0.051270, test_rouge_l_f = 0.000000\n",
      "2020-04-09 03:33:36 - Transformer_word2Vec - INFO: - epoch 10: 49000, training batch loss = 1.907617, running_avg_loss loss = 4.667602, validation loss = 5.084996\n",
      "I0409 03:33:36.110958 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 10: 49000, training batch loss = 1.907617, running_avg_loss loss = 4.667602, validation loss = 5.084996\n",
      "2020-04-09 03:33:36 - Transformer_word2Vec - INFO: - epoch 10: 49000, train_rouge_l_f = 0.091307, test_rouge_l_f = 0.218692\n",
      "I0409 03:33:36.436481 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 10: 49000, train_rouge_l_f = 0.091307, test_rouge_l_f = 0.218692\n",
      "2020-04-09 03:35:51 - Transformer_word2Vec - INFO: - epoch 10: 50000, training batch loss = 1.972432, running_avg_loss loss = 4.640651, validation loss = 5.078512\n",
      "I0409 03:35:51.833839 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 10: 50000, training batch loss = 1.972432, running_avg_loss loss = 4.640651, validation loss = 5.078512\n",
      "2020-04-09 03:35:51 - Transformer_word2Vec - INFO: - Saving model step 50000 to model/saved_models/Transformer_word2Vec/0050000.tar...\n",
      "I0409 03:35:51.835999 140206455236416 initialize.py:226] Saving model step 50000 to model/saved_models/Transformer_word2Vec/0050000.tar...\n",
      "2020-04-09 03:35:57 - Transformer_word2Vec - INFO: - epoch 10: 50000, train_rouge_l_f = 0.068928, test_rouge_l_f = 0.196001\n",
      "I0409 03:35:57.087804 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 10: 50000, train_rouge_l_f = 0.068928, test_rouge_l_f = 0.196001\n",
      "2020-04-09 03:38:02 - Transformer_word2Vec - INFO: - epoch 10: 51000, training batch loss = 2.201987, running_avg_loss loss = 4.616264, validation loss = 5.092301\n",
      "I0409 03:38:02.663319 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 10: 51000, training batch loss = 2.201987, running_avg_loss loss = 4.616264, validation loss = 5.092301\n",
      "2020-04-09 03:38:04 - Transformer_word2Vec - INFO: - epoch 10: 51000, train_rouge_l_f = 0.046391, test_rouge_l_f = 0.119325\n",
      "I0409 03:38:04.080391 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 10: 51000, train_rouge_l_f = 0.046391, test_rouge_l_f = 0.119325\n",
      "2020-04-09 03:40:30 - Transformer_word2Vec - INFO: - epoch 10: 51942, test_avg_acc = 0.066914\n",
      "I0409 03:40:30.823451 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 10: 51942, test_avg_acc = 0.066914\n",
      "2020-04-09 03:40:48 - Transformer_word2Vec - INFO: - epoch 11: 52000, training batch loss = 1.720638, running_avg_loss loss = 4.587308, validation loss = 5.144331\n",
      "I0409 03:40:48.630904 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 11: 52000, training batch loss = 1.720638, running_avg_loss loss = 4.587308, validation loss = 5.144331\n",
      "2020-04-09 03:40:48 - Transformer_word2Vec - INFO: - epoch 11: 52000, train_rouge_l_f = 0.173035, test_rouge_l_f = 0.189603\n",
      "I0409 03:40:48.838185 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 11: 52000, train_rouge_l_f = 0.173035, test_rouge_l_f = 0.189603\n",
      "2020-04-09 03:42:57 - Transformer_word2Vec - INFO: - epoch 11: 53000, training batch loss = 1.835981, running_avg_loss loss = 4.559795, validation loss = 5.201067\n",
      "I0409 03:42:57.820860 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 11: 53000, training batch loss = 1.835981, running_avg_loss loss = 4.559795, validation loss = 5.201067\n",
      "2020-04-09 03:42:58 - Transformer_word2Vec - INFO: - epoch 11: 53000, train_rouge_l_f = 0.054569, test_rouge_l_f = 0.089316\n",
      "I0409 03:42:58.713413 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 11: 53000, train_rouge_l_f = 0.054569, test_rouge_l_f = 0.089316\n",
      "2020-04-09 03:45:15 - Transformer_word2Vec - INFO: - epoch 11: 54000, training batch loss = 1.663071, running_avg_loss loss = 4.530827, validation loss = 5.225486\n",
      "I0409 03:45:15.201697 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 11: 54000, training batch loss = 1.663071, running_avg_loss loss = 4.530827, validation loss = 5.225486\n",
      "2020-04-09 03:45:15 - Transformer_word2Vec - INFO: - epoch 11: 54000, train_rouge_l_f = 0.170588, test_rouge_l_f = 0.164836\n",
      "I0409 03:45:15.494940 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 11: 54000, train_rouge_l_f = 0.170588, test_rouge_l_f = 0.164836\n",
      "2020-04-09 03:47:24 - Transformer_word2Vec - INFO: - epoch 11: 55000, training batch loss = 2.127892, running_avg_loss loss = 4.506798, validation loss = 5.235606\n",
      "I0409 03:47:24.364294 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 11: 55000, training batch loss = 2.127892, running_avg_loss loss = 4.506798, validation loss = 5.235606\n",
      "2020-04-09 03:47:24 - Transformer_word2Vec - INFO: - Saving model step 55000 to model/saved_models/Transformer_word2Vec/0055000.tar...\n",
      "I0409 03:47:24.369393 140206455236416 initialize.py:226] Saving model step 55000 to model/saved_models/Transformer_word2Vec/0055000.tar...\n",
      "2020-04-09 03:47:29 - Transformer_word2Vec - INFO: - epoch 11: 55000, train_rouge_l_f = 0.007021, test_rouge_l_f = 0.115179\n",
      "I0409 03:47:29.301169 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 11: 55000, train_rouge_l_f = 0.007021, test_rouge_l_f = 0.115179\n",
      "2020-04-09 03:49:38 - Transformer_word2Vec - INFO: - epoch 11: 56000, training batch loss = 1.893944, running_avg_loss loss = 4.480669, validation loss = 5.256088\n",
      "I0409 03:49:38.775346 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 11: 56000, training batch loss = 1.893944, running_avg_loss loss = 4.480669, validation loss = 5.256088\n",
      "2020-04-09 03:49:40 - Transformer_word2Vec - INFO: - epoch 11: 56000, train_rouge_l_f = 0.022514, test_rouge_l_f = 0.041667\n",
      "I0409 03:49:40.067981 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 11: 56000, train_rouge_l_f = 0.022514, test_rouge_l_f = 0.041667\n",
      "2020-04-09 03:51:59 - Transformer_word2Vec - INFO: - epoch 11: 56664, test_avg_acc = 0.054353\n",
      "I0409 03:51:59.191199 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 11: 56664, test_avg_acc = 0.054353\n",
      "2020-04-09 03:52:47 - Transformer_word2Vec - INFO: - epoch 12: 57000, training batch loss = 1.690763, running_avg_loss loss = 4.452770, validation loss = 5.297942\n",
      "I0409 03:52:47.717451 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 12: 57000, training batch loss = 1.690763, running_avg_loss loss = 4.452770, validation loss = 5.297942\n",
      "2020-04-09 03:52:47 - Transformer_word2Vec - INFO: - epoch 12: 57000, train_rouge_l_f = 0.100940, test_rouge_l_f = 0.179097\n",
      "I0409 03:52:47.932271 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 12: 57000, train_rouge_l_f = 0.100940, test_rouge_l_f = 0.179097\n",
      "2020-04-09 03:54:50 - Transformer_word2Vec - INFO: - epoch 12: 58000, training batch loss = 1.991821, running_avg_loss loss = 4.428161, validation loss = 5.356012\n",
      "I0409 03:54:50.388167 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 12: 58000, training batch loss = 1.991821, running_avg_loss loss = 4.428161, validation loss = 5.356012\n",
      "2020-04-09 03:54:50 - Transformer_word2Vec - INFO: - epoch 12: 58000, train_rouge_l_f = 0.092998, test_rouge_l_f = 0.097428\n",
      "I0409 03:54:50.586281 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 12: 58000, train_rouge_l_f = 0.092998, test_rouge_l_f = 0.097428\n",
      "2020-04-09 03:56:57 - Transformer_word2Vec - INFO: - epoch 12: 59000, training batch loss = 1.835068, running_avg_loss loss = 4.402230, validation loss = 5.357230\n",
      "I0409 03:56:57.401324 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 12: 59000, training batch loss = 1.835068, running_avg_loss loss = 4.402230, validation loss = 5.357230\n",
      "2020-04-09 03:56:58 - Transformer_word2Vec - INFO: - epoch 12: 59000, train_rouge_l_f = 0.016346, test_rouge_l_f = 0.126987\n",
      "I0409 03:56:58.518997 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 12: 59000, train_rouge_l_f = 0.016346, test_rouge_l_f = 0.126987\n",
      "2020-04-09 03:59:09 - Transformer_word2Vec - INFO: - epoch 12: 60000, training batch loss = 1.911350, running_avg_loss loss = 4.377321, validation loss = 5.354250\n",
      "I0409 03:59:09.507275 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 12: 60000, training batch loss = 1.911350, running_avg_loss loss = 4.377321, validation loss = 5.354250\n",
      "2020-04-09 03:59:09 - Transformer_word2Vec - INFO: - Saving model step 60000 to model/saved_models/Transformer_word2Vec/0060000.tar...\n",
      "I0409 03:59:09.509981 140206455236416 initialize.py:226] Saving model step 60000 to model/saved_models/Transformer_word2Vec/0060000.tar...\n",
      "2020-04-09 03:59:14 - Transformer_word2Vec - INFO: - epoch 12: 60000, train_rouge_l_f = 0.012897, test_rouge_l_f = 0.027256\n",
      "I0409 03:59:14.030078 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 12: 60000, train_rouge_l_f = 0.012897, test_rouge_l_f = 0.027256\n",
      "2020-04-09 04:01:27 - Transformer_word2Vec - INFO: - epoch 12: 61000, training batch loss = 1.671656, running_avg_loss loss = 4.350264, validation loss = 5.377322\n",
      "I0409 04:01:27.452782 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 12: 61000, training batch loss = 1.671656, running_avg_loss loss = 4.350264, validation loss = 5.377322\n",
      "2020-04-09 04:01:28 - Transformer_word2Vec - INFO: - epoch 12: 61000, train_rouge_l_f = 0.099691, test_rouge_l_f = 0.086956\n",
      "I0409 04:01:28.840815 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 12: 61000, train_rouge_l_f = 0.099691, test_rouge_l_f = 0.086956\n",
      "2020-04-09 04:03:29 - Transformer_word2Vec - INFO: - epoch 12: 61386, test_avg_acc = 0.057365\n",
      "I0409 04:03:29.760818 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 12: 61386, test_avg_acc = 0.057365\n",
      "2020-04-09 04:04:51 - Transformer_word2Vec - INFO: - epoch 13: 62000, training batch loss = 1.423681, running_avg_loss loss = 4.320999, validation loss = 5.454246\n",
      "I0409 04:04:51.283910 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 13: 62000, training batch loss = 1.423681, running_avg_loss loss = 4.320999, validation loss = 5.454246\n",
      "2020-04-09 04:04:52 - Transformer_word2Vec - INFO: - epoch 13: 62000, train_rouge_l_f = 0.025233, test_rouge_l_f = 0.042137\n",
      "I0409 04:04:52.163154 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 13: 62000, train_rouge_l_f = 0.025233, test_rouge_l_f = 0.042137\n",
      "2020-04-09 04:06:57 - Transformer_word2Vec - INFO: - epoch 13: 63000, training batch loss = 1.851153, running_avg_loss loss = 4.296300, validation loss = 5.438946\n",
      "I0409 04:06:57.138102 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 13: 63000, training batch loss = 1.851153, running_avg_loss loss = 4.296300, validation loss = 5.438946\n",
      "2020-04-09 04:06:57 - Transformer_word2Vec - INFO: - epoch 13: 63000, train_rouge_l_f = 0.099909, test_rouge_l_f = 0.099235\n",
      "I0409 04:06:57.901931 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 13: 63000, train_rouge_l_f = 0.099909, test_rouge_l_f = 0.099235\n",
      "2020-04-09 04:09:10 - Transformer_word2Vec - INFO: - epoch 13: 64000, training batch loss = 2.017503, running_avg_loss loss = 4.273512, validation loss = 5.454935\n",
      "I0409 04:09:10.209489 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 13: 64000, training batch loss = 2.017503, running_avg_loss loss = 4.273512, validation loss = 5.454935\n",
      "2020-04-09 04:09:10 - Transformer_word2Vec - INFO: - epoch 13: 64000, train_rouge_l_f = 0.080386, test_rouge_l_f = 0.080382\n",
      "I0409 04:09:10.536541 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 13: 64000, train_rouge_l_f = 0.080386, test_rouge_l_f = 0.080382\n",
      "2020-04-09 04:11:22 - Transformer_word2Vec - INFO: - epoch 13: 65000, training batch loss = 1.634410, running_avg_loss loss = 4.247121, validation loss = 5.458763\n",
      "I0409 04:11:22.551296 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 13: 65000, training batch loss = 1.634410, running_avg_loss loss = 4.247121, validation loss = 5.458763\n",
      "2020-04-09 04:11:22 - Transformer_word2Vec - INFO: - Saving model step 65000 to model/saved_models/Transformer_word2Vec/0065000.tar...\n",
      "I0409 04:11:22.553429 140206455236416 initialize.py:226] Saving model step 65000 to model/saved_models/Transformer_word2Vec/0065000.tar...\n",
      "2020-04-09 04:11:23 - Transformer_word2Vec - INFO: - epoch 13: 65000, train_rouge_l_f = 0.047027, test_rouge_l_f = 0.066166\n",
      "I0409 04:11:23.966371 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 13: 65000, train_rouge_l_f = 0.047027, test_rouge_l_f = 0.066166\n",
      "2020-04-09 04:13:34 - Transformer_word2Vec - INFO: - epoch 13: 66000, training batch loss = 1.726935, running_avg_loss loss = 4.221919, validation loss = 5.498252\n",
      "I0409 04:13:34.242609 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 13: 66000, training batch loss = 1.726935, running_avg_loss loss = 4.221919, validation loss = 5.498252\n",
      "2020-04-09 04:13:35 - Transformer_word2Vec - INFO: - epoch 13: 66000, train_rouge_l_f = 0.172577, test_rouge_l_f = 0.120154\n",
      "I0409 04:13:35.482550 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 13: 66000, train_rouge_l_f = 0.172577, test_rouge_l_f = 0.120154\n",
      "2020-04-09 04:15:17 - Transformer_word2Vec - INFO: - epoch 13: 66108, test_avg_acc = 0.085682\n",
      "I0409 04:15:17.611140 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 13: 66108, test_avg_acc = 0.085682\n",
      "2020-04-09 04:17:09 - Transformer_word2Vec - INFO: - epoch 14: 67000, training batch loss = 1.682876, running_avg_loss loss = 4.196529, validation loss = 5.550143\n",
      "I0409 04:17:09.432231 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 14: 67000, training batch loss = 1.682876, running_avg_loss loss = 4.196529, validation loss = 5.550143\n",
      "2020-04-09 04:17:10 - Transformer_word2Vec - INFO: - epoch 14: 67000, train_rouge_l_f = 0.032978, test_rouge_l_f = 0.158971\n",
      "I0409 04:17:10.141014 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 14: 67000, train_rouge_l_f = 0.032978, test_rouge_l_f = 0.158971\n",
      "2020-04-09 04:19:19 - Transformer_word2Vec - INFO: - epoch 14: 68000, training batch loss = 1.672041, running_avg_loss loss = 4.171284, validation loss = 5.530463\n",
      "I0409 04:19:19.297710 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 14: 68000, training batch loss = 1.672041, running_avg_loss loss = 4.171284, validation loss = 5.530463\n",
      "2020-04-09 04:19:19 - Transformer_word2Vec - INFO: - epoch 14: 68000, train_rouge_l_f = 0.119033, test_rouge_l_f = 0.058772\n",
      "I0409 04:19:19.612059 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 14: 68000, train_rouge_l_f = 0.119033, test_rouge_l_f = 0.058772\n",
      "2020-04-09 04:21:30 - Transformer_word2Vec - INFO: - epoch 14: 69000, training batch loss = 1.995353, running_avg_loss loss = 4.149525, validation loss = 5.578844\n",
      "I0409 04:21:30.698484 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 14: 69000, training batch loss = 1.995353, running_avg_loss loss = 4.149525, validation loss = 5.578844\n",
      "2020-04-09 04:21:32 - Transformer_word2Vec - INFO: - epoch 14: 69000, train_rouge_l_f = 0.105688, test_rouge_l_f = 0.092452\n",
      "I0409 04:21:32.138337 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 14: 69000, train_rouge_l_f = 0.105688, test_rouge_l_f = 0.092452\n",
      "2020-04-09 04:23:37 - Transformer_word2Vec - INFO: - epoch 14: 70000, training batch loss = 1.574859, running_avg_loss loss = 4.123778, validation loss = 5.560892\n",
      "I0409 04:23:37.537131 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 14: 70000, training batch loss = 1.574859, running_avg_loss loss = 4.123778, validation loss = 5.560892\n",
      "2020-04-09 04:23:37 - Transformer_word2Vec - INFO: - Saving model step 70000 to model/saved_models/Transformer_word2Vec/0070000.tar...\n",
      "I0409 04:23:37.540306 140206455236416 initialize.py:226] Saving model step 70000 to model/saved_models/Transformer_word2Vec/0070000.tar...\n",
      "2020-04-09 04:23:39 - Transformer_word2Vec - INFO: - epoch 14: 70000, train_rouge_l_f = 0.061413, test_rouge_l_f = 0.046130\n",
      "I0409 04:23:39.300752 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 14: 70000, train_rouge_l_f = 0.061413, test_rouge_l_f = 0.046130\n",
      "2020-04-09 04:26:02 - Transformer_word2Vec - INFO: - epoch 14: 70830, test_avg_acc = 0.103357\n",
      "I0409 04:26:02.445583 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 14: 70830, test_avg_acc = 0.103357\n",
      "2020-04-09 04:26:32 - Transformer_word2Vec - INFO: - epoch 15: 71000, training batch loss = 1.423296, running_avg_loss loss = 4.096773, validation loss = 5.613975\n",
      "I0409 04:26:32.918408 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 15: 71000, training batch loss = 1.423296, running_avg_loss loss = 4.096773, validation loss = 5.613975\n",
      "2020-04-09 04:26:34 - Transformer_word2Vec - INFO: - epoch 15: 71000, train_rouge_l_f = 0.042693, test_rouge_l_f = 0.029599\n",
      "I0409 04:26:34.828182 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 15: 71000, train_rouge_l_f = 0.042693, test_rouge_l_f = 0.029599\n",
      "2020-04-09 04:28:47 - Transformer_word2Vec - INFO: - epoch 15: 72000, training batch loss = 1.668329, running_avg_loss loss = 4.072489, validation loss = 5.629709\n",
      "I0409 04:28:47.175907 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 15: 72000, training batch loss = 1.668329, running_avg_loss loss = 4.072489, validation loss = 5.629709\n",
      "2020-04-09 04:28:48 - Transformer_word2Vec - INFO: - epoch 15: 72000, train_rouge_l_f = 0.079365, test_rouge_l_f = 0.018875\n",
      "I0409 04:28:48.335845 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 15: 72000, train_rouge_l_f = 0.079365, test_rouge_l_f = 0.018875\n",
      "2020-04-09 04:31:04 - Transformer_word2Vec - INFO: - epoch 15: 73000, training batch loss = 1.679611, running_avg_loss loss = 4.048560, validation loss = 5.618217\n",
      "I0409 04:31:04.813030 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 15: 73000, training batch loss = 1.679611, running_avg_loss loss = 4.048560, validation loss = 5.618217\n",
      "2020-04-09 04:31:05 - Transformer_word2Vec - INFO: - epoch 15: 73000, train_rouge_l_f = 0.107002, test_rouge_l_f = 0.115082\n",
      "I0409 04:31:05.489042 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 15: 73000, train_rouge_l_f = 0.107002, test_rouge_l_f = 0.115082\n",
      "2020-04-09 04:33:19 - Transformer_word2Vec - INFO: - epoch 15: 74000, training batch loss = 1.778778, running_avg_loss loss = 4.025862, validation loss = 5.644899\n",
      "I0409 04:33:19.244688 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 15: 74000, training batch loss = 1.778778, running_avg_loss loss = 4.025862, validation loss = 5.644899\n",
      "2020-04-09 04:33:19 - Transformer_word2Vec - INFO: - epoch 15: 74000, train_rouge_l_f = 0.104184, test_rouge_l_f = 0.023148\n",
      "I0409 04:33:19.690925 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 15: 74000, train_rouge_l_f = 0.104184, test_rouge_l_f = 0.023148\n",
      "2020-04-09 04:35:30 - Transformer_word2Vec - INFO: - epoch 15: 75000, training batch loss = 1.839387, running_avg_loss loss = 4.003997, validation loss = 5.654302\n",
      "I0409 04:35:30.592591 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 15: 75000, training batch loss = 1.839387, running_avg_loss loss = 4.003997, validation loss = 5.654302\n",
      "2020-04-09 04:35:30 - Transformer_word2Vec - INFO: - Saving model step 75000 to model/saved_models/Transformer_word2Vec/0075000.tar...\n",
      "I0409 04:35:30.595435 140206455236416 initialize.py:226] Saving model step 75000 to model/saved_models/Transformer_word2Vec/0075000.tar...\n",
      "2020-04-09 04:35:32 - Transformer_word2Vec - INFO: - epoch 15: 75000, train_rouge_l_f = 0.125495, test_rouge_l_f = 0.211785\n",
      "I0409 04:35:32.084141 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 15: 75000, train_rouge_l_f = 0.125495, test_rouge_l_f = 0.211785\n",
      "2020-04-09 04:37:17 - Transformer_word2Vec - INFO: - epoch 15: 75552, test_avg_acc = 0.044213\n",
      "I0409 04:37:17.237979 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 15: 75552, test_avg_acc = 0.044213\n",
      "2020-04-09 04:38:21 - Transformer_word2Vec - INFO: - epoch 16: 76000, training batch loss = 1.392334, running_avg_loss loss = 3.977881, validation loss = 5.705095\n",
      "I0409 04:38:21.575246 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 16: 76000, training batch loss = 1.392334, running_avg_loss loss = 3.977881, validation loss = 5.705095\n",
      "2020-04-09 04:38:22 - Transformer_word2Vec - INFO: - epoch 16: 76000, train_rouge_l_f = 0.023625, test_rouge_l_f = 0.116273\n",
      "I0409 04:38:22.048977 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 16: 76000, train_rouge_l_f = 0.023625, test_rouge_l_f = 0.116273\n",
      "2020-04-09 04:40:33 - Transformer_word2Vec - INFO: - epoch 16: 77000, training batch loss = 1.523498, running_avg_loss loss = 3.953337, validation loss = 5.763007\n",
      "I0409 04:40:33.153592 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 16: 77000, training batch loss = 1.523498, running_avg_loss loss = 3.953337, validation loss = 5.763007\n",
      "2020-04-09 04:40:33 - Transformer_word2Vec - INFO: - epoch 16: 77000, train_rouge_l_f = 0.102739, test_rouge_l_f = 0.116079\n",
      "I0409 04:40:33.383242 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 16: 77000, train_rouge_l_f = 0.102739, test_rouge_l_f = 0.116079\n",
      "2020-04-09 04:42:44 - Transformer_word2Vec - INFO: - epoch 16: 78000, training batch loss = 1.710064, running_avg_loss loss = 3.930904, validation loss = 5.688466\n",
      "I0409 04:42:44.994615 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 16: 78000, training batch loss = 1.710064, running_avg_loss loss = 3.930904, validation loss = 5.688466\n",
      "2020-04-09 04:42:45 - Transformer_word2Vec - INFO: - epoch 16: 78000, train_rouge_l_f = 0.054398, test_rouge_l_f = 0.022321\n",
      "I0409 04:42:45.364475 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 16: 78000, train_rouge_l_f = 0.054398, test_rouge_l_f = 0.022321\n",
      "2020-04-09 04:44:56 - Transformer_word2Vec - INFO: - epoch 16: 79000, training batch loss = 1.525174, running_avg_loss loss = 3.906847, validation loss = 5.714727\n",
      "I0409 04:44:56.351788 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 16: 79000, training batch loss = 1.525174, running_avg_loss loss = 3.906847, validation loss = 5.714727\n",
      "2020-04-09 04:44:56 - Transformer_word2Vec - INFO: - epoch 16: 79000, train_rouge_l_f = 0.110887, test_rouge_l_f = 0.036738\n",
      "I0409 04:44:56.929059 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 16: 79000, train_rouge_l_f = 0.110887, test_rouge_l_f = 0.036738\n",
      "2020-04-09 04:47:09 - Transformer_word2Vec - INFO: - epoch 16: 80000, training batch loss = 1.665347, running_avg_loss loss = 3.884432, validation loss = 5.713257\n",
      "I0409 04:47:09.538011 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 16: 80000, training batch loss = 1.665347, running_avg_loss loss = 3.884432, validation loss = 5.713257\n",
      "2020-04-09 04:47:09 - Transformer_word2Vec - INFO: - Saving model step 80000 to model/saved_models/Transformer_word2Vec/0080000.tar...\n",
      "I0409 04:47:09.542517 140206455236416 initialize.py:226] Saving model step 80000 to model/saved_models/Transformer_word2Vec/0080000.tar...\n",
      "2020-04-09 04:47:11 - Transformer_word2Vec - INFO: - epoch 16: 80000, train_rouge_l_f = 0.041579, test_rouge_l_f = 0.078468\n",
      "I0409 04:47:11.329057 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 16: 80000, train_rouge_l_f = 0.041579, test_rouge_l_f = 0.078468\n",
      "2020-04-09 04:48:14 - Transformer_word2Vec - INFO: - epoch 16: 80274, test_avg_acc = 0.110855\n",
      "I0409 04:48:14.783763 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 16: 80274, test_avg_acc = 0.110855\n",
      "2020-04-09 04:49:48 - Transformer_word2Vec - INFO: - epoch 17: 81000, training batch loss = 1.432224, running_avg_loss loss = 3.859910, validation loss = 5.803873\n",
      "I0409 04:49:48.428634 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 17: 81000, training batch loss = 1.432224, running_avg_loss loss = 3.859910, validation loss = 5.803873\n",
      "2020-04-09 04:49:48 - Transformer_word2Vec - INFO: - epoch 17: 81000, train_rouge_l_f = 0.056089, test_rouge_l_f = 0.158181\n",
      "I0409 04:49:48.756952 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 17: 81000, train_rouge_l_f = 0.056089, test_rouge_l_f = 0.158181\n",
      "2020-04-09 04:51:57 - Transformer_word2Vec - INFO: - epoch 17: 82000, training batch loss = 1.460509, running_avg_loss loss = 3.835916, validation loss = 5.802944\n",
      "I0409 04:51:57.185318 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 17: 82000, training batch loss = 1.460509, running_avg_loss loss = 3.835916, validation loss = 5.802944\n",
      "2020-04-09 04:51:57 - Transformer_word2Vec - INFO: - epoch 17: 82000, train_rouge_l_f = 0.107304, test_rouge_l_f = 0.062659\n",
      "I0409 04:51:57.964694 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 17: 82000, train_rouge_l_f = 0.107304, test_rouge_l_f = 0.062659\n",
      "2020-04-09 04:54:05 - Transformer_word2Vec - INFO: - epoch 17: 83000, training batch loss = 1.543293, running_avg_loss loss = 3.812990, validation loss = 5.850427\n",
      "I0409 04:54:05.865897 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 17: 83000, training batch loss = 1.543293, running_avg_loss loss = 3.812990, validation loss = 5.850427\n",
      "2020-04-09 04:54:06 - Transformer_word2Vec - INFO: - epoch 17: 83000, train_rouge_l_f = 0.005773, test_rouge_l_f = 0.046429\n",
      "I0409 04:54:06.247243 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 17: 83000, train_rouge_l_f = 0.005773, test_rouge_l_f = 0.046429\n",
      "2020-04-09 04:56:23 - Transformer_word2Vec - INFO: - epoch 17: 84000, training batch loss = 1.801306, running_avg_loss loss = 3.792873, validation loss = 5.819794\n",
      "I0409 04:56:23.008307 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 17: 84000, training batch loss = 1.801306, running_avg_loss loss = 3.792873, validation loss = 5.819794\n",
      "2020-04-09 04:56:23 - Transformer_word2Vec - INFO: - epoch 17: 84000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.042147\n",
      "I0409 04:56:23.500836 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 17: 84000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.042147\n",
      "2020-04-09 04:58:55 - Transformer_word2Vec - INFO: - epoch 17: 84996, test_avg_acc = 0.110855\n",
      "I0409 04:58:55.636511 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 17: 84996, test_avg_acc = 0.110855\n",
      "2020-04-09 04:59:07 - Transformer_word2Vec - INFO: - epoch 18: 85000, training batch loss = 1.507519, running_avg_loss loss = 3.770019, validation loss = 5.842526\n",
      "I0409 04:59:07.214165 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 18: 85000, training batch loss = 1.507519, running_avg_loss loss = 3.770019, validation loss = 5.842526\n",
      "2020-04-09 04:59:07 - Transformer_word2Vec - INFO: - Saving model step 85000 to model/saved_models/Transformer_word2Vec/0085000.tar...\n",
      "I0409 04:59:07.216720 140206455236416 initialize.py:226] Saving model step 85000 to model/saved_models/Transformer_word2Vec/0085000.tar...\n",
      "2020-04-09 04:59:08 - Transformer_word2Vec - INFO: - epoch 18: 85000, train_rouge_l_f = 0.104191, test_rouge_l_f = 0.043184\n",
      "I0409 04:59:08.676473 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 18: 85000, train_rouge_l_f = 0.104191, test_rouge_l_f = 0.043184\n",
      "2020-04-09 05:01:18 - Transformer_word2Vec - INFO: - epoch 18: 86000, training batch loss = 1.755470, running_avg_loss loss = 3.749874, validation loss = 5.880519\n",
      "I0409 05:01:18.128884 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 18: 86000, training batch loss = 1.755470, running_avg_loss loss = 3.749874, validation loss = 5.880519\n",
      "2020-04-09 05:01:18 - Transformer_word2Vec - INFO: - epoch 18: 86000, train_rouge_l_f = 0.159999, test_rouge_l_f = 0.080121\n",
      "I0409 05:01:18.993302 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 18: 86000, train_rouge_l_f = 0.159999, test_rouge_l_f = 0.080121\n",
      "2020-04-09 05:03:31 - Transformer_word2Vec - INFO: - epoch 18: 87000, training batch loss = 1.434477, running_avg_loss loss = 3.726720, validation loss = 5.900062\n",
      "I0409 05:03:31.817016 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 18: 87000, training batch loss = 1.434477, running_avg_loss loss = 3.726720, validation loss = 5.900062\n",
      "2020-04-09 05:03:32 - Transformer_word2Vec - INFO: - epoch 18: 87000, train_rouge_l_f = 0.015476, test_rouge_l_f = 0.000000\n",
      "I0409 05:03:32.461678 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 18: 87000, train_rouge_l_f = 0.015476, test_rouge_l_f = 0.000000\n",
      "2020-04-09 05:05:49 - Transformer_word2Vec - INFO: - epoch 18: 88000, training batch loss = 1.653589, running_avg_loss loss = 3.705988, validation loss = 5.819294\n",
      "I0409 05:05:49.452492 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 18: 88000, training batch loss = 1.653589, running_avg_loss loss = 3.705988, validation loss = 5.819294\n",
      "2020-04-09 05:05:50 - Transformer_word2Vec - INFO: - epoch 18: 88000, train_rouge_l_f = 0.066494, test_rouge_l_f = 0.030783\n",
      "I0409 05:05:50.234731 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 18: 88000, train_rouge_l_f = 0.066494, test_rouge_l_f = 0.030783\n",
      "2020-04-09 05:07:58 - Transformer_word2Vec - INFO: - epoch 18: 89000, training batch loss = 1.550684, running_avg_loss loss = 3.684435, validation loss = 5.823020\n",
      "I0409 05:07:58.816927 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 18: 89000, training batch loss = 1.550684, running_avg_loss loss = 3.684435, validation loss = 5.823020\n",
      "2020-04-09 05:07:59 - Transformer_word2Vec - INFO: - epoch 18: 89000, train_rouge_l_f = 0.028682, test_rouge_l_f = 0.172540\n",
      "I0409 05:07:59.059913 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 18: 89000, train_rouge_l_f = 0.028682, test_rouge_l_f = 0.172540\n",
      "2020-04-09 05:10:03 - Transformer_word2Vec - INFO: - epoch 18: 89718, test_avg_acc = 0.042498\n",
      "I0409 05:10:03.085983 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 18: 89718, test_avg_acc = 0.042498\n",
      "2020-04-09 05:10:46 - Transformer_word2Vec - INFO: - epoch 19: 90000, training batch loss = 1.338125, running_avg_loss loss = 3.660972, validation loss = 5.866014\n",
      "I0409 05:10:46.689460 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 19: 90000, training batch loss = 1.338125, running_avg_loss loss = 3.660972, validation loss = 5.866014\n",
      "2020-04-09 05:10:46 - Transformer_word2Vec - INFO: - Saving model step 90000 to model/saved_models/Transformer_word2Vec/0090000.tar...\n",
      "I0409 05:10:46.692820 140206455236416 initialize.py:226] Saving model step 90000 to model/saved_models/Transformer_word2Vec/0090000.tar...\n",
      "2020-04-09 05:10:48 - Transformer_word2Vec - INFO: - epoch 19: 90000, train_rouge_l_f = 0.137219, test_rouge_l_f = 0.114805\n",
      "I0409 05:10:48.465174 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 19: 90000, train_rouge_l_f = 0.137219, test_rouge_l_f = 0.114805\n",
      "2020-04-09 05:12:57 - Transformer_word2Vec - INFO: - epoch 19: 91000, training batch loss = 1.418550, running_avg_loss loss = 3.638548, validation loss = 5.881666\n",
      "I0409 05:12:57.448530 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 19: 91000, training batch loss = 1.418550, running_avg_loss loss = 3.638548, validation loss = 5.881666\n",
      "2020-04-09 05:12:58 - Transformer_word2Vec - INFO: - epoch 19: 91000, train_rouge_l_f = 0.082915, test_rouge_l_f = 0.077432\n",
      "I0409 05:12:58.886201 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 19: 91000, train_rouge_l_f = 0.082915, test_rouge_l_f = 0.077432\n",
      "2020-04-09 05:15:11 - Transformer_word2Vec - INFO: - epoch 19: 92000, training batch loss = 1.682589, running_avg_loss loss = 3.618989, validation loss = 5.918743\n",
      "I0409 05:15:11.063569 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 19: 92000, training batch loss = 1.682589, running_avg_loss loss = 3.618989, validation loss = 5.918743\n",
      "2020-04-09 05:15:11 - Transformer_word2Vec - INFO: - epoch 19: 92000, train_rouge_l_f = 0.079623, test_rouge_l_f = 0.073340\n",
      "I0409 05:15:11.657298 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 19: 92000, train_rouge_l_f = 0.079623, test_rouge_l_f = 0.073340\n",
      "2020-04-09 05:17:27 - Transformer_word2Vec - INFO: - epoch 19: 93000, training batch loss = 1.314106, running_avg_loss loss = 3.595940, validation loss = 5.893395\n",
      "I0409 05:17:27.032092 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 19: 93000, training batch loss = 1.314106, running_avg_loss loss = 3.595940, validation loss = 5.893395\n",
      "2020-04-09 05:17:27 - Transformer_word2Vec - INFO: - epoch 19: 93000, train_rouge_l_f = 0.026177, test_rouge_l_f = 0.022321\n",
      "I0409 05:17:27.929715 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 19: 93000, train_rouge_l_f = 0.026177, test_rouge_l_f = 0.022321\n",
      "2020-04-09 05:19:36 - Transformer_word2Vec - INFO: - epoch 19: 94000, training batch loss = 1.704258, running_avg_loss loss = 3.577023, validation loss = 5.919315\n",
      "I0409 05:19:36.577771 140206455236416 <ipython-input-9-86ea97d748bc>:28] epoch 19: 94000, training batch loss = 1.704258, running_avg_loss loss = 3.577023, validation loss = 5.919315\n",
      "2020-04-09 05:19:36 - Transformer_word2Vec - INFO: - epoch 19: 94000, train_rouge_l_f = 0.124737, test_rouge_l_f = 0.089733\n",
      "I0409 05:19:36.896466 140206455236416 <ipython-input-9-86ea97d748bc>:50] epoch 19: 94000, train_rouge_l_f = 0.124737, test_rouge_l_f = 0.089733\n",
      "2020-04-09 05:21:12 - Transformer_word2Vec - INFO: - epoch 19: 94440, test_avg_acc = 0.111730\n",
      "I0409 05:21:12.768820 140206455236416 <ipython-input-9-86ea97d748bc>:53] epoch 19: 94440, test_avg_acc = 0.111730\n",
      "2020-04-09 05:21:12 - Transformer_word2Vec - INFO: - ------Training END--------\n",
      "I0409 05:21:12.771070 140206455236416 <ipython-input-9-86ea97d748bc>:60] ------Training END--------\n",
      "2020-04-09 05:21:12 - Transformer_word2Vec - INFO: - logger已關閉\n",
      "I0409 05:21:12.773025 140206455236416 train_util.py:96] logger已關閉\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(config.max_epochs):\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        train_one(model, config, batch)\n",
    "        mle_loss = train_one(model, config, batch)\n",
    "        rl_loss = T.FloatTensor([0]).cuda()\n",
    "        (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "        \n",
    "#         '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "        if step % ( config.gradient_accum) == 0: # gradient accumulation\n",
    "#             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "#             (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "            optimizer.step() # 根据累计的梯度更新网络参数\n",
    "            optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            \n",
    "        if step%1000 == 0 :\n",
    "            with T.autograd.no_grad():\n",
    "                train_batch_loss = mle_loss.item()\n",
    "                val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                            % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                writer.add_scalars('scalar/Loss',  \n",
    "                   {'train_batch_loss': train_batch_loss\n",
    "                   }, step)\n",
    "                writer.add_scalars('scalar_avg/loss',  \n",
    "                   {'train_avg_loss': running_avg_loss,\n",
    "                    'test_avg_loss': val_avg_loss\n",
    "                   }, step)\n",
    "            \n",
    "        if step%5000 == 0:\n",
    "            save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                       r_loss=0, title = loggerName)        \n",
    "      \n",
    "        if step%1000 == 0 and step > 0:\n",
    "            train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "            test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "            writer.add_scalars('scalar/Rouge-L',  \n",
    "               {'train_rouge_l_f': train_rouge_l_f,\n",
    "                'test_rouge_l_f': test_rouge_l_f\n",
    "               }, step)\n",
    "            logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                            % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "            \n",
    "    train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "    test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "    logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "#     try:\n",
    "#         test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader)\n",
    "#         logger.info('epoch %d: %d, test_avg_acc = %f' % (epoch, step, test_avg_acc))\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "logger.info(u'------Training END--------')                \n",
    "removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2019, 0.1671, 0.1338, 0.8487, 0.1730],\n",
       "        [0.8708, 0.2498, 0.9451, 0.5590, 0.1955]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(2, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2019, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input.scatter_(dim, index, src)\n",
    "# 将src中数据根据index中的索引按照dim的方向填进input中\n",
    "torch.zeros(400, 50000).scatter_(1, torch.tensor([[1]\n",
    "                                           ]), x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
