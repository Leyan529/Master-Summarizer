{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 09:53:24.969929 139995784521536 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-05-11 09:53:25 - Pointer_Sep_BertEnc_Transformer_BertEmb - INFO: - logger已啟動\n",
      "I0511 09:53:25.703257 139995784521536 train_util.py:119] logger已啟動\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loggerName Pointer_Sep_BertEnc_Transformer_BertEmb\n",
      "writerPath runs/Mix6_mainCat/Pointer_Sep_BertEnc_Transformer/BertEmb/exp\n"
     ]
    }
   ],
   "source": [
    "from utils import config\n",
    "from utils.bert import data\n",
    "\n",
    "from utils.bert.batcher import *\n",
    "from utils.bert.train_util import *\n",
    "from utils.bert.initialize import loadCheckpoint, save_model\n",
    "from utils.bert.write_result import *\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_type', type=str, default='transformer', choices=['seq2seq', 'transformer'])\n",
    "parser.add_argument('--copy', type=bool, default=True, choices=[True, False])\n",
    "parser.add_argument(\"-encoder\", default='bert', type=str, choices=['bert', 'Transformer'])\n",
    "parser.add_argument(\"-max_pos\", default=1000, type=int)\n",
    "parser.add_argument(\"-use_bert_emb\", type=str2bool, nargs='?',const=True,default=True, choices=[False, True])\n",
    "\n",
    "parser.add_argument(\"-lr_bert\", default=2e-2, type=float, help='2e-3')\n",
    "parser.add_argument(\"-lr_dec\", default=2e-2, type=float, help='2e-3')\n",
    "parser.add_argument(\"-share_emb\", type=str2bool, nargs='?', const=True, default=False)\n",
    "parser.add_argument(\"-finetune_bert\", type=bool, default=True)\n",
    "    \n",
    "'''\n",
    "原 Bert Base paper核心參數\n",
    "dropout = 0.1\n",
    "num_layers = 12\n",
    "num_heads = 8\n",
    "emb_dim(d_model) : 768\n",
    "ff_embed_dim = 4*emb_dim = 3072\n",
    "\n",
    "bert_config = BertConfig(self.encoder.model.config.vocab_size, hidden_size=768,\n",
    "                                     num_hidden_layers=12, num_attention_heads=8,\n",
    "                                     intermediate_size= 3072,\n",
    "                                     hidden_dropout_prob=0.1,\n",
    "                                     attention_probs_dropout_prob=0.1)\n",
    "'''\n",
    "parser.add_argument(\"-enc_dropout\", default=0.1, type=float)\n",
    "parser.add_argument(\"-enc_layers\", default=12, type=int)\n",
    "parser.add_argument(\"-enc_hidden_size\", default=768, type=int)\n",
    "parser.add_argument(\"-enc_heads\", default=8, type=int)\n",
    "parser.add_argument(\"-enc_ff_size\", default=3072, type=int)\n",
    "\n",
    "parser.add_argument(\"-dec_dropout\", default=0.1, type=float)\n",
    "parser.add_argument(\"-dec_layers\", default=12, type=int)\n",
    "parser.add_argument(\"-dec_hidden_size\", default=768, type=int)\n",
    "parser.add_argument(\"-dec_heads\", default=8, type=int)\n",
    "parser.add_argument(\"-dec_ff_size\", default=2048, type=int)\n",
    "parser.add_argument(\"-sep_optim\", type=str2bool, nargs='?',const=True,default=True, choices=[False, True])\n",
    "\n",
    "parser.add_argument(\"-param_init\", default=0, type=float)\n",
    "parser.add_argument(\"-param_init_glorot\", type=str2bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-optim\", default='adam', type=str)\n",
    "parser.add_argument(\"-lr\", default=1, type=float)\n",
    "parser.add_argument(\"-beta1\", default= 0.9, type=float)\n",
    "parser.add_argument(\"-beta2\", default=0.999, type=float)\n",
    "parser.add_argument(\"-warmup_steps\", default=8000, type=int)\n",
    "parser.add_argument(\"-warmup_steps_bert\", default=8000, type=int)\n",
    "parser.add_argument(\"-warmup_steps_dec\", default=8000, type=int)\n",
    "parser.add_argument(\"-max_grad_norm\", default=0, type=float)\n",
    "\n",
    "parser.add_argument(\"-block_trigram\", type=str2bool, nargs='?', const=True, default=True)\n",
    "\n",
    "\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_keys', \n",
    "                    help = 'POS_keys / DEP_keys / Noun_adj_keys / TextRank_keys')\n",
    "\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument(\"-label_smoothing\", default=0.0, type=float)\n",
    "parser.add_argument(\"-generator_shard_size\", default=32, type=int)\n",
    "parser.add_argument(\"-alpha\",  default=0.6, type=float)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=40)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=10)\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "\n",
    "# parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "# parser.add_argument('--emb_dim', type=int, default=512)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default='0000010', help='0000010')\n",
    "# parser.add_argument('--word_emb_type', type=str, default='glove', help='word2Vec/glove/FastText')\n",
    "# parser.add_argument('--pre_train_emb', type=bool, default=False, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 09:53:26.771819 139995784521536 tokenization.py:157] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "{'BOS': 1, 'EOS': 2, 'PAD': 0, 'EOQ': 3, 'SEP': 102, 'CLS': 101, 'UNK': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 09:54:25 - Pointer_Sep_BertEnc_Transformer_BertEmb - INFO: - train : 397524, test : 44170\n",
      "I0511 09:54:25.737581 139995784521536 batcher.py:211] train : 397524, test : 44170\n",
      "2020-05-11 09:54:26 - Pointer_Sep_BertEnc_Transformer_BertEmb - INFO: - train batches : 99381, test batches : 11042\n",
      "I0511 09:54:26.081987 139995784521536 batcher.py:226] train batches : 99381, test batches : 11042\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab, symbols = getDataLoader(logger, config)\n",
    "tokenizer = vocab.tokenizer\n",
    "train_batches = len(iter(train_loader))\n",
    "test_batches = len(iter(validate_loader))\n",
    "save_steps = int(train_batches/1000)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 09:54:27.293477 139995784521536 modeling_utils.py:199] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0511 09:54:27.296614 139995784521536 modeling_utils.py:216] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0511 09:54:28.323001 139995784521536 modeling_utils.py:533] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AbsSummarizer(\n",
       "  (encoder): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(1000, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (word_prob): WordProbLayer(\n",
       "    (LogScore): LogSoftmax()\n",
       "    (proj): Linear(in_features=2304, out_features=30522, bias=True)\n",
       "    (prob_copy): Linear(in_features=2304, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.transformer.loss import *\n",
    "from utils.transformer.optimizers import Optimizer\n",
    "from transformer import *\n",
    "from utils.transformer.predictor import build_predictor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "model = AbsSummarizer(config)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (loggerName, config.load_ckpt)\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(config, logger, load_model_path, model)\n",
    "else:    \n",
    "    if (config.sep_optim):\n",
    "        optim_bert = Optimizer(\n",
    "            config.optim, config.lr_bert, config.max_grad_norm,\n",
    "            beta1=config.beta1, beta2=config.beta2,\n",
    "            decay_method='noam',\n",
    "            warmup_steps=config.warmup_steps_bert)\n",
    "\n",
    "        optim_dec = Optimizer(\n",
    "            config.optim, config.lr_dec, config.max_grad_norm,\n",
    "            beta1=config.beta1, beta2=config.beta2,\n",
    "            decay_method='noam',\n",
    "            warmup_steps=config.warmup_steps_dec)\n",
    "        \n",
    "        params = [(n, p) for n, p in list(model.named_parameters()) if n.startswith('encoder.model')]\n",
    "        optim_bert.set_parameters(params)\n",
    "\n",
    "        params = [(n, p) for n, p in list(model.named_parameters()) if not n.startswith('encoder.model')]\n",
    "        optim_dec.set_parameters(params)\n",
    "\n",
    "        optimizer = [optim_bert, optim_dec]\n",
    "    else:\n",
    "        optimizer = Optimizer(\n",
    "            config.optim, config.lr, config.max_grad_norm,\n",
    "            beta1=config.beta1, beta2=config.beta2,\n",
    "            decay_method='noam',\n",
    "            warmup_steps=config.warmup_steps)\n",
    "        optimizer.set_parameters(list(model.named_parameters()))\n",
    "        optimizer = [optimizer]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "setattr(config, 'device_ids', [0])\n",
    "\n",
    "model = get_cuda(model)\n",
    "net = nn.DataParallel(model, device_ids=config.device_ids)\n",
    "# model = nn.DataParallel(model).cuda()\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(net, model, config, batch):\n",
    "    normalization = 0\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, _, _, _, _, _, enc_seg, enc_cls, enc_cls_mask = get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    'Decoder data'\n",
    "    dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = get_output_from_batch(batch, config, batch_first = True) # Get input and target \n",
    "\n",
    "    \n",
    "    num_tokens = dec_batch[:, 1:].ne(0).sum()\n",
    "    normalization += num_tokens.item()    \n",
    "\n",
    "#     pred, state = model(enc_batch, dec_batch, enc_seg, \n",
    "#         enc_cls, enc_padding_mask, dec_padding_mask, enc_cls_mask, \n",
    "#         extra_zeros, enc_batch_extend_vocab)\n",
    "    pred, state = net(enc_batch, dec_batch, enc_seg, \n",
    "        enc_cls, enc_padding_mask, dec_padding_mask, enc_cls_mask, \n",
    "        extra_zeros, enc_batch_extend_vocab)\n",
    "    \n",
    "    criterion = choose_criterion(config, model.vocab_size)\n",
    "    loss, num_correct, target = compute_loss(None, criterion, pred, dec_batch[:,1:], num_tokens, tokenizer)\n",
    "    # loss = loss / normalization  # Normalized losses; (batch_size)\n",
    "    # --------------------------------------------------------------------------------\n",
    "    acc = accuracy(num_correct, num_tokens)\n",
    "    cross_entropy = xent(loss, num_tokens)\n",
    "    perplexity = ppl(loss, num_tokens)\n",
    "\n",
    "#     print(\"num_tokens:%s; acc: %6.2f; perplexity: %5.2f; cross entropy loss: %4.2f\" \n",
    "#                             % (num_tokens,\n",
    "#                             acc,\n",
    "#                             perplexity,\n",
    "#                             cross_entropy\n",
    "#                             ))\n",
    "    # >>>>>>>> DEBUG Session <<<<<<<<<\n",
    "    # print('------------------------------------')\n",
    "    # print(\"ENC\\n\")\n",
    "    # print(enc_batch.shape)\n",
    "    # print(\"DEC\\n\")\n",
    "    # print(dec_batch.shape)\n",
    "    # print(\"TGT\\n\")\n",
    "    # print(target_batch.shape)\n",
    "    # print(\"ENCP\\n\")\n",
    "    # print(enc_padding_mask.shape)\n",
    "    # print(\"DECP\\n\")\n",
    "    # print(dec_padding_mask.shape)\n",
    "    # print(\"enc_seg\\n\")\n",
    "    # print(enc_seg.shape)\n",
    "    # print(\"enc_cls\\n\")\n",
    "    # print(enc_cls.shape)\n",
    "    # print(\"enc_cls_mask\\n\")\n",
    "    # print(enc_cls_mask.shape)\n",
    "    return loss.div(float(normalization))    \n",
    "#     return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, net, model):\n",
    "    losses = []\n",
    "    # batch = next(iter(validate_loader))\n",
    "    val_num = len(iter(validate_loader))\n",
    "    for idx, batch in enumerate(validate_loader):\n",
    "        loss = train_one(net, model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "        if idx>= val_num/10: break\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        # num = len(iter(batch))\n",
    "        # select_batch = None\n",
    "        # rand_b_id = randint(0,num-1)\n",
    "        # logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        # for idx, b in enumerate(batch):\n",
    "        #     if idx == rand_b_id:\n",
    "        #         select_batch = b\n",
    "        #         break\n",
    "        select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    '''\n",
    "    batch_data = self.translate_batch(batch)\n",
    "    translations = self.from_batch(batch_data)\n",
    "    '''\n",
    "    gold_tgt_len = batch.dec_tgt.size(1)\n",
    "    setattr(config, 'min_length',gold_tgt_len + 20)\n",
    "    setattr(config, 'max_length',gold_tgt_len + 60)\n",
    "    predictor = build_predictor(config, tokenizer, symbols, model, logger)\n",
    "\n",
    "    # 'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, \\\n",
    "        _, _, _, _, _, enc_seg, enc_cls, enc_cls_mask = get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    # 'Decoder data'\n",
    "    dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = get_output_from_batch(batch, config, batch_first = True) # Get input and target \n",
    "\n",
    "    setattr(batch, 'src',enc_batch)\n",
    "    setattr(batch, 'segs',enc_seg)\n",
    "    setattr(batch, 'mask_src',enc_padding_mask)\n",
    "\n",
    "    batch_data = predictor.translate_batch(batch)\n",
    "    translations = predictor.from_batch(batch_data) # translation = (pred_sents, gold_sent, raw_src)\n",
    "    article_sents = [t[2] for t in translations]\n",
    "    decoded_sents = [t[0] for t in translations]\n",
    "    ref_sents = [t[1] for t in translations]\n",
    "    keywords_list = [str(word_list) for word_list in batch.key_words]\n",
    "#     print('decoded_sents',decoded_sents)\n",
    "    # ---------------------------------------------------------------------------\n",
    "    rouge_1, rouge_2, rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents,                     keywords_list, ref_sents, 0, write = False)\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, keywords_list, ref_sents, 0)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents, keywords_list, ref_sents, 0)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import time\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    acc_st, acc_cost = 0, 0\n",
    "    avg_acc_cost = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        if idx >= num/10000: break\n",
    "        acc_st = time.time()\n",
    "        # ---------------------------------------------------------------------------\n",
    "        '''\n",
    "        batch_data = self.translate_batch(batch)\n",
    "        translations = self.from_batch(batch_data)\n",
    "        '''\n",
    "        gold_tgt_len = batch.dec_tgt.size(1)\n",
    "        setattr(config, 'min_length',gold_tgt_len + 20)\n",
    "        setattr(config, 'max_length',gold_tgt_len + 60)\n",
    "        predictor = build_predictor(config, tokenizer, symbols, model, logger)\n",
    "\n",
    "        # 'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, \\\n",
    "        _, _, _, _, _, enc_seg, enc_cls, enc_cls_mask = get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        # 'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = get_output_from_batch(batch, config, batch_first = True) # Get input and target \n",
    "\n",
    "        setattr(batch, 'src',enc_batch)\n",
    "        setattr(batch, 'segs',enc_seg)\n",
    "        setattr(batch, 'mask_src',enc_padding_mask)\n",
    "\n",
    "        batch_data = predictor.translate_batch(batch)\n",
    "        translations = predictor.from_batch(batch_data) # translation = (pred_sents, gold_sent, raw_src)\n",
    "        article_sents = [t[2] for t in translations]\n",
    "        decoded_sents = [t[0] for t in translations]\n",
    "        ref_sents = [t[1] for t in translations]\n",
    "        keywords_list = [str(word_list) for word_list in batch.key_words]\n",
    "\n",
    "\n",
    "        rouge_1, rouge_2, rouge_l = \\\n",
    "        write_rouge(writer, None, None, article_sents, decoded_sents, keywords_list, ref_sents, 0, write = False)\n",
    "        # ---------------------------------------------------------------------------\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "        acc_cost = time.time() - acc_st\n",
    "        avg_acc_cost.append(acc_cost)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / len(avg_rouge_l)\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "    avg_acc_cost = sum(avg_acc_cost) / len(avg_acc_cost)\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from utils.seq2seq.write_result import total_evaulate, total_output\n",
    "\n",
    "@torch.autograd.no_grad()\n",
    "def decode_write_all(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(dataloader)\n",
    "    avg_rouge_1, avg_rouge_2, avg_rouge_l  = [], [], []\n",
    "    avg_self_bleu1, avg_self_bleu2, avg_self_bleu3, avg_self_bleu4 = [], [], [], []\n",
    "    avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4 = [], [], [], []\n",
    "    avg_meteor = []\n",
    "    outFrame = None\n",
    "    avg_time = 0\n",
    "    \n",
    "    rouge = Rouge()  \n",
    "    \n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        start = time.time() \n",
    "        gold_tgt_len = batch.dec_tgt.size(1)\n",
    "        setattr(config, 'min_length',gold_tgt_len + 20)\n",
    "        setattr(config, 'max_length',gold_tgt_len + 60)\n",
    "        predictor = build_predictor(config, tokenizer, symbols, model, logger)\n",
    "\n",
    "        # 'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, _, \\\n",
    "        _, _, _, _, enc_seg, enc_cls, enc_cls_mask = \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        # 'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target \n",
    "\n",
    "        setattr(batch, 'src',enc_batch)\n",
    "        setattr(batch, 'segs',enc_seg)\n",
    "        setattr(batch, 'mask_src',enc_padding_mask)\n",
    "\n",
    "        batch_data = predictor.translate_batch(batch)\n",
    "        translations = predictor.from_batch(batch_data) # translation = (pred_sents, gold_sent, raw_src)\n",
    "        article_sents = [t[2] for t in translations]\n",
    "        decoded_sents = [t[0] for t in translations]\n",
    "        ref_sents = [t[1] for t in translations]\n",
    "        keywords_list = [str(word_list) for word_list in batch.key_words]\n",
    "        cost = (time.time() - start)\n",
    "        avg_time += cost        \n",
    "\n",
    "        rouge_1, rouge_2, rouge_l, self_Bleu_1, self_Bleu_2, self_Bleu_3, self_Bleu_4, \\\n",
    "            Bleu_1, Bleu_2, Bleu_3, Bleu_4, Meteor, batch_frame = total_evaulate(article_sents, keywords_list, decoded_sents, ref_sents)\n",
    "\n",
    "        if idx %1000 ==0 and idx >0 : print(idx)\n",
    "        if idx == 0: outFrame = batch_frame\n",
    "        else: outFrame = pd.concat([outFrame, batch_frame], axis=0, ignore_index=True) \n",
    "        # ----------------------------------------------------\n",
    "        avg_rouge_1.extend(rouge_1)\n",
    "        avg_rouge_2.extend(rouge_2)\n",
    "        avg_rouge_l.extend(rouge_l)   \n",
    "        \n",
    "        avg_self_bleu1.extend(self_Bleu_1)\n",
    "        avg_self_bleu2.extend(self_Bleu_2)\n",
    "        avg_self_bleu3.extend(self_Bleu_3)\n",
    "        avg_self_bleu4.extend(self_Bleu_4)\n",
    "        \n",
    "        avg_bleu1.extend(Bleu_1)\n",
    "        avg_bleu2.extend(Bleu_2)\n",
    "        avg_bleu3.extend(Bleu_3)\n",
    "        avg_bleu4.extend(Bleu_4)\n",
    "        avg_meteor.extend(Meteor)\n",
    "        # ----------------------------------------------------    \n",
    "    avg_time = avg_time / (num * config.batch_size) \n",
    "    \n",
    "    avg_rouge_l, outFrame = total_output(mode, writerPath, outFrame, avg_time, avg_rouge_1, avg_rouge_2, avg_rouge_l, \\\n",
    "        avg_self_bleu1, avg_self_bleu2, avg_self_bleu3, avg_self_bleu4, \\\n",
    "        avg_bleu1, avg_bleu2, avg_bleu3, avg_bleu4, avg_meteor\n",
    "    )\n",
    "    \n",
    "    return avg_rouge_l, outFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 09:54:37 - Pointer_Sep_BertEnc_Transformer_BertEmb - INFO: - ------Training START--------\n",
      "I0511 09:54:37.113882 139995784521536 <ipython-input-11-95526b2f66f1>:6] ------Training START--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(6.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2 tensor(8.6519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3 tensor(7.7785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "4 tensor(7.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "5 tensor(8.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "6 tensor(7.8132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "7 tensor(8.2757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "8 tensor(8.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "9 tensor(7.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "10 tensor(8.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "11 tensor(8.1124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "12 tensor(7.9528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "13 tensor(8.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "14 tensor(8.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "15 tensor(7.8646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "16 tensor(8.0610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "17 tensor(8.8315, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 09:54:44 - Pointer_Sep_BertEnc_Transformer_BertEmb - INFO: - ------Training END--------\n",
      "I0511 09:54:44.981459 139995784521536 <ipython-input-11-95526b2f66f1>:103] ------Training END--------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.92 GiB total capacity; 9.97 GiB already allocated; 4.88 MiB free; 10.37 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95526b2f66f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mmle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmle_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-52cdc95a13fb>\u001b[0m in \u001b[0;36mtrain_one\u001b[0;34m(net, model, config, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0menc_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_cls_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         extra_zeros, enc_batch_extend_vocab)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, segs, clss, mask_src, mask_tgt, mask_cls, extra_zeros, src_extend_vocab)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msrc_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mdec_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_decoder_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, segs, mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# print('mask',mask.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mtop_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 10.92 GiB total capacity; 9.86 GiB already allocated; 108.88 MiB free; 10.27 GiB reserved in total by PyTorch)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95526b2f66f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0;32mexcept\u001b[0m \u001b[0mExcepation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Excepation' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95526b2f66f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'------Training END--------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtrain_avg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_outFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_write_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mtest_avg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_outFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_write_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d: train_avg_acc = %f, test_avg_acc = %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_avg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_avg_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c9134dea057a>\u001b[0m in \u001b[0;36mdecode_write_all\u001b[0;34m(writer, logger, epoch, config, model, dataloader, mode)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask_src'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# translation = (pred_sents, gold_sent, raw_src)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0marticle_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/utils/transformer/predictor.py\u001b[0m in \u001b[0;36mtranslate_batch\u001b[0;34m(self, batch, fast)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 min_length=self.min_length)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     def _fast_translate_batch(self,\n",
      "\u001b[0;32m~/Users/leyan/Summarize/utils/transformer/predictor.py\u001b[0m in \u001b[0;36m_fast_translate_batch\u001b[0;34m(self, batch, max_length, min_length)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m#                                          step=step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             dec_out, dec_states, dec_emb, last_dec_mid = decoder(decoder_input, src_features, dec_states,\n\u001b[0;32m--> 235\u001b[0;31m                                                      step=step)                                                     \n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# log_probs, check_attn = self.model.word_prob(dec_out.transpose(0,1).squeeze(0),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m#     dec_emb.transpose(0,1).squeeze(0), last_dec_mid,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/utils/transformer/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory_bank, state, memory_lengths, step, cache, memory_masks)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mlayer_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layer_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                     step=step)\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0msaved_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/utils/transformer/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, memory_bank, src_pad_mask, tgt_pad_mask, previous_input, layer_cache, step)\u001b[0m\n\u001b[1;32m     86\u001b[0m                                       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                       \u001b[0mlayer_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                                       type=\"context\")\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Summarize/utils/transformer/neural.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, key, value, query, mask, layer_cache, type, predefined_graph_1)\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlayer_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"memory_keys\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.92 GiB total capacity; 9.97 GiB already allocated; 4.88 MiB free; 10.37 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "loss_st, loss_cost = 0,0\n",
    "decode_st, decode_cost = 0,0\n",
    "\n",
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss, running_avg_rl_loss = 0, 0\n",
    "sum_total_reward = 0\n",
    "step = 0\n",
    "# save_steps = 10\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1            \n",
    "            loss_st = time.time()\n",
    "            mle_loss = train_one(net, model, config, batch)\n",
    "            print(step, mle_loss)\n",
    "            if config.train_rl:\n",
    "                rl_loss, batch_reward = train_one_RL(net, config, batch)             \n",
    "            else:\n",
    "                rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            model.zero_grad() # 清空过往梯度\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % (config.gradient_accum) == 0: # gradient accumulation\n",
    "                    # clip_grad_norm_(model.parameters(), 5.0)                     \n",
    "                for opt_idx, o in enumerate(optimizer):\n",
    "                    o.step() # 根据累计的梯度更新网络参数\n",
    "                    if opt_idx == 0: opt_name = 'lr_bert'\n",
    "                    else: opt_name = 'lr_dec'\n",
    "                    writer.add_scalars('scalar/%s' % opt_name,  \n",
    "                           {'lr': o.learning_rate\n",
    "                           }, step)\n",
    "\n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    train_batch_rl_loss = rl_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, net, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    running_avg_rl_loss = calc_running_avg_loss(train_batch_rl_loss, running_avg_rl_loss)\n",
    "                    running_avg_reward = sum_total_reward / step\n",
    "                    if step % save_steps == 0:\n",
    "                        logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                    % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "                    if running_avg_reward > 0:\n",
    "    #                         logger.info('epoch %d: %d, running_avg_reward = %f'\n",
    "    #                                 % (epoch, step, running_avg_reward))\n",
    "                        writer.add_scalars('scalar_avg/Reward',  \n",
    "                           {'running_avg_reward': running_avg_reward\n",
    "                           }, step)\n",
    "                    if running_avg_rl_loss != 0:\n",
    "    #                         logger.info('epoch %d: %d, running_avg_rl_loss = %f'\n",
    "    #                                 % (epoch, step, running_avg_rl_loss))\n",
    "                        writer.add_scalars('scalar_avg/RL_Loss',  \n",
    "                           {'running_avg_rl_loss': running_avg_rl_loss\n",
    "                           }, step)\n",
    "                    loss_cost = time.time() - loss_st\n",
    "                    if step % save_steps == 0: logger.info('epoch %d|step %d| compute loss cost = %f ms'\n",
    "                                % (epoch, step, loss_cost))\n",
    "            if step % save_steps == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                           r_loss=0, title = loggerName)\n",
    "            if step%1000 == 0 and step > 0:\n",
    "                decode_st = time.time()\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "                decode_cost = time.time() - decode_st\n",
    "                if step%save_steps == 0: logger.info('epoch %d|step %d| decode cost = %f ms'% (epoch, step, decode_cost))\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                if step%save_steps == 0:\n",
    "                    logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "    #         break\n",
    "        logger.info('-------------------------------------------------------------')\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')                   \n",
    "        logger.info('epoch %d|step %d| train_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "        if running_avg_reward > 0:\n",
    "            logger.info('epoch %d|step %d| running_avg_reward = %f'% (epoch, step, running_avg_reward))\n",
    "        if running_avg_rl_loss != 0:\n",
    "            logger.info('epoch %d|step %d| running_avg_rl_loss = %f'% (epoch, step, running_avg_rl_loss))\n",
    "        logger.info('-------------------------------------------------------------')\n",
    "\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')    \n",
    "    train_avg_acc, train_outFrame = decode_write_all(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "    test_avg_acc, test_outFrame = decode_write_all(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "    logger.info('epoch %d: train_avg_acc = %f, test_avg_acc = %f' % (epoch, train_avg_acc, test_avg_acc))\n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_outFrame.head()\n",
    "# test_outFrame.head()\n",
    "\n",
    "# !ipython nbconvert --to script Pointer_Bert_Transformer.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
