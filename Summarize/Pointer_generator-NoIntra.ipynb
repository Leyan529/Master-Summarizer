{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0404 12:06:13.908330 139723389826880 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-04 12:06:14 - Pointer_generator_word2Vec - INFO: - logger已啟動\n",
      "I0404 12:06:14.706316 139723389826880 train_util.py:87] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--transformer', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "config.rl_weight = 1 - config.mle_weight\n",
    "\n",
    "if not config.transformer:\n",
    "    loggerName = 'Pointer_generator_%s' % (config.word_emb_type)\n",
    "else:\n",
    "    loggerName = 'Transformer_%s' % (config.word_emb_type)\n",
    "    \n",
    "if config.intra_encoder and config.intra_decoder and True :\n",
    "    loggerName = loggerName + '_Intra_Atten'\n",
    "if config.key_attention:\n",
    "    loggerName = loggerName + '_Key_Atten'\n",
    "    \n",
    "logger = getLogger(loggerName) \n",
    "\n",
    "if not config.transformer:\n",
    "    writer = SummaryWriter('runs/Pointer-Generator_NoIntra/%s/exp' % config.word_emb_type)\n",
    "else:\n",
    "    writer = SummaryWriter('runs/Transformer_NoIntra/%s/exp' % config.word_emb_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 12:06:20 - Pointer_generator_word2Vec - INFO: - train : 37771, test : 4197\n",
      "I0404 12:06:20.404003 139723389826880 batcher.py:163] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0404 12:06:20.945006 139723389826880 utils_any2vec.py:341] loading projection weights from ../Train-Data/Cameras_new8/Embedding/word2Vec/word2Vec.300d.txt\n",
      "I0404 12:06:31.199201 139723389826880 utils_any2vec.py:405] loaded (46106, 300) matrix from ../Train-Data/Cameras_new8/Embedding/word2Vec/word2Vec.300d.txt\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    " \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > config.gound_truth_prob)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = model.embeds(x_t)  \n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * UNKNOWN_TOKEN  # Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "    enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    'Feed encoder data to predict'\n",
    "    pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                           enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                           START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                               enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                               START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 12:06:34 - Pointer_generator_word2Vec - INFO: - ------Training START--------\n",
      "I0404 12:06:34.712655 139723389826880 <ipython-input-9-3e087b2d97b6>:2] ------Training START--------\n",
      "2020-04-04 12:10:56 - Pointer_generator_word2Vec - INFO: - epoch 0: 1000, training batch loss = 4.511026, running_avg_loss loss = 4.511026, validation loss = 4.083765\n",
      "I0404 12:10:56.179063 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 1000, training batch loss = 4.511026, running_avg_loss loss = 4.511026, validation loss = 4.083765\n",
      "2020-04-04 12:10:57 - Pointer_generator_word2Vec - INFO: - epoch 0: 1000, train_rouge_l_f = 0.176879, test_rouge_l_f = 0.229894\n",
      "I0404 12:10:57.300801 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 1000, train_rouge_l_f = 0.176879, test_rouge_l_f = 0.229894\n",
      "2020-04-04 12:15:17 - Pointer_generator_word2Vec - INFO: - epoch 0: 2000, training batch loss = 3.383266, running_avg_loss loss = 4.499749, validation loss = 3.742979\n",
      "I0404 12:15:17.179747 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 2000, training batch loss = 3.383266, running_avg_loss loss = 4.499749, validation loss = 3.742979\n",
      "2020-04-04 12:15:18 - Pointer_generator_word2Vec - INFO: - epoch 0: 2000, train_rouge_l_f = 0.215861, test_rouge_l_f = 0.206551\n",
      "I0404 12:15:18.146358 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 2000, train_rouge_l_f = 0.215861, test_rouge_l_f = 0.206551\n",
      "2020-04-04 12:19:46 - Pointer_generator_word2Vec - INFO: - epoch 0: 3000, training batch loss = 3.245965, running_avg_loss loss = 4.487211, validation loss = 3.527928\n",
      "I0404 12:19:46.786636 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 3000, training batch loss = 3.245965, running_avg_loss loss = 4.487211, validation loss = 3.527928\n",
      "2020-04-04 12:19:47 - Pointer_generator_word2Vec - INFO: - epoch 0: 3000, train_rouge_l_f = 0.161007, test_rouge_l_f = 0.509155\n",
      "I0404 12:19:47.453379 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 3000, train_rouge_l_f = 0.161007, test_rouge_l_f = 0.509155\n",
      "2020-04-04 12:24:15 - Pointer_generator_word2Vec - INFO: - epoch 0: 4000, training batch loss = 4.181452, running_avg_loss loss = 4.484153, validation loss = 3.387564\n",
      "I0404 12:24:15.331471 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 4000, training batch loss = 4.181452, running_avg_loss loss = 4.484153, validation loss = 3.387564\n",
      "2020-04-04 12:24:16 - Pointer_generator_word2Vec - INFO: - epoch 0: 4000, train_rouge_l_f = 0.156989, test_rouge_l_f = 0.313351\n",
      "I0404 12:24:16.241367 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 4000, train_rouge_l_f = 0.156989, test_rouge_l_f = 0.313351\n",
      "2020-04-04 13:03:14 - Pointer_generator_word2Vec - INFO: - epoch 0: 4722, test_avg_acc = 0.303411, test_avg_acc = 0.304236\n",
      "I0404 13:03:14.873979 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 0: 4722, test_avg_acc = 0.303411, test_avg_acc = 0.304236\n",
      "2020-04-04 13:04:49 - Pointer_generator_word2Vec - INFO: - epoch 1: 5000, training batch loss = 3.012551, running_avg_loss loss = 4.469437, validation loss = 3.283639\n",
      "I0404 13:04:49.770682 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 5000, training batch loss = 3.012551, running_avg_loss loss = 4.469437, validation loss = 3.283639\n",
      "2020-04-04 13:04:49 - Pointer_generator_word2Vec - INFO: - Saving model step 5000 to model/saved_models/word2Vec/0005000.tar...\n",
      "I0404 13:04:49.772793 139723389826880 initialize.py:226] Saving model step 5000 to model/saved_models/word2Vec/0005000.tar...\n",
      "2020-04-04 13:04:54 - Pointer_generator_word2Vec - INFO: - epoch 1: 5000, train_rouge_l_f = 0.296526, test_rouge_l_f = 0.094511\n",
      "I0404 13:04:54.414564 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 5000, train_rouge_l_f = 0.296526, test_rouge_l_f = 0.094511\n",
      "2020-04-04 13:09:17 - Pointer_generator_word2Vec - INFO: - epoch 1: 6000, training batch loss = 3.440963, running_avg_loss loss = 4.459153, validation loss = 3.245016\n",
      "I0404 13:09:17.287438 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 6000, training batch loss = 3.440963, running_avg_loss loss = 4.459153, validation loss = 3.245016\n",
      "2020-04-04 13:09:18 - Pointer_generator_word2Vec - INFO: - epoch 1: 6000, train_rouge_l_f = 0.491297, test_rouge_l_f = 0.329212\n",
      "I0404 13:09:18.184339 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 6000, train_rouge_l_f = 0.491297, test_rouge_l_f = 0.329212\n",
      "2020-04-04 13:13:49 - Pointer_generator_word2Vec - INFO: - epoch 1: 7000, training batch loss = 2.683897, running_avg_loss loss = 4.441400, validation loss = 3.172942\n",
      "I0404 13:13:49.494297 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 7000, training batch loss = 2.683897, running_avg_loss loss = 4.441400, validation loss = 3.172942\n",
      "2020-04-04 13:13:51 - Pointer_generator_word2Vec - INFO: - epoch 1: 7000, train_rouge_l_f = 0.328655, test_rouge_l_f = 0.362931\n",
      "I0404 13:13:51.466442 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 7000, train_rouge_l_f = 0.328655, test_rouge_l_f = 0.362931\n",
      "2020-04-04 13:18:17 - Pointer_generator_word2Vec - INFO: - epoch 1: 8000, training batch loss = 3.861609, running_avg_loss loss = 4.435602, validation loss = 3.137074\n",
      "I0404 13:18:17.428920 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 8000, training batch loss = 3.861609, running_avg_loss loss = 4.435602, validation loss = 3.137074\n",
      "2020-04-04 13:18:18 - Pointer_generator_word2Vec - INFO: - epoch 1: 8000, train_rouge_l_f = 0.256881, test_rouge_l_f = 0.263152\n",
      "I0404 13:18:18.630824 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 8000, train_rouge_l_f = 0.256881, test_rouge_l_f = 0.263152\n",
      "2020-04-04 13:22:45 - Pointer_generator_word2Vec - INFO: - epoch 1: 9000, training batch loss = 3.830554, running_avg_loss loss = 4.429552, validation loss = 3.098207\n",
      "I0404 13:22:45.120462 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 9000, training batch loss = 3.830554, running_avg_loss loss = 4.429552, validation loss = 3.098207\n",
      "2020-04-04 13:22:45 - Pointer_generator_word2Vec - INFO: - epoch 1: 9000, train_rouge_l_f = 0.291972, test_rouge_l_f = 0.646751\n",
      "I0404 13:22:45.965900 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 9000, train_rouge_l_f = 0.291972, test_rouge_l_f = 0.646751\n",
      "2020-04-04 13:58:12 - Pointer_generator_word2Vec - INFO: - epoch 1: 9444, test_avg_acc = 0.316265, test_avg_acc = 0.307346\n",
      "I0404 13:58:12.801426 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 1: 9444, test_avg_acc = 0.316265, test_avg_acc = 0.307346\n",
      "2020-04-04 14:00:57 - Pointer_generator_word2Vec - INFO: - epoch 2: 10000, training batch loss = 2.432977, running_avg_loss loss = 4.409586, validation loss = 3.078029\n",
      "I0404 14:00:57.727411 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 10000, training batch loss = 2.432977, running_avg_loss loss = 4.409586, validation loss = 3.078029\n",
      "2020-04-04 14:00:57 - Pointer_generator_word2Vec - INFO: - Saving model step 10000 to model/saved_models/word2Vec/0010000.tar...\n",
      "I0404 14:00:57.730791 139723389826880 initialize.py:226] Saving model step 10000 to model/saved_models/word2Vec/0010000.tar...\n",
      "2020-04-04 14:01:02 - Pointer_generator_word2Vec - INFO: - epoch 2: 10000, train_rouge_l_f = 0.234897, test_rouge_l_f = 0.121434\n",
      "I0404 14:01:02.345463 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 10000, train_rouge_l_f = 0.234897, test_rouge_l_f = 0.121434\n",
      "2020-04-04 14:05:30 - Pointer_generator_word2Vec - INFO: - epoch 2: 11000, training batch loss = 3.512249, running_avg_loss loss = 4.400613, validation loss = 3.047030\n",
      "I0404 14:05:30.427440 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 11000, training batch loss = 3.512249, running_avg_loss loss = 4.400613, validation loss = 3.047030\n",
      "2020-04-04 14:05:31 - Pointer_generator_word2Vec - INFO: - epoch 2: 11000, train_rouge_l_f = 0.433810, test_rouge_l_f = 0.217653\n",
      "I0404 14:05:31.806071 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 11000, train_rouge_l_f = 0.433810, test_rouge_l_f = 0.217653\n",
      "2020-04-04 14:09:58 - Pointer_generator_word2Vec - INFO: - epoch 2: 12000, training batch loss = 3.024199, running_avg_loss loss = 4.386848, validation loss = 3.011350\n",
      "I0404 14:09:58.939424 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 12000, training batch loss = 3.024199, running_avg_loss loss = 4.386848, validation loss = 3.011350\n",
      "2020-04-04 14:10:00 - Pointer_generator_word2Vec - INFO: - epoch 2: 12000, train_rouge_l_f = 0.382934, test_rouge_l_f = 0.139368\n",
      "I0404 14:10:00.476073 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 12000, train_rouge_l_f = 0.382934, test_rouge_l_f = 0.139368\n",
      "2020-04-04 14:14:28 - Pointer_generator_word2Vec - INFO: - epoch 2: 13000, training batch loss = 2.719723, running_avg_loss loss = 4.370177, validation loss = 2.993682\n",
      "I0404 14:14:28.781679 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 13000, training batch loss = 2.719723, running_avg_loss loss = 4.370177, validation loss = 2.993682\n",
      "2020-04-04 14:14:29 - Pointer_generator_word2Vec - INFO: - epoch 2: 13000, train_rouge_l_f = 0.246690, test_rouge_l_f = 0.383328\n",
      "I0404 14:14:29.853033 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 13000, train_rouge_l_f = 0.246690, test_rouge_l_f = 0.383328\n",
      "2020-04-04 14:18:56 - Pointer_generator_word2Vec - INFO: - epoch 2: 14000, training batch loss = 3.568261, running_avg_loss loss = 4.362158, validation loss = 2.974551\n",
      "I0404 14:18:56.919525 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 14000, training batch loss = 3.568261, running_avg_loss loss = 4.362158, validation loss = 2.974551\n",
      "2020-04-04 14:18:58 - Pointer_generator_word2Vec - INFO: - epoch 2: 14000, train_rouge_l_f = 0.344315, test_rouge_l_f = 0.332459\n",
      "I0404 14:18:58.276624 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 14000, train_rouge_l_f = 0.344315, test_rouge_l_f = 0.332459\n",
      "2020-04-04 14:57:20 - Pointer_generator_word2Vec - INFO: - epoch 2: 14166, test_avg_acc = 0.340309, test_avg_acc = 0.327199\n",
      "I0404 14:57:20.370638 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 2: 14166, test_avg_acc = 0.340309, test_avg_acc = 0.327199\n",
      "2020-04-04 15:01:12 - Pointer_generator_word2Vec - INFO: - epoch 3: 15000, training batch loss = 3.202917, running_avg_loss loss = 4.350566, validation loss = 2.958632\n",
      "I0404 15:01:12.735779 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 15000, training batch loss = 3.202917, running_avg_loss loss = 4.350566, validation loss = 2.958632\n",
      "2020-04-04 15:01:12 - Pointer_generator_word2Vec - INFO: - Saving model step 15000 to model/saved_models/word2Vec/0015000.tar...\n",
      "I0404 15:01:12.738650 139723389826880 initialize.py:226] Saving model step 15000 to model/saved_models/word2Vec/0015000.tar...\n",
      "2020-04-04 15:01:17 - Pointer_generator_word2Vec - INFO: - epoch 3: 15000, train_rouge_l_f = 0.312314, test_rouge_l_f = 0.173444\n",
      "I0404 15:01:17.268193 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 15000, train_rouge_l_f = 0.312314, test_rouge_l_f = 0.173444\n",
      "2020-04-04 15:05:47 - Pointer_generator_word2Vec - INFO: - epoch 3: 16000, training batch loss = 3.543600, running_avg_loss loss = 4.342496, validation loss = 2.964271\n",
      "I0404 15:05:47.760728 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 16000, training batch loss = 3.543600, running_avg_loss loss = 4.342496, validation loss = 2.964271\n",
      "2020-04-04 15:05:49 - Pointer_generator_word2Vec - INFO: - epoch 3: 16000, train_rouge_l_f = 0.239449, test_rouge_l_f = 0.252498\n",
      "I0404 15:05:49.235202 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 16000, train_rouge_l_f = 0.239449, test_rouge_l_f = 0.252498\n",
      "2020-04-04 15:10:28 - Pointer_generator_word2Vec - INFO: - epoch 3: 17000, training batch loss = 2.908306, running_avg_loss loss = 4.328154, validation loss = 2.944863\n",
      "I0404 15:10:28.214633 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 17000, training batch loss = 2.908306, running_avg_loss loss = 4.328154, validation loss = 2.944863\n",
      "2020-04-04 15:10:29 - Pointer_generator_word2Vec - INFO: - epoch 3: 17000, train_rouge_l_f = 0.377170, test_rouge_l_f = 0.362217\n",
      "I0404 15:10:29.330458 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 17000, train_rouge_l_f = 0.377170, test_rouge_l_f = 0.362217\n",
      "2020-04-04 15:14:55 - Pointer_generator_word2Vec - INFO: - epoch 3: 18000, training batch loss = 2.167432, running_avg_loss loss = 4.306547, validation loss = 2.922713\n",
      "I0404 15:14:55.302298 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 18000, training batch loss = 2.167432, running_avg_loss loss = 4.306547, validation loss = 2.922713\n",
      "2020-04-04 15:14:57 - Pointer_generator_word2Vec - INFO: - epoch 3: 18000, train_rouge_l_f = 0.601657, test_rouge_l_f = 0.074817\n",
      "I0404 15:14:57.315289 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 18000, train_rouge_l_f = 0.601657, test_rouge_l_f = 0.074817\n",
      "2020-04-04 15:56:21 - Pointer_generator_word2Vec - INFO: - epoch 3: 18888, test_avg_acc = 0.356674, test_avg_acc = 0.330107\n",
      "I0404 15:56:21.780798 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 3: 18888, test_avg_acc = 0.356674, test_avg_acc = 0.330107\n",
      "2020-04-04 15:57:17 - Pointer_generator_word2Vec - INFO: - epoch 4: 19000, training batch loss = 3.019171, running_avg_loss loss = 4.293673, validation loss = 2.913477\n",
      "I0404 15:57:17.412771 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 19000, training batch loss = 3.019171, running_avg_loss loss = 4.293673, validation loss = 2.913477\n",
      "2020-04-04 15:57:18 - Pointer_generator_word2Vec - INFO: - epoch 4: 19000, train_rouge_l_f = 0.280369, test_rouge_l_f = 0.272241\n",
      "I0404 15:57:18.567592 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 19000, train_rouge_l_f = 0.280369, test_rouge_l_f = 0.272241\n",
      "2020-04-04 16:01:45 - Pointer_generator_word2Vec - INFO: - epoch 4: 20000, training batch loss = 2.798281, running_avg_loss loss = 4.278719, validation loss = 2.926621\n",
      "I0404 16:01:45.948689 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 20000, training batch loss = 2.798281, running_avg_loss loss = 4.278719, validation loss = 2.926621\n",
      "2020-04-04 16:01:45 - Pointer_generator_word2Vec - INFO: - Saving model step 20000 to model/saved_models/word2Vec/0020000.tar...\n",
      "I0404 16:01:45.950510 139723389826880 initialize.py:226] Saving model step 20000 to model/saved_models/word2Vec/0020000.tar...\n",
      "2020-04-04 16:01:49 - Pointer_generator_word2Vec - INFO: - epoch 4: 20000, train_rouge_l_f = 0.183915, test_rouge_l_f = 0.466793\n",
      "I0404 16:01:49.448569 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 20000, train_rouge_l_f = 0.183915, test_rouge_l_f = 0.466793\n",
      "2020-04-04 16:06:15 - Pointer_generator_word2Vec - INFO: - epoch 4: 21000, training batch loss = 2.642333, running_avg_loss loss = 4.262355, validation loss = 2.909752\n",
      "I0404 16:06:15.281217 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 21000, training batch loss = 2.642333, running_avg_loss loss = 4.262355, validation loss = 2.909752\n",
      "2020-04-04 16:06:16 - Pointer_generator_word2Vec - INFO: - epoch 4: 21000, train_rouge_l_f = 0.365505, test_rouge_l_f = 0.509935\n",
      "I0404 16:06:16.477057 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 21000, train_rouge_l_f = 0.365505, test_rouge_l_f = 0.509935\n",
      "2020-04-04 16:10:46 - Pointer_generator_word2Vec - INFO: - epoch 4: 22000, training batch loss = 2.495973, running_avg_loss loss = 4.244691, validation loss = 2.909029\n",
      "I0404 16:10:46.912908 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 22000, training batch loss = 2.495973, running_avg_loss loss = 4.244691, validation loss = 2.909029\n",
      "2020-04-04 16:10:49 - Pointer_generator_word2Vec - INFO: - epoch 4: 22000, train_rouge_l_f = 0.394825, test_rouge_l_f = 0.098287\n",
      "I0404 16:10:49.241353 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 22000, train_rouge_l_f = 0.394825, test_rouge_l_f = 0.098287\n",
      "2020-04-04 16:15:17 - Pointer_generator_word2Vec - INFO: - epoch 4: 23000, training batch loss = 2.902248, running_avg_loss loss = 4.231267, validation loss = 2.877455\n",
      "I0404 16:15:17.361010 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 23000, training batch loss = 2.902248, running_avg_loss loss = 4.231267, validation loss = 2.877455\n",
      "2020-04-04 16:15:18 - Pointer_generator_word2Vec - INFO: - epoch 4: 23000, train_rouge_l_f = 0.393152, test_rouge_l_f = 0.266620\n",
      "I0404 16:15:18.974158 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 23000, train_rouge_l_f = 0.393152, test_rouge_l_f = 0.266620\n",
      "2020-04-04 16:56:02 - Pointer_generator_word2Vec - INFO: - epoch 4: 23610, test_avg_acc = 0.376616, test_avg_acc = 0.333700\n",
      "I0404 16:56:02.155616 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 4: 23610, test_avg_acc = 0.376616, test_avg_acc = 0.333700\n",
      "2020-04-04 16:58:04 - Pointer_generator_word2Vec - INFO: - epoch 5: 24000, training batch loss = 2.697969, running_avg_loss loss = 4.215934, validation loss = 2.895786\n",
      "I0404 16:58:04.121805 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 24000, training batch loss = 2.697969, running_avg_loss loss = 4.215934, validation loss = 2.895786\n",
      "2020-04-04 16:58:05 - Pointer_generator_word2Vec - INFO: - epoch 5: 24000, train_rouge_l_f = 0.233269, test_rouge_l_f = 0.288828\n",
      "I0404 16:58:05.846552 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 24000, train_rouge_l_f = 0.233269, test_rouge_l_f = 0.288828\n",
      "2020-04-04 17:02:30 - Pointer_generator_word2Vec - INFO: - epoch 5: 25000, training batch loss = 3.156706, running_avg_loss loss = 4.205342, validation loss = 2.917399\n",
      "I0404 17:02:30.564293 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 25000, training batch loss = 3.156706, running_avg_loss loss = 4.205342, validation loss = 2.917399\n",
      "2020-04-04 17:02:30 - Pointer_generator_word2Vec - INFO: - Saving model step 25000 to model/saved_models/word2Vec/0025000.tar...\n",
      "I0404 17:02:30.567189 139723389826880 initialize.py:226] Saving model step 25000 to model/saved_models/word2Vec/0025000.tar...\n",
      "2020-04-04 17:02:34 - Pointer_generator_word2Vec - INFO: - epoch 5: 25000, train_rouge_l_f = 0.405677, test_rouge_l_f = 0.121848\n",
      "I0404 17:02:34.801306 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 25000, train_rouge_l_f = 0.405677, test_rouge_l_f = 0.121848\n",
      "2020-04-04 17:07:00 - Pointer_generator_word2Vec - INFO: - epoch 5: 26000, training batch loss = 1.738542, running_avg_loss loss = 4.180674, validation loss = 2.891328\n",
      "I0404 17:07:00.608235 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 26000, training batch loss = 1.738542, running_avg_loss loss = 4.180674, validation loss = 2.891328\n",
      "2020-04-04 17:07:02 - Pointer_generator_word2Vec - INFO: - epoch 5: 26000, train_rouge_l_f = 0.499139, test_rouge_l_f = 0.264427\n",
      "I0404 17:07:02.005805 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 26000, train_rouge_l_f = 0.499139, test_rouge_l_f = 0.264427\n",
      "2020-04-04 17:11:32 - Pointer_generator_word2Vec - INFO: - epoch 5: 27000, training batch loss = 2.604073, running_avg_loss loss = 4.164908, validation loss = 2.884156\n",
      "I0404 17:11:32.986342 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 27000, training batch loss = 2.604073, running_avg_loss loss = 4.164908, validation loss = 2.884156\n",
      "2020-04-04 17:11:33 - Pointer_generator_word2Vec - INFO: - epoch 5: 27000, train_rouge_l_f = 0.335736, test_rouge_l_f = 0.646714\n",
      "I0404 17:11:33.757443 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 27000, train_rouge_l_f = 0.335736, test_rouge_l_f = 0.646714\n",
      "2020-04-04 17:16:03 - Pointer_generator_word2Vec - INFO: - epoch 5: 28000, training batch loss = 2.336703, running_avg_loss loss = 4.146626, validation loss = 2.897081\n",
      "I0404 17:16:03.365785 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 28000, training batch loss = 2.336703, running_avg_loss loss = 4.146626, validation loss = 2.897081\n",
      "2020-04-04 17:16:04 - Pointer_generator_word2Vec - INFO: - epoch 5: 28000, train_rouge_l_f = 0.207239, test_rouge_l_f = 0.314152\n",
      "I0404 17:16:04.771916 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 28000, train_rouge_l_f = 0.207239, test_rouge_l_f = 0.314152\n",
      "2020-04-04 17:56:22 - Pointer_generator_word2Vec - INFO: - epoch 5: 28332, test_avg_acc = 0.397670, test_avg_acc = 0.335310\n",
      "I0404 17:56:22.724539 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 5: 28332, test_avg_acc = 0.397670, test_avg_acc = 0.335310\n",
      "2020-04-04 17:59:35 - Pointer_generator_word2Vec - INFO: - epoch 6: 29000, training batch loss = 2.208136, running_avg_loss loss = 4.127241, validation loss = 2.898652\n",
      "I0404 17:59:35.104624 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 29000, training batch loss = 2.208136, running_avg_loss loss = 4.127241, validation loss = 2.898652\n",
      "2020-04-04 17:59:36 - Pointer_generator_word2Vec - INFO: - epoch 6: 29000, train_rouge_l_f = 0.299916, test_rouge_l_f = 0.317362\n",
      "I0404 17:59:36.451173 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 29000, train_rouge_l_f = 0.299916, test_rouge_l_f = 0.317362\n",
      "2020-04-04 18:04:10 - Pointer_generator_word2Vec - INFO: - epoch 6: 30000, training batch loss = 1.884544, running_avg_loss loss = 4.104814, validation loss = 2.923357\n",
      "I0404 18:04:10.374102 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 30000, training batch loss = 1.884544, running_avg_loss loss = 4.104814, validation loss = 2.923357\n",
      "2020-04-04 18:04:10 - Pointer_generator_word2Vec - INFO: - Saving model step 30000 to model/saved_models/word2Vec/0030000.tar...\n",
      "I0404 18:04:10.376676 139723389826880 initialize.py:226] Saving model step 30000 to model/saved_models/word2Vec/0030000.tar...\n",
      "2020-04-04 18:04:15 - Pointer_generator_word2Vec - INFO: - epoch 6: 30000, train_rouge_l_f = 0.607963, test_rouge_l_f = 0.149169\n",
      "I0404 18:04:15.857519 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 30000, train_rouge_l_f = 0.607963, test_rouge_l_f = 0.149169\n",
      "2020-04-04 18:08:44 - Pointer_generator_word2Vec - INFO: - epoch 6: 31000, training batch loss = 2.730950, running_avg_loss loss = 4.091075, validation loss = 2.918143\n",
      "I0404 18:08:44.638731 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 31000, training batch loss = 2.730950, running_avg_loss loss = 4.091075, validation loss = 2.918143\n",
      "2020-04-04 18:08:45 - Pointer_generator_word2Vec - INFO: - epoch 6: 31000, train_rouge_l_f = 0.430937, test_rouge_l_f = 0.326047\n",
      "I0404 18:08:45.744337 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 31000, train_rouge_l_f = 0.430937, test_rouge_l_f = 0.326047\n",
      "2020-04-04 18:13:18 - Pointer_generator_word2Vec - INFO: - epoch 6: 32000, training batch loss = 2.356395, running_avg_loss loss = 4.073728, validation loss = 2.901233\n",
      "I0404 18:13:18.453836 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 32000, training batch loss = 2.356395, running_avg_loss loss = 4.073728, validation loss = 2.901233\n",
      "2020-04-04 18:13:19 - Pointer_generator_word2Vec - INFO: - epoch 6: 32000, train_rouge_l_f = 0.160200, test_rouge_l_f = 0.220389\n",
      "I0404 18:13:19.766054 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 32000, train_rouge_l_f = 0.160200, test_rouge_l_f = 0.220389\n",
      "2020-04-04 18:17:49 - Pointer_generator_word2Vec - INFO: - epoch 6: 33000, training batch loss = 2.802182, running_avg_loss loss = 4.061013, validation loss = 2.897012\n",
      "I0404 18:17:49.914818 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 33000, training batch loss = 2.802182, running_avg_loss loss = 4.061013, validation loss = 2.897012\n",
      "2020-04-04 18:17:51 - Pointer_generator_word2Vec - INFO: - epoch 6: 33000, train_rouge_l_f = 0.325125, test_rouge_l_f = 0.271414\n",
      "I0404 18:17:51.030970 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 33000, train_rouge_l_f = 0.325125, test_rouge_l_f = 0.271414\n",
      "2020-04-04 19:01:44 - Pointer_generator_word2Vec - INFO: - epoch 6: 33054, test_avg_acc = 0.424957, test_avg_acc = 0.339059\n",
      "I0404 19:01:44.880398 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 6: 33054, test_avg_acc = 0.424957, test_avg_acc = 0.339059\n",
      "2020-04-04 19:06:06 - Pointer_generator_word2Vec - INFO: - epoch 7: 34000, training batch loss = 3.057011, running_avg_loss loss = 4.050973, validation loss = 2.942470\n",
      "I0404 19:06:06.819723 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 34000, training batch loss = 3.057011, running_avg_loss loss = 4.050973, validation loss = 2.942470\n",
      "2020-04-04 19:06:07 - Pointer_generator_word2Vec - INFO: - epoch 7: 34000, train_rouge_l_f = 0.363798, test_rouge_l_f = 0.582522\n",
      "I0404 19:06:07.688804 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 34000, train_rouge_l_f = 0.363798, test_rouge_l_f = 0.582522\n",
      "2020-04-04 19:10:40 - Pointer_generator_word2Vec - INFO: - epoch 7: 35000, training batch loss = 1.161710, running_avg_loss loss = 4.022080, validation loss = 2.961433\n",
      "I0404 19:10:40.914946 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 35000, training batch loss = 1.161710, running_avg_loss loss = 4.022080, validation loss = 2.961433\n",
      "2020-04-04 19:10:40 - Pointer_generator_word2Vec - INFO: - Saving model step 35000 to model/saved_models/word2Vec/0035000.tar...\n",
      "I0404 19:10:40.917903 139723389826880 initialize.py:226] Saving model step 35000 to model/saved_models/word2Vec/0035000.tar...\n",
      "2020-04-04 19:10:45 - Pointer_generator_word2Vec - INFO: - epoch 7: 35000, train_rouge_l_f = 0.578382, test_rouge_l_f = 0.225305\n",
      "I0404 19:10:45.800180 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 35000, train_rouge_l_f = 0.578382, test_rouge_l_f = 0.225305\n",
      "2020-04-04 19:15:19 - Pointer_generator_word2Vec - INFO: - epoch 7: 36000, training batch loss = 2.629158, running_avg_loss loss = 4.008151, validation loss = 2.976046\n",
      "I0404 19:15:19.455400 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 36000, training batch loss = 2.629158, running_avg_loss loss = 4.008151, validation loss = 2.976046\n",
      "2020-04-04 19:15:20 - Pointer_generator_word2Vec - INFO: - epoch 7: 36000, train_rouge_l_f = 0.240902, test_rouge_l_f = 0.377227\n",
      "I0404 19:15:20.615543 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 36000, train_rouge_l_f = 0.240902, test_rouge_l_f = 0.377227\n",
      "2020-04-04 19:19:50 - Pointer_generator_word2Vec - INFO: - epoch 7: 37000, training batch loss = 2.764882, running_avg_loss loss = 3.995718, validation loss = 2.944696\n",
      "I0404 19:19:50.373176 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 37000, training batch loss = 2.764882, running_avg_loss loss = 3.995718, validation loss = 2.944696\n",
      "2020-04-04 19:19:51 - Pointer_generator_word2Vec - INFO: - epoch 7: 37000, train_rouge_l_f = 0.295290, test_rouge_l_f = 0.269142\n",
      "I0404 19:19:51.859296 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 37000, train_rouge_l_f = 0.295290, test_rouge_l_f = 0.269142\n",
      "2020-04-04 20:02:45 - Pointer_generator_word2Vec - INFO: - epoch 7: 37776, test_avg_acc = 0.472105, test_avg_acc = 0.338955\n",
      "I0404 20:02:45.482998 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 7: 37776, test_avg_acc = 0.472105, test_avg_acc = 0.338955\n",
      "2020-04-04 20:04:06 - Pointer_generator_word2Vec - INFO: - epoch 8: 38000, training batch loss = 2.274529, running_avg_loss loss = 3.978506, validation loss = 2.957114\n",
      "I0404 20:04:06.673325 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 38000, training batch loss = 2.274529, running_avg_loss loss = 3.978506, validation loss = 2.957114\n",
      "2020-04-04 20:04:08 - Pointer_generator_word2Vec - INFO: - epoch 8: 38000, train_rouge_l_f = 0.438131, test_rouge_l_f = 0.302611\n",
      "I0404 20:04:08.010219 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 38000, train_rouge_l_f = 0.438131, test_rouge_l_f = 0.302611\n",
      "2020-04-04 20:08:41 - Pointer_generator_word2Vec - INFO: - epoch 8: 39000, training batch loss = 2.492702, running_avg_loss loss = 3.963648, validation loss = 3.000053\n",
      "I0404 20:08:41.515872 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 39000, training batch loss = 2.492702, running_avg_loss loss = 3.963648, validation loss = 3.000053\n",
      "2020-04-04 20:08:42 - Pointer_generator_word2Vec - INFO: - epoch 8: 39000, train_rouge_l_f = 0.352588, test_rouge_l_f = 0.635162\n",
      "I0404 20:08:42.310046 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 39000, train_rouge_l_f = 0.352588, test_rouge_l_f = 0.635162\n",
      "2020-04-04 20:13:13 - Pointer_generator_word2Vec - INFO: - epoch 8: 40000, training batch loss = 1.852950, running_avg_loss loss = 3.942541, validation loss = 3.020111\n",
      "I0404 20:13:13.998033 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 40000, training batch loss = 1.852950, running_avg_loss loss = 3.942541, validation loss = 3.020111\n",
      "2020-04-04 20:13:14 - Pointer_generator_word2Vec - INFO: - Saving model step 40000 to model/saved_models/word2Vec/0040000.tar...\n",
      "I0404 20:13:14.001183 139723389826880 initialize.py:226] Saving model step 40000 to model/saved_models/word2Vec/0040000.tar...\n",
      "2020-04-04 20:13:18 - Pointer_generator_word2Vec - INFO: - epoch 8: 40000, train_rouge_l_f = 0.591929, test_rouge_l_f = 0.120392\n",
      "I0404 20:13:18.662187 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 40000, train_rouge_l_f = 0.591929, test_rouge_l_f = 0.120392\n",
      "2020-04-04 20:17:49 - Pointer_generator_word2Vec - INFO: - epoch 8: 41000, training batch loss = 1.818065, running_avg_loss loss = 3.921297, validation loss = 3.018605\n",
      "I0404 20:17:49.814575 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 41000, training batch loss = 1.818065, running_avg_loss loss = 3.921297, validation loss = 3.018605\n",
      "2020-04-04 20:17:50 - Pointer_generator_word2Vec - INFO: - epoch 8: 41000, train_rouge_l_f = 0.519569, test_rouge_l_f = 0.400799\n",
      "I0404 20:17:50.797587 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 41000, train_rouge_l_f = 0.519569, test_rouge_l_f = 0.400799\n",
      "2020-04-04 20:22:26 - Pointer_generator_word2Vec - INFO: - epoch 8: 42000, training batch loss = 2.441466, running_avg_loss loss = 3.906498, validation loss = 2.994143\n",
      "I0404 20:22:26.298817 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 42000, training batch loss = 2.441466, running_avg_loss loss = 3.906498, validation loss = 2.994143\n",
      "2020-04-04 20:22:27 - Pointer_generator_word2Vec - INFO: - epoch 8: 42000, train_rouge_l_f = 0.383604, test_rouge_l_f = 0.304387\n",
      "I0404 20:22:27.579621 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 42000, train_rouge_l_f = 0.383604, test_rouge_l_f = 0.304387\n",
      "2020-04-04 21:04:47 - Pointer_generator_word2Vec - INFO: - epoch 8: 42498, test_avg_acc = 0.490848, test_avg_acc = 0.337897\n",
      "I0404 21:04:47.079030 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 8: 42498, test_avg_acc = 0.490848, test_avg_acc = 0.337897\n",
      "2020-04-04 21:07:15 - Pointer_generator_word2Vec - INFO: - epoch 9: 43000, training batch loss = 2.124102, running_avg_loss loss = 3.888674, validation loss = 3.042804\n",
      "I0404 21:07:15.567975 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 43000, training batch loss = 2.124102, running_avg_loss loss = 3.888674, validation loss = 3.042804\n",
      "2020-04-04 21:07:17 - Pointer_generator_word2Vec - INFO: - epoch 9: 43000, train_rouge_l_f = 0.353099, test_rouge_l_f = 0.319190\n",
      "I0404 21:07:17.350372 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 43000, train_rouge_l_f = 0.353099, test_rouge_l_f = 0.319190\n",
      "2020-04-04 21:11:50 - Pointer_generator_word2Vec - INFO: - epoch 9: 44000, training batch loss = 2.415390, running_avg_loss loss = 3.873942, validation loss = 3.064489\n",
      "I0404 21:11:50.091409 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 44000, training batch loss = 2.415390, running_avg_loss loss = 3.873942, validation loss = 3.064489\n",
      "2020-04-04 21:11:51 - Pointer_generator_word2Vec - INFO: - epoch 9: 44000, train_rouge_l_f = 0.357401, test_rouge_l_f = 0.392654\n",
      "I0404 21:11:51.230462 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 44000, train_rouge_l_f = 0.357401, test_rouge_l_f = 0.392654\n",
      "2020-04-04 21:16:25 - Pointer_generator_word2Vec - INFO: - epoch 9: 45000, training batch loss = 1.416606, running_avg_loss loss = 3.849368, validation loss = 3.071643\n",
      "I0404 21:16:25.883513 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 45000, training batch loss = 1.416606, running_avg_loss loss = 3.849368, validation loss = 3.071643\n",
      "2020-04-04 21:16:25 - Pointer_generator_word2Vec - INFO: - Saving model step 45000 to model/saved_models/word2Vec/0045000.tar...\n",
      "I0404 21:16:25.885862 139723389826880 initialize.py:226] Saving model step 45000 to model/saved_models/word2Vec/0045000.tar...\n",
      "2020-04-04 21:16:29 - Pointer_generator_word2Vec - INFO: - epoch 9: 45000, train_rouge_l_f = 0.633463, test_rouge_l_f = 0.383826\n",
      "I0404 21:16:29.503222 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 45000, train_rouge_l_f = 0.633463, test_rouge_l_f = 0.383826\n",
      "2020-04-04 21:21:03 - Pointer_generator_word2Vec - INFO: - epoch 9: 46000, training batch loss = 2.209663, running_avg_loss loss = 3.832971, validation loss = 3.062520\n",
      "I0404 21:21:03.868255 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 46000, training batch loss = 2.209663, running_avg_loss loss = 3.832971, validation loss = 3.062520\n",
      "2020-04-04 21:21:04 - Pointer_generator_word2Vec - INFO: - epoch 9: 46000, train_rouge_l_f = 0.482953, test_rouge_l_f = 0.683174\n",
      "I0404 21:21:04.855026 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 46000, train_rouge_l_f = 0.482953, test_rouge_l_f = 0.683174\n",
      "2020-04-04 21:25:36 - Pointer_generator_word2Vec - INFO: - epoch 9: 47000, training batch loss = 1.865345, running_avg_loss loss = 3.813295, validation loss = 3.071578\n",
      "I0404 21:25:36.564267 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 47000, training batch loss = 1.865345, running_avg_loss loss = 3.813295, validation loss = 3.071578\n",
      "2020-04-04 21:25:38 - Pointer_generator_word2Vec - INFO: - epoch 9: 47000, train_rouge_l_f = 0.575915, test_rouge_l_f = 0.366153\n",
      "I0404 21:25:38.217093 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 47000, train_rouge_l_f = 0.575915, test_rouge_l_f = 0.366153\n",
      "2020-04-04 22:05:57 - Pointer_generator_word2Vec - INFO: - epoch 9: 47220, test_avg_acc = 0.532854, test_avg_acc = 0.332196\n",
      "I0404 22:05:57.543780 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 9: 47220, test_avg_acc = 0.532854, test_avg_acc = 0.332196\n",
      "2020-04-04 22:09:33 - Pointer_generator_word2Vec - INFO: - epoch 10: 48000, training batch loss = 1.762462, running_avg_loss loss = 3.792787, validation loss = 3.136850\n",
      "I0404 22:09:33.772233 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 48000, training batch loss = 1.762462, running_avg_loss loss = 3.792787, validation loss = 3.136850\n",
      "2020-04-04 22:09:34 - Pointer_generator_word2Vec - INFO: - epoch 10: 48000, train_rouge_l_f = 0.559766, test_rouge_l_f = 0.497619\n",
      "I0404 22:09:34.755741 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 48000, train_rouge_l_f = 0.559766, test_rouge_l_f = 0.497619\n",
      "2020-04-04 22:14:05 - Pointer_generator_word2Vec - INFO: - epoch 10: 49000, training batch loss = 2.031701, running_avg_loss loss = 3.775176, validation loss = 3.147210\n",
      "I0404 22:14:05.652203 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 49000, training batch loss = 2.031701, running_avg_loss loss = 3.775176, validation loss = 3.147210\n",
      "2020-04-04 22:14:06 - Pointer_generator_word2Vec - INFO: - epoch 10: 49000, train_rouge_l_f = 0.456421, test_rouge_l_f = 0.611561\n",
      "I0404 22:14:06.762276 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 49000, train_rouge_l_f = 0.456421, test_rouge_l_f = 0.611561\n",
      "2020-04-04 22:18:40 - Pointer_generator_word2Vec - INFO: - epoch 10: 50000, training batch loss = 2.049696, running_avg_loss loss = 3.757921, validation loss = 3.143371\n",
      "I0404 22:18:40.324237 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 50000, training batch loss = 2.049696, running_avg_loss loss = 3.757921, validation loss = 3.143371\n",
      "2020-04-04 22:18:40 - Pointer_generator_word2Vec - INFO: - Saving model step 50000 to model/saved_models/word2Vec/0050000.tar...\n",
      "I0404 22:18:40.326251 139723389826880 initialize.py:226] Saving model step 50000 to model/saved_models/word2Vec/0050000.tar...\n",
      "2020-04-04 22:18:44 - Pointer_generator_word2Vec - INFO: - epoch 10: 50000, train_rouge_l_f = 0.486948, test_rouge_l_f = 0.313527\n",
      "I0404 22:18:44.815794 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 50000, train_rouge_l_f = 0.486948, test_rouge_l_f = 0.313527\n",
      "2020-04-04 22:23:15 - Pointer_generator_word2Vec - INFO: - epoch 10: 51000, training batch loss = 1.885006, running_avg_loss loss = 3.739192, validation loss = 3.139278\n",
      "I0404 22:23:15.441639 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 51000, training batch loss = 1.885006, running_avg_loss loss = 3.739192, validation loss = 3.139278\n",
      "2020-04-04 22:23:16 - Pointer_generator_word2Vec - INFO: - epoch 10: 51000, train_rouge_l_f = 0.492155, test_rouge_l_f = 0.239192\n",
      "I0404 22:23:16.846229 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 51000, train_rouge_l_f = 0.492155, test_rouge_l_f = 0.239192\n",
      "2020-04-04 23:04:22 - Pointer_generator_word2Vec - INFO: - epoch 10: 51942, test_avg_acc = 0.555642, test_avg_acc = 0.323932\n",
      "I0404 23:04:22.892170 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 10: 51942, test_avg_acc = 0.555642, test_avg_acc = 0.323932\n",
      "2020-04-04 23:05:06 - Pointer_generator_word2Vec - INFO: - epoch 11: 52000, training batch loss = 1.428910, running_avg_loss loss = 3.716089, validation loss = 3.146131\n",
      "I0404 23:05:06.111751 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 52000, training batch loss = 1.428910, running_avg_loss loss = 3.716089, validation loss = 3.146131\n",
      "2020-04-04 23:05:07 - Pointer_generator_word2Vec - INFO: - epoch 11: 52000, train_rouge_l_f = 0.626369, test_rouge_l_f = 0.692335\n",
      "I0404 23:05:07.149539 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 52000, train_rouge_l_f = 0.626369, test_rouge_l_f = 0.692335\n",
      "2020-04-04 23:09:37 - Pointer_generator_word2Vec - INFO: - epoch 11: 53000, training batch loss = 1.843939, running_avg_loss loss = 3.697367, validation loss = 3.252238\n",
      "I0404 23:09:37.993313 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 53000, training batch loss = 1.843939, running_avg_loss loss = 3.697367, validation loss = 3.252238\n",
      "2020-04-04 23:09:39 - Pointer_generator_word2Vec - INFO: - epoch 11: 53000, train_rouge_l_f = 0.395079, test_rouge_l_f = 0.180951\n",
      "I0404 23:09:39.268758 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 53000, train_rouge_l_f = 0.395079, test_rouge_l_f = 0.180951\n",
      "2020-04-04 23:14:11 - Pointer_generator_word2Vec - INFO: - epoch 11: 54000, training batch loss = 1.852916, running_avg_loss loss = 3.678923, validation loss = 3.242440\n",
      "I0404 23:14:11.277983 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 54000, training batch loss = 1.852916, running_avg_loss loss = 3.678923, validation loss = 3.242440\n",
      "2020-04-04 23:14:13 - Pointer_generator_word2Vec - INFO: - epoch 11: 54000, train_rouge_l_f = 0.469380, test_rouge_l_f = 0.148926\n",
      "I0404 23:14:13.176155 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 54000, train_rouge_l_f = 0.469380, test_rouge_l_f = 0.148926\n",
      "2020-04-04 23:18:44 - Pointer_generator_word2Vec - INFO: - epoch 11: 55000, training batch loss = 1.694749, running_avg_loss loss = 3.659081, validation loss = 3.232331\n",
      "I0404 23:18:44.557585 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 55000, training batch loss = 1.694749, running_avg_loss loss = 3.659081, validation loss = 3.232331\n",
      "2020-04-04 23:18:44 - Pointer_generator_word2Vec - INFO: - Saving model step 55000 to model/saved_models/word2Vec/0055000.tar...\n",
      "I0404 23:18:44.560349 139723389826880 initialize.py:226] Saving model step 55000 to model/saved_models/word2Vec/0055000.tar...\n",
      "2020-04-04 23:18:48 - Pointer_generator_word2Vec - INFO: - epoch 11: 55000, train_rouge_l_f = 0.646406, test_rouge_l_f = 0.204535\n",
      "I0404 23:18:48.884310 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 55000, train_rouge_l_f = 0.646406, test_rouge_l_f = 0.204535\n",
      "2020-04-04 23:23:23 - Pointer_generator_word2Vec - INFO: - epoch 11: 56000, training batch loss = 1.757304, running_avg_loss loss = 3.640063, validation loss = 3.231334\n",
      "I0404 23:23:23.697033 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 56000, training batch loss = 1.757304, running_avg_loss loss = 3.640063, validation loss = 3.231334\n",
      "2020-04-04 23:23:25 - Pointer_generator_word2Vec - INFO: - epoch 11: 56000, train_rouge_l_f = 0.490844, test_rouge_l_f = 0.186364\n",
      "I0404 23:23:25.279013 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 56000, train_rouge_l_f = 0.490844, test_rouge_l_f = 0.186364\n",
      "2020-04-05 00:05:20 - Pointer_generator_word2Vec - INFO: - epoch 11: 56664, test_avg_acc = 0.588552, test_avg_acc = 0.327804\n",
      "I0405 00:05:20.200043 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 11: 56664, test_avg_acc = 0.588552, test_avg_acc = 0.327804\n",
      "2020-04-05 00:07:11 - Pointer_generator_word2Vec - INFO: - epoch 12: 57000, training batch loss = 1.562163, running_avg_loss loss = 3.619284, validation loss = 3.251138\n",
      "I0405 00:07:11.409942 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 57000, training batch loss = 1.562163, running_avg_loss loss = 3.619284, validation loss = 3.251138\n",
      "2020-04-05 00:07:12 - Pointer_generator_word2Vec - INFO: - epoch 12: 57000, train_rouge_l_f = 0.510655, test_rouge_l_f = 0.288166\n",
      "I0405 00:07:12.796249 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 57000, train_rouge_l_f = 0.510655, test_rouge_l_f = 0.288166\n",
      "2020-04-05 00:11:41 - Pointer_generator_word2Vec - INFO: - epoch 12: 58000, training batch loss = 2.250094, running_avg_loss loss = 3.605592, validation loss = 3.309088\n",
      "I0405 00:11:41.952669 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 58000, training batch loss = 2.250094, running_avg_loss loss = 3.605592, validation loss = 3.309088\n",
      "2020-04-05 00:11:44 - Pointer_generator_word2Vec - INFO: - epoch 12: 58000, train_rouge_l_f = 0.440354, test_rouge_l_f = 0.279348\n",
      "I0405 00:11:44.006050 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 58000, train_rouge_l_f = 0.440354, test_rouge_l_f = 0.279348\n",
      "2020-04-05 00:16:11 - Pointer_generator_word2Vec - INFO: - epoch 12: 59000, training batch loss = 1.300304, running_avg_loss loss = 3.582540, validation loss = 3.305682\n",
      "I0405 00:16:11.180305 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 59000, training batch loss = 1.300304, running_avg_loss loss = 3.582540, validation loss = 3.305682\n",
      "2020-04-05 00:16:12 - Pointer_generator_word2Vec - INFO: - epoch 12: 59000, train_rouge_l_f = 0.675823, test_rouge_l_f = 0.134094\n",
      "I0405 00:16:12.900997 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 59000, train_rouge_l_f = 0.675823, test_rouge_l_f = 0.134094\n",
      "2020-04-05 00:20:41 - Pointer_generator_word2Vec - INFO: - epoch 12: 60000, training batch loss = 1.612028, running_avg_loss loss = 3.562834, validation loss = 3.280616\n",
      "I0405 00:20:41.746741 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 60000, training batch loss = 1.612028, running_avg_loss loss = 3.562834, validation loss = 3.280616\n",
      "2020-04-05 00:20:41 - Pointer_generator_word2Vec - INFO: - Saving model step 60000 to model/saved_models/word2Vec/0060000.tar...\n",
      "I0405 00:20:41.749366 139723389826880 initialize.py:226] Saving model step 60000 to model/saved_models/word2Vec/0060000.tar...\n",
      "2020-04-05 00:20:45 - Pointer_generator_word2Vec - INFO: - epoch 12: 60000, train_rouge_l_f = 0.691612, test_rouge_l_f = 0.424512\n",
      "I0405 00:20:45.887554 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 60000, train_rouge_l_f = 0.691612, test_rouge_l_f = 0.424512\n",
      "2020-04-05 00:25:15 - Pointer_generator_word2Vec - INFO: - epoch 12: 61000, training batch loss = 1.444782, running_avg_loss loss = 3.541654, validation loss = 3.305946\n",
      "I0405 00:25:15.787316 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 61000, training batch loss = 1.444782, running_avg_loss loss = 3.541654, validation loss = 3.305946\n",
      "2020-04-05 00:25:17 - Pointer_generator_word2Vec - INFO: - epoch 12: 61000, train_rouge_l_f = 0.547347, test_rouge_l_f = 0.201091\n",
      "I0405 00:25:17.240818 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 61000, train_rouge_l_f = 0.547347, test_rouge_l_f = 0.201091\n",
      "2020-04-05 01:05:54 - Pointer_generator_word2Vec - INFO: - epoch 12: 61386, test_avg_acc = 0.605936, test_avg_acc = 0.328869\n",
      "I0405 01:05:54.065762 139723389826880 <ipython-input-9-3e087b2d97b6>:51] epoch 12: 61386, test_avg_acc = 0.605936, test_avg_acc = 0.328869\n",
      "2020-04-05 01:08:52 - Pointer_generator_word2Vec - INFO: - epoch 13: 62000, training batch loss = 0.797890, running_avg_loss loss = 3.514216, validation loss = 3.348001\n",
      "I0405 01:08:52.849864 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 62000, training batch loss = 0.797890, running_avg_loss loss = 3.514216, validation loss = 3.348001\n",
      "2020-04-05 01:08:53 - Pointer_generator_word2Vec - INFO: - epoch 13: 62000, train_rouge_l_f = 0.784245, test_rouge_l_f = 0.309359\n",
      "I0405 01:08:53.961563 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 62000, train_rouge_l_f = 0.784245, test_rouge_l_f = 0.309359\n",
      "2020-04-05 01:13:23 - Pointer_generator_word2Vec - INFO: - epoch 13: 63000, training batch loss = 0.507552, running_avg_loss loss = 3.484150, validation loss = 3.362978\n",
      "I0405 01:13:23.964103 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 63000, training batch loss = 0.507552, running_avg_loss loss = 3.484150, validation loss = 3.362978\n",
      "2020-04-05 01:13:25 - Pointer_generator_word2Vec - INFO: - epoch 13: 63000, train_rouge_l_f = 0.928735, test_rouge_l_f = 0.286053\n",
      "I0405 01:13:25.876138 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 63000, train_rouge_l_f = 0.928735, test_rouge_l_f = 0.286053\n",
      "2020-04-05 01:17:56 - Pointer_generator_word2Vec - INFO: - epoch 13: 64000, training batch loss = 2.344399, running_avg_loss loss = 3.472752, validation loss = 3.387967\n",
      "I0405 01:17:56.156787 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 64000, training batch loss = 2.344399, running_avg_loss loss = 3.472752, validation loss = 3.387967\n",
      "2020-04-05 01:17:57 - Pointer_generator_word2Vec - INFO: - epoch 13: 64000, train_rouge_l_f = 0.364097, test_rouge_l_f = 0.236595\n",
      "I0405 01:17:57.662691 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 64000, train_rouge_l_f = 0.364097, test_rouge_l_f = 0.236595\n",
      "2020-04-05 01:22:31 - Pointer_generator_word2Vec - INFO: - epoch 13: 65000, training batch loss = 0.960407, running_avg_loss loss = 3.447629, validation loss = 3.416196\n",
      "I0405 01:22:31.190687 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 65000, training batch loss = 0.960407, running_avg_loss loss = 3.447629, validation loss = 3.416196\n",
      "2020-04-05 01:22:31 - Pointer_generator_word2Vec - INFO: - Saving model step 65000 to model/saved_models/word2Vec/0065000.tar...\n",
      "I0405 01:22:31.193502 139723389826880 initialize.py:226] Saving model step 65000 to model/saved_models/word2Vec/0065000.tar...\n",
      "2020-04-05 01:22:35 - Pointer_generator_word2Vec - INFO: - epoch 13: 65000, train_rouge_l_f = 0.839274, test_rouge_l_f = 0.355341\n",
      "I0405 01:22:35.122829 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 65000, train_rouge_l_f = 0.839274, test_rouge_l_f = 0.355341\n",
      "2020-04-05 01:27:04 - Pointer_generator_word2Vec - INFO: - epoch 13: 66000, training batch loss = 1.409302, running_avg_loss loss = 3.427245, validation loss = 3.381975\n",
      "I0405 01:27:04.420534 139723389826880 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 66000, training batch loss = 1.409302, running_avg_loss loss = 3.427245, validation loss = 3.381975\n",
      "2020-04-05 01:27:06 - Pointer_generator_word2Vec - INFO: - epoch 13: 66000, train_rouge_l_f = 0.648807, test_rouge_l_f = 0.177153\n",
      "I0405 01:27:06.408107 139723389826880 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 66000, train_rouge_l_f = 0.648807, test_rouge_l_f = 0.177153\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            mle_loss = train_one(model, config, batch)\n",
    "            rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % ( config.gradient_accum) == 0: # gradient accumulation\n",
    "    #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "    #             (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "                optimizer.step() # 根据累计的梯度更新网络参数\n",
    "                optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "\n",
    "            if step%5000 == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                       r_loss=0, title = loggerName)\n",
    "            if step%1000 == 0 and step > 0:\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "        logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')                \n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
