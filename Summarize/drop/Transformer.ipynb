{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 06:46:05.625564 140149589550912 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-10 06:46:06 - Transformer_no_pretrain - INFO: - logger已啟動\n",
      "I0410 06:46:06.412704 140149589550912 train_util.py:125] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.transormer_beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--transformer', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=6)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=512)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=False, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 06:46:12 - Transformer_no_pretrain - INFO: - train : 37771, test : 4197\n",
      "I0410 06:46:12.554894 140149589550912 batcher.py:171] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab,config=config)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, _, \\\n",
    "        _, _, _, _= \\\n",
    "            get_input_from_batch(batch, config, batch_first = False)\n",
    "       \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = False) # Get input and target batchs for training decoder\n",
    "\n",
    "        pred = model(enc_batch, dec_batch, enc_padding_mask, dec_padding_mask, enc_batch_extend_vocab, extra_zeros)\n",
    "#         loss = model.label_smoothing_loss(pred, target_batch)\n",
    "        loss = model.nll_loss(pred, target_batch, dec_lens)\n",
    "#         print(loss)#         \n",
    "        # >>>>>>>> DEBUG Session <<<<<<<<<\n",
    "#         print('------------------------------------')\n",
    "#         print(\"ENC\\n\")\n",
    "#         print(enc_batch.shape)\n",
    "#         print(\"DEC\\n\")\n",
    "#         print(dec_batch.shape)\n",
    "        # print(\"TGT\\n\")\n",
    "        # print(target_batch.shape)\n",
    "        # print(\"ENCP\\n\")\n",
    "        # print(enc_padding_mask.shape)\n",
    "        # print(\"DECP\\n\")\n",
    "        # print(dec_padding_mask.shape)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    model.eval()\n",
    "    config.is_predicting = True\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "\n",
    "    pred_ids = beam_search(config, batch, model, START, END, UNKNOWN_TOKEN)\n",
    "    config.is_predicting = False\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "#     print(prepare_result(vocab, batch, pred_ids))\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    model.eval()\n",
    "    config.is_predicting = True\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        pred_ids = beam_search(config, batch, model, START, END, UNKNOWN_TOKEN)\n",
    "        config.is_predicting = False\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 06:46:16 - Transformer_no_pretrain - INFO: - ------Training START--------\n",
      "I0410 06:46:16.216916 140149589550912 <ipython-input-9-27f62b467aba>:2] ------Training START--------\n",
      "2020-04-10 06:48:29 - Transformer_no_pretrain - INFO: - epoch 0: 1000, training batch loss = 5.543754, running_avg_loss loss = 5.543754, validation loss = 5.107059\n",
      "I0410 06:48:29.636485 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 0: 1000, training batch loss = 5.543754, running_avg_loss loss = 5.543754, validation loss = 5.107059\n",
      "2020-04-10 06:48:30 - Transformer_no_pretrain - INFO: - epoch 0: 1000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.027256\n",
      "I0410 06:48:30.225006 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 0: 1000, train_rouge_l_f = 0.000000, test_rouge_l_f = 0.027256\n",
      "2020-04-10 06:50:36 - Transformer_no_pretrain - INFO: - epoch 0: 2000, training batch loss = 4.051977, running_avg_loss loss = 5.528836, validation loss = 4.786893\n",
      "I0410 06:50:36.049045 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 0: 2000, training batch loss = 4.051977, running_avg_loss loss = 5.528836, validation loss = 4.786893\n",
      "2020-04-10 06:50:37 - Transformer_no_pretrain - INFO: - epoch 0: 2000, train_rouge_l_f = 0.224261, test_rouge_l_f = 0.078823\n",
      "I0410 06:50:37.318665 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 0: 2000, train_rouge_l_f = 0.224261, test_rouge_l_f = 0.078823\n",
      "2020-04-10 06:52:42 - Transformer_no_pretrain - INFO: - epoch 0: 3000, training batch loss = 4.161268, running_avg_loss loss = 5.515160, validation loss = 4.641861\n",
      "I0410 06:52:42.677446 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 0: 3000, training batch loss = 4.161268, running_avg_loss loss = 5.515160, validation loss = 4.641861\n",
      "2020-04-10 06:52:42 - Transformer_no_pretrain - INFO: - epoch 0: 3000, train_rouge_l_f = 0.118402, test_rouge_l_f = 0.082470\n",
      "I0410 06:52:42.942862 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 0: 3000, train_rouge_l_f = 0.118402, test_rouge_l_f = 0.082470\n",
      "2020-04-10 06:54:43 - Transformer_no_pretrain - INFO: - epoch 0: 4000, training batch loss = 4.862231, running_avg_loss loss = 5.508631, validation loss = 4.545244\n",
      "I0410 06:54:43.979528 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 0: 4000, training batch loss = 4.862231, running_avg_loss loss = 5.508631, validation loss = 4.545244\n",
      "2020-04-10 06:54:44 - Transformer_no_pretrain - INFO: - epoch 0: 4000, train_rouge_l_f = 0.046902, test_rouge_l_f = 0.127579\n",
      "I0410 06:54:44.529471 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 0: 4000, train_rouge_l_f = 0.046902, test_rouge_l_f = 0.127579\n",
      "2020-04-10 07:02:49 - Transformer_no_pretrain - INFO: - epoch 0: 4722, test_avg_acc = 0.108779, test_avg_acc = 0.110855\n",
      "I0410 07:02:49.293890 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 0: 4722, test_avg_acc = 0.108779, test_avg_acc = 0.110855\n",
      "2020-04-10 07:03:32 - Transformer_no_pretrain - INFO: - epoch 1: 5000, training batch loss = 3.960904, running_avg_loss loss = 5.493154, validation loss = 4.469908\n",
      "I0410 07:03:32.793715 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 1: 5000, training batch loss = 3.960904, running_avg_loss loss = 5.493154, validation loss = 4.469908\n",
      "2020-04-10 07:03:32 - Transformer_no_pretrain - INFO: - Saving model step 5000 to model/saved_models/Transformer_no_pretrain/0005000.tar...\n",
      "I0410 07:03:32.796930 140149589550912 initialize.py:225] Saving model step 5000 to model/saved_models/Transformer_no_pretrain/0005000.tar...\n",
      "2020-04-10 07:03:33 - Transformer_no_pretrain - INFO: - epoch 1: 5000, train_rouge_l_f = 0.177004, test_rouge_l_f = 0.036738\n",
      "I0410 07:03:33.993455 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 1: 5000, train_rouge_l_f = 0.177004, test_rouge_l_f = 0.036738\n",
      "2020-04-10 07:05:37 - Transformer_no_pretrain - INFO: - epoch 1: 6000, training batch loss = 4.159915, running_avg_loss loss = 5.479821, validation loss = 4.433049\n",
      "I0410 07:05:37.135696 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 1: 6000, training batch loss = 4.159915, running_avg_loss loss = 5.479821, validation loss = 4.433049\n",
      "2020-04-10 07:05:37 - Transformer_no_pretrain - INFO: - epoch 1: 6000, train_rouge_l_f = 0.071460, test_rouge_l_f = 0.000000\n",
      "I0410 07:05:37.389617 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 1: 6000, train_rouge_l_f = 0.071460, test_rouge_l_f = 0.000000\n",
      "2020-04-10 07:07:41 - Transformer_no_pretrain - INFO: - epoch 1: 7000, training batch loss = 3.446755, running_avg_loss loss = 5.459491, validation loss = 4.392524\n",
      "I0410 07:07:41.669952 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 1: 7000, training batch loss = 3.446755, running_avg_loss loss = 5.459491, validation loss = 4.392524\n",
      "2020-04-10 07:07:42 - Transformer_no_pretrain - INFO: - epoch 1: 7000, train_rouge_l_f = 0.123023, test_rouge_l_f = 0.113954\n",
      "I0410 07:07:42.410782 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 1: 7000, train_rouge_l_f = 0.123023, test_rouge_l_f = 0.113954\n",
      "2020-04-10 07:09:53 - Transformer_no_pretrain - INFO: - epoch 1: 8000, training batch loss = 4.806437, running_avg_loss loss = 5.452960, validation loss = 4.360085\n",
      "I0410 07:09:53.709346 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 1: 8000, training batch loss = 4.806437, running_avg_loss loss = 5.452960, validation loss = 4.360085\n",
      "2020-04-10 07:09:53 - Transformer_no_pretrain - INFO: - epoch 1: 8000, train_rouge_l_f = 0.053355, test_rouge_l_f = 0.088495\n",
      "I0410 07:09:53.984759 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 1: 8000, train_rouge_l_f = 0.053355, test_rouge_l_f = 0.088495\n",
      "2020-04-10 07:11:58 - Transformer_no_pretrain - INFO: - epoch 1: 9000, training batch loss = 3.833449, running_avg_loss loss = 5.436765, validation loss = 4.326955\n",
      "I0410 07:11:58.246085 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 1: 9000, training batch loss = 3.833449, running_avg_loss loss = 5.436765, validation loss = 4.326955\n",
      "2020-04-10 07:11:59 - Transformer_no_pretrain - INFO: - epoch 1: 9000, train_rouge_l_f = 0.124552, test_rouge_l_f = 0.136119\n",
      "I0410 07:11:59.150016 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 1: 9000, train_rouge_l_f = 0.124552, test_rouge_l_f = 0.136119\n",
      "2020-04-10 07:19:30 - Transformer_no_pretrain - INFO: - epoch 1: 9444, test_avg_acc = 0.108714, test_avg_acc = 0.110855\n",
      "I0410 07:19:30.997489 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 1: 9444, test_avg_acc = 0.108714, test_avg_acc = 0.110855\n",
      "2020-04-10 07:20:42 - Transformer_no_pretrain - INFO: - epoch 2: 10000, training batch loss = 3.615552, running_avg_loss loss = 5.418553, validation loss = 4.313838\n",
      "I0410 07:20:42.711290 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 2: 10000, training batch loss = 3.615552, running_avg_loss loss = 5.418553, validation loss = 4.313838\n",
      "2020-04-10 07:20:42 - Transformer_no_pretrain - INFO: - Saving model step 10000 to model/saved_models/Transformer_no_pretrain/0010000.tar...\n",
      "I0410 07:20:42.715062 140149589550912 initialize.py:225] Saving model step 10000 to model/saved_models/Transformer_no_pretrain/0010000.tar...\n",
      "2020-04-10 07:20:43 - Transformer_no_pretrain - INFO: - epoch 2: 10000, train_rouge_l_f = 0.098278, test_rouge_l_f = 0.142276\n",
      "I0410 07:20:43.891167 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 2: 10000, train_rouge_l_f = 0.098278, test_rouge_l_f = 0.142276\n",
      "2020-04-10 07:22:52 - Transformer_no_pretrain - INFO: - epoch 2: 11000, training batch loss = 3.009404, running_avg_loss loss = 5.394461, validation loss = 4.310526\n",
      "I0410 07:22:52.729692 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 2: 11000, training batch loss = 3.009404, running_avg_loss loss = 5.394461, validation loss = 4.310526\n",
      "2020-04-10 07:22:53 - Transformer_no_pretrain - INFO: - epoch 2: 11000, train_rouge_l_f = 0.182286, test_rouge_l_f = 0.078823\n",
      "I0410 07:22:53.989253 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 2: 11000, train_rouge_l_f = 0.182286, test_rouge_l_f = 0.078823\n",
      "2020-04-10 07:25:02 - Transformer_no_pretrain - INFO: - epoch 2: 12000, training batch loss = 3.835634, running_avg_loss loss = 5.378873, validation loss = 4.286850\n",
      "I0410 07:25:02.316154 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 2: 12000, training batch loss = 3.835634, running_avg_loss loss = 5.378873, validation loss = 4.286850\n",
      "2020-04-10 07:25:03 - Transformer_no_pretrain - INFO: - epoch 2: 12000, train_rouge_l_f = 0.175842, test_rouge_l_f = 0.055972\n",
      "I0410 07:25:03.006097 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 2: 12000, train_rouge_l_f = 0.175842, test_rouge_l_f = 0.055972\n",
      "2020-04-10 07:27:07 - Transformer_no_pretrain - INFO: - epoch 2: 13000, training batch loss = 4.015297, running_avg_loss loss = 5.365237, validation loss = 4.281654\n",
      "I0410 07:27:07.954834 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 2: 13000, training batch loss = 4.015297, running_avg_loss loss = 5.365237, validation loss = 4.281654\n",
      "2020-04-10 07:27:09 - Transformer_no_pretrain - INFO: - epoch 2: 13000, train_rouge_l_f = 0.085063, test_rouge_l_f = 0.146220\n",
      "I0410 07:27:09.335858 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 2: 13000, train_rouge_l_f = 0.085063, test_rouge_l_f = 0.146220\n",
      "2020-04-10 07:29:17 - Transformer_no_pretrain - INFO: - epoch 2: 14000, training batch loss = 4.431806, running_avg_loss loss = 5.355903, validation loss = 4.262141\n",
      "I0410 07:29:17.325773 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 2: 14000, training batch loss = 4.431806, running_avg_loss loss = 5.355903, validation loss = 4.262141\n",
      "2020-04-10 07:29:18 - Transformer_no_pretrain - INFO: - epoch 2: 14000, train_rouge_l_f = 0.046429, test_rouge_l_f = 0.043660\n",
      "I0410 07:29:18.672591 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 2: 14000, train_rouge_l_f = 0.046429, test_rouge_l_f = 0.043660\n",
      "2020-04-10 07:36:19 - Transformer_no_pretrain - INFO: - epoch 2: 14166, test_avg_acc = 0.108747, test_avg_acc = 0.110855\n",
      "I0410 07:36:19.554052 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 2: 14166, test_avg_acc = 0.108747, test_avg_acc = 0.110855\n",
      "2020-04-10 07:38:05 - Transformer_no_pretrain - INFO: - epoch 3: 15000, training batch loss = 4.571482, running_avg_loss loss = 5.348059, validation loss = 4.268146\n",
      "I0410 07:38:05.225891 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 3: 15000, training batch loss = 4.571482, running_avg_loss loss = 5.348059, validation loss = 4.268146\n",
      "2020-04-10 07:38:05 - Transformer_no_pretrain - INFO: - Saving model step 15000 to model/saved_models/Transformer_no_pretrain/0015000.tar...\n",
      "I0410 07:38:05.227526 140149589550912 initialize.py:225] Saving model step 15000 to model/saved_models/Transformer_no_pretrain/0015000.tar...\n",
      "2020-04-10 07:38:06 - Transformer_no_pretrain - INFO: - epoch 3: 15000, train_rouge_l_f = 0.066494, test_rouge_l_f = 0.167811\n",
      "I0410 07:38:06.542627 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 3: 15000, train_rouge_l_f = 0.066494, test_rouge_l_f = 0.167811\n",
      "2020-04-10 07:40:10 - Transformer_no_pretrain - INFO: - epoch 3: 16000, training batch loss = 3.638669, running_avg_loss loss = 5.330965, validation loss = 4.277515\n",
      "I0410 07:40:10.174844 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 3: 16000, training batch loss = 3.638669, running_avg_loss loss = 5.330965, validation loss = 4.277515\n",
      "2020-04-10 07:40:11 - Transformer_no_pretrain - INFO: - epoch 3: 16000, train_rouge_l_f = 0.057823, test_rouge_l_f = 0.076294\n",
      "I0410 07:40:11.375130 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 3: 16000, train_rouge_l_f = 0.057823, test_rouge_l_f = 0.076294\n",
      "2020-04-10 07:42:19 - Transformer_no_pretrain - INFO: - epoch 3: 17000, training batch loss = 4.060892, running_avg_loss loss = 5.318264, validation loss = 4.269852\n",
      "I0410 07:42:19.259682 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 3: 17000, training batch loss = 4.060892, running_avg_loss loss = 5.318264, validation loss = 4.269852\n",
      "2020-04-10 07:42:20 - Transformer_no_pretrain - INFO: - epoch 3: 17000, train_rouge_l_f = 0.081706, test_rouge_l_f = 0.177614\n",
      "I0410 07:42:20.248185 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 3: 17000, train_rouge_l_f = 0.081706, test_rouge_l_f = 0.177614\n",
      "2020-04-10 07:44:25 - Transformer_no_pretrain - INFO: - epoch 3: 18000, training batch loss = 3.886824, running_avg_loss loss = 5.303950, validation loss = 4.253537\n",
      "I0410 07:44:25.580703 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 3: 18000, training batch loss = 3.886824, running_avg_loss loss = 5.303950, validation loss = 4.253537\n",
      "2020-04-10 07:44:25 - Transformer_no_pretrain - INFO: - epoch 3: 18000, train_rouge_l_f = 0.101757, test_rouge_l_f = 0.096447\n",
      "I0410 07:44:25.948114 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 3: 18000, train_rouge_l_f = 0.101757, test_rouge_l_f = 0.096447\n",
      "2020-04-10 07:53:17 - Transformer_no_pretrain - INFO: - epoch 3: 18888, test_avg_acc = 0.101454, test_avg_acc = 0.103100\n",
      "I0410 07:53:17.497384 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 3: 18888, test_avg_acc = 0.101454, test_avg_acc = 0.103100\n",
      "2020-04-10 07:53:41 - Transformer_no_pretrain - INFO: - epoch 4: 19000, training batch loss = 3.027133, running_avg_loss loss = 5.281182, validation loss = 4.252660\n",
      "I0410 07:53:41.033437 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 4: 19000, training batch loss = 3.027133, running_avg_loss loss = 5.281182, validation loss = 4.252660\n",
      "2020-04-10 07:53:41 - Transformer_no_pretrain - INFO: - epoch 4: 19000, train_rouge_l_f = 0.196927, test_rouge_l_f = 0.125374\n",
      "I0410 07:53:41.843225 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 4: 19000, train_rouge_l_f = 0.196927, test_rouge_l_f = 0.125374\n",
      "2020-04-10 07:55:49 - Transformer_no_pretrain - INFO: - epoch 4: 20000, training batch loss = 3.314258, running_avg_loss loss = 5.261512, validation loss = 4.300027\n",
      "I0410 07:55:49.416401 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 4: 20000, training batch loss = 3.314258, running_avg_loss loss = 5.261512, validation loss = 4.300027\n",
      "2020-04-10 07:55:49 - Transformer_no_pretrain - INFO: - Saving model step 20000 to model/saved_models/Transformer_no_pretrain/0020000.tar...\n",
      "I0410 07:55:49.419985 140149589550912 initialize.py:225] Saving model step 20000 to model/saved_models/Transformer_no_pretrain/0020000.tar...\n",
      "2020-04-10 07:55:51 - Transformer_no_pretrain - INFO: - epoch 4: 20000, train_rouge_l_f = 0.096319, test_rouge_l_f = 0.027683\n",
      "I0410 07:55:51.295837 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 4: 20000, train_rouge_l_f = 0.096319, test_rouge_l_f = 0.027683\n",
      "2020-04-10 07:58:00 - Transformer_no_pretrain - INFO: - epoch 4: 21000, training batch loss = 3.623393, running_avg_loss loss = 5.245131, validation loss = 4.299301\n",
      "I0410 07:58:00.742519 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 4: 21000, training batch loss = 3.623393, running_avg_loss loss = 5.245131, validation loss = 4.299301\n",
      "2020-04-10 07:58:01 - Transformer_no_pretrain - INFO: - epoch 4: 21000, train_rouge_l_f = 0.053755, test_rouge_l_f = 0.076833\n",
      "I0410 07:58:01.527697 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 4: 21000, train_rouge_l_f = 0.053755, test_rouge_l_f = 0.076833\n",
      "2020-04-10 08:00:08 - Transformer_no_pretrain - INFO: - epoch 4: 22000, training batch loss = 3.355183, running_avg_loss loss = 5.226232, validation loss = 4.295039\n",
      "I0410 08:00:08.288417 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 4: 22000, training batch loss = 3.355183, running_avg_loss loss = 5.226232, validation loss = 4.295039\n",
      "2020-04-10 08:00:08 - Transformer_no_pretrain - INFO: - epoch 4: 22000, train_rouge_l_f = 0.107104, test_rouge_l_f = 0.163692\n",
      "I0410 08:00:08.940754 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 4: 22000, train_rouge_l_f = 0.107104, test_rouge_l_f = 0.163692\n",
      "2020-04-10 08:02:17 - Transformer_no_pretrain - INFO: - epoch 4: 23000, training batch loss = 3.295220, running_avg_loss loss = 5.206922, validation loss = 4.292421\n",
      "I0410 08:02:17.979891 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 4: 23000, training batch loss = 3.295220, running_avg_loss loss = 5.206922, validation loss = 4.292421\n",
      "2020-04-10 08:02:18 - Transformer_no_pretrain - INFO: - epoch 4: 23000, train_rouge_l_f = 0.060824, test_rouge_l_f = 0.121950\n",
      "I0410 08:02:18.381102 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 4: 23000, train_rouge_l_f = 0.060824, test_rouge_l_f = 0.121950\n",
      "2020-04-10 08:10:04 - Transformer_no_pretrain - INFO: - epoch 4: 23610, test_avg_acc = 0.108727, test_avg_acc = 0.110855\n",
      "I0410 08:10:04.190238 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 4: 23610, test_avg_acc = 0.108727, test_avg_acc = 0.110855\n",
      "2020-04-10 08:11:00 - Transformer_no_pretrain - INFO: - epoch 5: 24000, training batch loss = 3.004631, running_avg_loss loss = 5.184899, validation loss = 4.330476\n",
      "I0410 08:11:00.753998 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 5: 24000, training batch loss = 3.004631, running_avg_loss loss = 5.184899, validation loss = 4.330476\n",
      "2020-04-10 08:11:01 - Transformer_no_pretrain - INFO: - epoch 5: 24000, train_rouge_l_f = 0.114823, test_rouge_l_f = 0.123465\n",
      "I0410 08:11:01.839514 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 5: 24000, train_rouge_l_f = 0.114823, test_rouge_l_f = 0.123465\n",
      "2020-04-10 08:13:04 - Transformer_no_pretrain - INFO: - epoch 5: 25000, training batch loss = 2.747971, running_avg_loss loss = 5.160529, validation loss = 4.349983\n",
      "I0410 08:13:04.872694 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 5: 25000, training batch loss = 2.747971, running_avg_loss loss = 5.160529, validation loss = 4.349983\n",
      "2020-04-10 08:13:04 - Transformer_no_pretrain - INFO: - Saving model step 25000 to model/saved_models/Transformer_no_pretrain/0025000.tar...\n",
      "I0410 08:13:04.875539 140149589550912 initialize.py:225] Saving model step 25000 to model/saved_models/Transformer_no_pretrain/0025000.tar...\n",
      "2020-04-10 08:13:06 - Transformer_no_pretrain - INFO: - epoch 5: 25000, train_rouge_l_f = 0.136818, test_rouge_l_f = 0.097350\n",
      "I0410 08:13:06.335568 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 5: 25000, train_rouge_l_f = 0.136818, test_rouge_l_f = 0.097350\n",
      "2020-04-10 08:15:12 - Transformer_no_pretrain - INFO: - epoch 5: 26000, training batch loss = 2.867578, running_avg_loss loss = 5.137600, validation loss = 4.381024\n",
      "I0410 08:15:12.279507 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 5: 26000, training batch loss = 2.867578, running_avg_loss loss = 5.137600, validation loss = 4.381024\n",
      "2020-04-10 08:15:13 - Transformer_no_pretrain - INFO: - epoch 5: 26000, train_rouge_l_f = 0.098594, test_rouge_l_f = 0.160536\n",
      "I0410 08:15:13.127257 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 5: 26000, train_rouge_l_f = 0.098594, test_rouge_l_f = 0.160536\n",
      "2020-04-10 08:17:18 - Transformer_no_pretrain - INFO: - epoch 5: 27000, training batch loss = 2.936536, running_avg_loss loss = 5.115589, validation loss = 4.370949\n",
      "I0410 08:17:18.693445 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 5: 27000, training batch loss = 2.936536, running_avg_loss loss = 5.115589, validation loss = 4.370949\n",
      "2020-04-10 08:17:19 - Transformer_no_pretrain - INFO: - epoch 5: 27000, train_rouge_l_f = 0.093233, test_rouge_l_f = 0.222415\n",
      "I0410 08:17:19.131451 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 5: 27000, train_rouge_l_f = 0.093233, test_rouge_l_f = 0.222415\n",
      "2020-04-10 08:19:28 - Transformer_no_pretrain - INFO: - epoch 5: 28000, training batch loss = 3.496845, running_avg_loss loss = 5.099402, validation loss = 4.358564\n",
      "I0410 08:19:28.396570 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 5: 28000, training batch loss = 3.496845, running_avg_loss loss = 5.099402, validation loss = 4.358564\n",
      "2020-04-10 08:19:29 - Transformer_no_pretrain - INFO: - epoch 5: 28000, train_rouge_l_f = 0.069081, test_rouge_l_f = 0.086956\n",
      "I0410 08:19:29.836158 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 5: 28000, train_rouge_l_f = 0.069081, test_rouge_l_f = 0.086956\n",
      "2020-04-10 08:26:44 - Transformer_no_pretrain - INFO: - epoch 5: 28332, test_avg_acc = 0.108730, test_avg_acc = 0.110855\n",
      "I0410 08:26:44.873114 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 5: 28332, test_avg_acc = 0.108730, test_avg_acc = 0.110855\n",
      "2020-04-10 08:28:09 - Transformer_no_pretrain - INFO: - epoch 6: 29000, training batch loss = 2.623950, running_avg_loss loss = 5.074647, validation loss = 4.440292\n",
      "I0410 08:28:09.888976 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 6: 29000, training batch loss = 2.623950, running_avg_loss loss = 5.074647, validation loss = 4.440292\n",
      "2020-04-10 08:28:10 - Transformer_no_pretrain - INFO: - epoch 6: 29000, train_rouge_l_f = 0.065891, test_rouge_l_f = 0.069877\n",
      "I0410 08:28:10.466312 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 6: 29000, train_rouge_l_f = 0.065891, test_rouge_l_f = 0.069877\n",
      "2020-04-10 08:30:12 - Transformer_no_pretrain - INFO: - epoch 6: 30000, training batch loss = 2.992473, running_avg_loss loss = 5.053825, validation loss = 4.469901\n",
      "I0410 08:30:12.647536 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 6: 30000, training batch loss = 2.992473, running_avg_loss loss = 5.053825, validation loss = 4.469901\n",
      "2020-04-10 08:30:12 - Transformer_no_pretrain - INFO: - Saving model step 30000 to model/saved_models/Transformer_no_pretrain/0030000.tar...\n",
      "I0410 08:30:12.650193 140149589550912 initialize.py:225] Saving model step 30000 to model/saved_models/Transformer_no_pretrain/0030000.tar...\n",
      "2020-04-10 08:30:14 - Transformer_no_pretrain - INFO: - epoch 6: 30000, train_rouge_l_f = 0.079092, test_rouge_l_f = 0.097871\n",
      "I0410 08:30:14.902225 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 6: 30000, train_rouge_l_f = 0.079092, test_rouge_l_f = 0.097871\n",
      "2020-04-10 08:32:22 - Transformer_no_pretrain - INFO: - epoch 6: 31000, training batch loss = 3.302020, running_avg_loss loss = 5.036307, validation loss = 4.483482\n",
      "I0410 08:32:22.545050 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 6: 31000, training batch loss = 3.302020, running_avg_loss loss = 5.036307, validation loss = 4.483482\n",
      "2020-04-10 08:32:23 - Transformer_no_pretrain - INFO: - epoch 6: 31000, train_rouge_l_f = 0.118850, test_rouge_l_f = 0.119249\n",
      "I0410 08:32:23.209328 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 6: 31000, train_rouge_l_f = 0.118850, test_rouge_l_f = 0.119249\n",
      "2020-04-10 08:34:27 - Transformer_no_pretrain - INFO: - epoch 6: 32000, training batch loss = 3.282156, running_avg_loss loss = 5.018766, validation loss = 4.470523\n",
      "I0410 08:34:27.702812 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 6: 32000, training batch loss = 3.282156, running_avg_loss loss = 5.018766, validation loss = 4.470523\n",
      "2020-04-10 08:34:28 - Transformer_no_pretrain - INFO: - epoch 6: 32000, train_rouge_l_f = 0.180974, test_rouge_l_f = 0.117577\n",
      "I0410 08:34:28.980892 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 6: 32000, train_rouge_l_f = 0.180974, test_rouge_l_f = 0.117577\n",
      "2020-04-10 08:36:37 - Transformer_no_pretrain - INFO: - epoch 6: 33000, training batch loss = 2.750737, running_avg_loss loss = 4.996086, validation loss = 4.464761\n",
      "I0410 08:36:37.460875 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 6: 33000, training batch loss = 2.750737, running_avg_loss loss = 4.996086, validation loss = 4.464761\n",
      "2020-04-10 08:36:38 - Transformer_no_pretrain - INFO: - epoch 6: 33000, train_rouge_l_f = 0.267177, test_rouge_l_f = 0.110838\n",
      "I0410 08:36:38.944697 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 6: 33000, train_rouge_l_f = 0.267177, test_rouge_l_f = 0.110838\n",
      "2020-04-10 09:12:28 - Transformer_no_pretrain - INFO: - epoch 6: 33054, test_avg_acc = 0.105761, test_avg_acc = 0.104891\n",
      "I0410 09:12:28.442520 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 6: 33054, test_avg_acc = 0.105761, test_avg_acc = 0.104891\n",
      "2020-04-10 09:14:21 - Transformer_no_pretrain - INFO: - epoch 7: 34000, training batch loss = 2.820188, running_avg_loss loss = 4.974327, validation loss = 4.590103\n",
      "I0410 09:14:21.144411 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 7: 34000, training batch loss = 2.820188, running_avg_loss loss = 4.974327, validation loss = 4.590103\n",
      "2020-04-10 09:14:21 - Transformer_no_pretrain - INFO: - epoch 7: 34000, train_rouge_l_f = 0.097460, test_rouge_l_f = 0.036738\n",
      "I0410 09:14:21.524925 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 7: 34000, train_rouge_l_f = 0.097460, test_rouge_l_f = 0.036738\n",
      "2020-04-10 09:16:27 - Transformer_no_pretrain - INFO: - epoch 7: 35000, training batch loss = 2.669720, running_avg_loss loss = 4.951281, validation loss = 4.605771\n",
      "I0410 09:16:27.074615 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 7: 35000, training batch loss = 2.669720, running_avg_loss loss = 4.951281, validation loss = 4.605771\n",
      "2020-04-10 09:16:27 - Transformer_no_pretrain - INFO: - Saving model step 35000 to model/saved_models/Transformer_no_pretrain/0035000.tar...\n",
      "I0410 09:16:27.077277 140149589550912 initialize.py:225] Saving model step 35000 to model/saved_models/Transformer_no_pretrain/0035000.tar...\n",
      "2020-04-10 09:16:29 - Transformer_no_pretrain - INFO: - epoch 7: 35000, train_rouge_l_f = 0.058366, test_rouge_l_f = 0.061907\n",
      "I0410 09:16:29.010702 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 7: 35000, train_rouge_l_f = 0.058366, test_rouge_l_f = 0.061907\n",
      "2020-04-10 09:18:34 - Transformer_no_pretrain - INFO: - epoch 7: 36000, training batch loss = 2.832252, running_avg_loss loss = 4.930090, validation loss = 4.606123\n",
      "I0410 09:18:34.795157 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 7: 36000, training batch loss = 2.832252, running_avg_loss loss = 4.930090, validation loss = 4.606123\n",
      "2020-04-10 09:18:36 - Transformer_no_pretrain - INFO: - epoch 7: 36000, train_rouge_l_f = 0.071212, test_rouge_l_f = 0.106127\n",
      "I0410 09:18:36.066693 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 7: 36000, train_rouge_l_f = 0.071212, test_rouge_l_f = 0.106127\n",
      "2020-04-10 09:20:43 - Transformer_no_pretrain - INFO: - epoch 7: 37000, training batch loss = 2.926695, running_avg_loss loss = 4.910056, validation loss = 4.626065\n",
      "I0410 09:20:43.215876 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 7: 37000, training batch loss = 2.926695, running_avg_loss loss = 4.910056, validation loss = 4.626065\n",
      "2020-04-10 09:20:43 - Transformer_no_pretrain - INFO: - epoch 7: 37000, train_rouge_l_f = 0.077015, test_rouge_l_f = 0.154847\n",
      "I0410 09:20:43.765388 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 7: 37000, train_rouge_l_f = 0.077015, test_rouge_l_f = 0.154847\n",
      "2020-04-10 09:34:40 - Transformer_no_pretrain - INFO: - epoch 7: 37776, test_avg_acc = 0.093652, test_avg_acc = 0.093316\n",
      "I0410 09:34:40.557626 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 7: 37776, test_avg_acc = 0.093652, test_avg_acc = 0.093316\n",
      "2020-04-10 09:35:15 - Transformer_no_pretrain - INFO: - epoch 8: 38000, training batch loss = 1.904527, running_avg_loss loss = 4.880001, validation loss = 4.678793\n",
      "I0410 09:35:15.951089 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 8: 38000, training batch loss = 1.904527, running_avg_loss loss = 4.880001, validation loss = 4.678793\n",
      "2020-04-10 09:35:17 - Transformer_no_pretrain - INFO: - epoch 8: 38000, train_rouge_l_f = 0.086389, test_rouge_l_f = 0.107218\n",
      "I0410 09:35:17.425918 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 8: 38000, train_rouge_l_f = 0.086389, test_rouge_l_f = 0.107218\n",
      "2020-04-10 09:37:19 - Transformer_no_pretrain - INFO: - epoch 8: 39000, training batch loss = 2.492259, running_avg_loss loss = 4.856124, validation loss = 4.754751\n",
      "I0410 09:37:19.512509 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 8: 39000, training batch loss = 2.492259, running_avg_loss loss = 4.856124, validation loss = 4.754751\n",
      "2020-04-10 09:37:20 - Transformer_no_pretrain - INFO: - epoch 8: 39000, train_rouge_l_f = 0.090392, test_rouge_l_f = 0.081758\n",
      "I0410 09:37:20.380362 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 8: 39000, train_rouge_l_f = 0.090392, test_rouge_l_f = 0.081758\n",
      "2020-04-10 09:39:28 - Transformer_no_pretrain - INFO: - epoch 8: 40000, training batch loss = 2.499499, running_avg_loss loss = 4.832557, validation loss = 4.775480\n",
      "I0410 09:39:28.293028 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 8: 40000, training batch loss = 2.499499, running_avg_loss loss = 4.832557, validation loss = 4.775480\n",
      "2020-04-10 09:39:28 - Transformer_no_pretrain - INFO: - Saving model step 40000 to model/saved_models/Transformer_no_pretrain/0040000.tar...\n",
      "I0410 09:39:28.295826 140149589550912 initialize.py:225] Saving model step 40000 to model/saved_models/Transformer_no_pretrain/0040000.tar...\n",
      "2020-04-10 09:39:30 - Transformer_no_pretrain - INFO: - epoch 8: 40000, train_rouge_l_f = 0.065134, test_rouge_l_f = 0.065139\n",
      "I0410 09:39:30.533012 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 8: 40000, train_rouge_l_f = 0.065134, test_rouge_l_f = 0.065139\n",
      "2020-04-10 09:41:42 - Transformer_no_pretrain - INFO: - epoch 8: 41000, training batch loss = 2.516204, running_avg_loss loss = 4.809394, validation loss = 4.770552\n",
      "I0410 09:41:42.233657 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 8: 41000, training batch loss = 2.516204, running_avg_loss loss = 4.809394, validation loss = 4.770552\n",
      "2020-04-10 09:41:43 - Transformer_no_pretrain - INFO: - epoch 8: 41000, train_rouge_l_f = 0.080318, test_rouge_l_f = 0.093824\n",
      "I0410 09:41:43.375692 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 8: 41000, train_rouge_l_f = 0.080318, test_rouge_l_f = 0.093824\n",
      "2020-04-10 09:43:51 - Transformer_no_pretrain - INFO: - epoch 8: 42000, training batch loss = 2.302301, running_avg_loss loss = 4.784323, validation loss = 4.762376\n",
      "I0410 09:43:51.987705 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 8: 42000, training batch loss = 2.302301, running_avg_loss loss = 4.784323, validation loss = 4.762376\n",
      "2020-04-10 09:43:53 - Transformer_no_pretrain - INFO: - epoch 8: 42000, train_rouge_l_f = 0.142356, test_rouge_l_f = 0.076511\n",
      "I0410 09:43:53.967165 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 8: 42000, train_rouge_l_f = 0.142356, test_rouge_l_f = 0.076511\n",
      "2020-04-10 10:22:26 - Transformer_no_pretrain - INFO: - epoch 8: 42498, test_avg_acc = 0.101382, test_avg_acc = 0.102077\n",
      "I0410 10:22:26.836015 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 8: 42498, test_avg_acc = 0.101382, test_avg_acc = 0.102077\n",
      "2020-04-10 10:23:34 - Transformer_no_pretrain - INFO: - epoch 9: 43000, training batch loss = 2.032299, running_avg_loss loss = 4.756803, validation loss = 4.856204\n",
      "I0410 10:23:34.741085 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 9: 43000, training batch loss = 2.032299, running_avg_loss loss = 4.756803, validation loss = 4.856204\n",
      "2020-04-10 10:23:35 - Transformer_no_pretrain - INFO: - epoch 9: 43000, train_rouge_l_f = 0.063766, test_rouge_l_f = 0.148388\n",
      "I0410 10:23:35.761372 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 9: 43000, train_rouge_l_f = 0.063766, test_rouge_l_f = 0.148388\n",
      "2020-04-10 10:25:41 - Transformer_no_pretrain - INFO: - epoch 9: 44000, training batch loss = 2.302677, running_avg_loss loss = 4.732261, validation loss = 4.923114\n",
      "I0410 10:25:41.796077 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 9: 44000, training batch loss = 2.302677, running_avg_loss loss = 4.732261, validation loss = 4.923114\n",
      "2020-04-10 10:25:43 - Transformer_no_pretrain - INFO: - epoch 9: 44000, train_rouge_l_f = 0.087981, test_rouge_l_f = 0.110972\n",
      "I0410 10:25:43.085922 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 9: 44000, train_rouge_l_f = 0.087981, test_rouge_l_f = 0.110972\n",
      "2020-04-10 10:27:47 - Transformer_no_pretrain - INFO: - epoch 9: 45000, training batch loss = 2.173579, running_avg_loss loss = 4.706675, validation loss = 4.938800\n",
      "I0410 10:27:47.436505 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 9: 45000, training batch loss = 2.173579, running_avg_loss loss = 4.706675, validation loss = 4.938800\n",
      "2020-04-10 10:27:47 - Transformer_no_pretrain - INFO: - Saving model step 45000 to model/saved_models/Transformer_no_pretrain/0045000.tar...\n",
      "I0410 10:27:47.441327 140149589550912 initialize.py:225] Saving model step 45000 to model/saved_models/Transformer_no_pretrain/0045000.tar...\n",
      "2020-04-10 10:27:49 - Transformer_no_pretrain - INFO: - epoch 9: 45000, train_rouge_l_f = 0.057387, test_rouge_l_f = 0.049110\n",
      "I0410 10:27:49.635451 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 9: 45000, train_rouge_l_f = 0.057387, test_rouge_l_f = 0.049110\n",
      "2020-04-10 10:29:57 - Transformer_no_pretrain - INFO: - epoch 9: 46000, training batch loss = 2.268950, running_avg_loss loss = 4.682297, validation loss = 4.923996\n",
      "I0410 10:29:57.413187 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 9: 46000, training batch loss = 2.268950, running_avg_loss loss = 4.682297, validation loss = 4.923996\n",
      "2020-04-10 10:29:57 - Transformer_no_pretrain - INFO: - epoch 9: 46000, train_rouge_l_f = 0.089479, test_rouge_l_f = 0.196055\n",
      "I0410 10:29:57.623260 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 9: 46000, train_rouge_l_f = 0.089479, test_rouge_l_f = 0.196055\n",
      "2020-04-10 10:32:05 - Transformer_no_pretrain - INFO: - epoch 9: 47000, training batch loss = 2.494649, running_avg_loss loss = 4.660421, validation loss = 4.943768\n",
      "I0410 10:32:05.218307 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 9: 47000, training batch loss = 2.494649, running_avg_loss loss = 4.660421, validation loss = 4.943768\n",
      "2020-04-10 10:32:06 - Transformer_no_pretrain - INFO: - epoch 9: 47000, train_rouge_l_f = 0.125054, test_rouge_l_f = 0.066515\n",
      "I0410 10:32:06.278426 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 9: 47000, train_rouge_l_f = 0.125054, test_rouge_l_f = 0.066515\n",
      "2020-04-10 11:11:53 - Transformer_no_pretrain - INFO: - epoch 9: 47220, test_avg_acc = 0.089836, test_avg_acc = 0.090851\n",
      "I0410 11:11:53.955235 140149589550912 <ipython-input-9-27f62b467aba>:54] epoch 9: 47220, test_avg_acc = 0.089836, test_avg_acc = 0.090851\n",
      "2020-04-10 11:13:31 - Transformer_no_pretrain - INFO: - epoch 10: 48000, training batch loss = 2.154086, running_avg_loss loss = 4.635358, validation loss = 5.053116\n",
      "I0410 11:13:31.674619 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 10: 48000, training batch loss = 2.154086, running_avg_loss loss = 4.635358, validation loss = 5.053116\n",
      "2020-04-10 11:13:32 - Transformer_no_pretrain - INFO: - epoch 10: 48000, train_rouge_l_f = 0.078335, test_rouge_l_f = 0.087246\n",
      "I0410 11:13:32.778195 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 10: 48000, train_rouge_l_f = 0.078335, test_rouge_l_f = 0.087246\n",
      "2020-04-10 11:15:37 - Transformer_no_pretrain - INFO: - epoch 10: 49000, training batch loss = 1.760602, running_avg_loss loss = 4.606610, validation loss = 5.088439\n",
      "I0410 11:15:37.542591 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 10: 49000, training batch loss = 1.760602, running_avg_loss loss = 4.606610, validation loss = 5.088439\n",
      "2020-04-10 11:15:38 - Transformer_no_pretrain - INFO: - epoch 10: 49000, train_rouge_l_f = 0.077420, test_rouge_l_f = 0.089892\n",
      "I0410 11:15:38.740502 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 10: 49000, train_rouge_l_f = 0.077420, test_rouge_l_f = 0.089892\n",
      "2020-04-10 11:17:49 - Transformer_no_pretrain - INFO: - epoch 10: 50000, training batch loss = 2.226981, running_avg_loss loss = 4.582814, validation loss = 5.095043\n",
      "I0410 11:17:49.939099 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 10: 50000, training batch loss = 2.226981, running_avg_loss loss = 4.582814, validation loss = 5.095043\n",
      "2020-04-10 11:17:49 - Transformer_no_pretrain - INFO: - Saving model step 50000 to model/saved_models/Transformer_no_pretrain/0050000.tar...\n",
      "I0410 11:17:49.941857 140149589550912 initialize.py:225] Saving model step 50000 to model/saved_models/Transformer_no_pretrain/0050000.tar...\n",
      "2020-04-10 11:17:51 - Transformer_no_pretrain - INFO: - epoch 10: 50000, train_rouge_l_f = 0.093345, test_rouge_l_f = 0.071800\n",
      "I0410 11:17:51.274706 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 10: 50000, train_rouge_l_f = 0.093345, test_rouge_l_f = 0.071800\n",
      "2020-04-10 11:19:57 - Transformer_no_pretrain - INFO: - epoch 10: 51000, training batch loss = 2.063743, running_avg_loss loss = 4.557623, validation loss = 5.089730\n",
      "I0410 11:19:57.714498 140149589550912 <ipython-input-9-27f62b467aba>:28] epoch 10: 51000, training batch loss = 2.063743, running_avg_loss loss = 4.557623, validation loss = 5.089730\n",
      "2020-04-10 11:19:58 - Transformer_no_pretrain - INFO: - epoch 10: 51000, train_rouge_l_f = 0.076708, test_rouge_l_f = 0.103357\n",
      "I0410 11:19:58.749075 140149589550912 <ipython-input-9-27f62b467aba>:50] epoch 10: 51000, train_rouge_l_f = 0.076708, test_rouge_l_f = 0.103357\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(config.max_epochs):\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        train_one(model, config, batch)\n",
    "        mle_loss = train_one(model, config, batch)\n",
    "        rl_loss = T.FloatTensor([0]).cuda()\n",
    "        (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "        \n",
    "#         '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "        if step % ( config.gradient_accum) == 0: # gradient accumulation\n",
    "#             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "#             (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "            optimizer.step() # 根据累计的梯度更新网络参数\n",
    "            optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            \n",
    "        if step%1000 == 0 :\n",
    "            with T.autograd.no_grad():\n",
    "                train_batch_loss = mle_loss.item()\n",
    "                val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                            % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                writer.add_scalars('scalar/Loss',  \n",
    "                   {'train_batch_loss': train_batch_loss\n",
    "                   }, step)\n",
    "                writer.add_scalars('scalar_avg/loss',  \n",
    "                   {'train_avg_loss': running_avg_loss,\n",
    "                    'test_avg_loss': val_avg_loss\n",
    "                   }, step)\n",
    "            \n",
    "        if step%5000 == 0:\n",
    "            save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                       r_loss=0, title = loggerName)        \n",
    "      \n",
    "        if step%1000 == 0 and step > 0:\n",
    "            train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "            test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "            writer.add_scalars('scalar/Rouge-L',  \n",
    "               {'train_rouge_l_f': train_rouge_l_f,\n",
    "                'test_rouge_l_f': test_rouge_l_f\n",
    "               }, step)\n",
    "            logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                            % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "            \n",
    "    train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "    test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "    logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "#     try:\n",
    "#         test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader)\n",
    "#         logger.info('epoch %d: %d, test_avg_acc = %f' % (epoch, step, test_avg_acc))\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "logger.info(u'------Training END--------')                \n",
    "removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(2, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input.scatter_(dim, index, src)\n",
    "# 将src中数据根据index中的索引按照dim的方向填进input中\n",
    "torch.zeros(400, 50000).scatter_(1, torch.tensor([[1]\n",
    "                                           ]), x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
