{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0404 12:09:18.214089 140253884581696 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-04 12:09:19 - Pointer_generator_NoPretrain - INFO: - logger已啟動\n",
      "I0404 12:09:19.032576 140253884581696 train_util.py:87] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--transformer', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=False)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "config.rl_weight = 1 - config.mle_weight\n",
    "\n",
    "if not config.transformer:\n",
    "    loggerName = 'Pointer_generator_NoPretrain' \n",
    "else:\n",
    "    loggerName = 'Transformer_NoPretrain' \n",
    "    \n",
    "if config.intra_encoder and config.intra_decoder and True :\n",
    "    loggerName = loggerName + '_Intra_Atten'\n",
    "if config.key_attention:\n",
    "    loggerName = loggerName + '_Key_Atten'\n",
    "    \n",
    "logger = getLogger(loggerName) \n",
    "\n",
    "if not config.transformer:\n",
    "    writer = SummaryWriter('runs/Pointer-Generator_NoPretrain/exp') \n",
    "else:\n",
    "    writer = SummaryWriter('runs/Transformer_NoPretrain/exp') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 12:09:25 - Pointer_generator_NoPretrain - INFO: - train : 37771, test : 4197\n",
      "I0404 12:09:25.127750 140253884581696 batcher.py:163] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    " \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > config.gound_truth_prob)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = model.embeds(x_t)  \n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * UNKNOWN_TOKEN  # Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "    enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    'Feed encoder data to predict'\n",
    "    pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                           enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                           START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                               enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                               START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 12:09:28 - Pointer_generator_NoPretrain - INFO: - ------Training START--------\n",
      "I0404 12:09:28.493502 140253884581696 <ipython-input-9-3e087b2d97b6>:2] ------Training START--------\n",
      "2020-04-04 12:14:21 - Pointer_generator_NoPretrain - INFO: - epoch 0: 1000, training batch loss = 4.823654, running_avg_loss loss = 4.823654, validation loss = 4.384056\n",
      "I0404 12:14:21.862295 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 1000, training batch loss = 4.823654, running_avg_loss loss = 4.823654, validation loss = 4.384056\n",
      "2020-04-04 12:14:22 - Pointer_generator_NoPretrain - INFO: - epoch 0: 1000, train_rouge_l_f = 0.174189, test_rouge_l_f = 0.124826\n",
      "I0404 12:14:22.850632 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 1000, train_rouge_l_f = 0.174189, test_rouge_l_f = 0.124826\n",
      "2020-04-04 12:19:13 - Pointer_generator_NoPretrain - INFO: - epoch 0: 2000, training batch loss = 4.024135, running_avg_loss loss = 4.815659, validation loss = 4.178088\n",
      "I0404 12:19:13.672317 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 2000, training batch loss = 4.024135, running_avg_loss loss = 4.815659, validation loss = 4.178088\n",
      "2020-04-04 12:19:14 - Pointer_generator_NoPretrain - INFO: - epoch 0: 2000, train_rouge_l_f = 0.068260, test_rouge_l_f = 0.179812\n",
      "I0404 12:19:14.717866 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 2000, train_rouge_l_f = 0.068260, test_rouge_l_f = 0.179812\n",
      "2020-04-04 12:24:09 - Pointer_generator_NoPretrain - INFO: - epoch 0: 3000, training batch loss = 4.213731, running_avg_loss loss = 4.809640, validation loss = 4.023774\n",
      "I0404 12:24:09.285105 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 3000, training batch loss = 4.213731, running_avg_loss loss = 4.809640, validation loss = 4.023774\n",
      "2020-04-04 12:24:09 - Pointer_generator_NoPretrain - INFO: - epoch 0: 3000, train_rouge_l_f = 0.167793, test_rouge_l_f = 0.270014\n",
      "I0404 12:24:09.848442 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 3000, train_rouge_l_f = 0.167793, test_rouge_l_f = 0.270014\n",
      "2020-04-04 12:28:58 - Pointer_generator_NoPretrain - INFO: - epoch 0: 4000, training batch loss = 4.422843, running_avg_loss loss = 4.805772, validation loss = 3.902090\n",
      "I0404 12:28:58.529337 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 0: 4000, training batch loss = 4.422843, running_avg_loss loss = 4.805772, validation loss = 3.902090\n",
      "2020-04-04 12:28:59 - Pointer_generator_NoPretrain - INFO: - epoch 0: 4000, train_rouge_l_f = 0.201182, test_rouge_l_f = 0.213098\n",
      "I0404 12:28:59.271798 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 0: 4000, train_rouge_l_f = 0.201182, test_rouge_l_f = 0.213098\n",
      "2020-04-04 12:58:43 - Pointer_generator_NoPretrain - INFO: - epoch 0: 4722, test_avg_acc = 0.251608, test_avg_acc = 0.248934\n",
      "I0404 12:58:43.138238 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 0: 4722, test_avg_acc = 0.251608, test_avg_acc = 0.248934\n",
      "2020-04-04 13:00:24 - Pointer_generator_NoPretrain - INFO: - epoch 1: 5000, training batch loss = 4.596822, running_avg_loss loss = 4.803682, validation loss = 3.767669\n",
      "I0404 13:00:24.643790 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 5000, training batch loss = 4.596822, running_avg_loss loss = 4.803682, validation loss = 3.767669\n",
      "2020-04-04 13:00:24 - Pointer_generator_NoPretrain - INFO: - Saving model step 5000 to model/saved_models/word2Vec/0005000.tar...\n",
      "I0404 13:00:24.645526 140253884581696 initialize.py:226] Saving model step 5000 to model/saved_models/word2Vec/0005000.tar...\n",
      "2020-04-04 13:00:29 - Pointer_generator_NoPretrain - INFO: - epoch 1: 5000, train_rouge_l_f = 0.099634, test_rouge_l_f = 0.357653\n",
      "I0404 13:00:29.171432 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 5000, train_rouge_l_f = 0.099634, test_rouge_l_f = 0.357653\n",
      "2020-04-04 13:05:22 - Pointer_generator_NoPretrain - INFO: - epoch 1: 6000, training batch loss = 3.886489, running_avg_loss loss = 4.794510, validation loss = 3.679083\n",
      "I0404 13:05:22.942899 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 6000, training batch loss = 3.886489, running_avg_loss loss = 4.794510, validation loss = 3.679083\n",
      "2020-04-04 13:05:24 - Pointer_generator_NoPretrain - INFO: - epoch 1: 6000, train_rouge_l_f = 0.119643, test_rouge_l_f = 0.232258\n",
      "I0404 13:05:24.224013 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 6000, train_rouge_l_f = 0.119643, test_rouge_l_f = 0.232258\n",
      "2020-04-04 13:10:17 - Pointer_generator_NoPretrain - INFO: - epoch 1: 7000, training batch loss = 2.972048, running_avg_loss loss = 4.776286, validation loss = 3.607055\n",
      "I0404 13:10:17.722423 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 7000, training batch loss = 2.972048, running_avg_loss loss = 4.776286, validation loss = 3.607055\n",
      "2020-04-04 13:10:18 - Pointer_generator_NoPretrain - INFO: - epoch 1: 7000, train_rouge_l_f = 0.310277, test_rouge_l_f = 0.657496\n",
      "I0404 13:10:18.553221 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 7000, train_rouge_l_f = 0.310277, test_rouge_l_f = 0.657496\n",
      "2020-04-04 13:15:11 - Pointer_generator_NoPretrain - INFO: - epoch 1: 8000, training batch loss = 3.205845, running_avg_loss loss = 4.760581, validation loss = 3.549847\n",
      "I0404 13:15:11.338438 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 8000, training batch loss = 3.205845, running_avg_loss loss = 4.760581, validation loss = 3.549847\n",
      "2020-04-04 13:15:12 - Pointer_generator_NoPretrain - INFO: - epoch 1: 8000, train_rouge_l_f = 0.328159, test_rouge_l_f = 0.247584\n",
      "I0404 13:15:12.351805 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 8000, train_rouge_l_f = 0.328159, test_rouge_l_f = 0.247584\n",
      "2020-04-04 13:20:05 - Pointer_generator_NoPretrain - INFO: - epoch 1: 9000, training batch loss = 3.521651, running_avg_loss loss = 4.748192, validation loss = 3.484993\n",
      "I0404 13:20:05.782764 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 1: 9000, training batch loss = 3.521651, running_avg_loss loss = 4.748192, validation loss = 3.484993\n",
      "2020-04-04 13:20:07 - Pointer_generator_NoPretrain - INFO: - epoch 1: 9000, train_rouge_l_f = 0.243888, test_rouge_l_f = 0.187159\n",
      "I0404 13:20:07.277333 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 1: 9000, train_rouge_l_f = 0.243888, test_rouge_l_f = 0.187159\n",
      "2020-04-04 13:59:42 - Pointer_generator_NoPretrain - INFO: - epoch 1: 9444, test_avg_acc = 0.306987, test_avg_acc = 0.304204\n",
      "I0404 13:59:42.933860 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 1: 9444, test_avg_acc = 0.306987, test_avg_acc = 0.304204\n",
      "2020-04-04 14:02:38 - Pointer_generator_NoPretrain - INFO: - epoch 2: 10000, training batch loss = 2.766561, running_avg_loss loss = 4.728376, validation loss = 3.430366\n",
      "I0404 14:02:38.323088 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 10000, training batch loss = 2.766561, running_avg_loss loss = 4.728376, validation loss = 3.430366\n",
      "2020-04-04 14:02:38 - Pointer_generator_NoPretrain - INFO: - Saving model step 10000 to model/saved_models/word2Vec/0010000.tar...\n",
      "I0404 14:02:38.325696 140253884581696 initialize.py:226] Saving model step 10000 to model/saved_models/word2Vec/0010000.tar...\n",
      "2020-04-04 14:02:43 - Pointer_generator_NoPretrain - INFO: - epoch 2: 10000, train_rouge_l_f = 0.459291, test_rouge_l_f = 0.247497\n",
      "I0404 14:02:43.700600 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 10000, train_rouge_l_f = 0.459291, test_rouge_l_f = 0.247497\n",
      "2020-04-04 14:07:37 - Pointer_generator_NoPretrain - INFO: - epoch 2: 11000, training batch loss = 2.987391, running_avg_loss loss = 4.710966, validation loss = 3.398824\n",
      "I0404 14:07:37.226213 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 11000, training batch loss = 2.987391, running_avg_loss loss = 4.710966, validation loss = 3.398824\n",
      "2020-04-04 14:07:38 - Pointer_generator_NoPretrain - INFO: - epoch 2: 11000, train_rouge_l_f = 0.420239, test_rouge_l_f = 0.165870\n",
      "I0404 14:07:38.440104 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 11000, train_rouge_l_f = 0.420239, test_rouge_l_f = 0.165870\n",
      "2020-04-04 14:12:30 - Pointer_generator_NoPretrain - INFO: - epoch 2: 12000, training batch loss = 3.672295, running_avg_loss loss = 4.700579, validation loss = 3.357571\n",
      "I0404 14:12:30.242575 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 12000, training batch loss = 3.672295, running_avg_loss loss = 4.700579, validation loss = 3.357571\n",
      "2020-04-04 14:12:31 - Pointer_generator_NoPretrain - INFO: - epoch 2: 12000, train_rouge_l_f = 0.198093, test_rouge_l_f = 0.292346\n",
      "I0404 14:12:31.475381 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 12000, train_rouge_l_f = 0.198093, test_rouge_l_f = 0.292346\n",
      "2020-04-04 14:17:23 - Pointer_generator_NoPretrain - INFO: - epoch 2: 13000, training batch loss = 3.730297, running_avg_loss loss = 4.690876, validation loss = 3.321898\n",
      "I0404 14:17:23.716690 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 13000, training batch loss = 3.730297, running_avg_loss loss = 4.690876, validation loss = 3.321898\n",
      "2020-04-04 14:17:24 - Pointer_generator_NoPretrain - INFO: - epoch 2: 13000, train_rouge_l_f = 0.169678, test_rouge_l_f = 0.351922\n",
      "I0404 14:17:24.870586 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 13000, train_rouge_l_f = 0.169678, test_rouge_l_f = 0.351922\n",
      "2020-04-04 14:22:19 - Pointer_generator_NoPretrain - INFO: - epoch 2: 14000, training batch loss = 2.752775, running_avg_loss loss = 4.671495, validation loss = 3.299541\n",
      "I0404 14:22:19.410344 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 2: 14000, training batch loss = 2.752775, running_avg_loss loss = 4.671495, validation loss = 3.299541\n",
      "2020-04-04 14:22:20 - Pointer_generator_NoPretrain - INFO: - epoch 2: 14000, train_rouge_l_f = 0.417845, test_rouge_l_f = 0.398104\n",
      "I0404 14:22:20.709863 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 2: 14000, train_rouge_l_f = 0.417845, test_rouge_l_f = 0.398104\n",
      "2020-04-04 15:00:24 - Pointer_generator_NoPretrain - INFO: - epoch 2: 14166, test_avg_acc = 0.319291, test_avg_acc = 0.313284\n",
      "I0404 15:00:24.927672 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 2: 14166, test_avg_acc = 0.319291, test_avg_acc = 0.313284\n",
      "2020-04-04 15:04:36 - Pointer_generator_NoPretrain - INFO: - epoch 3: 15000, training batch loss = 4.070331, running_avg_loss loss = 4.665484, validation loss = 3.294597\n",
      "I0404 15:04:36.190926 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 15000, training batch loss = 4.070331, running_avg_loss loss = 4.665484, validation loss = 3.294597\n",
      "2020-04-04 15:04:36 - Pointer_generator_NoPretrain - INFO: - Saving model step 15000 to model/saved_models/word2Vec/0015000.tar...\n",
      "I0404 15:04:36.193676 140253884581696 initialize.py:226] Saving model step 15000 to model/saved_models/word2Vec/0015000.tar...\n",
      "2020-04-04 15:04:42 - Pointer_generator_NoPretrain - INFO: - epoch 3: 15000, train_rouge_l_f = 0.307349, test_rouge_l_f = 0.188285\n",
      "I0404 15:04:42.130806 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 15000, train_rouge_l_f = 0.307349, test_rouge_l_f = 0.188285\n",
      "2020-04-04 15:09:41 - Pointer_generator_NoPretrain - INFO: - epoch 3: 16000, training batch loss = 2.842156, running_avg_loss loss = 4.647250, validation loss = 3.265064\n",
      "I0404 15:09:41.572909 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 16000, training batch loss = 2.842156, running_avg_loss loss = 4.647250, validation loss = 3.265064\n",
      "2020-04-04 15:09:43 - Pointer_generator_NoPretrain - INFO: - epoch 3: 16000, train_rouge_l_f = 0.417542, test_rouge_l_f = 0.237345\n",
      "I0404 15:09:43.377075 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 16000, train_rouge_l_f = 0.417542, test_rouge_l_f = 0.237345\n",
      "2020-04-04 15:14:37 - Pointer_generator_NoPretrain - INFO: - epoch 3: 17000, training batch loss = 4.287597, running_avg_loss loss = 4.643654, validation loss = 3.232576\n",
      "I0404 15:14:37.453469 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 17000, training batch loss = 4.287597, running_avg_loss loss = 4.643654, validation loss = 3.232576\n",
      "2020-04-04 15:14:39 - Pointer_generator_NoPretrain - INFO: - epoch 3: 17000, train_rouge_l_f = 0.153855, test_rouge_l_f = 0.217162\n",
      "I0404 15:14:39.018069 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 17000, train_rouge_l_f = 0.153855, test_rouge_l_f = 0.217162\n",
      "2020-04-04 15:19:32 - Pointer_generator_NoPretrain - INFO: - epoch 3: 18000, training batch loss = 3.357014, running_avg_loss loss = 4.630787, validation loss = 3.201292\n",
      "I0404 15:19:32.913634 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 3: 18000, training batch loss = 3.357014, running_avg_loss loss = 4.630787, validation loss = 3.201292\n",
      "2020-04-04 15:19:35 - Pointer_generator_NoPretrain - INFO: - epoch 3: 18000, train_rouge_l_f = 0.379900, test_rouge_l_f = 0.134240\n",
      "I0404 15:19:35.035742 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 3: 18000, train_rouge_l_f = 0.379900, test_rouge_l_f = 0.134240\n",
      "2020-04-04 16:03:22 - Pointer_generator_NoPretrain - INFO: - epoch 3: 18888, test_avg_acc = 0.332685, test_avg_acc = 0.327751\n",
      "I0404 16:03:22.211279 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 3: 18888, test_avg_acc = 0.332685, test_avg_acc = 0.327751\n",
      "2020-04-04 16:04:19 - Pointer_generator_NoPretrain - INFO: - epoch 4: 19000, training batch loss = 2.319324, running_avg_loss loss = 4.607673, validation loss = 3.199753\n",
      "I0404 16:04:19.866605 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 19000, training batch loss = 2.319324, running_avg_loss loss = 4.607673, validation loss = 3.199753\n",
      "2020-04-04 16:04:20 - Pointer_generator_NoPretrain - INFO: - epoch 4: 19000, train_rouge_l_f = 0.331836, test_rouge_l_f = 0.311984\n",
      "I0404 16:04:20.813702 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 19000, train_rouge_l_f = 0.331836, test_rouge_l_f = 0.311984\n",
      "2020-04-04 16:09:11 - Pointer_generator_NoPretrain - INFO: - epoch 4: 20000, training batch loss = 2.521543, running_avg_loss loss = 4.586811, validation loss = 3.168922\n",
      "I0404 16:09:11.312345 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 20000, training batch loss = 2.521543, running_avg_loss loss = 4.586811, validation loss = 3.168922\n",
      "2020-04-04 16:09:11 - Pointer_generator_NoPretrain - INFO: - Saving model step 20000 to model/saved_models/word2Vec/0020000.tar...\n",
      "I0404 16:09:11.314274 140253884581696 initialize.py:226] Saving model step 20000 to model/saved_models/word2Vec/0020000.tar...\n",
      "2020-04-04 16:09:16 - Pointer_generator_NoPretrain - INFO: - epoch 4: 20000, train_rouge_l_f = 0.332933, test_rouge_l_f = 0.427719\n",
      "I0404 16:09:16.088443 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 20000, train_rouge_l_f = 0.332933, test_rouge_l_f = 0.427719\n",
      "2020-04-04 16:14:11 - Pointer_generator_NoPretrain - INFO: - epoch 4: 21000, training batch loss = 4.400559, running_avg_loss loss = 4.584949, validation loss = 3.164133\n",
      "I0404 16:14:11.051434 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 21000, training batch loss = 4.400559, running_avg_loss loss = 4.584949, validation loss = 3.164133\n",
      "2020-04-04 16:14:13 - Pointer_generator_NoPretrain - INFO: - epoch 4: 21000, train_rouge_l_f = 0.144711, test_rouge_l_f = 0.084098\n",
      "I0404 16:14:13.175331 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 21000, train_rouge_l_f = 0.144711, test_rouge_l_f = 0.084098\n",
      "2020-04-04 16:19:04 - Pointer_generator_NoPretrain - INFO: - epoch 4: 22000, training batch loss = 2.932370, running_avg_loss loss = 4.568423, validation loss = 3.156176\n",
      "I0404 16:19:04.388353 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 22000, training batch loss = 2.932370, running_avg_loss loss = 4.568423, validation loss = 3.156176\n",
      "2020-04-04 16:19:05 - Pointer_generator_NoPretrain - INFO: - epoch 4: 22000, train_rouge_l_f = 0.413549, test_rouge_l_f = 0.542431\n",
      "I0404 16:19:05.326209 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 22000, train_rouge_l_f = 0.413549, test_rouge_l_f = 0.542431\n",
      "2020-04-04 16:24:03 - Pointer_generator_NoPretrain - INFO: - epoch 4: 23000, training batch loss = 2.011128, running_avg_loss loss = 4.542850, validation loss = 3.130074\n",
      "I0404 16:24:03.262381 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 4: 23000, training batch loss = 2.011128, running_avg_loss loss = 4.542850, validation loss = 3.130074\n",
      "2020-04-04 16:24:03 - Pointer_generator_NoPretrain - INFO: - epoch 4: 23000, train_rouge_l_f = 0.535035, test_rouge_l_f = 0.595856\n",
      "I0404 16:24:03.890103 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 4: 23000, train_rouge_l_f = 0.535035, test_rouge_l_f = 0.595856\n",
      "2020-04-04 17:06:06 - Pointer_generator_NoPretrain - INFO: - epoch 4: 23610, test_avg_acc = 0.337310, test_avg_acc = 0.327443\n",
      "I0404 17:06:06.607487 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 4: 23610, test_avg_acc = 0.337310, test_avg_acc = 0.327443\n",
      "2020-04-04 17:08:18 - Pointer_generator_NoPretrain - INFO: - epoch 5: 24000, training batch loss = 2.652525, running_avg_loss loss = 4.523947, validation loss = 3.137760\n",
      "I0404 17:08:18.140943 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 24000, training batch loss = 2.652525, running_avg_loss loss = 4.523947, validation loss = 3.137760\n",
      "2020-04-04 17:08:19 - Pointer_generator_NoPretrain - INFO: - epoch 5: 24000, train_rouge_l_f = 0.335178, test_rouge_l_f = 0.282724\n",
      "I0404 17:08:19.680081 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 24000, train_rouge_l_f = 0.335178, test_rouge_l_f = 0.282724\n",
      "2020-04-04 17:13:09 - Pointer_generator_NoPretrain - INFO: - epoch 5: 25000, training batch loss = 2.406390, running_avg_loss loss = 4.502771, validation loss = 3.126122\n",
      "I0404 17:13:09.974342 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 25000, training batch loss = 2.406390, running_avg_loss loss = 4.502771, validation loss = 3.126122\n",
      "2020-04-04 17:13:09 - Pointer_generator_NoPretrain - INFO: - Saving model step 25000 to model/saved_models/word2Vec/0025000.tar...\n",
      "I0404 17:13:09.977612 140253884581696 initialize.py:226] Saving model step 25000 to model/saved_models/word2Vec/0025000.tar...\n",
      "2020-04-04 17:13:15 - Pointer_generator_NoPretrain - INFO: - epoch 5: 25000, train_rouge_l_f = 0.558651, test_rouge_l_f = 0.242561\n",
      "I0404 17:13:15.853178 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 25000, train_rouge_l_f = 0.558651, test_rouge_l_f = 0.242561\n",
      "2020-04-04 17:18:06 - Pointer_generator_NoPretrain - INFO: - epoch 5: 26000, training batch loss = 3.340328, running_avg_loss loss = 4.491147, validation loss = 3.138434\n",
      "I0404 17:18:06.048975 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 26000, training batch loss = 3.340328, running_avg_loss loss = 4.491147, validation loss = 3.138434\n",
      "2020-04-04 17:18:07 - Pointer_generator_NoPretrain - INFO: - epoch 5: 26000, train_rouge_l_f = 0.236299, test_rouge_l_f = 0.197864\n",
      "I0404 17:18:07.836367 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 26000, train_rouge_l_f = 0.236299, test_rouge_l_f = 0.197864\n",
      "2020-04-04 17:23:01 - Pointer_generator_NoPretrain - INFO: - epoch 5: 27000, training batch loss = 2.966002, running_avg_loss loss = 4.475896, validation loss = 3.123096\n",
      "I0404 17:23:01.992300 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 27000, training batch loss = 2.966002, running_avg_loss loss = 4.475896, validation loss = 3.123096\n",
      "2020-04-04 17:23:03 - Pointer_generator_NoPretrain - INFO: - epoch 5: 27000, train_rouge_l_f = 0.399808, test_rouge_l_f = 0.308599\n",
      "I0404 17:23:03.841734 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 27000, train_rouge_l_f = 0.399808, test_rouge_l_f = 0.308599\n",
      "2020-04-04 17:27:52 - Pointer_generator_NoPretrain - INFO: - epoch 5: 28000, training batch loss = 1.838567, running_avg_loss loss = 4.449522, validation loss = 3.082919\n",
      "I0404 17:27:52.995637 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 5: 28000, training batch loss = 1.838567, running_avg_loss loss = 4.449522, validation loss = 3.082919\n",
      "2020-04-04 17:27:54 - Pointer_generator_NoPretrain - INFO: - epoch 5: 28000, train_rouge_l_f = 0.281217, test_rouge_l_f = 0.250069\n",
      "I0404 17:27:54.487203 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 5: 28000, train_rouge_l_f = 0.281217, test_rouge_l_f = 0.250069\n",
      "2020-04-04 18:09:05 - Pointer_generator_NoPretrain - INFO: - epoch 5: 28332, test_avg_acc = 0.342584, test_avg_acc = 0.330419\n",
      "I0404 18:09:05.402212 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 5: 28332, test_avg_acc = 0.342584, test_avg_acc = 0.330419\n",
      "2020-04-04 18:12:33 - Pointer_generator_NoPretrain - INFO: - epoch 6: 29000, training batch loss = 2.384700, running_avg_loss loss = 4.428874, validation loss = 3.093393\n",
      "I0404 18:12:33.189796 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 29000, training batch loss = 2.384700, running_avg_loss loss = 4.428874, validation loss = 3.093393\n",
      "2020-04-04 18:12:35 - Pointer_generator_NoPretrain - INFO: - epoch 6: 29000, train_rouge_l_f = 0.490757, test_rouge_l_f = 0.210181\n",
      "I0404 18:12:35.274604 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 29000, train_rouge_l_f = 0.490757, test_rouge_l_f = 0.210181\n",
      "2020-04-04 18:17:32 - Pointer_generator_NoPretrain - INFO: - epoch 6: 30000, training batch loss = 2.848428, running_avg_loss loss = 4.413070, validation loss = 3.086901\n",
      "I0404 18:17:32.786240 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 30000, training batch loss = 2.848428, running_avg_loss loss = 4.413070, validation loss = 3.086901\n",
      "2020-04-04 18:17:32 - Pointer_generator_NoPretrain - INFO: - Saving model step 30000 to model/saved_models/word2Vec/0030000.tar...\n",
      "I0404 18:17:32.788627 140253884581696 initialize.py:226] Saving model step 30000 to model/saved_models/word2Vec/0030000.tar...\n",
      "2020-04-04 18:17:38 - Pointer_generator_NoPretrain - INFO: - epoch 6: 30000, train_rouge_l_f = 0.395030, test_rouge_l_f = 0.131085\n",
      "I0404 18:17:38.187887 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 30000, train_rouge_l_f = 0.395030, test_rouge_l_f = 0.131085\n",
      "2020-04-04 18:22:33 - Pointer_generator_NoPretrain - INFO: - epoch 6: 31000, training batch loss = 3.322261, running_avg_loss loss = 4.402161, validation loss = 3.090830\n",
      "I0404 18:22:33.352674 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 31000, training batch loss = 3.322261, running_avg_loss loss = 4.402161, validation loss = 3.090830\n",
      "2020-04-04 18:22:34 - Pointer_generator_NoPretrain - INFO: - epoch 6: 31000, train_rouge_l_f = 0.284476, test_rouge_l_f = 0.353988\n",
      "I0404 18:22:34.271059 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 31000, train_rouge_l_f = 0.284476, test_rouge_l_f = 0.353988\n",
      "2020-04-04 18:27:33 - Pointer_generator_NoPretrain - INFO: - epoch 6: 32000, training batch loss = 2.922462, running_avg_loss loss = 4.387364, validation loss = 3.066536\n",
      "I0404 18:27:33.182446 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 32000, training batch loss = 2.922462, running_avg_loss loss = 4.387364, validation loss = 3.066536\n",
      "2020-04-04 18:27:35 - Pointer_generator_NoPretrain - INFO: - epoch 6: 32000, train_rouge_l_f = 0.437734, test_rouge_l_f = 0.221520\n",
      "I0404 18:27:35.184720 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 32000, train_rouge_l_f = 0.437734, test_rouge_l_f = 0.221520\n",
      "2020-04-04 18:32:29 - Pointer_generator_NoPretrain - INFO: - epoch 6: 33000, training batch loss = 2.982474, running_avg_loss loss = 4.373316, validation loss = 3.059157\n",
      "I0404 18:32:29.305529 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 6: 33000, training batch loss = 2.982474, running_avg_loss loss = 4.373316, validation loss = 3.059157\n",
      "2020-04-04 18:32:30 - Pointer_generator_NoPretrain - INFO: - epoch 6: 33000, train_rouge_l_f = 0.279219, test_rouge_l_f = 0.450160\n",
      "I0404 18:32:30.173192 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 6: 33000, train_rouge_l_f = 0.279219, test_rouge_l_f = 0.450160\n",
      "2020-04-04 19:16:04 - Pointer_generator_NoPretrain - INFO: - epoch 6: 33054, test_avg_acc = 0.349102, test_avg_acc = 0.330397\n",
      "I0404 19:16:04.178783 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 6: 33054, test_avg_acc = 0.349102, test_avg_acc = 0.330397\n",
      "2020-04-04 19:20:46 - Pointer_generator_NoPretrain - INFO: - epoch 7: 34000, training batch loss = 2.903394, running_avg_loss loss = 4.358616, validation loss = 3.063150\n",
      "I0404 19:20:46.918932 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 34000, training batch loss = 2.903394, running_avg_loss loss = 4.358616, validation loss = 3.063150\n",
      "2020-04-04 19:20:48 - Pointer_generator_NoPretrain - INFO: - epoch 7: 34000, train_rouge_l_f = 0.273098, test_rouge_l_f = 0.431849\n",
      "I0404 19:20:48.391207 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 34000, train_rouge_l_f = 0.273098, test_rouge_l_f = 0.431849\n",
      "2020-04-04 19:25:45 - Pointer_generator_NoPretrain - INFO: - epoch 7: 35000, training batch loss = 3.185806, running_avg_loss loss = 4.346888, validation loss = 3.060007\n",
      "I0404 19:25:45.333173 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 35000, training batch loss = 3.185806, running_avg_loss loss = 4.346888, validation loss = 3.060007\n",
      "2020-04-04 19:25:45 - Pointer_generator_NoPretrain - INFO: - Saving model step 35000 to model/saved_models/word2Vec/0035000.tar...\n",
      "I0404 19:25:45.335130 140253884581696 initialize.py:226] Saving model step 35000 to model/saved_models/word2Vec/0035000.tar...\n",
      "2020-04-04 19:25:52 - Pointer_generator_NoPretrain - INFO: - epoch 7: 35000, train_rouge_l_f = 0.300043, test_rouge_l_f = 0.068550\n",
      "I0404 19:25:52.322625 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 35000, train_rouge_l_f = 0.300043, test_rouge_l_f = 0.068550\n",
      "2020-04-04 19:30:51 - Pointer_generator_NoPretrain - INFO: - epoch 7: 36000, training batch loss = 1.791244, running_avg_loss loss = 4.321332, validation loss = 3.069425\n",
      "I0404 19:30:51.313958 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 36000, training batch loss = 1.791244, running_avg_loss loss = 4.321332, validation loss = 3.069425\n",
      "2020-04-04 19:30:51 - Pointer_generator_NoPretrain - INFO: - epoch 7: 36000, train_rouge_l_f = 0.594024, test_rouge_l_f = 0.552081\n",
      "I0404 19:30:51.986182 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 36000, train_rouge_l_f = 0.594024, test_rouge_l_f = 0.552081\n",
      "2020-04-04 19:35:46 - Pointer_generator_NoPretrain - INFO: - epoch 7: 37000, training batch loss = 2.454379, running_avg_loss loss = 4.302662, validation loss = 3.047893\n",
      "I0404 19:35:46.697567 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 7: 37000, training batch loss = 2.454379, running_avg_loss loss = 4.302662, validation loss = 3.047893\n",
      "2020-04-04 19:35:47 - Pointer_generator_NoPretrain - INFO: - epoch 7: 37000, train_rouge_l_f = 0.395984, test_rouge_l_f = 0.550125\n",
      "I0404 19:35:47.743865 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 7: 37000, train_rouge_l_f = 0.395984, test_rouge_l_f = 0.550125\n",
      "2020-04-04 20:16:19 - Pointer_generator_NoPretrain - INFO: - epoch 7: 37776, test_avg_acc = 0.350100, test_avg_acc = 0.316698\n",
      "I0404 20:16:19.938257 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 7: 37776, test_avg_acc = 0.350100, test_avg_acc = 0.316698\n",
      "2020-04-04 20:17:50 - Pointer_generator_NoPretrain - INFO: - epoch 8: 38000, training batch loss = 2.578996, running_avg_loss loss = 4.285426, validation loss = 3.044788\n",
      "I0404 20:17:50.174777 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 38000, training batch loss = 2.578996, running_avg_loss loss = 4.285426, validation loss = 3.044788\n",
      "2020-04-04 20:17:52 - Pointer_generator_NoPretrain - INFO: - epoch 8: 38000, train_rouge_l_f = 0.420865, test_rouge_l_f = 0.350092\n",
      "I0404 20:17:52.067149 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 38000, train_rouge_l_f = 0.420865, test_rouge_l_f = 0.350092\n",
      "2020-04-04 20:22:46 - Pointer_generator_NoPretrain - INFO: - epoch 8: 39000, training batch loss = 2.911053, running_avg_loss loss = 4.271682, validation loss = 3.062056\n",
      "I0404 20:22:46.404104 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 39000, training batch loss = 2.911053, running_avg_loss loss = 4.271682, validation loss = 3.062056\n",
      "2020-04-04 20:22:47 - Pointer_generator_NoPretrain - INFO: - epoch 8: 39000, train_rouge_l_f = 0.436461, test_rouge_l_f = 0.538373\n",
      "I0404 20:22:47.224745 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 39000, train_rouge_l_f = 0.436461, test_rouge_l_f = 0.538373\n",
      "2020-04-04 20:27:45 - Pointer_generator_NoPretrain - INFO: - epoch 8: 40000, training batch loss = 2.776739, running_avg_loss loss = 4.256732, validation loss = 3.055581\n",
      "I0404 20:27:45.151107 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 40000, training batch loss = 2.776739, running_avg_loss loss = 4.256732, validation loss = 3.055581\n",
      "2020-04-04 20:27:45 - Pointer_generator_NoPretrain - INFO: - Saving model step 40000 to model/saved_models/word2Vec/0040000.tar...\n",
      "I0404 20:27:45.152669 140253884581696 initialize.py:226] Saving model step 40000 to model/saved_models/word2Vec/0040000.tar...\n",
      "2020-04-04 20:27:50 - Pointer_generator_NoPretrain - INFO: - epoch 8: 40000, train_rouge_l_f = 0.331921, test_rouge_l_f = 0.120448\n",
      "I0404 20:27:50.729373 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 40000, train_rouge_l_f = 0.331921, test_rouge_l_f = 0.120448\n",
      "2020-04-04 20:32:48 - Pointer_generator_NoPretrain - INFO: - epoch 8: 41000, training batch loss = 3.542734, running_avg_loss loss = 4.249592, validation loss = 3.053805\n",
      "I0404 20:32:48.428481 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 41000, training batch loss = 3.542734, running_avg_loss loss = 4.249592, validation loss = 3.053805\n",
      "2020-04-04 20:32:49 - Pointer_generator_NoPretrain - INFO: - epoch 8: 41000, train_rouge_l_f = 0.369416, test_rouge_l_f = 0.322296\n",
      "I0404 20:32:49.659582 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 41000, train_rouge_l_f = 0.369416, test_rouge_l_f = 0.322296\n",
      "2020-04-04 20:37:43 - Pointer_generator_NoPretrain - INFO: - epoch 8: 42000, training batch loss = 2.400356, running_avg_loss loss = 4.231100, validation loss = 3.044621\n",
      "I0404 20:37:43.915366 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 8: 42000, training batch loss = 2.400356, running_avg_loss loss = 4.231100, validation loss = 3.044621\n",
      "2020-04-04 20:37:45 - Pointer_generator_NoPretrain - INFO: - epoch 8: 42000, train_rouge_l_f = 0.733503, test_rouge_l_f = 0.248261\n",
      "I0404 20:37:45.596437 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 8: 42000, train_rouge_l_f = 0.733503, test_rouge_l_f = 0.248261\n",
      "2020-04-04 21:21:27 - Pointer_generator_NoPretrain - INFO: - epoch 8: 42498, test_avg_acc = 0.364809, test_avg_acc = 0.328458\n",
      "I0404 21:21:27.060632 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 8: 42498, test_avg_acc = 0.364809, test_avg_acc = 0.328458\n",
      "2020-04-04 21:24:08 - Pointer_generator_NoPretrain - INFO: - epoch 9: 43000, training batch loss = 2.445803, running_avg_loss loss = 4.213247, validation loss = 3.053213\n",
      "I0404 21:24:08.176829 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 43000, training batch loss = 2.445803, running_avg_loss loss = 4.213247, validation loss = 3.053213\n",
      "2020-04-04 21:24:08 - Pointer_generator_NoPretrain - INFO: - epoch 9: 43000, train_rouge_l_f = 0.500569, test_rouge_l_f = 0.440802\n",
      "I0404 21:24:08.999061 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 43000, train_rouge_l_f = 0.500569, test_rouge_l_f = 0.440802\n",
      "2020-04-04 21:29:00 - Pointer_generator_NoPretrain - INFO: - epoch 9: 44000, training batch loss = 2.891570, running_avg_loss loss = 4.200030, validation loss = 3.046960\n",
      "I0404 21:29:00.532164 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 44000, training batch loss = 2.891570, running_avg_loss loss = 4.200030, validation loss = 3.046960\n",
      "2020-04-04 21:29:01 - Pointer_generator_NoPretrain - INFO: - epoch 9: 44000, train_rouge_l_f = 0.217529, test_rouge_l_f = 0.222938\n",
      "I0404 21:29:01.592995 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 44000, train_rouge_l_f = 0.217529, test_rouge_l_f = 0.222938\n",
      "2020-04-04 21:33:59 - Pointer_generator_NoPretrain - INFO: - epoch 9: 45000, training batch loss = 3.750772, running_avg_loss loss = 4.195538, validation loss = 3.054791\n",
      "I0404 21:33:59.924613 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 45000, training batch loss = 3.750772, running_avg_loss loss = 4.195538, validation loss = 3.054791\n",
      "2020-04-04 21:33:59 - Pointer_generator_NoPretrain - INFO: - Saving model step 45000 to model/saved_models/word2Vec/0045000.tar...\n",
      "I0404 21:33:59.928734 140253884581696 initialize.py:226] Saving model step 45000 to model/saved_models/word2Vec/0045000.tar...\n",
      "2020-04-04 21:34:04 - Pointer_generator_NoPretrain - INFO: - epoch 9: 45000, train_rouge_l_f = 0.272479, test_rouge_l_f = 0.324409\n",
      "I0404 21:34:04.933438 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 45000, train_rouge_l_f = 0.272479, test_rouge_l_f = 0.324409\n",
      "2020-04-04 21:39:01 - Pointer_generator_NoPretrain - INFO: - epoch 9: 46000, training batch loss = 2.793481, running_avg_loss loss = 4.181517, validation loss = 3.035771\n",
      "I0404 21:39:01.794850 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 46000, training batch loss = 2.793481, running_avg_loss loss = 4.181517, validation loss = 3.035771\n",
      "2020-04-04 21:39:02 - Pointer_generator_NoPretrain - INFO: - epoch 9: 46000, train_rouge_l_f = 0.249032, test_rouge_l_f = 0.421631\n",
      "I0404 21:39:02.771648 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 46000, train_rouge_l_f = 0.249032, test_rouge_l_f = 0.421631\n",
      "2020-04-04 21:44:04 - Pointer_generator_NoPretrain - INFO: - epoch 9: 47000, training batch loss = 3.248180, running_avg_loss loss = 4.172184, validation loss = 3.037716\n",
      "I0404 21:44:04.590862 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 9: 47000, training batch loss = 3.248180, running_avg_loss loss = 4.172184, validation loss = 3.037716\n",
      "2020-04-04 21:44:05 - Pointer_generator_NoPretrain - INFO: - epoch 9: 47000, train_rouge_l_f = 0.371108, test_rouge_l_f = 0.388400\n",
      "I0404 21:44:05.569458 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 9: 47000, train_rouge_l_f = 0.371108, test_rouge_l_f = 0.388400\n",
      "2020-04-04 22:28:24 - Pointer_generator_NoPretrain - INFO: - epoch 9: 47220, test_avg_acc = 0.368672, test_avg_acc = 0.331840\n",
      "I0404 22:28:24.140142 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 9: 47220, test_avg_acc = 0.368672, test_avg_acc = 0.331840\n",
      "2020-04-04 22:32:28 - Pointer_generator_NoPretrain - INFO: - epoch 10: 48000, training batch loss = 2.120409, running_avg_loss loss = 4.151666, validation loss = 3.051756\n",
      "I0404 22:32:28.634459 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 48000, training batch loss = 2.120409, running_avg_loss loss = 4.151666, validation loss = 3.051756\n",
      "2020-04-04 22:32:29 - Pointer_generator_NoPretrain - INFO: - epoch 10: 48000, train_rouge_l_f = 0.551005, test_rouge_l_f = 0.741380\n",
      "I0404 22:32:29.404250 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 48000, train_rouge_l_f = 0.551005, test_rouge_l_f = 0.741380\n",
      "2020-04-04 22:37:27 - Pointer_generator_NoPretrain - INFO: - epoch 10: 49000, training batch loss = 2.546525, running_avg_loss loss = 4.135615, validation loss = 3.084333\n",
      "I0404 22:37:27.063753 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 49000, training batch loss = 2.546525, running_avg_loss loss = 4.135615, validation loss = 3.084333\n",
      "2020-04-04 22:37:28 - Pointer_generator_NoPretrain - INFO: - epoch 10: 49000, train_rouge_l_f = 0.268000, test_rouge_l_f = 0.378690\n",
      "I0404 22:37:28.042430 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 49000, train_rouge_l_f = 0.268000, test_rouge_l_f = 0.378690\n",
      "2020-04-04 22:42:23 - Pointer_generator_NoPretrain - INFO: - epoch 10: 50000, training batch loss = 3.479871, running_avg_loss loss = 4.129057, validation loss = 3.065113\n",
      "I0404 22:42:23.446455 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 50000, training batch loss = 3.479871, running_avg_loss loss = 4.129057, validation loss = 3.065113\n",
      "2020-04-04 22:42:23 - Pointer_generator_NoPretrain - INFO: - Saving model step 50000 to model/saved_models/word2Vec/0050000.tar...\n",
      "I0404 22:42:23.448975 140253884581696 initialize.py:226] Saving model step 50000 to model/saved_models/word2Vec/0050000.tar...\n",
      "2020-04-04 22:42:28 - Pointer_generator_NoPretrain - INFO: - epoch 10: 50000, train_rouge_l_f = 0.149086, test_rouge_l_f = 0.179658\n",
      "I0404 22:42:28.765105 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 50000, train_rouge_l_f = 0.149086, test_rouge_l_f = 0.179658\n",
      "2020-04-04 22:47:31 - Pointer_generator_NoPretrain - INFO: - epoch 10: 51000, training batch loss = 2.397391, running_avg_loss loss = 4.111741, validation loss = 3.061612\n",
      "I0404 22:47:31.061977 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 10: 51000, training batch loss = 2.397391, running_avg_loss loss = 4.111741, validation loss = 3.061612\n",
      "2020-04-04 22:47:33 - Pointer_generator_NoPretrain - INFO: - epoch 10: 51000, train_rouge_l_f = 0.287041, test_rouge_l_f = 0.250729\n",
      "I0404 22:47:33.031101 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 10: 51000, train_rouge_l_f = 0.287041, test_rouge_l_f = 0.250729\n",
      "2020-04-04 23:31:08 - Pointer_generator_NoPretrain - INFO: - epoch 10: 51942, test_avg_acc = 0.378869, test_avg_acc = 0.328556\n",
      "I0404 23:31:08.848831 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 10: 51942, test_avg_acc = 0.378869, test_avg_acc = 0.328556\n",
      "2020-04-04 23:31:52 - Pointer_generator_NoPretrain - INFO: - epoch 11: 52000, training batch loss = 3.424865, running_avg_loss loss = 4.104872, validation loss = 3.047659\n",
      "I0404 23:31:52.171064 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 52000, training batch loss = 3.424865, running_avg_loss loss = 4.104872, validation loss = 3.047659\n",
      "2020-04-04 23:31:53 - Pointer_generator_NoPretrain - INFO: - epoch 11: 52000, train_rouge_l_f = 0.192244, test_rouge_l_f = 0.072655\n",
      "I0404 23:31:53.970432 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 52000, train_rouge_l_f = 0.192244, test_rouge_l_f = 0.072655\n",
      "2020-04-04 23:36:47 - Pointer_generator_NoPretrain - INFO: - epoch 11: 53000, training batch loss = 2.493566, running_avg_loss loss = 4.088759, validation loss = 3.059327\n",
      "I0404 23:36:47.853036 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 53000, training batch loss = 2.493566, running_avg_loss loss = 4.088759, validation loss = 3.059327\n",
      "2020-04-04 23:36:48 - Pointer_generator_NoPretrain - INFO: - epoch 11: 53000, train_rouge_l_f = 0.495858, test_rouge_l_f = 0.398007\n",
      "I0404 23:36:48.761945 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 53000, train_rouge_l_f = 0.495858, test_rouge_l_f = 0.398007\n",
      "2020-04-04 23:41:40 - Pointer_generator_NoPretrain - INFO: - epoch 11: 54000, training batch loss = 2.056402, running_avg_loss loss = 4.068435, validation loss = 3.064614\n",
      "I0404 23:41:40.394380 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 54000, training batch loss = 2.056402, running_avg_loss loss = 4.068435, validation loss = 3.064614\n",
      "2020-04-04 23:41:41 - Pointer_generator_NoPretrain - INFO: - epoch 11: 54000, train_rouge_l_f = 0.366891, test_rouge_l_f = 0.349516\n",
      "I0404 23:41:41.362965 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 54000, train_rouge_l_f = 0.366891, test_rouge_l_f = 0.349516\n",
      "2020-04-04 23:46:37 - Pointer_generator_NoPretrain - INFO: - epoch 11: 55000, training batch loss = 2.501244, running_avg_loss loss = 4.052763, validation loss = 3.055579\n",
      "I0404 23:46:37.395158 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 55000, training batch loss = 2.501244, running_avg_loss loss = 4.052763, validation loss = 3.055579\n",
      "2020-04-04 23:46:37 - Pointer_generator_NoPretrain - INFO: - Saving model step 55000 to model/saved_models/word2Vec/0055000.tar...\n",
      "I0404 23:46:37.397478 140253884581696 initialize.py:226] Saving model step 55000 to model/saved_models/word2Vec/0055000.tar...\n",
      "2020-04-04 23:46:41 - Pointer_generator_NoPretrain - INFO: - epoch 11: 55000, train_rouge_l_f = 0.302576, test_rouge_l_f = 0.324494\n",
      "I0404 23:46:41.921171 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 55000, train_rouge_l_f = 0.302576, test_rouge_l_f = 0.324494\n",
      "2020-04-04 23:51:35 - Pointer_generator_NoPretrain - INFO: - epoch 11: 56000, training batch loss = 2.155747, running_avg_loss loss = 4.033793, validation loss = 3.065638\n",
      "I0404 23:51:35.650930 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 11: 56000, training batch loss = 2.155747, running_avg_loss loss = 4.033793, validation loss = 3.065638\n",
      "2020-04-04 23:51:36 - Pointer_generator_NoPretrain - INFO: - epoch 11: 56000, train_rouge_l_f = 0.509322, test_rouge_l_f = 0.321749\n",
      "I0404 23:51:36.703555 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 11: 56000, train_rouge_l_f = 0.509322, test_rouge_l_f = 0.321749\n",
      "2020-04-05 00:36:09 - Pointer_generator_NoPretrain - INFO: - epoch 11: 56664, test_avg_acc = 0.385701, test_avg_acc = 0.327287\n",
      "I0405 00:36:09.030702 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 11: 56664, test_avg_acc = 0.385701, test_avg_acc = 0.327287\n",
      "2020-04-05 00:38:07 - Pointer_generator_NoPretrain - INFO: - epoch 12: 57000, training batch loss = 2.761016, running_avg_loss loss = 4.021065, validation loss = 3.086265\n",
      "I0405 00:38:07.535853 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 57000, training batch loss = 2.761016, running_avg_loss loss = 4.021065, validation loss = 3.086265\n",
      "2020-04-05 00:38:09 - Pointer_generator_NoPretrain - INFO: - epoch 12: 57000, train_rouge_l_f = 0.209903, test_rouge_l_f = 0.091953\n",
      "I0405 00:38:09.171625 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 57000, train_rouge_l_f = 0.209903, test_rouge_l_f = 0.091953\n",
      "2020-04-05 00:43:03 - Pointer_generator_NoPretrain - INFO: - epoch 12: 58000, training batch loss = 2.655799, running_avg_loss loss = 4.007413, validation loss = 3.081160\n",
      "I0405 00:43:03.406215 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 58000, training batch loss = 2.655799, running_avg_loss loss = 4.007413, validation loss = 3.081160\n",
      "2020-04-05 00:43:04 - Pointer_generator_NoPretrain - INFO: - epoch 12: 58000, train_rouge_l_f = 0.313610, test_rouge_l_f = 0.306469\n",
      "I0405 00:43:04.594057 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 58000, train_rouge_l_f = 0.313610, test_rouge_l_f = 0.306469\n",
      "2020-04-05 00:47:57 - Pointer_generator_NoPretrain - INFO: - epoch 12: 59000, training batch loss = 2.673049, running_avg_loss loss = 3.994069, validation loss = 3.086428\n",
      "I0405 00:47:57.775180 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 59000, training batch loss = 2.673049, running_avg_loss loss = 3.994069, validation loss = 3.086428\n",
      "2020-04-05 00:47:58 - Pointer_generator_NoPretrain - INFO: - epoch 12: 59000, train_rouge_l_f = 0.412920, test_rouge_l_f = 0.593200\n",
      "I0405 00:47:58.580862 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 59000, train_rouge_l_f = 0.412920, test_rouge_l_f = 0.593200\n",
      "2020-04-05 00:52:55 - Pointer_generator_NoPretrain - INFO: - epoch 12: 60000, training batch loss = 2.370518, running_avg_loss loss = 3.977834, validation loss = 3.086471\n",
      "I0405 00:52:55.258634 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 60000, training batch loss = 2.370518, running_avg_loss loss = 3.977834, validation loss = 3.086471\n",
      "2020-04-05 00:52:55 - Pointer_generator_NoPretrain - INFO: - Saving model step 60000 to model/saved_models/word2Vec/0060000.tar...\n",
      "I0405 00:52:55.260436 140253884581696 initialize.py:226] Saving model step 60000 to model/saved_models/word2Vec/0060000.tar...\n",
      "2020-04-05 00:53:00 - Pointer_generator_NoPretrain - INFO: - epoch 12: 60000, train_rouge_l_f = 0.384953, test_rouge_l_f = 0.214038\n",
      "I0405 00:53:00.851980 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 60000, train_rouge_l_f = 0.384953, test_rouge_l_f = 0.214038\n",
      "2020-04-05 00:57:56 - Pointer_generator_NoPretrain - INFO: - epoch 12: 61000, training batch loss = 2.435494, running_avg_loss loss = 3.962410, validation loss = 3.082613\n",
      "I0405 00:57:56.933696 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 12: 61000, training batch loss = 2.435494, running_avg_loss loss = 3.962410, validation loss = 3.082613\n",
      "2020-04-05 00:57:58 - Pointer_generator_NoPretrain - INFO: - epoch 12: 61000, train_rouge_l_f = 0.398357, test_rouge_l_f = 0.119473\n",
      "I0405 00:57:58.699696 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 12: 61000, train_rouge_l_f = 0.398357, test_rouge_l_f = 0.119473\n",
      "2020-04-05 01:40:09 - Pointer_generator_NoPretrain - INFO: - epoch 12: 61386, test_avg_acc = 0.401147, test_avg_acc = 0.331038\n",
      "I0405 01:40:09.157735 140253884581696 <ipython-input-9-3e087b2d97b6>:51] epoch 12: 61386, test_avg_acc = 0.401147, test_avg_acc = 0.331038\n",
      "2020-04-05 01:43:23 - Pointer_generator_NoPretrain - INFO: - epoch 13: 62000, training batch loss = 2.744178, running_avg_loss loss = 3.950228, validation loss = 3.120916\n",
      "I0405 01:43:23.888847 140253884581696 <ipython-input-9-3e087b2d97b6>:26] epoch 13: 62000, training batch loss = 2.744178, running_avg_loss loss = 3.950228, validation loss = 3.120916\n",
      "2020-04-05 01:43:24 - Pointer_generator_NoPretrain - INFO: - epoch 13: 62000, train_rouge_l_f = 0.489638, test_rouge_l_f = 0.340671\n",
      "I0405 01:43:24.743268 140253884581696 <ipython-input-9-3e087b2d97b6>:47] epoch 13: 62000, train_rouge_l_f = 0.489638, test_rouge_l_f = 0.340671\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            mle_loss = train_one(model, config, batch)\n",
    "            rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % ( config.gradient_accum) == 0: # gradient accumulation\n",
    "    #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "    #             (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "                optimizer.step() # 根据累计的梯度更新网络参数\n",
    "                optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "\n",
    "            if step%5000 == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                       r_loss=0, title = loggerName) \n",
    "            if step%1000 == 0 and step > 0:\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "        logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')                \n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
