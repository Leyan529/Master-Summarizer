{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 11:20:40.502177 140716206561088 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-11 11:20:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - logger已啟動\n",
      "I0411 11:20:42.141128 140716206561088 train_util.py:132] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.rl_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from utils.data import output2words\n",
    "import argparse\n",
    "from utils.rl_util import *\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--copy', type=bool, default=True, help = 'True/False') # for transformer\n",
    "\n",
    "parser.add_argument('--transformer', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='word2Vec', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-11 11:20:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - train : 37771, test : 4197\n",
      "I0411 11:20:48.782642 140716206561088 batcher.py:171] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 11:20:49.396810 140716206561088 utils_any2vec.py:341] loading projection weights from ../Train-Data/Cameras/Embedding/word2Vec/word2Vec.300d.txt\n",
      "I0411 11:20:59.563756 140716206561088 utils_any2vec.py:405] loaded (46106, 300) matrix from ../Train-Data/Cameras/Embedding/word2Vec/word2Vec.300d.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): Encoder(\n",
      "    (lstm): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
      "    (reduce_h): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (reduce_c): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (enc_attention): encoder_attention(\n",
      "      (W_h): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      (W_s): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_t): Linear(in_features=300, out_features=1024, bias=True)\n",
      "      (v): Linear(in_features=1024, out_features=1, bias=False)\n",
      "    )\n",
      "    (dec_attention): decoder_attention(\n",
      "      (W_prev): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (W_s): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (W_t): Linear(in_features=300, out_features=512, bias=True)\n",
      "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
      "    )\n",
      "    (x_context): Linear(in_features=1324, out_features=300, bias=True)\n",
      "    (x_key_context): Linear(in_features=1624, out_features=300, bias=True)\n",
      "    (lstm): LSTMCell(300, 512)\n",
      "    (p_gen_linear): Linear(in_features=2860, out_features=1, bias=True)\n",
      "    (V): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (V1): Linear(in_features=512, out_features=50000, bias=True)\n",
      "  )\n",
      "  (embeds): Embedding(50000, 300)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "print(model)\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    " \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > config.gound_truth_prob)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = model.embeds(x_t)  \n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * UNKNOWN_TOKEN  # Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "    enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    'Feed encoder data to predict'\n",
    "    pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                           enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                           START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                               enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                               START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(model, config, batch, greedy):    \n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param article_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "        \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        s_t = enc_hidden                                                                            #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []                       # Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []       # Stores padding masks of generated samples\n",
    "        log_probs = []                                                                              #Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "        # Generate RL tokens and compute rl-log-loss\n",
    "        # ----------------------------------------------------------------------\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = model.embeds(x_t)\n",
    "            \n",
    "            probs, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            \n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs) # 建立以參數probs為標準的類別分佈\n",
    "                # perform multinomial sampling\n",
    "                x_t = multi_dist.sample()  # 將下一個時間點的x_t，視為下一個action   \n",
    "                # 使用log_prob实施梯度方法 Policy Gradient，构造一个等价類別分佈的损失函数\n",
    "                log_prob = multi_dist.log_prob(x_t)  \n",
    "                log_probs.append(log_prob) #\n",
    "            else:\n",
    "                # perform greedy sampling distribution\n",
    "                _, x_t = T.max(probs, dim=1)  # 因greedy以機率最大進行取樣，視為其中一個action   \n",
    "            x_t = x_t.detach() # detach返回的 Variable 永远不会需要梯度\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "            mask[(mask == 1) + (x_t == END) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "            is_oov = (x_t>=config.vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n",
    "            x_t = (1-is_oov)*x_t + (is_oov)*UNKNOWN_TOKEN                                             #Replace OOVs with [UNK] token\n",
    "        # -----------------------------------End loop -----------------------------------\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n",
    "            log_probs = T.stack(log_probs, dim=1) # 在第1个维度上stack, 增加新的维度进行堆叠\n",
    "            log_probs = log_probs * decoder_padding_mask # 遮罩掉為[END] or [STOP]不計算損失           #Not considering sampled words with padding mask = 0\n",
    "            lens = T.sum(decoder_padding_mask, dim=1) # 計算每個sample words生成的總長度               #Length of sampled sentence\n",
    "            log_probs = T.sum(log_probs, dim=1) / lens  # 計算平均的每個句子的log loss # (bs,1)        #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy() # 取出每個sample sentence 的word id list\n",
    "            S = output2words(id_list, vocab, batch.art_oovs[i]) #Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:          #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "        return decoded_strs, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_RL(model, config, batch):\n",
    "    # Self-Critical sequence training(SCST)\n",
    "    sample_sents, RL_log_probs = RL(model, config, batch, greedy=False)   # multinomial sampling\n",
    "    with T.autograd.no_grad():        \n",
    "        greedy_sents, _ = RL(model, config, batch, greedy=True)  # greedy sampling\n",
    "\n",
    "    sample_reward = reward_function(sample_sents, batch.original_abstract) # r(w^s):通过根据概率来随机sample词生成句子的reward值\n",
    "    baseline_reward = reward_function(greedy_sents, batch.original_abstract) # r(w^):测试阶段使用greedy decoding取概率最大的词来生成句子的reward值\n",
    "\n",
    "    batch_reward = T.mean(sample_reward).item()\n",
    "    #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "    rl_loss = -(sample_reward - baseline_reward) * RL_log_probs  # SCST梯度計算公式     \n",
    "    rl_loss = T.mean(rl_loss)  \n",
    "    '''\n",
    "    公式的意思就是：对于如果当前sample到的词比测试阶段生成的词好，那么在这次词的维度上，整个式子的值就是负的（因为后面那一项一定为负），\n",
    "    这样梯度就会上升，从而提高这个词的分数st；而对于其他词，后面那一项为正，梯度就会下降，从而降低其他词的分数\n",
    "    '''                 \n",
    "    return rl_loss, batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_avg_reward(batch_reward, running_avg_reward, count = 1000):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-11 11:21:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - ------Training START--------\n",
      "I0411 11:21:03.626340 140716206561088 <ipython-input-12-bc07426dfa84>:2] ------Training START--------\n",
      "2020-04-11 11:39:19 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 1000, RL_Loss = -0.398851, batch_reward = 0.145045\n",
      "I0411 11:39:19.633028 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 0: 1000, RL_Loss = -0.398851, batch_reward = 0.145045\n",
      "2020-04-11 11:39:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 1000, training batch loss = 3.546901, running_avg_loss loss = 3.546901, validation loss = 4.058685\n",
      "I0411 11:39:50.461424 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 0: 1000, training batch loss = 3.546901, running_avg_loss loss = 3.546901, validation loss = 4.058685\n",
      "2020-04-11 11:39:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 1000, running_avg_reward = 0.125322\n",
      "I0411 11:39:50.463176 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 0: 1000, running_avg_reward = 0.125322\n",
      "2020-04-11 11:39:51 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 1000, train_rouge_l_f = 0.219673, test_rouge_l_f = 0.295115\n",
      "I0411 11:39:51.305536 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 0: 1000, train_rouge_l_f = 0.219673, test_rouge_l_f = 0.295115\n",
      "2020-04-11 11:58:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 2000, RL_Loss = -0.535787, batch_reward = 0.140728\n",
      "I0411 11:58:08.345064 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 0: 2000, RL_Loss = -0.535787, batch_reward = 0.140728\n",
      "2020-04-11 11:58:39 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 2000, training batch loss = 4.056594, running_avg_loss loss = 3.551997, validation loss = 3.706521\n",
      "I0411 11:58:39.075546 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 0: 2000, training batch loss = 4.056594, running_avg_loss loss = 3.551997, validation loss = 3.706521\n",
      "2020-04-11 11:58:39 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 2000, running_avg_reward = 0.137708\n",
      "I0411 11:58:39.077231 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 0: 2000, running_avg_reward = 0.137708\n",
      "2020-04-11 11:58:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 2000, train_rouge_l_f = 0.169485, test_rouge_l_f = 0.337502\n",
      "I0411 11:58:40.011542 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 0: 2000, train_rouge_l_f = 0.169485, test_rouge_l_f = 0.337502\n",
      "2020-04-11 12:16:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 3000, RL_Loss = -0.504524, batch_reward = 0.124230\n",
      "I0411 12:16:53.540706 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 0: 3000, RL_Loss = -0.504524, batch_reward = 0.124230\n",
      "2020-04-11 12:17:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 3000, training batch loss = 4.392373, running_avg_loss loss = 3.560401, validation loss = 3.503535\n",
      "I0411 12:17:24.464531 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 0: 3000, training batch loss = 4.392373, running_avg_loss loss = 3.560401, validation loss = 3.503535\n",
      "2020-04-11 12:17:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 3000, running_avg_reward = 0.146960\n",
      "I0411 12:17:24.465842 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 0: 3000, running_avg_reward = 0.146960\n",
      "2020-04-11 12:17:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 3000, train_rouge_l_f = 0.210538, test_rouge_l_f = 0.291583\n",
      "I0411 12:17:25.180211 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 0: 3000, train_rouge_l_f = 0.210538, test_rouge_l_f = 0.291583\n",
      "2020-04-11 12:35:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 4000, RL_Loss = -0.773574, batch_reward = 0.195079\n",
      "I0411 12:35:21.991281 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 0: 4000, RL_Loss = -0.773574, batch_reward = 0.195079\n",
      "2020-04-11 12:35:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 4000, training batch loss = 2.515397, running_avg_loss loss = 3.549951, validation loss = 3.363020\n",
      "I0411 12:35:52.730429 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 0: 4000, training batch loss = 2.515397, running_avg_loss loss = 3.549951, validation loss = 3.363020\n",
      "2020-04-11 12:35:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 4000, running_avg_reward = 0.152206\n",
      "I0411 12:35:52.732155 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 0: 4000, running_avg_reward = 0.152206\n",
      "2020-04-11 12:35:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 4000, train_rouge_l_f = 0.530748, test_rouge_l_f = 0.203030\n",
      "I0411 12:35:53.490307 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 0: 4000, train_rouge_l_f = 0.530748, test_rouge_l_f = 0.203030\n",
      "2020-04-11 13:25:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 0: 4722, test_avg_acc = 0.301004, test_avg_acc = 0.297132\n",
      "I0411 13:25:14.681159 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 0: 4722, test_avg_acc = 0.301004, test_avg_acc = 0.297132\n",
      "2020-04-11 13:30:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 5000, RL_Loss = -0.237160, batch_reward = 0.254379\n",
      "I0411 13:30:21.727373 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 1: 5000, RL_Loss = -0.237160, batch_reward = 0.254379\n",
      "2020-04-11 13:30:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 5000, training batch loss = 3.007077, running_avg_loss loss = 3.544522, validation loss = 3.283466\n",
      "I0411 13:30:53.935461 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 1: 5000, training batch loss = 3.007077, running_avg_loss loss = 3.544522, validation loss = 3.283466\n",
      "2020-04-11 13:30:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 5000, running_avg_reward = 0.156387\n",
      "I0411 13:30:53.937215 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 1: 5000, running_avg_reward = 0.156387\n",
      "2020-04-11 13:30:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 5000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0005000.tar...\n",
      "I0411 13:30:53.940684 140716206561088 initialize.py:225] Saving model step 5000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0005000.tar...\n",
      "2020-04-11 13:30:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 5000, train_rouge_l_f = 0.388045, test_rouge_l_f = 0.524492\n",
      "I0411 13:30:55.307382 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 1: 5000, train_rouge_l_f = 0.388045, test_rouge_l_f = 0.524492\n",
      "2020-04-11 13:49:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 6000, RL_Loss = -0.769150, batch_reward = 0.276537\n",
      "I0411 13:49:24.371786 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 1: 6000, RL_Loss = -0.769150, batch_reward = 0.276537\n",
      "2020-04-11 13:49:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 6000, training batch loss = 2.662139, running_avg_loss loss = 3.535699, validation loss = 3.230449\n",
      "I0411 13:49:56.427439 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 1: 6000, training batch loss = 2.662139, running_avg_loss loss = 3.535699, validation loss = 3.230449\n",
      "2020-04-11 13:49:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 6000, running_avg_reward = 0.160527\n",
      "I0411 13:49:56.429180 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 1: 6000, running_avg_reward = 0.160527\n",
      "2020-04-11 13:49:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 6000, train_rouge_l_f = 0.492993, test_rouge_l_f = 0.456881\n",
      "I0411 13:49:57.535820 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 1: 6000, train_rouge_l_f = 0.492993, test_rouge_l_f = 0.456881\n",
      "2020-04-11 14:08:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 7000, RL_Loss = -0.485554, batch_reward = 0.240053\n",
      "I0411 14:08:11.646019 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 1: 7000, RL_Loss = -0.485554, batch_reward = 0.240053\n",
      "2020-04-11 14:08:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 7000, training batch loss = 1.822641, running_avg_loss loss = 3.518568, validation loss = 3.164782\n",
      "I0411 14:08:42.212621 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 1: 7000, training batch loss = 1.822641, running_avg_loss loss = 3.518568, validation loss = 3.164782\n",
      "2020-04-11 14:08:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 7000, running_avg_reward = 0.163336\n",
      "I0411 14:08:42.214382 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 1: 7000, running_avg_reward = 0.163336\n",
      "2020-04-11 14:08:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 7000, train_rouge_l_f = 0.570257, test_rouge_l_f = 0.282547\n",
      "I0411 14:08:43.467626 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 1: 7000, train_rouge_l_f = 0.570257, test_rouge_l_f = 0.282547\n",
      "2020-04-11 14:26:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 8000, RL_Loss = -0.220685, batch_reward = 0.337524\n",
      "I0411 14:26:42.641090 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 1: 8000, RL_Loss = -0.220685, batch_reward = 0.337524\n",
      "2020-04-11 14:27:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 8000, training batch loss = 2.708488, running_avg_loss loss = 3.510467, validation loss = 3.119475\n",
      "I0411 14:27:13.186575 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 1: 8000, training batch loss = 2.708488, running_avg_loss loss = 3.510467, validation loss = 3.119475\n",
      "2020-04-11 14:27:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 8000, running_avg_reward = 0.166545\n",
      "I0411 14:27:13.188439 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 1: 8000, running_avg_reward = 0.166545\n",
      "2020-04-11 14:27:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 8000, train_rouge_l_f = 0.345706, test_rouge_l_f = 0.192157\n",
      "I0411 14:27:14.483385 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 1: 8000, train_rouge_l_f = 0.345706, test_rouge_l_f = 0.192157\n",
      "2020-04-11 14:45:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 9000, RL_Loss = -0.241905, batch_reward = 0.367226\n",
      "I0411 14:45:24.695513 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 1: 9000, RL_Loss = -0.241905, batch_reward = 0.367226\n",
      "2020-04-11 14:45:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 9000, training batch loss = 3.119670, running_avg_loss loss = 3.506559, validation loss = 3.088021\n",
      "I0411 14:45:55.312353 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 1: 9000, training batch loss = 3.119670, running_avg_loss loss = 3.506559, validation loss = 3.088021\n",
      "2020-04-11 14:45:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 9000, running_avg_reward = 0.168888\n",
      "I0411 14:45:55.314491 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 1: 9000, running_avg_reward = 0.168888\n",
      "2020-04-11 14:45:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 9000, train_rouge_l_f = 0.413126, test_rouge_l_f = 0.493538\n",
      "I0411 14:45:56.231561 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 1: 9000, train_rouge_l_f = 0.413126, test_rouge_l_f = 0.493538\n",
      "2020-04-11 15:31:00 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 1: 9444, test_avg_acc = 0.321254, test_avg_acc = 0.313153\n",
      "I0411 15:31:00.235325 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 1: 9444, test_avg_acc = 0.321254, test_avg_acc = 0.313153\n",
      "2020-04-11 15:41:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 10000, RL_Loss = -0.057505, batch_reward = 0.182395\n",
      "I0411 15:41:10.071408 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 2: 10000, RL_Loss = -0.057505, batch_reward = 0.182395\n",
      "2020-04-11 15:41:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 10000, training batch loss = 3.091138, running_avg_loss loss = 3.502405, validation loss = 3.036631\n",
      "I0411 15:41:40.626680 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 2: 10000, training batch loss = 3.091138, running_avg_loss loss = 3.502405, validation loss = 3.036631\n",
      "2020-04-11 15:41:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 10000, running_avg_reward = 0.171605\n",
      "I0411 15:41:40.628438 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 2: 10000, running_avg_reward = 0.171605\n",
      "2020-04-11 15:41:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 10000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0010000.tar...\n",
      "I0411 15:41:40.631674 140716206561088 initialize.py:225] Saving model step 10000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0010000.tar...\n",
      "2020-04-11 15:41:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 10000, train_rouge_l_f = 0.271267, test_rouge_l_f = 0.174112\n",
      "I0411 15:41:42.702856 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 2: 10000, train_rouge_l_f = 0.271267, test_rouge_l_f = 0.174112\n",
      "2020-04-11 16:00:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 11000, RL_Loss = 0.077551, batch_reward = 0.196235\n",
      "I0411 16:00:06.399115 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 2: 11000, RL_Loss = 0.077551, batch_reward = 0.196235\n",
      "2020-04-11 16:00:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 11000, training batch loss = 3.773778, running_avg_loss loss = 3.505119, validation loss = 3.026050\n",
      "I0411 16:00:37.028998 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 2: 11000, training batch loss = 3.773778, running_avg_loss loss = 3.505119, validation loss = 3.026050\n",
      "2020-04-11 16:00:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 11000, running_avg_reward = 0.173984\n",
      "I0411 16:00:37.031154 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 2: 11000, running_avg_reward = 0.173984\n",
      "2020-04-11 16:00:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 11000, train_rouge_l_f = 0.214311, test_rouge_l_f = 0.745260\n",
      "I0411 16:00:37.985986 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 2: 11000, train_rouge_l_f = 0.214311, test_rouge_l_f = 0.745260\n",
      "2020-04-11 16:18:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 12000, RL_Loss = -0.303860, batch_reward = 0.268006\n",
      "I0411 16:18:50.756199 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 2: 12000, RL_Loss = -0.303860, batch_reward = 0.268006\n",
      "2020-04-11 16:19:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 12000, training batch loss = 2.638351, running_avg_loss loss = 3.496451, validation loss = 3.023071\n",
      "I0411 16:19:21.351070 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 2: 12000, training batch loss = 2.638351, running_avg_loss loss = 3.496451, validation loss = 3.023071\n",
      "2020-04-11 16:19:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 12000, running_avg_reward = 0.175738\n",
      "I0411 16:19:21.352186 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 2: 12000, running_avg_reward = 0.175738\n",
      "2020-04-11 16:19:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 12000, train_rouge_l_f = 0.323654, test_rouge_l_f = 0.376228\n",
      "I0411 16:19:22.081188 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 2: 12000, train_rouge_l_f = 0.323654, test_rouge_l_f = 0.376228\n",
      "2020-04-11 16:37:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 13000, RL_Loss = -0.607875, batch_reward = 0.188389\n",
      "I0411 16:37:20.432236 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 2: 13000, RL_Loss = -0.607875, batch_reward = 0.188389\n",
      "2020-04-11 16:37:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 13000, training batch loss = 3.308435, running_avg_loss loss = 3.494571, validation loss = 2.987415\n",
      "I0411 16:37:50.983023 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 2: 13000, training batch loss = 3.308435, running_avg_loss loss = 3.494571, validation loss = 2.987415\n",
      "2020-04-11 16:37:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 13000, running_avg_reward = 0.177409\n",
      "I0411 16:37:50.984679 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 2: 13000, running_avg_reward = 0.177409\n",
      "2020-04-11 16:37:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 13000, train_rouge_l_f = 0.410983, test_rouge_l_f = 0.200653\n",
      "I0411 16:37:52.609964 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 2: 13000, train_rouge_l_f = 0.410983, test_rouge_l_f = 0.200653\n",
      "2020-04-11 16:55:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 14000, RL_Loss = -0.654884, batch_reward = 0.178548\n",
      "I0411 16:55:58.006662 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 2: 14000, RL_Loss = -0.654884, batch_reward = 0.178548\n",
      "2020-04-11 16:56:28 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 14000, training batch loss = 3.537847, running_avg_loss loss = 3.495004, validation loss = 2.958966\n",
      "I0411 16:56:28.787889 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 2: 14000, training batch loss = 3.537847, running_avg_loss loss = 3.495004, validation loss = 2.958966\n",
      "2020-04-11 16:56:28 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 14000, running_avg_reward = 0.179037\n",
      "I0411 16:56:28.789106 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 2: 14000, running_avg_reward = 0.179037\n",
      "2020-04-11 16:56:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 14000, train_rouge_l_f = 0.345345, test_rouge_l_f = 0.392641\n",
      "I0411 16:56:29.821043 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 2: 14000, train_rouge_l_f = 0.345345, test_rouge_l_f = 0.392641\n",
      "2020-04-11 17:38:54 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 2: 14166, test_avg_acc = 0.341377, test_avg_acc = 0.328241\n",
      "I0411 17:38:54.984353 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 2: 14166, test_avg_acc = 0.341377, test_avg_acc = 0.328241\n",
      "2020-04-11 17:54:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 15000, RL_Loss = -0.840387, batch_reward = 0.075477\n",
      "I0411 17:54:08.564697 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 3: 15000, RL_Loss = -0.840387, batch_reward = 0.075477\n",
      "2020-04-11 17:54:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 15000, training batch loss = 2.957263, running_avg_loss loss = 3.489626, validation loss = 2.966057\n",
      "I0411 17:54:40.958432 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 3: 15000, training batch loss = 2.957263, running_avg_loss loss = 3.489626, validation loss = 2.966057\n",
      "2020-04-11 17:54:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 15000, running_avg_reward = 0.181030\n",
      "I0411 17:54:40.960167 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 3: 15000, running_avg_reward = 0.181030\n",
      "2020-04-11 17:54:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 15000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0015000.tar...\n",
      "I0411 17:54:40.963157 140716206561088 initialize.py:225] Saving model step 15000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0015000.tar...\n",
      "2020-04-11 17:54:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 15000, train_rouge_l_f = 0.212982, test_rouge_l_f = 0.170152\n",
      "I0411 17:54:43.194754 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 3: 15000, train_rouge_l_f = 0.212982, test_rouge_l_f = 0.170152\n",
      "2020-04-11 18:13:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 16000, RL_Loss = 0.091589, batch_reward = 0.242973\n",
      "I0411 18:13:14.393018 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 3: 16000, RL_Loss = 0.091589, batch_reward = 0.242973\n",
      "2020-04-11 18:13:45 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 16000, training batch loss = 3.076166, running_avg_loss loss = 3.485492, validation loss = 2.950350\n",
      "I0411 18:13:45.399727 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 3: 16000, training batch loss = 3.076166, running_avg_loss loss = 3.485492, validation loss = 2.950350\n",
      "2020-04-11 18:13:45 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 16000, running_avg_reward = 0.182773\n",
      "I0411 18:13:45.400872 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 3: 16000, running_avg_reward = 0.182773\n",
      "2020-04-11 18:13:46 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 16000, train_rouge_l_f = 0.334694, test_rouge_l_f = 0.327908\n",
      "I0411 18:13:46.754157 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 3: 16000, train_rouge_l_f = 0.334694, test_rouge_l_f = 0.327908\n",
      "2020-04-11 18:32:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 17000, RL_Loss = -0.320128, batch_reward = 0.114502\n",
      "I0411 18:32:02.674878 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 3: 17000, RL_Loss = -0.320128, batch_reward = 0.114502\n",
      "2020-04-11 18:32:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 17000, training batch loss = 2.372337, running_avg_loss loss = 3.474360, validation loss = 2.931617\n",
      "I0411 18:32:33.469856 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 3: 17000, training batch loss = 2.372337, running_avg_loss loss = 3.474360, validation loss = 2.931617\n",
      "2020-04-11 18:32:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 17000, running_avg_reward = 0.184510\n",
      "I0411 18:32:33.471724 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 3: 17000, running_avg_reward = 0.184510\n",
      "2020-04-11 18:32:34 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 17000, train_rouge_l_f = 0.364457, test_rouge_l_f = 0.261375\n",
      "I0411 18:32:34.506628 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 3: 17000, train_rouge_l_f = 0.364457, test_rouge_l_f = 0.261375\n",
      "2020-04-11 18:50:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 18000, RL_Loss = -0.525061, batch_reward = 0.146488\n",
      "I0411 18:50:35.217019 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 3: 18000, RL_Loss = -0.525061, batch_reward = 0.146488\n",
      "2020-04-11 18:51:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 18000, training batch loss = 3.177365, running_avg_loss loss = 3.471390, validation loss = 2.918146\n",
      "I0411 18:51:06.172706 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 3: 18000, training batch loss = 3.177365, running_avg_loss loss = 3.471390, validation loss = 2.918146\n",
      "2020-04-11 18:51:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 18000, running_avg_reward = 0.186090\n",
      "I0411 18:51:06.174384 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 3: 18000, running_avg_reward = 0.186090\n",
      "2020-04-11 18:51:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 18000, train_rouge_l_f = 0.267465, test_rouge_l_f = 0.224468\n",
      "I0411 18:51:08.058774 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 3: 18000, train_rouge_l_f = 0.267465, test_rouge_l_f = 0.224468\n",
      "2020-04-11 19:51:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 3: 18888, test_avg_acc = 0.352676, test_avg_acc = 0.329391\n",
      "I0411 19:51:25.806235 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 3: 18888, test_avg_acc = 0.352676, test_avg_acc = 0.329391\n",
      "2020-04-11 19:53:27 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 19000, RL_Loss = -0.538060, batch_reward = 0.082500\n",
      "I0411 19:53:27.812917 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 4: 19000, RL_Loss = -0.538060, batch_reward = 0.082500\n",
      "2020-04-11 19:53:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 19000, training batch loss = 3.078292, running_avg_loss loss = 3.467459, validation loss = 2.918284\n",
      "I0411 19:53:58.593841 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 4: 19000, training batch loss = 3.078292, running_avg_loss loss = 3.467459, validation loss = 2.918284\n",
      "2020-04-11 19:53:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 19000, running_avg_reward = 0.187573\n",
      "I0411 19:53:58.595585 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 4: 19000, running_avg_reward = 0.187573\n",
      "2020-04-11 19:53:59 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 19000, train_rouge_l_f = 0.108917, test_rouge_l_f = 0.103924\n",
      "I0411 19:53:59.805807 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 4: 19000, train_rouge_l_f = 0.108917, test_rouge_l_f = 0.103924\n",
      "2020-04-11 20:12:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 20000, RL_Loss = 0.026341, batch_reward = 0.380440\n",
      "I0411 20:12:16.479053 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 4: 20000, RL_Loss = 0.026341, batch_reward = 0.380440\n",
      "2020-04-11 20:12:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 20000, training batch loss = 2.211334, running_avg_loss loss = 3.454898, validation loss = 2.903095\n",
      "I0411 20:12:47.663625 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 4: 20000, training batch loss = 2.211334, running_avg_loss loss = 3.454898, validation loss = 2.903095\n",
      "2020-04-11 20:12:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 20000, running_avg_reward = 0.189498\n",
      "I0411 20:12:47.665071 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 4: 20000, running_avg_reward = 0.189498\n",
      "2020-04-11 20:12:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 20000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0020000.tar...\n",
      "I0411 20:12:47.673708 140716206561088 initialize.py:225] Saving model step 20000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0020000.tar...\n",
      "2020-04-11 20:12:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 20000, train_rouge_l_f = 0.416843, test_rouge_l_f = 0.105718\n",
      "I0411 20:12:50.063904 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 4: 20000, train_rouge_l_f = 0.416843, test_rouge_l_f = 0.105718\n",
      "2020-04-11 20:31:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 21000, RL_Loss = -0.278195, batch_reward = 0.171243\n",
      "I0411 20:31:11.872392 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 4: 21000, RL_Loss = -0.278195, batch_reward = 0.171243\n",
      "2020-04-11 20:31:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 21000, training batch loss = 2.568319, running_avg_loss loss = 3.446032, validation loss = 2.894422\n",
      "I0411 20:31:42.787443 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 4: 21000, training batch loss = 2.568319, running_avg_loss loss = 3.446032, validation loss = 2.894422\n",
      "2020-04-11 20:31:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 21000, running_avg_reward = 0.191169\n",
      "I0411 20:31:42.789210 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 4: 21000, running_avg_reward = 0.191169\n",
      "2020-04-11 20:31:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 21000, train_rouge_l_f = 0.335865, test_rouge_l_f = 0.095317\n",
      "I0411 20:31:44.735008 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 4: 21000, train_rouge_l_f = 0.335865, test_rouge_l_f = 0.095317\n",
      "2020-04-11 20:49:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 22000, RL_Loss = -0.301666, batch_reward = 0.179569\n",
      "I0411 20:49:44.601081 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 4: 22000, RL_Loss = -0.301666, batch_reward = 0.179569\n",
      "2020-04-11 20:50:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 22000, training batch loss = 1.848799, running_avg_loss loss = 3.430060, validation loss = 2.893814\n",
      "I0411 20:50:15.592828 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 4: 22000, training batch loss = 1.848799, running_avg_loss loss = 3.430060, validation loss = 2.893814\n",
      "2020-04-11 20:50:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 22000, running_avg_reward = 0.192799\n",
      "I0411 20:50:15.594570 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 4: 22000, running_avg_reward = 0.192799\n",
      "2020-04-11 20:50:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 22000, train_rouge_l_f = 0.442596, test_rouge_l_f = 0.391008\n",
      "I0411 20:50:16.813554 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 4: 22000, train_rouge_l_f = 0.442596, test_rouge_l_f = 0.391008\n",
      "2020-04-11 21:08:27 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 23000, RL_Loss = -0.682120, batch_reward = 0.081917\n",
      "I0411 21:08:27.433502 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 4: 23000, RL_Loss = -0.682120, batch_reward = 0.081917\n",
      "2020-04-11 21:08:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 23000, training batch loss = 3.725745, running_avg_loss loss = 3.433017, validation loss = 2.866139\n",
      "I0411 21:08:58.505779 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 4: 23000, training batch loss = 3.725745, running_avg_loss loss = 3.433017, validation loss = 2.866139\n",
      "2020-04-11 21:08:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 23000, running_avg_reward = 0.194107\n",
      "I0411 21:08:58.506771 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 4: 23000, running_avg_reward = 0.194107\n",
      "2020-04-11 21:09:00 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 23000, train_rouge_l_f = 0.260841, test_rouge_l_f = 0.265525\n",
      "I0411 21:09:00.123967 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 4: 23000, train_rouge_l_f = 0.260841, test_rouge_l_f = 0.265525\n",
      "2020-04-11 22:01:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 4: 23610, test_avg_acc = 0.375387, test_avg_acc = 0.334057\n",
      "I0411 22:01:22.322676 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 4: 23610, test_avg_acc = 0.375387, test_avg_acc = 0.334057\n",
      "2020-04-11 22:08:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 24000, RL_Loss = 0.533520, batch_reward = 0.342141\n",
      "I0411 22:08:33.188189 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 5: 24000, RL_Loss = 0.533520, batch_reward = 0.342141\n",
      "2020-04-11 22:09:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 24000, training batch loss = 2.673138, running_avg_loss loss = 3.425418, validation loss = 2.885979\n",
      "I0411 22:09:04.143753 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 5: 24000, training batch loss = 2.673138, running_avg_loss loss = 3.425418, validation loss = 2.885979\n",
      "2020-04-11 22:09:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 24000, running_avg_reward = 0.195690\n",
      "I0411 22:09:04.144799 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 5: 24000, running_avg_reward = 0.195690\n",
      "2020-04-11 22:09:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 24000, train_rouge_l_f = 0.213483, test_rouge_l_f = 0.419028\n",
      "I0411 22:09:05.163274 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 5: 24000, train_rouge_l_f = 0.213483, test_rouge_l_f = 0.419028\n",
      "2020-04-11 22:27:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 25000, RL_Loss = -0.157224, batch_reward = 0.212969\n",
      "I0411 22:27:25.041524 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 5: 25000, RL_Loss = -0.157224, batch_reward = 0.212969\n",
      "2020-04-11 22:27:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 25000, training batch loss = 3.332759, running_avg_loss loss = 3.424491, validation loss = 2.906814\n",
      "I0411 22:27:57.201954 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 5: 25000, training batch loss = 3.332759, running_avg_loss loss = 3.424491, validation loss = 2.906814\n",
      "2020-04-11 22:27:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 25000, running_avg_reward = 0.197796\n",
      "I0411 22:27:57.203985 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 5: 25000, running_avg_reward = 0.197796\n",
      "2020-04-11 22:27:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 25000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0025000.tar...\n",
      "I0411 22:27:57.207000 140716206561088 initialize.py:225] Saving model step 25000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0025000.tar...\n",
      "2020-04-11 22:27:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 25000, train_rouge_l_f = 0.321303, test_rouge_l_f = 0.682449\n",
      "I0411 22:27:58.762106 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 5: 25000, train_rouge_l_f = 0.321303, test_rouge_l_f = 0.682449\n",
      "2020-04-11 22:46:34 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 26000, RL_Loss = -0.746533, batch_reward = 0.234439\n",
      "I0411 22:46:34.234821 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 5: 26000, RL_Loss = -0.746533, batch_reward = 0.234439\n",
      "2020-04-11 22:47:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 26000, training batch loss = 2.555746, running_avg_loss loss = 3.415804, validation loss = 2.898279\n",
      "I0411 22:47:06.510525 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 5: 26000, training batch loss = 2.555746, running_avg_loss loss = 3.415804, validation loss = 2.898279\n",
      "2020-04-11 22:47:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 26000, running_avg_reward = 0.199546\n",
      "I0411 22:47:06.512618 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 5: 26000, running_avg_reward = 0.199546\n",
      "2020-04-11 22:47:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 26000, train_rouge_l_f = 0.482067, test_rouge_l_f = 0.241540\n",
      "I0411 22:47:08.480723 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 5: 26000, train_rouge_l_f = 0.482067, test_rouge_l_f = 0.241540\n",
      "2020-04-11 23:05:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 27000, RL_Loss = -0.718286, batch_reward = 0.184577\n",
      "I0411 23:05:47.635621 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 5: 27000, RL_Loss = -0.718286, batch_reward = 0.184577\n",
      "2020-04-11 23:06:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 27000, training batch loss = 2.376976, running_avg_loss loss = 3.405416, validation loss = 2.890081\n",
      "I0411 23:06:20.005530 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 5: 27000, training batch loss = 2.376976, running_avg_loss loss = 3.405416, validation loss = 2.890081\n",
      "2020-04-11 23:06:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 27000, running_avg_reward = 0.200970\n",
      "I0411 23:06:20.007412 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 5: 27000, running_avg_reward = 0.200970\n",
      "2020-04-11 23:06:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 27000, train_rouge_l_f = 0.375593, test_rouge_l_f = 0.092645\n",
      "I0411 23:06:21.378932 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 5: 27000, train_rouge_l_f = 0.375593, test_rouge_l_f = 0.092645\n",
      "2020-04-11 23:24:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 28000, RL_Loss = -0.475787, batch_reward = 0.221001\n",
      "I0411 23:24:41.195117 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 5: 28000, RL_Loss = -0.475787, batch_reward = 0.221001\n",
      "2020-04-11 23:25:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 28000, training batch loss = 2.669600, running_avg_loss loss = 3.398057, validation loss = 2.882633\n",
      "I0411 23:25:12.804221 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 5: 28000, training batch loss = 2.669600, running_avg_loss loss = 3.398057, validation loss = 2.882633\n",
      "2020-04-11 23:25:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 28000, running_avg_reward = 0.202398\n",
      "I0411 23:25:12.806056 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 5: 28000, running_avg_reward = 0.202398\n",
      "2020-04-11 23:25:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 28000, train_rouge_l_f = 0.424084, test_rouge_l_f = 0.532868\n",
      "I0411 23:25:13.748777 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 5: 28000, train_rouge_l_f = 0.424084, test_rouge_l_f = 0.532868\n",
      "2020-04-12 00:15:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 5: 28332, test_avg_acc = 0.396626, test_avg_acc = 0.337937\n",
      "I0412 00:15:06.034254 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 5: 28332, test_avg_acc = 0.396626, test_avg_acc = 0.337937\n",
      "2020-04-12 00:27:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 29000, RL_Loss = -0.378648, batch_reward = 0.193427\n",
      "I0412 00:27:06.305352 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 6: 29000, RL_Loss = -0.378648, batch_reward = 0.193427\n",
      "2020-04-12 00:27:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 29000, training batch loss = 2.847763, running_avg_loss loss = 3.392554, validation loss = 2.906871\n",
      "I0412 00:27:36.768730 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 6: 29000, training batch loss = 2.847763, running_avg_loss loss = 3.392554, validation loss = 2.906871\n",
      "2020-04-12 00:27:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 29000, running_avg_reward = 0.204042\n",
      "I0412 00:27:36.770434 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 6: 29000, running_avg_reward = 0.204042\n",
      "2020-04-12 00:27:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 29000, train_rouge_l_f = 0.296130, test_rouge_l_f = 0.581229\n",
      "I0412 00:27:37.794711 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 6: 29000, train_rouge_l_f = 0.296130, test_rouge_l_f = 0.581229\n",
      "2020-04-12 00:45:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 30000, RL_Loss = -0.556769, batch_reward = 0.163071\n",
      "I0412 00:45:47.930002 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 6: 30000, RL_Loss = -0.556769, batch_reward = 0.163071\n",
      "2020-04-12 00:46:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 30000, training batch loss = 2.080178, running_avg_loss loss = 3.379431, validation loss = 2.911391\n",
      "I0412 00:46:18.669846 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 6: 30000, training batch loss = 2.080178, running_avg_loss loss = 3.379431, validation loss = 2.911391\n",
      "2020-04-12 00:46:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 30000, running_avg_reward = 0.205989\n",
      "I0412 00:46:18.671981 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 6: 30000, running_avg_reward = 0.205989\n",
      "2020-04-12 00:46:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 30000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0030000.tar...\n",
      "I0412 00:46:18.675209 140716206561088 initialize.py:225] Saving model step 30000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0030000.tar...\n",
      "2020-04-12 00:46:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 30000, train_rouge_l_f = 0.367407, test_rouge_l_f = 0.398457\n",
      "I0412 00:46:20.217627 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 6: 30000, train_rouge_l_f = 0.367407, test_rouge_l_f = 0.398457\n",
      "2020-04-12 01:04:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 31000, RL_Loss = -0.367361, batch_reward = 0.240923\n",
      "I0412 01:04:53.292031 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 6: 31000, RL_Loss = -0.367361, batch_reward = 0.240923\n",
      "2020-04-12 01:05:26 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 31000, training batch loss = 2.800155, running_avg_loss loss = 3.373638, validation loss = 2.922535\n",
      "I0412 01:05:26.079886 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 6: 31000, training batch loss = 2.800155, running_avg_loss loss = 3.373638, validation loss = 2.922535\n",
      "2020-04-12 01:05:26 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 31000, running_avg_reward = 0.207781\n",
      "I0412 01:05:26.081618 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 6: 31000, running_avg_reward = 0.207781\n",
      "2020-04-12 01:05:27 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 31000, train_rouge_l_f = 0.297658, test_rouge_l_f = 0.629755\n",
      "I0412 01:05:27.274627 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 6: 31000, train_rouge_l_f = 0.297658, test_rouge_l_f = 0.629755\n",
      "2020-04-12 01:24:00 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 32000, RL_Loss = -0.258565, batch_reward = 0.460604\n",
      "I0412 01:24:00.959174 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 6: 32000, RL_Loss = -0.258565, batch_reward = 0.460604\n",
      "2020-04-12 01:24:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 32000, training batch loss = 2.417867, running_avg_loss loss = 3.364080, validation loss = 2.912596\n",
      "I0412 01:24:33.014976 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 6: 32000, training batch loss = 2.417867, running_avg_loss loss = 3.364080, validation loss = 2.912596\n",
      "2020-04-12 01:24:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 32000, running_avg_reward = 0.209329\n",
      "I0412 01:24:33.016515 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 6: 32000, running_avg_reward = 0.209329\n",
      "2020-04-12 01:24:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 32000, train_rouge_l_f = 0.509095, test_rouge_l_f = 0.473208\n",
      "I0412 01:24:33.983268 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 6: 32000, train_rouge_l_f = 0.509095, test_rouge_l_f = 0.473208\n",
      "2020-04-12 01:42:58 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 33000, RL_Loss = 0.101939, batch_reward = 0.317631\n",
      "I0412 01:42:58.142728 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 6: 33000, RL_Loss = 0.101939, batch_reward = 0.317631\n",
      "2020-04-12 01:43:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 33000, training batch loss = 2.858319, running_avg_loss loss = 3.359023, validation loss = 2.899762\n",
      "I0412 01:43:29.611210 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 6: 33000, training batch loss = 2.858319, running_avg_loss loss = 3.359023, validation loss = 2.899762\n",
      "2020-04-12 01:43:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 33000, running_avg_reward = 0.210925\n",
      "I0412 01:43:29.612929 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 6: 33000, running_avg_reward = 0.210925\n",
      "2020-04-12 01:43:31 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 33000, train_rouge_l_f = 0.281868, test_rouge_l_f = 0.382193\n",
      "I0412 01:43:31.016252 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 6: 33000, train_rouge_l_f = 0.281868, test_rouge_l_f = 0.382193\n",
      "2020-04-12 02:21:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 6: 33054, test_avg_acc = 0.420867, test_avg_acc = 0.319726\n",
      "I0412 02:21:08.038252 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 6: 33054, test_avg_acc = 0.420867, test_avg_acc = 0.319726\n",
      "2020-04-12 02:38:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 34000, RL_Loss = -0.996655, batch_reward = 0.095118\n",
      "I0412 02:38:41.909156 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 7: 34000, RL_Loss = -0.996655, batch_reward = 0.095118\n",
      "2020-04-12 02:39:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 34000, training batch loss = 3.089155, running_avg_loss loss = 3.356324, validation loss = 2.957036\n",
      "I0412 02:39:12.543606 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 7: 34000, training batch loss = 3.089155, running_avg_loss loss = 3.356324, validation loss = 2.957036\n",
      "2020-04-12 02:39:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 34000, running_avg_reward = 0.213180\n",
      "I0412 02:39:12.545318 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 7: 34000, running_avg_reward = 0.213180\n",
      "2020-04-12 02:39:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 34000, train_rouge_l_f = 0.262357, test_rouge_l_f = 0.422287\n",
      "I0412 02:39:13.838174 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 7: 34000, train_rouge_l_f = 0.262357, test_rouge_l_f = 0.422287\n",
      "2020-04-12 02:57:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 35000, RL_Loss = -0.340593, batch_reward = 0.193276\n",
      "I0412 02:57:48.011088 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 7: 35000, RL_Loss = -0.340593, batch_reward = 0.193276\n",
      "2020-04-12 02:58:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 35000, training batch loss = 2.049793, running_avg_loss loss = 3.343259, validation loss = 2.961052\n",
      "I0412 02:58:20.133154 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 7: 35000, training batch loss = 2.049793, running_avg_loss loss = 3.343259, validation loss = 2.961052\n",
      "2020-04-12 02:58:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 35000, running_avg_reward = 0.215393\n",
      "I0412 02:58:20.134607 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 7: 35000, running_avg_reward = 0.215393\n",
      "2020-04-12 02:58:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 35000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0035000.tar...\n",
      "I0412 02:58:20.137156 140716206561088 initialize.py:225] Saving model step 35000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0035000.tar...\n",
      "2020-04-12 02:58:21 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 35000, train_rouge_l_f = 0.329888, test_rouge_l_f = 0.306218\n",
      "I0412 02:58:21.816849 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 7: 35000, train_rouge_l_f = 0.329888, test_rouge_l_f = 0.306218\n",
      "2020-04-12 03:16:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 36000, RL_Loss = -0.382958, batch_reward = 0.170437\n",
      "I0412 03:16:50.280176 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 7: 36000, RL_Loss = -0.382958, batch_reward = 0.170437\n",
      "2020-04-12 03:17:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 36000, training batch loss = 2.271022, running_avg_loss loss = 3.332536, validation loss = 2.962816\n",
      "I0412 03:17:22.597725 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 7: 36000, training batch loss = 2.271022, running_avg_loss loss = 3.332536, validation loss = 2.962816\n",
      "2020-04-12 03:17:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 36000, running_avg_reward = 0.217421\n",
      "I0412 03:17:22.599624 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 7: 36000, running_avg_reward = 0.217421\n",
      "2020-04-12 03:17:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 36000, train_rouge_l_f = 0.283122, test_rouge_l_f = 0.200700\n",
      "I0412 03:17:24.551256 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 7: 36000, train_rouge_l_f = 0.283122, test_rouge_l_f = 0.200700\n",
      "2020-04-12 03:36:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 37000, RL_Loss = -0.849005, batch_reward = 0.551124\n",
      "I0412 03:36:05.277343 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 7: 37000, RL_Loss = -0.849005, batch_reward = 0.551124\n",
      "2020-04-12 03:36:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 37000, training batch loss = 0.608258, running_avg_loss loss = 3.305293, validation loss = 2.947209\n",
      "I0412 03:36:37.290074 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 7: 37000, training batch loss = 0.608258, running_avg_loss loss = 3.305293, validation loss = 2.947209\n",
      "2020-04-12 03:36:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 37000, running_avg_reward = 0.219158\n",
      "I0412 03:36:37.292039 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 7: 37000, running_avg_reward = 0.219158\n",
      "2020-04-12 03:36:38 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 37000, train_rouge_l_f = 0.886224, test_rouge_l_f = 0.182486\n",
      "I0412 03:36:38.665448 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 7: 37000, train_rouge_l_f = 0.886224, test_rouge_l_f = 0.182486\n",
      "2020-04-12 04:33:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 7: 37776, test_avg_acc = 0.463817, test_avg_acc = 0.339000\n",
      "I0412 04:33:05.283098 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 7: 37776, test_avg_acc = 0.463817, test_avg_acc = 0.339000\n",
      "2020-04-12 04:37:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 38000, RL_Loss = -0.042898, batch_reward = 0.448427\n",
      "I0412 04:37:15.602131 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 8: 38000, RL_Loss = -0.042898, batch_reward = 0.448427\n",
      "2020-04-12 04:37:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 38000, training batch loss = 2.001320, running_avg_loss loss = 3.292254, validation loss = 2.966979\n",
      "I0412 04:37:47.389465 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 8: 38000, training batch loss = 2.001320, running_avg_loss loss = 3.292254, validation loss = 2.966979\n",
      "2020-04-12 04:37:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 38000, running_avg_reward = 0.221017\n",
      "I0412 04:37:47.391094 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 8: 38000, running_avg_reward = 0.221017\n",
      "2020-04-12 04:37:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 38000, train_rouge_l_f = 0.605639, test_rouge_l_f = 0.192240\n",
      "I0412 04:37:48.974067 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 8: 38000, train_rouge_l_f = 0.605639, test_rouge_l_f = 0.192240\n",
      "2020-04-12 04:56:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 39000, RL_Loss = -0.189262, batch_reward = 0.248357\n",
      "I0412 04:56:36.117222 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 8: 39000, RL_Loss = -0.189262, batch_reward = 0.248357\n",
      "2020-04-12 04:57:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 39000, training batch loss = 2.117435, running_avg_loss loss = 3.280506, validation loss = 3.007738\n",
      "I0412 04:57:08.457846 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 8: 39000, training batch loss = 2.117435, running_avg_loss loss = 3.280506, validation loss = 3.007738\n",
      "2020-04-12 04:57:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 39000, running_avg_reward = 0.223589\n",
      "I0412 04:57:08.459175 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 8: 39000, running_avg_reward = 0.223589\n",
      "2020-04-12 04:57:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 39000, train_rouge_l_f = 0.390001, test_rouge_l_f = 0.179048\n",
      "I0412 04:57:10.146014 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 8: 39000, train_rouge_l_f = 0.390001, test_rouge_l_f = 0.179048\n",
      "2020-04-12 05:15:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 40000, RL_Loss = -0.858461, batch_reward = 0.300807\n",
      "I0412 05:15:42.491322 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 8: 40000, RL_Loss = -0.858461, batch_reward = 0.300807\n",
      "2020-04-12 05:16:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 40000, training batch loss = 2.382799, running_avg_loss loss = 3.271528, validation loss = 3.016950\n",
      "I0412 05:16:14.438306 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 8: 40000, training batch loss = 2.382799, running_avg_loss loss = 3.271528, validation loss = 3.016950\n",
      "2020-04-12 05:16:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 40000, running_avg_reward = 0.225774\n",
      "I0412 05:16:14.439348 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 8: 40000, running_avg_reward = 0.225774\n",
      "2020-04-12 05:16:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 40000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0040000.tar...\n",
      "I0412 05:16:14.440783 140716206561088 initialize.py:225] Saving model step 40000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0040000.tar...\n",
      "2020-04-12 05:16:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 40000, train_rouge_l_f = 0.522057, test_rouge_l_f = 0.753888\n",
      "I0412 05:16:15.886268 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 8: 40000, train_rouge_l_f = 0.522057, test_rouge_l_f = 0.753888\n",
      "2020-04-12 05:34:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 41000, RL_Loss = -0.272802, batch_reward = 0.225761\n",
      "I0412 05:34:44.094281 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 8: 41000, RL_Loss = -0.272802, batch_reward = 0.225761\n",
      "2020-04-12 05:35:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 41000, training batch loss = 2.662226, running_avg_loss loss = 3.265435, validation loss = 2.995787\n",
      "I0412 05:35:16.128222 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 8: 41000, training batch loss = 2.662226, running_avg_loss loss = 3.265435, validation loss = 2.995787\n",
      "2020-04-12 05:35:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 41000, running_avg_reward = 0.227809\n",
      "I0412 05:35:16.129612 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 8: 41000, running_avg_reward = 0.227809\n",
      "2020-04-12 05:35:17 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 41000, train_rouge_l_f = 0.348880, test_rouge_l_f = 0.244334\n",
      "I0412 05:35:17.439137 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 8: 41000, train_rouge_l_f = 0.348880, test_rouge_l_f = 0.244334\n",
      "2020-04-12 05:53:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 42000, RL_Loss = -0.381304, batch_reward = 0.380342\n",
      "I0412 05:53:48.466463 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 8: 42000, RL_Loss = -0.381304, batch_reward = 0.380342\n",
      "2020-04-12 05:54:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 42000, training batch loss = 1.805087, running_avg_loss loss = 3.250832, validation loss = 3.010337\n",
      "I0412 05:54:20.819849 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 8: 42000, training batch loss = 1.805087, running_avg_loss loss = 3.250832, validation loss = 3.010337\n",
      "2020-04-12 05:54:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 42000, running_avg_reward = 0.229788\n",
      "I0412 05:54:20.820886 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 8: 42000, running_avg_reward = 0.229788\n",
      "2020-04-12 05:54:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 42000, train_rouge_l_f = 0.618962, test_rouge_l_f = 0.220742\n",
      "I0412 05:54:22.851346 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 8: 42000, train_rouge_l_f = 0.618962, test_rouge_l_f = 0.220742\n",
      "2020-04-12 06:42:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 8: 42498, test_avg_acc = 0.497768, test_avg_acc = 0.326562\n",
      "I0412 06:42:40.492127 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 8: 42498, test_avg_acc = 0.497768, test_avg_acc = 0.326562\n",
      "2020-04-12 06:52:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 43000, RL_Loss = -0.503685, batch_reward = 0.262407\n",
      "I0412 06:52:03.454314 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 9: 43000, RL_Loss = -0.503685, batch_reward = 0.262407\n",
      "2020-04-12 06:52:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 43000, training batch loss = 1.766735, running_avg_loss loss = 3.235991, validation loss = 3.037905\n",
      "I0412 06:52:35.416798 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 9: 43000, training batch loss = 1.766735, running_avg_loss loss = 3.235991, validation loss = 3.037905\n",
      "2020-04-12 06:52:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 43000, running_avg_reward = 0.232138\n",
      "I0412 06:52:35.418215 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 9: 43000, running_avg_reward = 0.232138\n",
      "2020-04-12 06:52:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 43000, train_rouge_l_f = 0.480554, test_rouge_l_f = 0.239847\n",
      "I0412 06:52:36.660240 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 9: 43000, train_rouge_l_f = 0.480554, test_rouge_l_f = 0.239847\n",
      "2020-04-12 07:11:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 44000, RL_Loss = -0.289592, batch_reward = 0.364860\n",
      "I0412 07:11:11.547054 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 9: 44000, RL_Loss = -0.289592, batch_reward = 0.364860\n",
      "2020-04-12 07:11:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 44000, training batch loss = 1.791193, running_avg_loss loss = 3.221543, validation loss = 3.080130\n",
      "I0412 07:11:43.383265 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 9: 44000, training batch loss = 1.791193, running_avg_loss loss = 3.221543, validation loss = 3.080130\n",
      "2020-04-12 07:11:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 44000, running_avg_reward = 0.234644\n",
      "I0412 07:11:43.385338 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 9: 44000, running_avg_reward = 0.234644\n",
      "2020-04-12 07:11:45 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 44000, train_rouge_l_f = 0.447635, test_rouge_l_f = 0.174866\n",
      "I0412 07:11:45.104687 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 9: 44000, train_rouge_l_f = 0.447635, test_rouge_l_f = 0.174866\n",
      "2020-04-12 07:30:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 45000, RL_Loss = -0.148870, batch_reward = 0.355326\n",
      "I0412 07:30:16.478305 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 9: 45000, RL_Loss = -0.148870, batch_reward = 0.355326\n",
      "2020-04-12 07:30:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 45000, training batch loss = 2.032478, running_avg_loss loss = 3.209652, validation loss = 3.083548\n",
      "I0412 07:30:48.679751 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 9: 45000, training batch loss = 2.032478, running_avg_loss loss = 3.209652, validation loss = 3.083548\n",
      "2020-04-12 07:30:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 45000, running_avg_reward = 0.237185\n",
      "I0412 07:30:48.681028 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 9: 45000, running_avg_reward = 0.237185\n",
      "2020-04-12 07:30:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 45000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0045000.tar...\n",
      "I0412 07:30:48.683516 140716206561088 initialize.py:225] Saving model step 45000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0045000.tar...\n",
      "2020-04-12 07:30:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 45000, train_rouge_l_f = 0.393105, test_rouge_l_f = 0.144359\n",
      "I0412 07:30:50.566473 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 9: 45000, train_rouge_l_f = 0.393105, test_rouge_l_f = 0.144359\n",
      "2020-04-12 07:49:27 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 46000, RL_Loss = -0.531134, batch_reward = 0.281509\n",
      "I0412 07:49:27.387202 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 9: 46000, RL_Loss = -0.531134, batch_reward = 0.281509\n",
      "2020-04-12 07:49:59 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 46000, training batch loss = 1.618052, running_avg_loss loss = 3.193736, validation loss = 3.072271\n",
      "I0412 07:49:59.300890 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 9: 46000, training batch loss = 1.618052, running_avg_loss loss = 3.193736, validation loss = 3.072271\n",
      "2020-04-12 07:49:59 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 46000, running_avg_reward = 0.239374\n",
      "I0412 07:49:59.302446 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 9: 46000, running_avg_reward = 0.239374\n",
      "2020-04-12 07:50:01 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 46000, train_rouge_l_f = 0.526690, test_rouge_l_f = 0.178266\n",
      "I0412 07:50:01.405745 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 9: 46000, train_rouge_l_f = 0.526690, test_rouge_l_f = 0.178266\n",
      "2020-04-12 08:08:46 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 47000, RL_Loss = -0.239306, batch_reward = 0.376348\n",
      "I0412 08:08:46.640793 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 9: 47000, RL_Loss = -0.239306, batch_reward = 0.376348\n",
      "2020-04-12 08:09:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 47000, training batch loss = 2.377509, running_avg_loss loss = 3.185574, validation loss = 3.062067\n",
      "I0412 08:09:18.793982 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 9: 47000, training batch loss = 2.377509, running_avg_loss loss = 3.185574, validation loss = 3.062067\n",
      "2020-04-12 08:09:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 47000, running_avg_reward = 0.241408\n",
      "I0412 08:09:18.795001 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 9: 47000, running_avg_reward = 0.241408\n",
      "2020-04-12 08:09:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 47000, train_rouge_l_f = 0.418665, test_rouge_l_f = 0.230333\n",
      "I0412 08:09:20.628543 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 9: 47000, train_rouge_l_f = 0.418665, test_rouge_l_f = 0.230333\n",
      "2020-04-12 08:54:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 9: 47220, test_avg_acc = 0.530740, test_avg_acc = 0.323768\n",
      "I0412 08:54:56.449512 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 9: 47220, test_avg_acc = 0.530740, test_avg_acc = 0.323768\n",
      "2020-04-12 09:09:09 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 48000, RL_Loss = -0.487105, batch_reward = 0.277150\n",
      "I0412 09:09:09.264094 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 10: 48000, RL_Loss = -0.487105, batch_reward = 0.277150\n",
      "2020-04-12 09:09:39 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 48000, training batch loss = 1.704898, running_avg_loss loss = 3.170767, validation loss = 3.146996\n",
      "I0412 09:09:39.201973 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 10: 48000, training batch loss = 1.704898, running_avg_loss loss = 3.170767, validation loss = 3.146996\n",
      "2020-04-12 09:09:39 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 48000, running_avg_reward = 0.244076\n",
      "I0412 09:09:39.203709 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 10: 48000, running_avg_reward = 0.244076\n",
      "2020-04-12 09:09:40 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 48000, train_rouge_l_f = 0.397330, test_rouge_l_f = 0.338289\n",
      "I0412 09:09:40.058470 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 10: 48000, train_rouge_l_f = 0.397330, test_rouge_l_f = 0.338289\n",
      "2020-04-12 09:27:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 49000, RL_Loss = -0.509518, batch_reward = 0.624550\n",
      "I0412 09:27:23.921170 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 10: 49000, RL_Loss = -0.509518, batch_reward = 0.624550\n",
      "2020-04-12 09:27:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 49000, training batch loss = 0.735127, running_avg_loss loss = 3.146411, validation loss = 3.164134\n",
      "I0412 09:27:53.767619 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 10: 49000, training batch loss = 0.735127, running_avg_loss loss = 3.146411, validation loss = 3.164134\n",
      "2020-04-12 09:27:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 49000, running_avg_reward = 0.246632\n",
      "I0412 09:27:53.769308 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 10: 49000, running_avg_reward = 0.246632\n",
      "2020-04-12 09:27:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 49000, train_rouge_l_f = 0.858886, test_rouge_l_f = 0.261446\n",
      "I0412 09:27:55.628867 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 10: 49000, train_rouge_l_f = 0.858886, test_rouge_l_f = 0.261446\n",
      "2020-04-12 09:45:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 50000, RL_Loss = -0.622288, batch_reward = 0.415486\n",
      "I0412 09:45:55.896618 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 10: 50000, RL_Loss = -0.622288, batch_reward = 0.415486\n",
      "2020-04-12 09:46:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 50000, training batch loss = 1.639221, running_avg_loss loss = 3.131339, validation loss = 3.150029\n",
      "I0412 09:46:25.717047 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 10: 50000, training batch loss = 1.639221, running_avg_loss loss = 3.131339, validation loss = 3.150029\n",
      "2020-04-12 09:46:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 50000, running_avg_reward = 0.249021\n",
      "I0412 09:46:25.718879 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 10: 50000, running_avg_reward = 0.249021\n",
      "2020-04-12 09:46:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 50000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0050000.tar...\n",
      "I0412 09:46:25.721434 140716206561088 initialize.py:225] Saving model step 50000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0050000.tar...\n",
      "2020-04-12 09:46:28 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 50000, train_rouge_l_f = 0.593435, test_rouge_l_f = 0.182387\n",
      "I0412 09:46:28.004809 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 10: 50000, train_rouge_l_f = 0.593435, test_rouge_l_f = 0.182387\n",
      "2020-04-12 10:04:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 51000, RL_Loss = -0.582815, batch_reward = 0.181349\n",
      "I0412 10:04:14.710620 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 10: 51000, RL_Loss = -0.582815, batch_reward = 0.181349\n",
      "2020-04-12 10:04:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 51000, training batch loss = 2.168729, running_avg_loss loss = 3.121713, validation loss = 3.153424\n",
      "I0412 10:04:44.316859 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 10: 51000, training batch loss = 2.168729, running_avg_loss loss = 3.121713, validation loss = 3.153424\n",
      "2020-04-12 10:04:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 51000, running_avg_reward = 0.251332\n",
      "I0412 10:04:44.318623 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 10: 51000, running_avg_reward = 0.251332\n",
      "2020-04-12 10:04:45 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 51000, train_rouge_l_f = 0.279789, test_rouge_l_f = 0.272188\n",
      "I0412 10:04:45.581546 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 10: 51000, train_rouge_l_f = 0.279789, test_rouge_l_f = 0.272188\n",
      "2020-04-12 11:00:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 10: 51942, test_avg_acc = 0.561424, test_avg_acc = 0.326795\n",
      "I0412 11:00:37.925490 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 10: 51942, test_avg_acc = 0.561424, test_avg_acc = 0.326795\n",
      "2020-04-12 11:01:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 52000, RL_Loss = -0.252467, batch_reward = 0.369969\n",
      "I0412 11:01:41.013560 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 11: 52000, RL_Loss = -0.252467, batch_reward = 0.369969\n",
      "2020-04-12 11:02:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 52000, training batch loss = 1.926765, running_avg_loss loss = 3.109763, validation loss = 3.161345\n",
      "I0412 11:02:11.740697 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 11: 52000, training batch loss = 1.926765, running_avg_loss loss = 3.109763, validation loss = 3.161345\n",
      "2020-04-12 11:02:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 52000, running_avg_reward = 0.253407\n",
      "I0412 11:02:11.742401 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 11: 52000, running_avg_reward = 0.253407\n",
      "2020-04-12 11:02:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 52000, train_rouge_l_f = 0.553601, test_rouge_l_f = 0.516478\n",
      "I0412 11:02:12.693487 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 11: 52000, train_rouge_l_f = 0.553601, test_rouge_l_f = 0.516478\n",
      "2020-04-12 11:20:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 53000, RL_Loss = -0.474540, batch_reward = 0.248948\n",
      "I0412 11:20:10.875380 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 11: 53000, RL_Loss = -0.474540, batch_reward = 0.248948\n",
      "2020-04-12 11:20:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 53000, training batch loss = 2.290191, running_avg_loss loss = 3.101568, validation loss = 3.246375\n",
      "I0412 11:20:43.054970 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 11: 53000, training batch loss = 2.290191, running_avg_loss loss = 3.101568, validation loss = 3.246375\n",
      "2020-04-12 11:20:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 53000, running_avg_reward = 0.256089\n",
      "I0412 11:20:43.056658 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 11: 53000, running_avg_reward = 0.256089\n",
      "2020-04-12 11:20:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 53000, train_rouge_l_f = 0.284713, test_rouge_l_f = 0.405164\n",
      "I0412 11:20:44.193581 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 11: 53000, train_rouge_l_f = 0.284713, test_rouge_l_f = 0.405164\n",
      "2020-04-12 11:38:54 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 54000, RL_Loss = -0.829438, batch_reward = 0.408530\n",
      "I0412 11:38:54.864413 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 11: 54000, RL_Loss = -0.829438, batch_reward = 0.408530\n",
      "2020-04-12 11:39:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 54000, training batch loss = 1.112021, running_avg_loss loss = 3.081672, validation loss = 3.240489\n",
      "I0412 11:39:25.154864 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 11: 54000, training batch loss = 1.112021, running_avg_loss loss = 3.081672, validation loss = 3.240489\n",
      "2020-04-12 11:39:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 54000, running_avg_reward = 0.258735\n",
      "I0412 11:39:25.156431 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 11: 54000, running_avg_reward = 0.258735\n",
      "2020-04-12 11:39:26 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 54000, train_rouge_l_f = 0.711992, test_rouge_l_f = 0.236013\n",
      "I0412 11:39:26.377162 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 11: 54000, train_rouge_l_f = 0.711992, test_rouge_l_f = 0.236013\n",
      "2020-04-12 11:57:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 55000, RL_Loss = -0.233426, batch_reward = 0.441305\n",
      "I0412 11:57:33.460992 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 11: 55000, RL_Loss = -0.233426, batch_reward = 0.441305\n",
      "2020-04-12 11:58:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 55000, training batch loss = 1.591919, running_avg_loss loss = 3.066775, validation loss = 3.240650\n",
      "I0412 11:58:04.616482 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 11: 55000, training batch loss = 1.591919, running_avg_loss loss = 3.066775, validation loss = 3.240650\n",
      "2020-04-12 11:58:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 55000, running_avg_reward = 0.261110\n",
      "I0412 11:58:04.618258 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 11: 55000, running_avg_reward = 0.261110\n",
      "2020-04-12 11:58:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 55000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0055000.tar...\n",
      "I0412 11:58:04.621736 140716206561088 initialize.py:225] Saving model step 55000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0055000.tar...\n",
      "2020-04-12 11:58:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 55000, train_rouge_l_f = 0.520924, test_rouge_l_f = 0.219610\n",
      "I0412 11:58:06.572618 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 11: 55000, train_rouge_l_f = 0.520924, test_rouge_l_f = 0.219610\n",
      "2020-04-12 12:16:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 56000, RL_Loss = -1.057256, batch_reward = 0.318368\n",
      "I0412 12:16:16.549006 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 11: 56000, RL_Loss = -1.057256, batch_reward = 0.318368\n",
      "2020-04-12 12:16:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 56000, training batch loss = 1.325777, running_avg_loss loss = 3.049365, validation loss = 3.266025\n",
      "I0412 12:16:47.336170 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 11: 56000, training batch loss = 1.325777, running_avg_loss loss = 3.049365, validation loss = 3.266025\n",
      "2020-04-12 12:16:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 56000, running_avg_reward = 0.263325\n",
      "I0412 12:16:47.337811 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 11: 56000, running_avg_reward = 0.263325\n",
      "2020-04-12 12:16:48 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 56000, train_rouge_l_f = 0.700664, test_rouge_l_f = 0.352383\n",
      "I0412 12:16:48.430219 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 11: 56000, train_rouge_l_f = 0.700664, test_rouge_l_f = 0.352383\n",
      "2020-04-12 13:06:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 11: 56664, test_avg_acc = 0.575057, test_avg_acc = 0.316341\n",
      "I0412 13:06:55.984514 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 11: 56664, test_avg_acc = 0.575057, test_avg_acc = 0.316341\n",
      "2020-04-12 13:12:54 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 57000, RL_Loss = -0.543808, batch_reward = 0.388383\n",
      "I0412 13:12:54.489094 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 12: 57000, RL_Loss = -0.543808, batch_reward = 0.388383\n",
      "2020-04-12 13:13:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 57000, training batch loss = 1.175648, running_avg_loss loss = 3.030628, validation loss = 3.277224\n",
      "I0412 13:13:25.210193 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 12: 57000, training batch loss = 1.175648, running_avg_loss loss = 3.030628, validation loss = 3.277224\n",
      "2020-04-12 13:13:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 57000, running_avg_reward = 0.265665\n",
      "I0412 13:13:25.212074 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 12: 57000, running_avg_reward = 0.265665\n",
      "2020-04-12 13:13:27 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 57000, train_rouge_l_f = 0.589720, test_rouge_l_f = 0.274094\n",
      "I0412 13:13:27.041236 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 12: 57000, train_rouge_l_f = 0.589720, test_rouge_l_f = 0.274094\n",
      "2020-04-12 13:31:32 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 58000, RL_Loss = -0.240095, batch_reward = 0.305429\n",
      "I0412 13:31:32.506250 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 12: 58000, RL_Loss = -0.240095, batch_reward = 0.305429\n",
      "2020-04-12 13:32:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 58000, training batch loss = 1.745096, running_avg_loss loss = 3.017772, validation loss = 3.291419\n",
      "I0412 13:32:03.578286 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 12: 58000, training batch loss = 1.745096, running_avg_loss loss = 3.017772, validation loss = 3.291419\n",
      "2020-04-12 13:32:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 58000, running_avg_reward = 0.268443\n",
      "I0412 13:32:03.579605 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 12: 58000, running_avg_reward = 0.268443\n",
      "2020-04-12 13:32:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 58000, train_rouge_l_f = 0.590297, test_rouge_l_f = 0.507186\n",
      "I0412 13:32:04.272378 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 12: 58000, train_rouge_l_f = 0.590297, test_rouge_l_f = 0.507186\n",
      "2020-04-12 13:50:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 59000, RL_Loss = -0.539490, batch_reward = 0.425801\n",
      "I0412 13:50:10.600615 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 12: 59000, RL_Loss = -0.539490, batch_reward = 0.425801\n",
      "2020-04-12 13:50:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 59000, training batch loss = 1.134238, running_avg_loss loss = 2.998937, validation loss = 3.310968\n",
      "I0412 13:50:41.481716 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 12: 59000, training batch loss = 1.134238, running_avg_loss loss = 2.998937, validation loss = 3.310968\n",
      "2020-04-12 13:50:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 59000, running_avg_reward = 0.271037\n",
      "I0412 13:50:41.483455 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 12: 59000, running_avg_reward = 0.271037\n",
      "2020-04-12 13:50:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 59000, train_rouge_l_f = 0.701035, test_rouge_l_f = 0.550974\n",
      "I0412 13:50:42.292859 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 12: 59000, train_rouge_l_f = 0.701035, test_rouge_l_f = 0.550974\n",
      "2020-04-12 14:08:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 60000, RL_Loss = -0.643532, batch_reward = 0.496757\n",
      "I0412 14:08:52.505740 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 12: 60000, RL_Loss = -0.643532, batch_reward = 0.496757\n",
      "2020-04-12 14:09:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 60000, training batch loss = 0.939288, running_avg_loss loss = 2.978340, validation loss = 3.294254\n",
      "I0412 14:09:23.078920 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 12: 60000, training batch loss = 0.939288, running_avg_loss loss = 2.978340, validation loss = 3.294254\n",
      "2020-04-12 14:09:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 60000, running_avg_reward = 0.273343\n",
      "I0412 14:09:23.080640 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 12: 60000, running_avg_reward = 0.273343\n",
      "2020-04-12 14:09:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 60000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0060000.tar...\n",
      "I0412 14:09:23.082795 140716206561088 initialize.py:225] Saving model step 60000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0060000.tar...\n",
      "2020-04-12 14:09:25 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 60000, train_rouge_l_f = 0.718124, test_rouge_l_f = 0.319295\n",
      "I0412 14:09:25.263852 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 12: 60000, train_rouge_l_f = 0.718124, test_rouge_l_f = 0.319295\n",
      "2020-04-12 14:27:44 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 61000, RL_Loss = -0.447349, batch_reward = 0.245669\n",
      "I0412 14:27:44.755377 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 12: 61000, RL_Loss = -0.447349, batch_reward = 0.245669\n",
      "2020-04-12 14:28:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 61000, training batch loss = 1.548832, running_avg_loss loss = 2.964045, validation loss = 3.316276\n",
      "I0412 14:28:15.662187 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 12: 61000, training batch loss = 1.548832, running_avg_loss loss = 2.964045, validation loss = 3.316276\n",
      "2020-04-12 14:28:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 61000, running_avg_reward = 0.275536\n",
      "I0412 14:28:15.663421 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 12: 61000, running_avg_reward = 0.275536\n",
      "2020-04-12 14:28:17 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 61000, train_rouge_l_f = 0.526164, test_rouge_l_f = 0.102994\n",
      "I0412 14:28:17.857811 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 12: 61000, train_rouge_l_f = 0.526164, test_rouge_l_f = 0.102994\n",
      "2020-04-12 15:15:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 12: 61386, test_avg_acc = 0.609345, test_avg_acc = 0.330030\n",
      "I0412 15:15:52.940152 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 12: 61386, test_avg_acc = 0.609345, test_avg_acc = 0.330030\n",
      "2020-04-12 15:27:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 62000, RL_Loss = -0.303916, batch_reward = 0.571252\n",
      "I0412 15:27:06.386141 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 13: 62000, RL_Loss = -0.303916, batch_reward = 0.571252\n",
      "2020-04-12 15:27:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 62000, training batch loss = 1.034661, running_avg_loss loss = 2.944752, validation loss = 3.391882\n",
      "I0412 15:27:37.838705 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 13: 62000, training batch loss = 1.034661, running_avg_loss loss = 2.944752, validation loss = 3.391882\n",
      "2020-04-12 15:27:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 62000, running_avg_reward = 0.278053\n",
      "I0412 15:27:37.839927 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 13: 62000, running_avg_reward = 0.278053\n",
      "2020-04-12 15:27:38 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 62000, train_rouge_l_f = 0.651991, test_rouge_l_f = 0.346558\n",
      "I0412 15:27:38.918105 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 13: 62000, train_rouge_l_f = 0.651991, test_rouge_l_f = 0.346558\n",
      "2020-04-12 15:45:54 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 63000, RL_Loss = -0.802222, batch_reward = 0.430808\n",
      "I0412 15:45:54.537754 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 13: 63000, RL_Loss = -0.802222, batch_reward = 0.430808\n",
      "2020-04-12 15:46:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 63000, training batch loss = 0.821539, running_avg_loss loss = 2.923519, validation loss = 3.421713\n",
      "I0412 15:46:24.961492 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 13: 63000, training batch loss = 0.821539, running_avg_loss loss = 2.923519, validation loss = 3.421713\n",
      "2020-04-12 15:46:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 63000, running_avg_reward = 0.280591\n",
      "I0412 15:46:24.962757 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 13: 63000, running_avg_reward = 0.280591\n",
      "2020-04-12 15:46:26 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 63000, train_rouge_l_f = 0.750000, test_rouge_l_f = 0.165116\n",
      "I0412 15:46:26.526345 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 13: 63000, train_rouge_l_f = 0.750000, test_rouge_l_f = 0.165116\n",
      "2020-04-12 16:04:39 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 64000, RL_Loss = -0.214971, batch_reward = 0.439250\n",
      "I0412 16:04:39.038624 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 13: 64000, RL_Loss = -0.214971, batch_reward = 0.439250\n",
      "2020-04-12 16:05:09 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 64000, training batch loss = 1.968520, running_avg_loss loss = 2.913969, validation loss = 3.392938\n",
      "I0412 16:05:09.416394 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 13: 64000, training batch loss = 1.968520, running_avg_loss loss = 2.913969, validation loss = 3.392938\n",
      "2020-04-12 16:05:09 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 64000, running_avg_reward = 0.282950\n",
      "I0412 16:05:09.418068 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 13: 64000, running_avg_reward = 0.282950\n",
      "2020-04-12 16:05:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 64000, train_rouge_l_f = 0.640224, test_rouge_l_f = 0.414344\n",
      "I0412 16:05:10.436232 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 13: 64000, train_rouge_l_f = 0.640224, test_rouge_l_f = 0.414344\n",
      "2020-04-12 16:23:43 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 65000, RL_Loss = -0.915310, batch_reward = 0.443454\n",
      "I0412 16:23:43.184207 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 13: 65000, RL_Loss = -0.915310, batch_reward = 0.443454\n",
      "2020-04-12 16:24:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 65000, training batch loss = 1.062252, running_avg_loss loss = 2.895452, validation loss = 3.417742\n",
      "I0412 16:24:13.832601 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 13: 65000, training batch loss = 1.062252, running_avg_loss loss = 2.895452, validation loss = 3.417742\n",
      "2020-04-12 16:24:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 65000, running_avg_reward = 0.285232\n",
      "I0412 16:24:13.834230 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 13: 65000, running_avg_reward = 0.285232\n",
      "2020-04-12 16:24:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 65000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0065000.tar...\n",
      "I0412 16:24:13.836602 140716206561088 initialize.py:225] Saving model step 65000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0065000.tar...\n",
      "2020-04-12 16:24:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 65000, train_rouge_l_f = 0.749455, test_rouge_l_f = 0.354124\n",
      "I0412 16:24:15.764062 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 13: 65000, train_rouge_l_f = 0.749455, test_rouge_l_f = 0.354124\n",
      "2020-04-12 16:42:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 66000, RL_Loss = -0.535401, batch_reward = 0.483033\n",
      "I0412 16:42:20.128136 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 13: 66000, RL_Loss = -0.535401, batch_reward = 0.483033\n",
      "2020-04-12 16:42:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 66000, training batch loss = 1.408836, running_avg_loss loss = 2.880586, validation loss = 3.387248\n",
      "I0412 16:42:50.626178 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 13: 66000, training batch loss = 1.408836, running_avg_loss loss = 2.880586, validation loss = 3.387248\n",
      "2020-04-12 16:42:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 66000, running_avg_reward = 0.287388\n",
      "I0412 16:42:50.627259 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 13: 66000, running_avg_reward = 0.287388\n",
      "2020-04-12 16:42:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 66000, train_rouge_l_f = 0.702177, test_rouge_l_f = 0.332344\n",
      "I0412 16:42:52.470205 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 13: 66000, train_rouge_l_f = 0.702177, test_rouge_l_f = 0.332344\n",
      "2020-04-12 17:24:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 13: 66108, test_avg_acc = 0.630568, test_avg_acc = 0.325519\n",
      "I0412 17:24:29.925214 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 13: 66108, test_avg_acc = 0.630568, test_avg_acc = 0.325519\n",
      "2020-04-12 17:40:51 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 67000, RL_Loss = 0.214593, batch_reward = 0.796763\n",
      "I0412 17:40:51.275013 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 14: 67000, RL_Loss = 0.214593, batch_reward = 0.796763\n",
      "2020-04-12 17:41:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 67000, training batch loss = 0.532784, running_avg_loss loss = 2.857108, validation loss = 3.452947\n",
      "I0412 17:41:22.582525 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 14: 67000, training batch loss = 0.532784, running_avg_loss loss = 2.857108, validation loss = 3.452947\n",
      "2020-04-12 17:41:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 67000, running_avg_reward = 0.290033\n",
      "I0412 17:41:22.584746 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 14: 67000, running_avg_reward = 0.290033\n",
      "2020-04-12 17:41:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 67000, train_rouge_l_f = 0.785527, test_rouge_l_f = 0.386714\n",
      "I0412 17:41:23.719785 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 14: 67000, train_rouge_l_f = 0.785527, test_rouge_l_f = 0.386714\n",
      "2020-04-12 17:59:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 68000, RL_Loss = -0.615378, batch_reward = 0.310655\n",
      "I0412 17:59:33.973857 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 14: 68000, RL_Loss = -0.615378, batch_reward = 0.310655\n",
      "2020-04-12 18:00:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 68000, training batch loss = 1.722136, running_avg_loss loss = 2.845758, validation loss = 3.510434\n",
      "I0412 18:00:05.467201 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 14: 68000, training batch loss = 1.722136, running_avg_loss loss = 2.845758, validation loss = 3.510434\n",
      "2020-04-12 18:00:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 68000, running_avg_reward = 0.292547\n",
      "I0412 18:00:05.469015 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 14: 68000, running_avg_reward = 0.292547\n",
      "2020-04-12 18:00:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 68000, train_rouge_l_f = 0.497557, test_rouge_l_f = 0.311535\n",
      "I0412 18:00:06.725749 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 14: 68000, train_rouge_l_f = 0.497557, test_rouge_l_f = 0.311535\n",
      "2020-04-12 18:18:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 69000, RL_Loss = -0.514450, batch_reward = 0.538428\n",
      "I0412 18:18:42.417966 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 14: 69000, RL_Loss = -0.514450, batch_reward = 0.538428\n",
      "2020-04-12 18:19:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 69000, training batch loss = 0.832415, running_avg_loss loss = 2.825625, validation loss = 3.480541\n",
      "I0412 18:19:14.214901 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 14: 69000, training batch loss = 0.832415, running_avg_loss loss = 2.825625, validation loss = 3.480541\n",
      "2020-04-12 18:19:14 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 69000, running_avg_reward = 0.294843\n",
      "I0412 18:19:14.216325 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 14: 69000, running_avg_reward = 0.294843\n",
      "2020-04-12 18:19:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 69000, train_rouge_l_f = 0.757762, test_rouge_l_f = 0.287116\n",
      "I0412 18:19:16.021751 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 14: 69000, train_rouge_l_f = 0.757762, test_rouge_l_f = 0.287116\n",
      "2020-04-12 18:37:46 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 70000, RL_Loss = -0.172264, batch_reward = 0.594102\n",
      "I0412 18:37:46.668177 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 14: 70000, RL_Loss = -0.172264, batch_reward = 0.594102\n",
      "2020-04-12 18:38:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 70000, training batch loss = 0.637597, running_avg_loss loss = 2.803745, validation loss = 3.504086\n",
      "I0412 18:38:18.001373 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 14: 70000, training batch loss = 0.637597, running_avg_loss loss = 2.803745, validation loss = 3.504086\n",
      "2020-04-12 18:38:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 70000, running_avg_reward = 0.297064\n",
      "I0412 18:38:18.002675 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 14: 70000, running_avg_reward = 0.297064\n",
      "2020-04-12 18:38:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 70000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0070000.tar...\n",
      "I0412 18:38:18.004740 140716206561088 initialize.py:225] Saving model step 70000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0070000.tar...\n",
      "2020-04-12 18:38:19 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 70000, train_rouge_l_f = 0.856915, test_rouge_l_f = 0.447623\n",
      "I0412 18:38:19.804871 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 14: 70000, train_rouge_l_f = 0.856915, test_rouge_l_f = 0.447623\n",
      "2020-04-12 19:34:32 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 14: 70830, test_avg_acc = 0.651870, test_avg_acc = 0.324932\n",
      "I0412 19:34:32.091319 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 14: 70830, test_avg_acc = 0.651870, test_avg_acc = 0.324932\n",
      "2020-04-12 19:37:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 71000, RL_Loss = -0.190500, batch_reward = 0.640903\n",
      "I0412 19:37:37.451607 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 15: 71000, RL_Loss = -0.190500, batch_reward = 0.640903\n",
      "2020-04-12 19:38:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 71000, training batch loss = 0.535509, running_avg_loss loss = 2.781062, validation loss = 3.497235\n",
      "I0412 19:38:08.652909 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 15: 71000, training batch loss = 0.535509, running_avg_loss loss = 2.781062, validation loss = 3.497235\n",
      "2020-04-12 19:38:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 71000, running_avg_reward = 0.299330\n",
      "I0412 19:38:08.653991 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 15: 71000, running_avg_reward = 0.299330\n",
      "2020-04-12 19:38:09 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 71000, train_rouge_l_f = 0.732038, test_rouge_l_f = 0.290377\n",
      "I0412 19:38:09.920556 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 15: 71000, train_rouge_l_f = 0.732038, test_rouge_l_f = 0.290377\n",
      "2020-04-12 19:56:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 72000, RL_Loss = -0.253955, batch_reward = 0.434311\n",
      "I0412 19:56:37.092983 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 15: 72000, RL_Loss = -0.253955, batch_reward = 0.434311\n",
      "2020-04-12 19:57:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 72000, training batch loss = 1.466140, running_avg_loss loss = 2.767913, validation loss = 3.597904\n",
      "I0412 19:57:08.146800 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 15: 72000, training batch loss = 1.466140, running_avg_loss loss = 2.767913, validation loss = 3.597904\n",
      "2020-04-12 19:57:08 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 72000, running_avg_reward = 0.301878\n",
      "I0412 19:57:08.148087 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 15: 72000, running_avg_reward = 0.301878\n",
      "2020-04-12 19:57:09 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 72000, train_rouge_l_f = 0.569046, test_rouge_l_f = 0.225490\n",
      "I0412 19:57:09.598117 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 15: 72000, train_rouge_l_f = 0.569046, test_rouge_l_f = 0.225490\n",
      "2020-04-12 20:15:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 73000, RL_Loss = -0.274552, batch_reward = 0.581174\n",
      "I0412 20:15:18.353015 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 15: 73000, RL_Loss = -0.274552, batch_reward = 0.581174\n",
      "2020-04-12 20:15:49 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 73000, training batch loss = 0.951821, running_avg_loss loss = 2.749752, validation loss = 3.577610\n",
      "I0412 20:15:49.705471 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 15: 73000, training batch loss = 0.951821, running_avg_loss loss = 2.749752, validation loss = 3.577610\n",
      "2020-04-12 20:15:49 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 73000, running_avg_reward = 0.304321\n",
      "I0412 20:15:49.707390 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 15: 73000, running_avg_reward = 0.304321\n",
      "2020-04-12 20:15:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 73000, train_rouge_l_f = 0.628740, test_rouge_l_f = 0.327815\n",
      "I0412 20:15:50.810140 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 15: 73000, train_rouge_l_f = 0.628740, test_rouge_l_f = 0.327815\n",
      "2020-04-12 20:34:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 74000, RL_Loss = -0.505308, batch_reward = 0.326882\n",
      "I0412 20:34:04.732214 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 15: 74000, RL_Loss = -0.505308, batch_reward = 0.326882\n",
      "2020-04-12 20:34:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 74000, training batch loss = 1.520496, running_avg_loss loss = 2.737460, validation loss = 3.553974\n",
      "I0412 20:34:36.150014 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 15: 74000, training batch loss = 1.520496, running_avg_loss loss = 2.737460, validation loss = 3.553974\n",
      "2020-04-12 20:34:36 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 74000, running_avg_reward = 0.306619\n",
      "I0412 20:34:36.152457 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 15: 74000, running_avg_reward = 0.306619\n",
      "2020-04-12 20:34:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 74000, train_rouge_l_f = 0.623542, test_rouge_l_f = 0.340568\n",
      "I0412 20:34:37.110768 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 15: 74000, train_rouge_l_f = 0.623542, test_rouge_l_f = 0.340568\n",
      "2020-04-12 20:52:53 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 75000, RL_Loss = -0.064435, batch_reward = 0.402892\n",
      "I0412 20:52:53.586790 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 15: 75000, RL_Loss = -0.064435, batch_reward = 0.402892\n",
      "2020-04-12 20:53:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 75000, training batch loss = 1.263893, running_avg_loss loss = 2.722724, validation loss = 3.594246\n",
      "I0412 20:53:24.839941 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 15: 75000, training batch loss = 1.263893, running_avg_loss loss = 2.722724, validation loss = 3.594246\n",
      "2020-04-12 20:53:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 75000, running_avg_reward = 0.308762\n",
      "I0412 20:53:24.842139 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 15: 75000, running_avg_reward = 0.308762\n",
      "2020-04-12 20:53:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 75000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0075000.tar...\n",
      "I0412 20:53:24.844739 140716206561088 initialize.py:225] Saving model step 75000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0075000.tar...\n",
      "2020-04-12 20:53:26 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 75000, train_rouge_l_f = 0.556965, test_rouge_l_f = 0.439895\n",
      "I0412 20:53:26.460235 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 15: 75000, train_rouge_l_f = 0.556965, test_rouge_l_f = 0.439895\n",
      "2020-04-12 21:46:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 15: 75552, test_avg_acc = 0.680891, test_avg_acc = 0.327547\n",
      "I0412 21:46:29.666023 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 15: 75552, test_avg_acc = 0.680891, test_avg_acc = 0.327547\n",
      "2020-04-12 21:54:45 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 76000, RL_Loss = -0.005726, batch_reward = 0.740310\n",
      "I0412 21:54:45.591175 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 16: 76000, RL_Loss = -0.005726, batch_reward = 0.740310\n",
      "2020-04-12 21:55:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 76000, training batch loss = 0.862140, running_avg_loss loss = 2.704118, validation loss = 3.614553\n",
      "I0412 21:55:16.539595 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 16: 76000, training batch loss = 0.862140, running_avg_loss loss = 2.704118, validation loss = 3.614553\n",
      "2020-04-12 21:55:16 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 76000, running_avg_reward = 0.311054\n",
      "I0412 21:55:16.541512 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 16: 76000, running_avg_reward = 0.311054\n",
      "2020-04-12 21:55:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 76000, train_rouge_l_f = 0.807568, test_rouge_l_f = 0.304488\n",
      "I0412 21:55:18.237957 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 16: 76000, train_rouge_l_f = 0.807568, test_rouge_l_f = 0.304488\n",
      "2020-04-12 22:13:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 77000, RL_Loss = -0.448346, batch_reward = 0.316402\n",
      "I0412 22:13:42.156474 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 16: 77000, RL_Loss = -0.448346, batch_reward = 0.316402\n",
      "2020-04-12 22:14:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 77000, training batch loss = 1.143085, running_avg_loss loss = 2.688508, validation loss = 3.637513\n",
      "I0412 22:14:13.346972 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 16: 77000, training batch loss = 1.143085, running_avg_loss loss = 2.688508, validation loss = 3.637513\n",
      "2020-04-12 22:14:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 77000, running_avg_reward = 0.313580\n",
      "I0412 22:14:13.348668 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 16: 77000, running_avg_reward = 0.313580\n",
      "2020-04-12 22:14:15 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 77000, train_rouge_l_f = 0.577649, test_rouge_l_f = 0.133290\n",
      "I0412 22:14:15.001044 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 16: 77000, train_rouge_l_f = 0.577649, test_rouge_l_f = 0.133290\n",
      "2020-04-12 22:32:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 78000, RL_Loss = -0.878406, batch_reward = 0.613602\n",
      "I0412 22:32:35.086765 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 16: 78000, RL_Loss = -0.878406, batch_reward = 0.613602\n",
      "2020-04-12 22:33:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 78000, training batch loss = 0.446299, running_avg_loss loss = 2.666086, validation loss = 3.660438\n",
      "I0412 22:33:06.060664 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 16: 78000, training batch loss = 0.446299, running_avg_loss loss = 2.666086, validation loss = 3.660438\n",
      "2020-04-12 22:33:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 78000, running_avg_reward = 0.315856\n",
      "I0412 22:33:06.062364 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 16: 78000, running_avg_reward = 0.315856\n",
      "2020-04-12 22:33:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 78000, train_rouge_l_f = 0.944240, test_rouge_l_f = 0.698732\n",
      "I0412 22:33:06.924827 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 16: 78000, train_rouge_l_f = 0.944240, test_rouge_l_f = 0.698732\n",
      "2020-04-12 22:51:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 79000, RL_Loss = -0.163285, batch_reward = 0.598146\n",
      "I0412 22:51:05.048955 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 16: 79000, RL_Loss = -0.163285, batch_reward = 0.598146\n",
      "2020-04-12 22:51:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 79000, training batch loss = 1.179841, running_avg_loss loss = 2.651223, validation loss = 3.650127\n",
      "I0412 22:51:35.269559 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 16: 79000, training batch loss = 1.179841, running_avg_loss loss = 2.651223, validation loss = 3.650127\n",
      "2020-04-12 22:51:35 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 79000, running_avg_reward = 0.317915\n",
      "I0412 22:51:35.271360 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 16: 79000, running_avg_reward = 0.317915\n",
      "2020-04-12 22:51:37 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 79000, train_rouge_l_f = 0.588728, test_rouge_l_f = 0.232227\n",
      "I0412 22:51:37.369445 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 16: 79000, train_rouge_l_f = 0.588728, test_rouge_l_f = 0.232227\n",
      "2020-04-12 23:09:32 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 80000, RL_Loss = -0.464769, batch_reward = 0.680174\n",
      "I0412 23:09:32.323374 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 16: 80000, RL_Loss = -0.464769, batch_reward = 0.680174\n",
      "2020-04-12 23:10:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 80000, training batch loss = 0.550478, running_avg_loss loss = 2.630216, validation loss = 3.701609\n",
      "I0412 23:10:02.573863 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 16: 80000, training batch loss = 0.550478, running_avg_loss loss = 2.630216, validation loss = 3.701609\n",
      "2020-04-12 23:10:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 80000, running_avg_reward = 0.320024\n",
      "I0412 23:10:02.575337 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 16: 80000, running_avg_reward = 0.320024\n",
      "2020-04-12 23:10:02 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 80000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0080000.tar...\n",
      "I0412 23:10:02.578088 140716206561088 initialize.py:225] Saving model step 80000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0080000.tar...\n",
      "2020-04-12 23:10:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 80000, train_rouge_l_f = 0.903427, test_rouge_l_f = 0.150313\n",
      "I0412 23:10:04.232842 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 16: 80000, train_rouge_l_f = 0.903427, test_rouge_l_f = 0.150313\n",
      "2020-04-12 23:55:23 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 16: 80274, test_avg_acc = 0.694611, test_avg_acc = 0.318561\n",
      "I0412 23:55:23.160447 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 16: 80274, test_avg_acc = 0.694611, test_avg_acc = 0.318561\n",
      "2020-04-13 00:08:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 81000, RL_Loss = -0.215443, batch_reward = 0.593462\n",
      "I0413 00:08:24.738191 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 17: 81000, RL_Loss = -0.215443, batch_reward = 0.593462\n",
      "2020-04-13 00:08:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 81000, training batch loss = 0.761443, running_avg_loss loss = 2.611528, validation loss = 3.725602\n",
      "I0413 00:08:55.645756 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 17: 81000, training batch loss = 0.761443, running_avg_loss loss = 2.611528, validation loss = 3.725602\n",
      "2020-04-13 00:08:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 81000, running_avg_reward = 0.322529\n",
      "I0413 00:08:55.647553 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 17: 81000, running_avg_reward = 0.322529\n",
      "2020-04-13 00:08:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 81000, train_rouge_l_f = 0.769440, test_rouge_l_f = 0.313163\n",
      "I0413 00:08:56.897168 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 17: 81000, train_rouge_l_f = 0.769440, test_rouge_l_f = 0.313163\n",
      "2020-04-13 00:27:01 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 82000, RL_Loss = -0.619596, batch_reward = 0.441243\n",
      "I0413 00:27:01.652389 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 17: 82000, RL_Loss = -0.619596, batch_reward = 0.441243\n",
      "2020-04-13 00:27:32 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 82000, training batch loss = 0.818406, running_avg_loss loss = 2.593597, validation loss = 3.758497\n",
      "I0413 00:27:32.014598 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 17: 82000, training batch loss = 0.818406, running_avg_loss loss = 2.593597, validation loss = 3.758497\n",
      "2020-04-13 00:27:32 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 82000, running_avg_reward = 0.324957\n",
      "I0413 00:27:32.016332 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 17: 82000, running_avg_reward = 0.324957\n",
      "2020-04-13 00:27:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 82000, train_rouge_l_f = 0.684790, test_rouge_l_f = 0.172100\n",
      "I0413 00:27:33.669511 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 17: 82000, train_rouge_l_f = 0.684790, test_rouge_l_f = 0.172100\n",
      "2020-04-13 00:45:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 83000, RL_Loss = -0.204749, batch_reward = 0.481980\n",
      "I0413 00:45:33.188111 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 17: 83000, RL_Loss = -0.204749, batch_reward = 0.481980\n",
      "2020-04-13 00:46:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 83000, training batch loss = 1.634173, running_avg_loss loss = 2.584003, validation loss = 3.742181\n",
      "I0413 00:46:03.488499 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 17: 83000, training batch loss = 1.634173, running_avg_loss loss = 2.584003, validation loss = 3.742181\n",
      "2020-04-13 00:46:03 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 83000, running_avg_reward = 0.327255\n",
      "I0413 00:46:03.490232 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 17: 83000, running_avg_reward = 0.327255\n",
      "2020-04-13 00:46:04 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 83000, train_rouge_l_f = 0.592026, test_rouge_l_f = 0.478283\n",
      "I0413 00:46:04.904537 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 17: 83000, train_rouge_l_f = 0.592026, test_rouge_l_f = 0.478283\n",
      "2020-04-13 01:03:59 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 84000, RL_Loss = -0.588184, batch_reward = 0.567666\n",
      "I0413 01:03:59.376010 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 17: 84000, RL_Loss = -0.588184, batch_reward = 0.567666\n",
      "2020-04-13 01:04:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 84000, training batch loss = 0.768621, running_avg_loss loss = 2.565849, validation loss = 3.744139\n",
      "I0413 01:04:29.833291 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 17: 84000, training batch loss = 0.768621, running_avg_loss loss = 2.565849, validation loss = 3.744139\n",
      "2020-04-13 01:04:29 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 84000, running_avg_reward = 0.329370\n",
      "I0413 01:04:29.835452 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 17: 84000, running_avg_reward = 0.329370\n",
      "2020-04-13 01:04:30 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 84000, train_rouge_l_f = 0.862946, test_rouge_l_f = 0.494337\n",
      "I0413 01:04:30.974750 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 17: 84000, train_rouge_l_f = 0.862946, test_rouge_l_f = 0.494337\n",
      "2020-04-13 02:03:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 17: 84996, test_avg_acc = 0.725978, test_avg_acc = 0.319160\n",
      "I0413 02:03:57.922916 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 17: 84996, test_avg_acc = 0.725978, test_avg_acc = 0.319160\n",
      "2020-04-13 02:04:01 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 85000, RL_Loss = -0.668830, batch_reward = 0.454078\n",
      "I0413 02:04:01.269582 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 18: 85000, RL_Loss = -0.668830, batch_reward = 0.454078\n",
      "2020-04-13 02:04:31 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 85000, training batch loss = 1.000292, running_avg_loss loss = 2.550193, validation loss = 3.742603\n",
      "I0413 02:04:31.576672 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 18: 85000, training batch loss = 1.000292, running_avg_loss loss = 2.550193, validation loss = 3.742603\n",
      "2020-04-13 02:04:31 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 85000, running_avg_reward = 0.331296\n",
      "I0413 02:04:31.578394 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 18: 85000, running_avg_reward = 0.331296\n",
      "2020-04-13 02:04:31 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 85000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0085000.tar...\n",
      "I0413 02:04:31.580701 140716206561088 initialize.py:225] Saving model step 85000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0085000.tar...\n",
      "2020-04-13 02:04:33 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 85000, train_rouge_l_f = 0.732212, test_rouge_l_f = 0.426345\n",
      "I0413 02:04:33.036391 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 18: 85000, train_rouge_l_f = 0.732212, test_rouge_l_f = 0.426345\n",
      "2020-04-13 02:22:34 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 86000, RL_Loss = -0.105613, batch_reward = 0.667348\n",
      "I0413 02:22:34.801603 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 18: 86000, RL_Loss = -0.105613, batch_reward = 0.667348\n",
      "2020-04-13 02:23:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 86000, training batch loss = 0.484513, running_avg_loss loss = 2.529536, validation loss = 3.797198\n",
      "I0413 02:23:05.076569 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 18: 86000, training batch loss = 0.484513, running_avg_loss loss = 2.529536, validation loss = 3.797198\n",
      "2020-04-13 02:23:05 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 86000, running_avg_reward = 0.333811\n",
      "I0413 02:23:05.078283 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 18: 86000, running_avg_reward = 0.333811\n",
      "2020-04-13 02:23:06 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 86000, train_rouge_l_f = 0.842072, test_rouge_l_f = 0.353912\n",
      "I0413 02:23:06.692399 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 18: 86000, train_rouge_l_f = 0.842072, test_rouge_l_f = 0.353912\n",
      "2020-04-13 02:41:10 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 87000, RL_Loss = -0.440449, batch_reward = 0.425388\n",
      "I0413 02:41:10.723256 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 18: 87000, RL_Loss = -0.440449, batch_reward = 0.425388\n",
      "2020-04-13 02:41:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 87000, training batch loss = 1.244326, running_avg_loss loss = 2.516684, validation loss = 3.801734\n",
      "I0413 02:41:41.116894 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 18: 87000, training batch loss = 1.244326, running_avg_loss loss = 2.516684, validation loss = 3.801734\n",
      "2020-04-13 02:41:41 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 87000, running_avg_reward = 0.336157\n",
      "I0413 02:41:41.118642 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 18: 87000, running_avg_reward = 0.336157\n",
      "2020-04-13 02:41:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 87000, train_rouge_l_f = 0.640583, test_rouge_l_f = 0.250004\n",
      "I0413 02:41:42.583977 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 18: 87000, train_rouge_l_f = 0.640583, test_rouge_l_f = 0.250004\n",
      "2020-04-13 02:59:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 88000, RL_Loss = -0.117287, batch_reward = 0.636051\n",
      "I0413 02:59:42.177928 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 18: 88000, RL_Loss = -0.117287, batch_reward = 0.636051\n",
      "2020-04-13 03:00:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 88000, training batch loss = 0.831093, running_avg_loss loss = 2.499828, validation loss = 3.826094\n",
      "I0413 03:00:12.400196 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 18: 88000, training batch loss = 0.831093, running_avg_loss loss = 2.499828, validation loss = 3.826094\n",
      "2020-04-13 03:00:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 88000, running_avg_reward = 0.338326\n",
      "I0413 03:00:12.402069 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 18: 88000, running_avg_reward = 0.338326\n",
      "2020-04-13 03:00:13 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 88000, train_rouge_l_f = 0.772988, test_rouge_l_f = 0.345457\n",
      "I0413 03:00:13.740667 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 18: 88000, train_rouge_l_f = 0.772988, test_rouge_l_f = 0.345457\n",
      "2020-04-13 03:18:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 89000, RL_Loss = -0.117276, batch_reward = 0.668496\n",
      "I0413 03:18:20.792410 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 18: 89000, RL_Loss = -0.117276, batch_reward = 0.668496\n",
      "2020-04-13 03:18:51 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 89000, training batch loss = 0.700305, running_avg_loss loss = 2.481833, validation loss = 3.837573\n",
      "I0413 03:18:51.050835 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 18: 89000, training batch loss = 0.700305, running_avg_loss loss = 2.481833, validation loss = 3.837573\n",
      "2020-04-13 03:18:51 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 89000, running_avg_reward = 0.340366\n",
      "I0413 03:18:51.052053 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 18: 89000, running_avg_reward = 0.340366\n",
      "2020-04-13 03:18:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 89000, train_rouge_l_f = 0.933141, test_rouge_l_f = 0.569741\n",
      "I0413 03:18:52.080550 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 18: 89000, train_rouge_l_f = 0.933141, test_rouge_l_f = 0.569741\n",
      "2020-04-13 04:13:12 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 18: 89718, test_avg_acc = 0.746986, test_avg_acc = 0.320436\n",
      "I0413 04:13:12.045987 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 18: 89718, test_avg_acc = 0.746986, test_avg_acc = 0.320436\n",
      "2020-04-13 04:18:20 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 90000, RL_Loss = -0.145644, batch_reward = 0.767322\n",
      "I0413 04:18:20.350018 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 19: 90000, RL_Loss = -0.145644, batch_reward = 0.767322\n",
      "2020-04-13 04:18:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 90000, training batch loss = 0.422240, running_avg_loss loss = 2.461237, validation loss = 3.843777\n",
      "I0413 04:18:50.917645 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 19: 90000, training batch loss = 0.422240, running_avg_loss loss = 2.461237, validation loss = 3.843777\n",
      "2020-04-13 04:18:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 90000, running_avg_reward = 0.342518\n",
      "I0413 04:18:50.919452 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 19: 90000, running_avg_reward = 0.342518\n",
      "2020-04-13 04:18:50 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - Saving model step 90000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0090000.tar...\n",
      "I0413 04:18:50.922642 140716206561088 initialize.py:225] Saving model step 90000 to model/saved_models/Pointer_generator_word2Vec_Intra_Atten_RL/0090000.tar...\n",
      "2020-04-13 04:18:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 90000, train_rouge_l_f = 0.934524, test_rouge_l_f = 0.169077\n",
      "I0413 04:18:52.795356 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 19: 90000, train_rouge_l_f = 0.934524, test_rouge_l_f = 0.169077\n",
      "2020-04-13 04:36:47 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 91000, RL_Loss = -0.753794, batch_reward = 0.447239\n",
      "I0413 04:36:47.162352 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 19: 91000, RL_Loss = -0.753794, batch_reward = 0.447239\n",
      "2020-04-13 04:37:17 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 91000, training batch loss = 0.408098, running_avg_loss loss = 2.440706, validation loss = 3.902135\n",
      "I0413 04:37:17.452190 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 19: 91000, training batch loss = 0.408098, running_avg_loss loss = 2.440706, validation loss = 3.902135\n",
      "2020-04-13 04:37:17 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 91000, running_avg_reward = 0.344914\n",
      "I0413 04:37:17.453977 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 19: 91000, running_avg_reward = 0.344914\n",
      "2020-04-13 04:37:18 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 91000, train_rouge_l_f = 0.913014, test_rouge_l_f = 0.342500\n",
      "I0413 04:37:18.996365 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 19: 91000, train_rouge_l_f = 0.913014, test_rouge_l_f = 0.342500\n",
      "2020-04-13 04:55:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 92000, RL_Loss = -0.298484, batch_reward = 0.424963\n",
      "I0413 04:55:24.842889 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 19: 92000, RL_Loss = -0.298484, batch_reward = 0.424963\n",
      "2020-04-13 04:55:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 92000, training batch loss = 1.226334, running_avg_loss loss = 2.428562, validation loss = 3.901297\n",
      "I0413 04:55:55.337411 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 19: 92000, training batch loss = 1.226334, running_avg_loss loss = 2.428562, validation loss = 3.901297\n",
      "2020-04-13 04:55:55 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 92000, running_avg_reward = 0.347235\n",
      "I0413 04:55:55.339213 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 19: 92000, running_avg_reward = 0.347235\n",
      "2020-04-13 04:55:56 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 92000, train_rouge_l_f = 0.547130, test_rouge_l_f = 0.400721\n",
      "I0413 04:55:56.510650 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 19: 92000, train_rouge_l_f = 0.547130, test_rouge_l_f = 0.400721\n",
      "2020-04-13 05:14:11 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 93000, RL_Loss = -0.126121, batch_reward = 0.606381\n",
      "I0413 05:14:11.481429 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 19: 93000, RL_Loss = -0.126121, batch_reward = 0.606381\n",
      "2020-04-13 05:14:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 93000, training batch loss = 1.246793, running_avg_loss loss = 2.416744, validation loss = 3.948814\n",
      "I0413 05:14:42.019783 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 19: 93000, training batch loss = 1.246793, running_avg_loss loss = 2.416744, validation loss = 3.948814\n",
      "2020-04-13 05:14:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 93000, running_avg_reward = 0.349389\n",
      "I0413 05:14:42.021049 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 19: 93000, running_avg_reward = 0.349389\n",
      "2020-04-13 05:14:42 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 93000, train_rouge_l_f = 0.708309, test_rouge_l_f = 0.704960\n",
      "I0413 05:14:42.957041 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 19: 93000, train_rouge_l_f = 0.708309, test_rouge_l_f = 0.704960\n",
      "2020-04-13 05:32:52 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 94000, RL_Loss = -0.065476, batch_reward = 0.659784\n",
      "I0413 05:32:52.335946 140716206561088 <ipython-input-12-bc07426dfa84>:22] epoch 19: 94000, RL_Loss = -0.065476, batch_reward = 0.659784\n",
      "2020-04-13 05:33:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 94000, training batch loss = 0.720902, running_avg_loss loss = 2.399786, validation loss = 3.923328\n",
      "I0413 05:33:22.729853 140716206561088 <ipython-input-12-bc07426dfa84>:41] epoch 19: 94000, training batch loss = 0.720902, running_avg_loss loss = 2.399786, validation loss = 3.923328\n",
      "2020-04-13 05:33:22 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 94000, running_avg_reward = 0.351466\n",
      "I0413 05:33:22.730872 140716206561088 <ipython-input-12-bc07426dfa84>:43] epoch 19: 94000, running_avg_reward = 0.351466\n",
      "2020-04-13 05:33:24 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 94000, train_rouge_l_f = 0.799700, test_rouge_l_f = 0.315979\n",
      "I0413 05:33:24.258763 140716206561088 <ipython-input-12-bc07426dfa84>:67] epoch 19: 94000, train_rouge_l_f = 0.799700, test_rouge_l_f = 0.315979\n",
      "2020-04-13 06:22:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - epoch 19: 94440, test_avg_acc = 0.772124, test_avg_acc = 0.320661\n",
      "I0413 06:22:57.563218 140716206561088 <ipython-input-12-bc07426dfa84>:71] epoch 19: 94440, test_avg_acc = 0.772124, test_avg_acc = 0.320661\n",
      "2020-04-13 06:22:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - ------Training SUCCESS--------\n",
      "I0413 06:22:57.565144 140716206561088 <ipython-input-12-bc07426dfa84>:75] ------Training SUCCESS--------\n",
      "2020-04-13 06:22:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - ------Training END--------\n",
      "I0413 06:22:57.566565 140716206561088 <ipython-input-12-bc07426dfa84>:77] ------Training END--------\n",
      "2020-04-13 06:22:57 - Pointer_generator_word2Vec_Intra_Atten_RL - INFO: - logger已關閉\n",
      "I0413 06:22:57.567940 140716206561088 train_util.py:136] logger已關閉\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "sum_total_reward = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            mle_loss = train_one(model, config, batch)\n",
    "            if config.train_rl:\n",
    "                rl_loss, batch_reward = train_one_RL(model, config, batch)             \n",
    "                writer.add_scalars('scalar/RL_Loss',  \n",
    "                       {'rl_loss': rl_loss\n",
    "                       }, step)\n",
    "                writer.add_scalars('scalar/Reward',  \n",
    "                       {'batch_reward': batch_reward\n",
    "                       }, step)\n",
    "                \n",
    "                if step%1000 == 0 :\n",
    "                    logger.info('epoch %d: %d, RL_Loss = %f, batch_reward = %f'\n",
    "                                    % (epoch, step, rl_loss, batch_reward))\n",
    "                sum_total_reward += batch_reward\n",
    "            else:\n",
    "                rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % (config.gradient_accum) == 0: # gradient accumulation\n",
    "    #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "                optimizer.step() # 根据累计的梯度更新网络参数\n",
    "                optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    running_avg_reward = sum_total_reward / step\n",
    "                    logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "                    if running_avg_reward > 0:\n",
    "                        logger.info('epoch %d: %d, running_avg_reward = %f'\n",
    "                                % (epoch, step, running_avg_reward))\n",
    "                        writer.add_scalars('scalar_avg/Reward',  \n",
    "                           {'running_avg_reward': running_avg_reward\n",
    "                           }, step)\n",
    "\n",
    "            if step%5000 == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                           r_loss=0, title = loggerName)\n",
    "            if step%1000 == 0 and step > 0:\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "        logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')                \n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
