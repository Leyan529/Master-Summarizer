{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 11:43:37.142198 139686077519680 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "2020-04-10 11:43:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - logger已啟動\n",
      "I0410 11:43:37.971573 139686077519680 train_util.py:125] logger已啟動\n"
     ]
    }
   ],
   "source": [
    "from utils import config, data\n",
    "from utils.batcher import *\n",
    "from utils.train_util import *\n",
    "from utils.rl_util import *\n",
    "from utils.initialize import loadCheckpoint, save_model\n",
    "from utils.write_result import *\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from beam.beam_search import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "from utils.rl_util import *\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--key_attention', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--intra_encoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--intra_decoder', type=bool, default=True, help = 'True/False')\n",
    "parser.add_argument('--copy', type=bool, default=True, help = 'True/False') # for transformer\n",
    "\n",
    "parser.add_argument('--transformer', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--train_rl', type=bool, default=False, help = 'True/False')\n",
    "parser.add_argument('--keywords', type=str, default='POS_FOP_keywords', \n",
    "                    help = 'POS_FOP_keywords / DEP_FOP_keywords / TextRank_keywords')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0001)\n",
    "parser.add_argument('--rand_unif_init_mag', type=float, default=0.02)\n",
    "parser.add_argument('--trunc_norm_init_std', type=float, default=0.001)\n",
    "parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "parser.add_argument('--gound_truth_prob', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--max_enc_steps', type=int, default=1000)\n",
    "parser.add_argument('--max_dec_steps', type=int, default=50)\n",
    "parser.add_argument('--min_dec_steps', type=int, default=8)\n",
    "parser.add_argument('--max_epochs', type=int, default=20)\n",
    "parser.add_argument('--vocab_size', type=int, default=50000)\n",
    "parser.add_argument('--beam_size', type=int, default=16)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--emb_dim', type=int, default=300)\n",
    "parser.add_argument('--gradient_accum', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--load_ckpt', type=str, default=None, help='0002000')\n",
    "parser.add_argument('--word_emb_type', type=str, default='FastText', help='word2Vec/glove/FastText')\n",
    "parser.add_argument('--pre_train_emb', type=bool, default=True, help = 'True/False') # 若pre_train_emb為false, 則emb type為NoPretrain\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "config = re_config(opt)\n",
    "loggerName, writerPath = getName(config)    \n",
    "logger = getLogger(loggerName)\n",
    "writer = SummaryWriter(writerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 11:43:43 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - train : 37771, test : 4197\n",
      "I0410 11:43:43.936291 139686077519680 batcher.py:171] train : 37771, test : 4197\n"
     ]
    }
   ],
   "source": [
    "train_loader, validate_loader, vocab = getDataLoader(logger, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import torch.nn as nn\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "load_step = None\n",
    "model = Model(pre_train_emb=config.pre_train_emb, \n",
    "              word_emb_type = config.word_emb_type, \n",
    "              vocab = vocab)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=config.lr)   \n",
    "# optimizer = T.optim.Adagrad(model.parameters(),lr=config.lr, initial_accumulator_value=0.1)\n",
    "\n",
    "load_model_path = config.save_model_path + '/%s/%s.tar' % (logger, config.load_ckpt)\n",
    "\n",
    "if os.path.exists(load_model_path):\n",
    "    model, optimizer, load_step = loadCheckpoint(logger, load_model_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, config, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    " \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input \n",
    "#         print(enc_key_batch.shape)\n",
    "#         print(enc_key_batch[0])\n",
    "#         print(enc_key_batch[0])\n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        'Decoder data'\n",
    "        dec_batch, dec_padding_mask, dec_lens, max_dec_len, target_batch = \\\n",
    "        get_output_from_batch(batch, config, batch_first = True) # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > config.gound_truth_prob)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = model.embeds(x_t)  \n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=PAD)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * UNKNOWN_TOKEN  # Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "@torch.autograd.no_grad()\n",
    "def validate(validate_loader, config, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "#     batch = next(iter(validate_loader))\n",
    "    for batch in validate_loader:\n",
    "        loss = train_one(model, config, batch)\n",
    "        losses.append(loss.item())\n",
    "#         break\n",
    "    model.train()\n",
    "    ave_loss = sum(losses) / len(losses)\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autograd.no_grad()\n",
    "def calc_running_avg_loss(loss, running_avg_loss, decay=0.99):\n",
    "    if running_avg_loss == 0:  # on the first iteration just take the loss\n",
    "        running_avg_loss = loss\n",
    "    else:\n",
    "        running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
    "    running_avg_loss = min(running_avg_loss, 12)  # clip\n",
    "    return running_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def decode(writer, logger, step, config, model, batch, mode):\n",
    "    # 動態取batch\n",
    "    if mode == 'test':\n",
    "        num = len(iter(batch))\n",
    "        select_batch = None\n",
    "        rand_b_id = randint(0,num-1)\n",
    "#         logger.info('test_batch : ' + str(num)+ ' ' + str(rand_b_id))\n",
    "        for idx, b in enumerate(batch):\n",
    "            if idx == rand_b_id:\n",
    "                select_batch = b\n",
    "                break\n",
    "#         select_batch = next(iter(batch))\n",
    "        batch = select_batch\n",
    "        if type(batch) == torch.utils.data.dataloader.DataLoader:\n",
    "            batch = next(iter(batch))\n",
    "    'Encoder data'\n",
    "    enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "    enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input   \n",
    "    enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    'Feed encoder data to predict'\n",
    "    pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                           enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                           START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "    article_sents, decoded_sents, keywords_list, \\\n",
    "    ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "    rouge_l = write_rouge(writer, step, mode,article_sents, decoded_sents, \\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_bleu(writer, step, mode, article_sents, decoded_sents, \\\n",
    "               keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    write_group(writer, step, mode, article_sents, decoded_sents,\\\n",
    "                keywords_list, ref_sents, long_seq_index)\n",
    "\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "@torch.autograd.no_grad()\n",
    "def avg_acc(writer, logger, epoch, config, model, dataloader, mode):\n",
    "    # 動態取batch\n",
    "    num = len(iter(dataloader))\n",
    "    avg_rouge_l = []\n",
    "    for idx, batch in enumerate(dataloader): \n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "\n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        'Feed encoder data to predict'\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, \n",
    "                               enc_batch_extend_vocab, enc_key_batch, enc_key_lens, model, \n",
    "                               START, END, UNKNOWN_TOKEN)\n",
    "\n",
    "        article_sents, decoded_sents, keywords_list, \\\n",
    "        ref_sents, long_seq_index = prepare_result(vocab, batch, pred_ids)\n",
    "\n",
    "        rouge_l = write_rouge(writer, None, None, article_sents, decoded_sents, \\\n",
    "                    keywords_list, ref_sents, long_seq_index, write = False)\n",
    "        avg_rouge_l.append(rouge_l)\n",
    "\n",
    "\n",
    "    avg_rouge_l = sum(avg_rouge_l) / num\n",
    "    writer.add_scalars('scalar_avg/acc',  \n",
    "                   {'%sing_avg_acc'%(mode): avg_rouge_l\n",
    "                   }, epoch)\n",
    "\n",
    "    return avg_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL(model, config, batch, greedy):    \n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param article_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        'Encoder data'\n",
    "        enc_batch, enc_padding_mask, enc_lens, enc_batch_extend_vocab, extra_zeros, coverage, \\\n",
    "        ct_e, enc_key_batch, enc_key_mask, enc_key_lens= \\\n",
    "            get_input_from_batch(batch, config, batch_first = True)\n",
    "        \n",
    "        enc_batch = model.embeds(enc_batch)  # Get embeddings for encoder input    \n",
    "        enc_key_batch = model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "\n",
    "        enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "        \n",
    "        s_t = enc_hidden                                                                            #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(START))  # Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []                       # Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []       # Stores padding masks of generated samples\n",
    "        log_probs = []                                                                              #Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "        # Generate RL tokens and compute rl-log-loss\n",
    "        # ----------------------------------------------------------------------\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = model.embeds(x_t)\n",
    "            \n",
    "            probs, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                      ct_e, extra_zeros,\n",
    "                                                                                      enc_batch_extend_vocab,\n",
    "                                                                                      sum_temporal_srcs, prev_s, enc_key_batch, enc_key_mask)\n",
    "            \n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs) # 建立以參數probs為標準的類別分佈\n",
    "                # perform multinomial sampling\n",
    "                x_t = multi_dist.sample()  # 將下一個時間點的x_t，視為下一個action   \n",
    "                # 使用log_prob实施梯度方法 Policy Gradient，构造一个等价類別分佈的损失函数\n",
    "                log_prob = multi_dist.log_prob(x_t)  \n",
    "                log_probs.append(log_prob) #\n",
    "            else:\n",
    "                # perform greedy sampling distribution\n",
    "                _, x_t = T.max(probs, dim=1)  # 因greedy以機率最大進行取樣，視為其中一個action   \n",
    "            x_t = x_t.detach() # detach返回的 Variable 永远不会需要梯度\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "            mask[(mask == 1) + (x_t == END) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "            is_oov = (x_t>=config.vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n",
    "            x_t = (1-is_oov)*x_t + (is_oov)*UNKNOWN_TOKEN                                             #Replace OOVs with [UNK] token\n",
    "        # -----------------------------------End loop -----------------------------------\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n",
    "            log_probs = T.stack(log_probs, dim=1) # 在第1个维度上stack, 增加新的维度进行堆叠\n",
    "            log_probs = log_probs * decoder_padding_mask # 遮罩掉為[END] or [STOP]不計算損失           #Not considering sampled words with padding mask = 0\n",
    "            lens = T.sum(decoder_padding_mask, dim=1) # 計算每個sample words生成的總長度               #Length of sampled sentence\n",
    "            log_probs = T.sum(log_probs, dim=1) / lens  # 計算平均的每個句子的log loss # (bs,1)        #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy() # 取出每個sample sentence 的word id list\n",
    "            S = output2words(id_list, vocab, batch.art_oovs[i]) #Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:          #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "        return decoded_strs, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_RL(model, config, batch):\n",
    "    # Self-Critical sequence training(SCST)\n",
    "    sample_sents, RL_log_probs = RL(model, config, batch, greedy=False)   # multinomial sampling\n",
    "    with T.autograd.no_grad():        \n",
    "        greedy_sents, _ = RL(model, config, batch, greedy=True)  # greedy sampling\n",
    "\n",
    "    sample_reward = reward_function(sample_sents, batch.original_abstract) # r(w^s):通过根据概率来随机sample词生成句子的reward值\n",
    "    baseline_reward = reward_function(greedy_sents, batch.original_abstract) # r(w^):测试阶段使用greedy decoding取概率最大的词来生成句子的reward值\n",
    "\n",
    "    batch_reward = T.mean(sample_reward).item()\n",
    "    #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "    rl_loss = -(sample_reward - baseline_reward) * RL_log_probs  # SCST梯度計算公式     \n",
    "    rl_loss = T.mean(rl_loss)  \n",
    "    '''\n",
    "    公式的意思就是：对于如果当前sample到的词比测试阶段生成的词好，那么在这次词的维度上，整个式子的值就是负的（因为后面那一项一定为负），\n",
    "    这样梯度就会上升，从而提高这个词的分数st；而对于其他词，后面那一项为正，梯度就会下降，从而降低其他词的分数\n",
    "    '''                 \n",
    "    return rl_loss, batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 11:43:48 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - ------Training START--------\n",
      "I0410 11:43:48.751812 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:2] ------Training START--------\n",
      "2020-04-10 11:48:49 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 1000, training batch loss = 3.852457, running_avg_loss loss = 3.852457, validation loss = 4.286448\n",
      "I0410 11:48:49.762014 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 0: 1000, training batch loss = 3.852457, running_avg_loss loss = 3.852457, validation loss = 4.286448\n",
      "2020-04-10 11:48:51 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 1000, train_rouge_l_f = 0.188155, test_rouge_l_f = 0.184396\n",
      "I0410 11:48:51.228162 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 0: 1000, train_rouge_l_f = 0.188155, test_rouge_l_f = 0.184396\n",
      "2020-04-10 11:53:54 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 2000, training batch loss = 4.412667, running_avg_loss loss = 3.858059, validation loss = 4.139594\n",
      "I0410 11:53:54.046176 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 0: 2000, training batch loss = 4.412667, running_avg_loss loss = 3.858059, validation loss = 4.139594\n",
      "2020-04-10 11:53:54 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 2000, train_rouge_l_f = 0.203038, test_rouge_l_f = 0.266867\n",
      "I0410 11:53:54.757361 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 0: 2000, train_rouge_l_f = 0.203038, test_rouge_l_f = 0.266867\n",
      "2020-04-10 11:59:02 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 3000, training batch loss = 4.580373, running_avg_loss loss = 3.865282, validation loss = 4.018112\n",
      "I0410 11:59:02.545799 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 0: 3000, training batch loss = 4.580373, running_avg_loss loss = 3.865282, validation loss = 4.018112\n",
      "2020-04-10 11:59:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 3000, train_rouge_l_f = 0.190664, test_rouge_l_f = 0.131075\n",
      "I0410 11:59:04.127197 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 0: 3000, train_rouge_l_f = 0.190664, test_rouge_l_f = 0.131075\n",
      "2020-04-10 12:04:13 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 4000, training batch loss = 3.453747, running_avg_loss loss = 3.861166, validation loss = 3.890901\n",
      "I0410 12:04:13.454122 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 0: 4000, training batch loss = 3.453747, running_avg_loss loss = 3.861166, validation loss = 3.890901\n",
      "2020-04-10 12:04:14 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 4000, train_rouge_l_f = 0.218578, test_rouge_l_f = 0.168813\n",
      "I0410 12:04:14.838892 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 0: 4000, train_rouge_l_f = 0.218578, test_rouge_l_f = 0.168813\n",
      "2020-04-10 12:36:44 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 0: 4722, test_avg_acc = 0.236339, test_avg_acc = 0.237972\n",
      "I0410 12:36:44.096195 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 0: 4722, test_avg_acc = 0.236339, test_avg_acc = 0.237972\n",
      "2020-04-10 12:38:31 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 5000, training batch loss = 3.210287, running_avg_loss loss = 3.854658, validation loss = 3.788089\n",
      "I0410 12:38:31.307384 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 1: 5000, training batch loss = 3.210287, running_avg_loss loss = 3.854658, validation loss = 3.788089\n",
      "2020-04-10 12:38:31 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 5000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0005000.tar...\n",
      "I0410 12:38:31.310455 139686077519680 initialize.py:225] Saving model step 5000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0005000.tar...\n",
      "2020-04-10 12:38:33 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 5000, train_rouge_l_f = 0.208983, test_rouge_l_f = 0.190560\n",
      "I0410 12:38:33.029879 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 1: 5000, train_rouge_l_f = 0.208983, test_rouge_l_f = 0.190560\n",
      "2020-04-10 12:43:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 6000, training batch loss = 2.820086, running_avg_loss loss = 3.844312, validation loss = 3.729812\n",
      "I0410 12:43:37.809995 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 1: 6000, training batch loss = 2.820086, running_avg_loss loss = 3.844312, validation loss = 3.729812\n",
      "2020-04-10 12:43:39 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 6000, train_rouge_l_f = 0.459980, test_rouge_l_f = 0.269098\n",
      "I0410 12:43:39.616162 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 1: 6000, train_rouge_l_f = 0.459980, test_rouge_l_f = 0.269098\n",
      "2020-04-10 12:48:44 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 7000, training batch loss = 2.381028, running_avg_loss loss = 3.829679, validation loss = 3.628590\n",
      "I0410 12:48:44.366414 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 1: 7000, training batch loss = 2.381028, running_avg_loss loss = 3.829679, validation loss = 3.628590\n",
      "2020-04-10 12:48:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 7000, train_rouge_l_f = 0.461328, test_rouge_l_f = 0.393472\n",
      "I0410 12:48:45.274777 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 1: 7000, train_rouge_l_f = 0.461328, test_rouge_l_f = 0.393472\n",
      "2020-04-10 12:53:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 8000, training batch loss = 3.001204, running_avg_loss loss = 3.821394, validation loss = 3.568306\n",
      "I0410 12:53:45.791322 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 1: 8000, training batch loss = 3.001204, running_avg_loss loss = 3.821394, validation loss = 3.568306\n",
      "2020-04-10 12:53:47 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 8000, train_rouge_l_f = 0.324731, test_rouge_l_f = 0.187171\n",
      "I0410 12:53:47.319745 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 1: 8000, train_rouge_l_f = 0.324731, test_rouge_l_f = 0.187171\n",
      "2020-04-10 12:58:50 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 9000, training batch loss = 3.562756, running_avg_loss loss = 3.818808, validation loss = 3.507810\n",
      "I0410 12:58:50.091844 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 1: 9000, training batch loss = 3.562756, running_avg_loss loss = 3.818808, validation loss = 3.507810\n",
      "2020-04-10 12:58:50 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 9000, train_rouge_l_f = 0.346534, test_rouge_l_f = 0.629760\n",
      "I0410 12:58:50.852389 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 1: 9000, train_rouge_l_f = 0.346534, test_rouge_l_f = 0.629760\n",
      "2020-04-10 13:38:34 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 1: 9444, test_avg_acc = 0.283847, test_avg_acc = 0.287567\n",
      "I0410 13:38:34.187566 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 1: 9444, test_avg_acc = 0.283847, test_avg_acc = 0.287567\n",
      "2020-04-10 13:41:38 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 10000, training batch loss = 3.792377, running_avg_loss loss = 3.818544, validation loss = 3.453552\n",
      "I0410 13:41:38.784798 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 2: 10000, training batch loss = 3.792377, running_avg_loss loss = 3.818544, validation loss = 3.453552\n",
      "2020-04-10 13:41:38 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 10000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0010000.tar...\n",
      "I0410 13:41:38.787502 139686077519680 initialize.py:225] Saving model step 10000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0010000.tar...\n",
      "2020-04-10 13:41:40 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 10000, train_rouge_l_f = 0.223282, test_rouge_l_f = 0.195640\n",
      "I0410 13:41:40.995743 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 2: 10000, train_rouge_l_f = 0.223282, test_rouge_l_f = 0.195640\n",
      "2020-04-10 13:46:51 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 11000, training batch loss = 4.111176, running_avg_loss loss = 3.821470, validation loss = 3.402270\n",
      "I0410 13:46:51.569548 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 2: 11000, training batch loss = 4.111176, running_avg_loss loss = 3.821470, validation loss = 3.402270\n",
      "2020-04-10 13:46:53 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 11000, train_rouge_l_f = 0.233563, test_rouge_l_f = 0.165019\n",
      "I0410 13:46:53.337220 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 2: 11000, train_rouge_l_f = 0.233563, test_rouge_l_f = 0.165019\n",
      "2020-04-10 13:51:58 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 12000, training batch loss = 2.905330, running_avg_loss loss = 3.812309, validation loss = 3.370704\n",
      "I0410 13:51:58.941408 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 2: 12000, training batch loss = 2.905330, running_avg_loss loss = 3.812309, validation loss = 3.370704\n",
      "2020-04-10 13:52:00 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 12000, train_rouge_l_f = 0.331871, test_rouge_l_f = 0.203384\n",
      "I0410 13:52:00.353613 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 2: 12000, train_rouge_l_f = 0.331871, test_rouge_l_f = 0.203384\n",
      "2020-04-10 13:57:03 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 13000, training batch loss = 3.711639, running_avg_loss loss = 3.811302, validation loss = 3.339841\n",
      "I0410 13:57:03.227792 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 2: 13000, training batch loss = 3.711639, running_avg_loss loss = 3.811302, validation loss = 3.339841\n",
      "2020-04-10 13:57:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 13000, train_rouge_l_f = 0.294597, test_rouge_l_f = 0.210927\n",
      "I0410 13:57:04.420137 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 2: 13000, train_rouge_l_f = 0.294597, test_rouge_l_f = 0.210927\n",
      "2020-04-10 14:02:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 14000, training batch loss = 3.759190, running_avg_loss loss = 3.810781, validation loss = 3.307535\n",
      "I0410 14:02:04.626172 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 2: 14000, training batch loss = 3.759190, running_avg_loss loss = 3.810781, validation loss = 3.307535\n",
      "2020-04-10 14:02:06 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 14000, train_rouge_l_f = 0.330797, test_rouge_l_f = 0.267804\n",
      "I0410 14:02:06.277129 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 2: 14000, train_rouge_l_f = 0.330797, test_rouge_l_f = 0.267804\n",
      "2020-04-10 14:41:58 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 2: 14166, test_avg_acc = 0.293899, test_avg_acc = 0.301483\n",
      "I0410 14:41:58.594081 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 2: 14166, test_avg_acc = 0.293899, test_avg_acc = 0.301483\n",
      "2020-04-10 14:46:17 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 15000, training batch loss = 3.603498, running_avg_loss loss = 3.808708, validation loss = 3.307306\n",
      "I0410 14:46:17.197436 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 3: 15000, training batch loss = 3.603498, running_avg_loss loss = 3.808708, validation loss = 3.307306\n",
      "2020-04-10 14:46:17 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 15000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0015000.tar...\n",
      "I0410 14:46:17.200348 139686077519680 initialize.py:225] Saving model step 15000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0015000.tar...\n",
      "2020-04-10 14:46:18 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 15000, train_rouge_l_f = 0.206510, test_rouge_l_f = 0.135030\n",
      "I0410 14:46:18.983338 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 3: 15000, train_rouge_l_f = 0.206510, test_rouge_l_f = 0.135030\n",
      "2020-04-10 14:51:20 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 16000, training batch loss = 3.504821, running_avg_loss loss = 3.805669, validation loss = 3.263582\n",
      "I0410 14:51:20.013069 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 3: 16000, training batch loss = 3.504821, running_avg_loss loss = 3.805669, validation loss = 3.263582\n",
      "2020-04-10 14:51:21 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 16000, train_rouge_l_f = 0.406164, test_rouge_l_f = 0.449234\n",
      "I0410 14:51:21.597190 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 3: 16000, train_rouge_l_f = 0.406164, test_rouge_l_f = 0.449234\n",
      "2020-04-10 14:56:25 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 17000, training batch loss = 2.300054, running_avg_loss loss = 3.790613, validation loss = 3.235643\n",
      "I0410 14:56:25.490457 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 3: 17000, training batch loss = 2.300054, running_avg_loss loss = 3.790613, validation loss = 3.235643\n",
      "2020-04-10 14:56:26 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 17000, train_rouge_l_f = 0.385177, test_rouge_l_f = 0.407384\n",
      "I0410 14:56:26.591711 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 3: 17000, train_rouge_l_f = 0.385177, test_rouge_l_f = 0.407384\n",
      "2020-04-10 15:01:27 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 18000, training batch loss = 3.333823, running_avg_loss loss = 3.786045, validation loss = 3.217059\n",
      "I0410 15:01:27.995325 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 3: 18000, training batch loss = 3.333823, running_avg_loss loss = 3.786045, validation loss = 3.217059\n",
      "2020-04-10 15:01:29 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 18000, train_rouge_l_f = 0.194794, test_rouge_l_f = 0.164969\n",
      "I0410 15:01:29.977706 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 3: 18000, train_rouge_l_f = 0.194794, test_rouge_l_f = 0.164969\n",
      "2020-04-10 15:51:16 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 3: 18888, test_avg_acc = 0.305433, test_avg_acc = 0.309958\n",
      "I0410 15:51:16.772498 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 3: 18888, test_avg_acc = 0.305433, test_avg_acc = 0.309958\n",
      "2020-04-10 15:52:19 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 19000, training batch loss = 3.829633, running_avg_loss loss = 3.786481, validation loss = 3.179896\n",
      "I0410 15:52:19.143630 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 4: 19000, training batch loss = 3.829633, running_avg_loss loss = 3.786481, validation loss = 3.179896\n",
      "2020-04-10 15:52:19 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 19000, train_rouge_l_f = 0.081226, test_rouge_l_f = 0.487677\n",
      "I0410 15:52:19.847715 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 4: 19000, train_rouge_l_f = 0.081226, test_rouge_l_f = 0.487677\n",
      "2020-04-10 15:57:22 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 20000, training batch loss = 2.591534, running_avg_loss loss = 3.774531, validation loss = 3.175281\n",
      "I0410 15:57:22.513675 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 4: 20000, training batch loss = 2.591534, running_avg_loss loss = 3.774531, validation loss = 3.175281\n",
      "2020-04-10 15:57:22 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 20000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0020000.tar...\n",
      "I0410 15:57:22.516572 139686077519680 initialize.py:225] Saving model step 20000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0020000.tar...\n",
      "2020-04-10 15:57:25 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 20000, train_rouge_l_f = 0.384613, test_rouge_l_f = 0.184101\n",
      "I0410 15:57:25.229927 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 4: 20000, train_rouge_l_f = 0.384613, test_rouge_l_f = 0.184101\n",
      "2020-04-10 16:02:28 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 21000, training batch loss = 3.286996, running_avg_loss loss = 3.769656, validation loss = 3.160058\n",
      "I0410 16:02:28.958536 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 4: 21000, training batch loss = 3.286996, running_avg_loss loss = 3.769656, validation loss = 3.160058\n",
      "2020-04-10 16:02:29 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 21000, train_rouge_l_f = 0.390692, test_rouge_l_f = 0.598611\n",
      "I0410 16:02:29.758615 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 4: 21000, train_rouge_l_f = 0.390692, test_rouge_l_f = 0.598611\n",
      "2020-04-10 16:07:32 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 22000, training batch loss = 2.480337, running_avg_loss loss = 3.756763, validation loss = 3.157716\n",
      "I0410 16:07:32.471529 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 4: 22000, training batch loss = 2.480337, running_avg_loss loss = 3.756763, validation loss = 3.157716\n",
      "2020-04-10 16:07:34 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 22000, train_rouge_l_f = 0.301203, test_rouge_l_f = 0.189659\n",
      "I0410 16:07:34.764689 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 4: 22000, train_rouge_l_f = 0.301203, test_rouge_l_f = 0.189659\n",
      "2020-04-10 16:12:38 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 23000, training batch loss = 4.190075, running_avg_loss loss = 3.761096, validation loss = 3.108978\n",
      "I0410 16:12:38.407139 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 4: 23000, training batch loss = 4.190075, running_avg_loss loss = 3.761096, validation loss = 3.108978\n",
      "2020-04-10 16:12:39 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 23000, train_rouge_l_f = 0.274584, test_rouge_l_f = 0.574495\n",
      "I0410 16:12:39.510574 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 4: 23000, train_rouge_l_f = 0.274584, test_rouge_l_f = 0.574495\n",
      "2020-04-10 16:57:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 4: 23610, test_avg_acc = 0.312731, test_avg_acc = 0.316006\n",
      "I0410 16:57:37.005384 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 4: 23610, test_avg_acc = 0.312731, test_avg_acc = 0.316006\n",
      "2020-04-10 16:59:55 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 24000, training batch loss = 3.057364, running_avg_loss loss = 3.754059, validation loss = 3.100429\n",
      "I0410 16:59:55.884889 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 5: 24000, training batch loss = 3.057364, running_avg_loss loss = 3.754059, validation loss = 3.100429\n",
      "2020-04-10 16:59:57 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 24000, train_rouge_l_f = 0.308186, test_rouge_l_f = 0.447948\n",
      "I0410 16:59:57.034427 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 5: 24000, train_rouge_l_f = 0.308186, test_rouge_l_f = 0.447948\n",
      "2020-04-10 17:05:02 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 25000, training batch loss = 3.639050, running_avg_loss loss = 3.752909, validation loss = 3.099303\n",
      "I0410 17:05:02.626923 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 5: 25000, training batch loss = 3.639050, running_avg_loss loss = 3.752909, validation loss = 3.099303\n",
      "2020-04-10 17:05:02 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 25000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0025000.tar...\n",
      "I0410 17:05:02.630065 139686077519680 initialize.py:225] Saving model step 25000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0025000.tar...\n",
      "2020-04-10 17:05:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 25000, train_rouge_l_f = 0.197707, test_rouge_l_f = 0.262721\n",
      "I0410 17:05:04.460409 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 5: 25000, train_rouge_l_f = 0.197707, test_rouge_l_f = 0.262721\n",
      "2020-04-10 17:10:07 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 26000, training batch loss = 2.690833, running_avg_loss loss = 3.742288, validation loss = 3.100659\n",
      "I0410 17:10:07.254999 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 5: 26000, training batch loss = 2.690833, running_avg_loss loss = 3.742288, validation loss = 3.100659\n",
      "2020-04-10 17:10:08 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 26000, train_rouge_l_f = 0.392994, test_rouge_l_f = 0.169627\n",
      "I0410 17:10:08.938819 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 5: 26000, train_rouge_l_f = 0.392994, test_rouge_l_f = 0.169627\n",
      "2020-04-10 17:15:11 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 27000, training batch loss = 2.986460, running_avg_loss loss = 3.734730, validation loss = 3.091060\n",
      "I0410 17:15:11.237813 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 5: 27000, training batch loss = 2.986460, running_avg_loss loss = 3.734730, validation loss = 3.091060\n",
      "2020-04-10 17:15:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 27000, train_rouge_l_f = 0.260098, test_rouge_l_f = 0.400765\n",
      "I0410 17:15:12.185009 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 5: 27000, train_rouge_l_f = 0.260098, test_rouge_l_f = 0.400765\n",
      "2020-04-10 17:20:10 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 28000, training batch loss = 3.121552, running_avg_loss loss = 3.728598, validation loss = 3.060888\n",
      "I0410 17:20:10.435297 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 5: 28000, training batch loss = 3.121552, running_avg_loss loss = 3.728598, validation loss = 3.060888\n",
      "2020-04-10 17:20:11 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 28000, train_rouge_l_f = 0.257681, test_rouge_l_f = 0.180266\n",
      "I0410 17:20:11.632825 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 5: 28000, train_rouge_l_f = 0.257681, test_rouge_l_f = 0.180266\n",
      "2020-04-10 18:09:05 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 5: 28332, test_avg_acc = 0.320211, test_avg_acc = 0.317839\n",
      "I0410 18:09:05.544597 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 5: 28332, test_avg_acc = 0.320211, test_avg_acc = 0.317839\n",
      "2020-04-10 18:12:36 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 29000, training batch loss = 3.622240, running_avg_loss loss = 3.727534, validation loss = 3.055412\n",
      "I0410 18:12:36.658145 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 6: 29000, training batch loss = 3.622240, running_avg_loss loss = 3.727534, validation loss = 3.055412\n",
      "2020-04-10 18:12:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 29000, train_rouge_l_f = 0.227230, test_rouge_l_f = 0.270915\n",
      "I0410 18:12:37.625458 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 6: 29000, train_rouge_l_f = 0.227230, test_rouge_l_f = 0.270915\n",
      "2020-04-10 18:17:40 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 30000, training batch loss = 2.649252, running_avg_loss loss = 3.716751, validation loss = 3.066919\n",
      "I0410 18:17:40.804009 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 6: 30000, training batch loss = 2.649252, running_avg_loss loss = 3.716751, validation loss = 3.066919\n",
      "2020-04-10 18:17:40 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 30000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0030000.tar...\n",
      "I0410 18:17:40.805489 139686077519680 initialize.py:225] Saving model step 30000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0030000.tar...\n",
      "2020-04-10 18:17:42 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 30000, train_rouge_l_f = 0.294802, test_rouge_l_f = 0.485075\n",
      "I0410 18:17:42.167579 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 6: 30000, train_rouge_l_f = 0.294802, test_rouge_l_f = 0.485075\n",
      "2020-04-10 18:22:42 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 31000, training batch loss = 3.226315, running_avg_loss loss = 3.711847, validation loss = 3.048578\n",
      "I0410 18:22:42.936708 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 6: 31000, training batch loss = 3.226315, running_avg_loss loss = 3.711847, validation loss = 3.048578\n",
      "2020-04-10 18:22:44 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 31000, train_rouge_l_f = 0.421054, test_rouge_l_f = 0.244522\n",
      "I0410 18:22:44.914313 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 6: 31000, train_rouge_l_f = 0.421054, test_rouge_l_f = 0.244522\n",
      "2020-04-10 18:27:52 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 32000, training batch loss = 2.721569, running_avg_loss loss = 3.701944, validation loss = 3.037686\n",
      "I0410 18:27:52.095539 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 6: 32000, training batch loss = 2.721569, running_avg_loss loss = 3.701944, validation loss = 3.037686\n",
      "2020-04-10 18:27:53 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 32000, train_rouge_l_f = 0.403062, test_rouge_l_f = 0.184744\n",
      "I0410 18:27:53.408246 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 6: 32000, train_rouge_l_f = 0.403062, test_rouge_l_f = 0.184744\n",
      "2020-04-10 18:32:52 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 33000, training batch loss = 3.499220, running_avg_loss loss = 3.699917, validation loss = 3.033620\n",
      "I0410 18:32:52.682227 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 6: 33000, training batch loss = 3.499220, running_avg_loss loss = 3.699917, validation loss = 3.033620\n",
      "2020-04-10 18:32:54 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 33000, train_rouge_l_f = 0.342189, test_rouge_l_f = 0.121867\n",
      "I0410 18:32:54.298471 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 6: 33000, train_rouge_l_f = 0.342189, test_rouge_l_f = 0.121867\n",
      "2020-04-10 19:13:15 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 6: 33054, test_avg_acc = 0.321498, test_avg_acc = 0.314330\n",
      "I0410 19:13:15.837337 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 6: 33054, test_avg_acc = 0.321498, test_avg_acc = 0.314330\n",
      "2020-04-10 19:18:11 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 34000, training batch loss = 3.469242, running_avg_loss loss = 3.697610, validation loss = 3.035689\n",
      "I0410 19:18:11.565520 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 7: 34000, training batch loss = 3.469242, running_avg_loss loss = 3.697610, validation loss = 3.035689\n",
      "2020-04-10 19:18:13 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 34000, train_rouge_l_f = 0.227676, test_rouge_l_f = 0.297676\n",
      "I0410 19:18:13.242318 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 7: 34000, train_rouge_l_f = 0.227676, test_rouge_l_f = 0.297676\n",
      "2020-04-10 19:23:23 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 35000, training batch loss = 2.838356, running_avg_loss loss = 3.689018, validation loss = 3.023560\n",
      "I0410 19:23:23.307851 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 7: 35000, training batch loss = 2.838356, running_avg_loss loss = 3.689018, validation loss = 3.023560\n",
      "2020-04-10 19:23:23 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 35000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0035000.tar...\n",
      "I0410 19:23:23.309791 139686077519680 initialize.py:225] Saving model step 35000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0035000.tar...\n",
      "2020-04-10 19:23:25 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 35000, train_rouge_l_f = 0.240725, test_rouge_l_f = 0.366200\n",
      "I0410 19:23:25.066405 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 7: 35000, train_rouge_l_f = 0.240725, test_rouge_l_f = 0.366200\n",
      "2020-04-10 19:28:28 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 36000, training batch loss = 2.713780, running_avg_loss loss = 3.679265, validation loss = 3.031619\n",
      "I0410 19:28:28.947138 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 7: 36000, training batch loss = 2.713780, running_avg_loss loss = 3.679265, validation loss = 3.031619\n",
      "2020-04-10 19:28:29 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 36000, train_rouge_l_f = 0.404154, test_rouge_l_f = 0.364280\n",
      "I0410 19:28:29.992565 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 7: 36000, train_rouge_l_f = 0.404154, test_rouge_l_f = 0.364280\n",
      "2020-04-10 19:33:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 37000, training batch loss = 0.947667, running_avg_loss loss = 3.651949, validation loss = 2.999432\n",
      "I0410 19:33:37.880102 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 7: 37000, training batch loss = 0.947667, running_avg_loss loss = 3.651949, validation loss = 2.999432\n",
      "2020-04-10 19:33:39 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 37000, train_rouge_l_f = 0.572446, test_rouge_l_f = 0.152412\n",
      "I0410 19:33:39.806915 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 7: 37000, train_rouge_l_f = 0.572446, test_rouge_l_f = 0.152412\n",
      "2020-04-10 20:18:28 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 7: 37776, test_avg_acc = 0.331284, test_avg_acc = 0.319602\n",
      "I0410 20:18:28.911673 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 7: 37776, test_avg_acc = 0.331284, test_avg_acc = 0.319602\n",
      "2020-04-10 20:20:00 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 38000, training batch loss = 2.307608, running_avg_loss loss = 3.638506, validation loss = 3.010773\n",
      "I0410 20:20:00.648339 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 8: 38000, training batch loss = 2.307608, running_avg_loss loss = 3.638506, validation loss = 3.010773\n",
      "2020-04-10 20:20:01 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 38000, train_rouge_l_f = 0.455517, test_rouge_l_f = 0.265375\n",
      "I0410 20:20:01.961593 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 8: 38000, train_rouge_l_f = 0.455517, test_rouge_l_f = 0.265375\n",
      "2020-04-10 20:25:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 39000, training batch loss = 2.585928, running_avg_loss loss = 3.627980, validation loss = 3.000870\n",
      "I0410 20:25:12.975057 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 8: 39000, training batch loss = 2.585928, running_avg_loss loss = 3.627980, validation loss = 3.000870\n",
      "2020-04-10 20:25:14 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 39000, train_rouge_l_f = 0.290831, test_rouge_l_f = 0.264863\n",
      "I0410 20:25:14.532357 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 8: 39000, train_rouge_l_f = 0.290831, test_rouge_l_f = 0.264863\n",
      "2020-04-10 20:30:18 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 40000, training batch loss = 2.819385, running_avg_loss loss = 3.619894, validation loss = 3.021375\n",
      "I0410 20:30:18.075931 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 8: 40000, training batch loss = 2.819385, running_avg_loss loss = 3.619894, validation loss = 3.021375\n",
      "2020-04-10 20:30:18 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 40000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0040000.tar...\n",
      "I0410 20:30:18.078597 139686077519680 initialize.py:225] Saving model step 40000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0040000.tar...\n",
      "2020-04-10 20:30:19 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 40000, train_rouge_l_f = 0.447812, test_rouge_l_f = 0.829324\n",
      "I0410 20:30:19.570543 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 8: 40000, train_rouge_l_f = 0.447812, test_rouge_l_f = 0.829324\n",
      "2020-04-10 20:35:22 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 41000, training batch loss = 3.569960, running_avg_loss loss = 3.619395, validation loss = 2.993920\n",
      "I0410 20:35:22.097285 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 8: 41000, training batch loss = 3.569960, running_avg_loss loss = 3.619395, validation loss = 2.993920\n",
      "2020-04-10 20:35:24 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 41000, train_rouge_l_f = 0.268559, test_rouge_l_f = 0.163728\n",
      "I0410 20:35:24.703776 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 8: 41000, train_rouge_l_f = 0.268559, test_rouge_l_f = 0.163728\n",
      "2020-04-10 20:40:20 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 42000, training batch loss = 2.228953, running_avg_loss loss = 3.605490, validation loss = 2.990361\n",
      "I0410 20:40:20.801625 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 8: 42000, training batch loss = 2.228953, running_avg_loss loss = 3.605490, validation loss = 2.990361\n",
      "2020-04-10 20:40:23 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 42000, train_rouge_l_f = 0.354444, test_rouge_l_f = 0.185547\n",
      "I0410 20:40:23.055577 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 8: 42000, train_rouge_l_f = 0.354444, test_rouge_l_f = 0.185547\n",
      "2020-04-10 21:23:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 8: 42498, test_avg_acc = 0.335687, test_avg_acc = 0.321041\n",
      "I0410 21:23:45.107782 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 8: 42498, test_avg_acc = 0.335687, test_avg_acc = 0.321041\n",
      "2020-04-10 21:26:34 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 43000, training batch loss = 2.087607, running_avg_loss loss = 3.590312, validation loss = 2.987816\n",
      "I0410 21:26:34.188319 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 9: 43000, training batch loss = 2.087607, running_avg_loss loss = 3.590312, validation loss = 2.987816\n",
      "2020-04-10 21:26:35 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 43000, train_rouge_l_f = 0.451431, test_rouge_l_f = 0.286541\n",
      "I0410 21:26:35.663128 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 9: 43000, train_rouge_l_f = 0.451431, test_rouge_l_f = 0.286541\n",
      "2020-04-10 21:31:41 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 44000, training batch loss = 2.629601, running_avg_loss loss = 3.580705, validation loss = 3.005903\n",
      "I0410 21:31:41.311438 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 9: 44000, training batch loss = 2.629601, running_avg_loss loss = 3.580705, validation loss = 3.005903\n",
      "2020-04-10 21:31:42 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 44000, train_rouge_l_f = 0.446175, test_rouge_l_f = 0.249515\n",
      "I0410 21:31:42.183973 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 9: 44000, train_rouge_l_f = 0.446175, test_rouge_l_f = 0.249515\n",
      "2020-04-10 21:36:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 45000, training batch loss = 2.708625, running_avg_loss loss = 3.571984, validation loss = 2.988821\n",
      "I0410 21:36:45.750507 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 9: 45000, training batch loss = 2.708625, running_avg_loss loss = 3.571984, validation loss = 2.988821\n",
      "2020-04-10 21:36:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 45000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0045000.tar...\n",
      "I0410 21:36:45.753859 139686077519680 initialize.py:225] Saving model step 45000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0045000.tar...\n",
      "2020-04-10 21:36:48 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 45000, train_rouge_l_f = 0.367851, test_rouge_l_f = 0.115599\n",
      "I0410 21:36:48.343213 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 9: 45000, train_rouge_l_f = 0.367851, test_rouge_l_f = 0.115599\n",
      "2020-04-10 21:41:53 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 46000, training batch loss = 2.342701, running_avg_loss loss = 3.559691, validation loss = 2.979343\n",
      "I0410 21:41:53.715024 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 9: 46000, training batch loss = 2.342701, running_avg_loss loss = 3.559691, validation loss = 2.979343\n",
      "2020-04-10 21:41:55 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 46000, train_rouge_l_f = 0.428982, test_rouge_l_f = 0.117325\n",
      "I0410 21:41:55.911190 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 9: 46000, train_rouge_l_f = 0.428982, test_rouge_l_f = 0.117325\n",
      "2020-04-10 21:47:01 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 47000, training batch loss = 2.917615, running_avg_loss loss = 3.553270, validation loss = 2.971287\n",
      "I0410 21:47:01.275840 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 9: 47000, training batch loss = 2.917615, running_avg_loss loss = 3.553270, validation loss = 2.971287\n",
      "2020-04-10 21:47:02 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 47000, train_rouge_l_f = 0.443126, test_rouge_l_f = 0.268926\n",
      "I0410 21:47:02.449483 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 9: 47000, train_rouge_l_f = 0.443126, test_rouge_l_f = 0.268926\n",
      "2020-04-10 22:32:52 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 9: 47220, test_avg_acc = 0.343876, test_avg_acc = 0.320990\n",
      "I0410 22:32:52.539471 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 9: 47220, test_avg_acc = 0.343876, test_avg_acc = 0.320990\n",
      "2020-04-10 22:36:55 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 48000, training batch loss = 2.750663, running_avg_loss loss = 3.545244, validation loss = 3.007533\n",
      "I0410 22:36:55.540753 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 10: 48000, training batch loss = 2.750663, running_avg_loss loss = 3.545244, validation loss = 3.007533\n",
      "2020-04-10 22:36:56 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 48000, train_rouge_l_f = 0.183642, test_rouge_l_f = 0.646061\n",
      "I0410 22:36:56.419660 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 10: 48000, train_rouge_l_f = 0.183642, test_rouge_l_f = 0.646061\n",
      "2020-04-10 22:41:53 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 49000, training batch loss = 1.507306, running_avg_loss loss = 3.524865, validation loss = 3.001837\n",
      "I0410 22:41:53.941792 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 10: 49000, training batch loss = 1.507306, running_avg_loss loss = 3.524865, validation loss = 3.001837\n",
      "2020-04-10 22:41:55 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 49000, train_rouge_l_f = 0.670409, test_rouge_l_f = 0.081431\n",
      "I0410 22:41:55.781771 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 10: 49000, train_rouge_l_f = 0.670409, test_rouge_l_f = 0.081431\n",
      "2020-04-10 22:46:57 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 50000, training batch loss = 2.403927, running_avg_loss loss = 3.513655, validation loss = 2.993400\n",
      "I0410 22:46:57.449556 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 10: 50000, training batch loss = 2.403927, running_avg_loss loss = 3.513655, validation loss = 2.993400\n",
      "2020-04-10 22:46:57 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 50000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0050000.tar...\n",
      "I0410 22:46:57.451606 139686077519680 initialize.py:225] Saving model step 50000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0050000.tar...\n",
      "2020-04-10 22:47:00 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 50000, train_rouge_l_f = 0.360364, test_rouge_l_f = 0.082340\n",
      "I0410 22:47:00.073541 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 10: 50000, train_rouge_l_f = 0.360364, test_rouge_l_f = 0.082340\n",
      "2020-04-10 22:52:01 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 51000, training batch loss = 2.934186, running_avg_loss loss = 3.507861, validation loss = 2.993880\n",
      "I0410 22:52:01.902482 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 10: 51000, training batch loss = 2.934186, running_avg_loss loss = 3.507861, validation loss = 2.993880\n",
      "2020-04-10 22:52:03 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 51000, train_rouge_l_f = 0.141068, test_rouge_l_f = 0.316949\n",
      "I0410 22:52:03.025555 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 10: 51000, train_rouge_l_f = 0.141068, test_rouge_l_f = 0.316949\n",
      "2020-04-10 23:40:09 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 10: 51942, test_avg_acc = 0.352934, test_avg_acc = 0.326374\n",
      "I0410 23:40:09.813112 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 10: 51942, test_avg_acc = 0.352934, test_avg_acc = 0.326374\n",
      "2020-04-10 23:40:56 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 52000, training batch loss = 2.574594, running_avg_loss loss = 3.498528, validation loss = 2.981474\n",
      "I0410 23:40:56.996757 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 11: 52000, training batch loss = 2.574594, running_avg_loss loss = 3.498528, validation loss = 2.981474\n",
      "2020-04-10 23:40:58 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 52000, train_rouge_l_f = 0.466319, test_rouge_l_f = 0.343981\n",
      "I0410 23:40:58.027142 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 11: 52000, train_rouge_l_f = 0.466319, test_rouge_l_f = 0.343981\n",
      "2020-04-10 23:46:01 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 53000, training batch loss = 3.362743, running_avg_loss loss = 3.497170, validation loss = 3.012150\n",
      "I0410 23:46:01.716987 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 11: 53000, training batch loss = 3.362743, running_avg_loss loss = 3.497170, validation loss = 3.012150\n",
      "2020-04-10 23:46:03 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 53000, train_rouge_l_f = 0.193498, test_rouge_l_f = 0.246258\n",
      "I0410 23:46:03.012092 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 11: 53000, train_rouge_l_f = 0.193498, test_rouge_l_f = 0.246258\n",
      "2020-04-10 23:51:07 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 54000, training batch loss = 2.355069, running_avg_loss loss = 3.485749, validation loss = 3.006016\n",
      "I0410 23:51:07.532437 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 11: 54000, training batch loss = 2.355069, running_avg_loss loss = 3.485749, validation loss = 3.006016\n",
      "2020-04-10 23:51:08 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 54000, train_rouge_l_f = 0.348554, test_rouge_l_f = 0.443479\n",
      "I0410 23:51:08.509369 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 11: 54000, train_rouge_l_f = 0.348554, test_rouge_l_f = 0.443479\n",
      "2020-04-10 23:56:09 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 55000, training batch loss = 2.339084, running_avg_loss loss = 3.474282, validation loss = 3.011118\n",
      "I0410 23:56:09.343592 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 11: 55000, training batch loss = 2.339084, running_avg_loss loss = 3.474282, validation loss = 3.011118\n",
      "2020-04-10 23:56:09 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 55000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0055000.tar...\n",
      "I0410 23:56:09.346578 139686077519680 initialize.py:225] Saving model step 55000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0055000.tar...\n",
      "2020-04-10 23:56:10 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 55000, train_rouge_l_f = 0.346510, test_rouge_l_f = 0.743260\n",
      "I0410 23:56:10.714841 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 11: 55000, train_rouge_l_f = 0.346510, test_rouge_l_f = 0.743260\n",
      "2020-04-11 00:01:10 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 56000, training batch loss = 2.252988, running_avg_loss loss = 3.462069, validation loss = 2.997028\n",
      "I0411 00:01:10.896399 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 11: 56000, training batch loss = 2.252988, running_avg_loss loss = 3.462069, validation loss = 2.997028\n",
      "2020-04-11 00:01:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 56000, train_rouge_l_f = 0.261668, test_rouge_l_f = 0.229810\n",
      "I0411 00:01:12.669364 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 11: 56000, train_rouge_l_f = 0.261668, test_rouge_l_f = 0.229810\n",
      "2020-04-11 00:44:07 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 11: 56664, test_avg_acc = 0.356761, test_avg_acc = 0.312741\n",
      "I0411 00:44:07.515607 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 11: 56664, test_avg_acc = 0.356761, test_avg_acc = 0.312741\n",
      "2020-04-11 00:46:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 57000, training batch loss = 1.990229, running_avg_loss loss = 3.447351, validation loss = 2.998745\n",
      "I0411 00:46:12.673224 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 12: 57000, training batch loss = 1.990229, running_avg_loss loss = 3.447351, validation loss = 2.998745\n",
      "2020-04-11 00:46:14 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 57000, train_rouge_l_f = 0.403993, test_rouge_l_f = 0.277527\n",
      "I0411 00:46:14.729502 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 12: 57000, train_rouge_l_f = 0.403993, test_rouge_l_f = 0.277527\n",
      "2020-04-11 00:51:23 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 58000, training batch loss = 2.488980, running_avg_loss loss = 3.437767, validation loss = 3.023649\n",
      "I0411 00:51:23.450919 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 12: 58000, training batch loss = 2.488980, running_avg_loss loss = 3.437767, validation loss = 3.023649\n",
      "2020-04-11 00:51:24 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 58000, train_rouge_l_f = 0.247325, test_rouge_l_f = 0.174754\n",
      "I0411 00:51:24.916190 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 12: 58000, train_rouge_l_f = 0.247325, test_rouge_l_f = 0.174754\n",
      "2020-04-11 00:56:31 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 59000, training batch loss = 1.801357, running_avg_loss loss = 3.421403, validation loss = 3.025192\n",
      "I0411 00:56:31.693894 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 12: 59000, training batch loss = 1.801357, running_avg_loss loss = 3.421403, validation loss = 3.025192\n",
      "2020-04-11 00:56:33 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 59000, train_rouge_l_f = 0.391911, test_rouge_l_f = 0.226241\n",
      "I0411 00:56:33.313701 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 12: 59000, train_rouge_l_f = 0.391911, test_rouge_l_f = 0.226241\n",
      "2020-04-11 01:01:41 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 60000, training batch loss = 1.545611, running_avg_loss loss = 3.402645, validation loss = 3.014273\n",
      "I0411 01:01:41.103467 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 12: 60000, training batch loss = 1.545611, running_avg_loss loss = 3.402645, validation loss = 3.014273\n",
      "2020-04-11 01:01:41 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 60000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0060000.tar...\n",
      "I0411 01:01:41.105969 139686077519680 initialize.py:225] Saving model step 60000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0060000.tar...\n",
      "2020-04-11 01:01:43 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 60000, train_rouge_l_f = 0.369970, test_rouge_l_f = 0.234158\n",
      "I0411 01:01:43.675974 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 12: 60000, train_rouge_l_f = 0.369970, test_rouge_l_f = 0.234158\n",
      "2020-04-11 01:06:57 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 61000, training batch loss = 2.407147, running_avg_loss loss = 3.392690, validation loss = 3.022999\n",
      "I0411 01:06:57.149103 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 12: 61000, training batch loss = 2.407147, running_avg_loss loss = 3.392690, validation loss = 3.022999\n",
      "2020-04-11 01:06:58 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 61000, train_rouge_l_f = 0.389857, test_rouge_l_f = 0.286464\n",
      "I0411 01:06:58.119605 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 12: 61000, train_rouge_l_f = 0.389857, test_rouge_l_f = 0.286464\n",
      "2020-04-11 01:50:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 12: 61386, test_avg_acc = 0.372357, test_avg_acc = 0.321374\n",
      "I0411 01:50:04.499032 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 12: 61386, test_avg_acc = 0.372357, test_avg_acc = 0.321374\n",
      "2020-04-11 01:53:23 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 62000, training batch loss = 2.422099, running_avg_loss loss = 3.382984, validation loss = 3.057769\n",
      "I0411 01:53:23.956110 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 13: 62000, training batch loss = 2.422099, running_avg_loss loss = 3.382984, validation loss = 3.057769\n",
      "2020-04-11 01:53:25 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 62000, train_rouge_l_f = 0.295283, test_rouge_l_f = 0.397089\n",
      "I0411 01:53:25.139915 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 13: 62000, train_rouge_l_f = 0.295283, test_rouge_l_f = 0.397089\n",
      "2020-04-11 01:58:26 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 63000, training batch loss = 1.556337, running_avg_loss loss = 3.364718, validation loss = 3.068727\n",
      "I0411 01:58:26.442741 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 13: 63000, training batch loss = 1.556337, running_avg_loss loss = 3.364718, validation loss = 3.068727\n",
      "2020-04-11 01:58:27 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 63000, train_rouge_l_f = 0.463645, test_rouge_l_f = 0.398569\n",
      "I0411 01:58:27.855775 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 13: 63000, train_rouge_l_f = 0.463645, test_rouge_l_f = 0.398569\n",
      "2020-04-11 02:03:28 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 64000, training batch loss = 2.710247, running_avg_loss loss = 3.358173, validation loss = 3.054599\n",
      "I0411 02:03:28.146800 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 13: 64000, training batch loss = 2.710247, running_avg_loss loss = 3.358173, validation loss = 3.054599\n",
      "2020-04-11 02:03:29 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 64000, train_rouge_l_f = 0.201565, test_rouge_l_f = 0.503298\n",
      "I0411 02:03:29.345882 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 13: 64000, train_rouge_l_f = 0.201565, test_rouge_l_f = 0.503298\n",
      "2020-04-11 02:08:32 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 65000, training batch loss = 2.221903, running_avg_loss loss = 3.346811, validation loss = 3.041023\n",
      "I0411 02:08:32.783890 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 13: 65000, training batch loss = 2.221903, running_avg_loss loss = 3.346811, validation loss = 3.041023\n",
      "2020-04-11 02:08:32 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 65000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0065000.tar...\n",
      "I0411 02:08:32.786431 139686077519680 initialize.py:225] Saving model step 65000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0065000.tar...\n",
      "2020-04-11 02:08:34 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 65000, train_rouge_l_f = 0.555933, test_rouge_l_f = 0.305572\n",
      "I0411 02:08:34.801155 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 13: 65000, train_rouge_l_f = 0.555933, test_rouge_l_f = 0.305572\n",
      "2020-04-11 02:13:38 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 66000, training batch loss = 2.365025, running_avg_loss loss = 3.336993, validation loss = 3.030313\n",
      "I0411 02:13:38.008052 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 13: 66000, training batch loss = 2.365025, running_avg_loss loss = 3.336993, validation loss = 3.030313\n",
      "2020-04-11 02:13:38 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 66000, train_rouge_l_f = 0.412411, test_rouge_l_f = 0.455479\n",
      "I0411 02:13:38.936681 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 13: 66000, train_rouge_l_f = 0.412411, test_rouge_l_f = 0.455479\n",
      "2020-04-11 02:53:32 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 13: 66108, test_avg_acc = 0.378007, test_avg_acc = 0.311304\n",
      "I0411 02:53:32.798748 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 13: 66108, test_avg_acc = 0.378007, test_avg_acc = 0.311304\n",
      "2020-04-11 02:58:05 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 67000, training batch loss = 1.167843, running_avg_loss loss = 3.315301, validation loss = 3.074269\n",
      "I0411 02:58:05.387666 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 14: 67000, training batch loss = 1.167843, running_avg_loss loss = 3.315301, validation loss = 3.074269\n",
      "2020-04-11 02:58:06 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 67000, train_rouge_l_f = 0.623259, test_rouge_l_f = 0.467301\n",
      "I0411 02:58:06.844232 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 14: 67000, train_rouge_l_f = 0.623259, test_rouge_l_f = 0.467301\n",
      "2020-04-11 03:03:03 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 68000, training batch loss = 2.832033, running_avg_loss loss = 3.310469, validation loss = 3.083954\n",
      "I0411 03:03:03.519749 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 14: 68000, training batch loss = 2.832033, running_avg_loss loss = 3.310469, validation loss = 3.083954\n",
      "2020-04-11 03:03:04 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 68000, train_rouge_l_f = 0.339982, test_rouge_l_f = 0.253705\n",
      "I0411 03:03:04.836187 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 14: 68000, train_rouge_l_f = 0.339982, test_rouge_l_f = 0.253705\n",
      "2020-04-11 03:08:09 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 69000, training batch loss = 1.299803, running_avg_loss loss = 3.290362, validation loss = 3.075220\n",
      "I0411 03:08:09.822798 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 14: 69000, training batch loss = 1.299803, running_avg_loss loss = 3.290362, validation loss = 3.075220\n",
      "2020-04-11 03:08:10 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 69000, train_rouge_l_f = 0.508336, test_rouge_l_f = 0.708656\n",
      "I0411 03:08:10.749638 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 14: 69000, train_rouge_l_f = 0.508336, test_rouge_l_f = 0.708656\n",
      "2020-04-11 03:13:17 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 70000, training batch loss = 1.113584, running_avg_loss loss = 3.268594, validation loss = 3.094753\n",
      "I0411 03:13:17.522497 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 14: 70000, training batch loss = 1.113584, running_avg_loss loss = 3.268594, validation loss = 3.094753\n",
      "2020-04-11 03:13:17 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 70000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0070000.tar...\n",
      "I0411 03:13:17.525306 139686077519680 initialize.py:225] Saving model step 70000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0070000.tar...\n",
      "2020-04-11 03:13:19 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 70000, train_rouge_l_f = 0.563649, test_rouge_l_f = 0.451123\n",
      "I0411 03:13:19.355936 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 14: 70000, train_rouge_l_f = 0.563649, test_rouge_l_f = 0.451123\n",
      "2020-04-11 03:59:21 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 14: 70830, test_avg_acc = 0.393124, test_avg_acc = 0.315562\n",
      "I0411 03:59:21.072791 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:51] epoch 14: 70830, test_avg_acc = 0.393124, test_avg_acc = 0.315562\n",
      "2020-04-11 04:00:35 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 71000, training batch loss = 1.069131, running_avg_loss loss = 3.246599, validation loss = 3.106004\n",
      "I0411 04:00:35.840957 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 15: 71000, training batch loss = 1.069131, running_avg_loss loss = 3.246599, validation loss = 3.106004\n",
      "2020-04-11 04:00:37 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 71000, train_rouge_l_f = 0.592676, test_rouge_l_f = 0.217258\n",
      "I0411 04:00:37.946247 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 15: 71000, train_rouge_l_f = 0.592676, test_rouge_l_f = 0.217258\n",
      "2020-04-11 04:05:39 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 72000, training batch loss = 2.285491, running_avg_loss loss = 3.236988, validation loss = 3.149573\n",
      "I0411 04:05:39.788001 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 15: 72000, training batch loss = 2.285491, running_avg_loss loss = 3.236988, validation loss = 3.149573\n",
      "2020-04-11 04:05:40 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 72000, train_rouge_l_f = 0.428379, test_rouge_l_f = 0.542440\n",
      "I0411 04:05:40.626299 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 15: 72000, train_rouge_l_f = 0.428379, test_rouge_l_f = 0.542440\n",
      "2020-04-11 04:10:40 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 73000, training batch loss = 1.551968, running_avg_loss loss = 3.220138, validation loss = 3.121997\n",
      "I0411 04:10:40.201388 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 15: 73000, training batch loss = 1.551968, running_avg_loss loss = 3.220138, validation loss = 3.121997\n",
      "2020-04-11 04:10:41 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 73000, train_rouge_l_f = 0.538472, test_rouge_l_f = 0.214063\n",
      "I0411 04:10:41.462679 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 15: 73000, train_rouge_l_f = 0.538472, test_rouge_l_f = 0.214063\n",
      "2020-04-11 04:15:44 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 74000, training batch loss = 2.696828, running_avg_loss loss = 3.214905, validation loss = 3.128423\n",
      "I0411 04:15:44.418832 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 15: 74000, training batch loss = 2.696828, running_avg_loss loss = 3.214905, validation loss = 3.128423\n",
      "2020-04-11 04:15:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 74000, train_rouge_l_f = 0.502494, test_rouge_l_f = 0.186292\n",
      "I0411 04:15:45.972509 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 15: 74000, train_rouge_l_f = 0.502494, test_rouge_l_f = 0.186292\n",
      "2020-04-11 04:20:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 75000, training batch loss = 2.472024, running_avg_loss loss = 3.207476, validation loss = 3.136319\n",
      "I0411 04:20:45.233420 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:26] epoch 15: 75000, training batch loss = 2.472024, running_avg_loss loss = 3.207476, validation loss = 3.136319\n",
      "2020-04-11 04:20:45 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - Saving model step 75000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0075000.tar...\n",
      "I0411 04:20:45.235664 139686077519680 initialize.py:225] Saving model step 75000 to model/saved_models/Pointer_generator_glove_Intra_Atten_Key_Atten/0075000.tar...\n",
      "2020-04-11 04:20:46 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - epoch 15: 75000, train_rouge_l_f = 0.225974, test_rouge_l_f = 0.382487\n",
      "I0411 04:20:46.907292 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:47] epoch 15: 75000, train_rouge_l_f = 0.225974, test_rouge_l_f = 0.382487\n",
      "2020-04-11 04:23:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - ------Training END--------\n",
      "I0411 04:23:12.064970 139686077519680 <ipython-input-9-a2ef7f0cc4ac>:57] ------Training END--------\n",
      "2020-04-11 04:23:12 - Pointer_generator_glove_Intra_Atten_Key_Atten - INFO: - logger已關閉\n",
      "I0411 04:23:12.066829 139686077519680 train_util.py:129] logger已關閉\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA error: device-side assert triggered\n"
     ]
    }
   ],
   "source": [
    "write_train_para(writer, config)\n",
    "logger.info('------Training START--------')\n",
    "running_avg_loss = 0\n",
    "sum_total_reward = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(config.max_epochs):\n",
    "        for batch in train_loader:\n",
    "            step += 1\n",
    "            mle_loss = train_one(model, config, batch)\n",
    "            if config.train_rl:\n",
    "                rl_loss, batch_reward = train_one_RL(model, config, batch)             \n",
    "                writer.add_scalars('scalar/RL_Loss',  \n",
    "                       {'rl_loss': rl_loss\n",
    "                       }, step)\n",
    "                writer.add_scalars('scalar/Reward',  \n",
    "                       {'batch_reward': batch_reward\n",
    "                       }, step)\n",
    "                \n",
    "                if step%1000 == 0 :\n",
    "                    logger.info('epoch %d: %d, RL_Loss = %f, batch_reward = %f'\n",
    "                                    % (epoch, step, rl_loss, batch_reward))\n",
    "                sum_total_reward += batch_reward\n",
    "            else:\n",
    "                rl_loss = T.FloatTensor([0]).cuda()\n",
    "            (config.mle_weight * mle_loss + config.rl_weight * rl_loss).backward()  # 反向传播，计算当前梯度\n",
    "\n",
    "            '''梯度累加就是，每次获取1个batch的数据，计算1次梯度，梯度不清空'''\n",
    "            if step % (config.gradient_accum) == 0: # gradient accumulation\n",
    "    #             clip_grad_norm_(model.parameters(), 5.0)                      \n",
    "                optimizer.step() # 根据累计的梯度更新网络参数\n",
    "                optimizer.zero_grad() # 清空过往梯度 \n",
    "\n",
    "            if step%1000 == 0 :\n",
    "                with T.autograd.no_grad():\n",
    "                    train_batch_loss = mle_loss.item()\n",
    "                    val_avg_loss = validate(validate_loader, config, model) # call batch by validate_loader\n",
    "                    running_avg_loss = calc_running_avg_loss(train_batch_loss, running_avg_loss)\n",
    "                    running_avg_reward = sum_total_reward / step\n",
    "                    logger.info('epoch %d: %d, training batch loss = %f, running_avg_loss loss = %f, validation loss = %f'\n",
    "                                % (epoch, step, train_batch_loss, running_avg_loss, val_avg_loss))\n",
    "                    writer.add_scalars('scalar/Loss',  \n",
    "                       {'train_batch_loss': train_batch_loss\n",
    "                       }, step)\n",
    "                    writer.add_scalars('scalar_avg/loss',  \n",
    "                       {'train_avg_loss': running_avg_loss,\n",
    "                        'test_avg_loss': val_avg_loss\n",
    "                       }, step)\n",
    "                    if running_avg_reward > 0:\n",
    "                        logger.info('epoch %d: %d, running_avg_reward = %f'\n",
    "                                % (epoch, step, running_avg_reward))\n",
    "                        writer.add_scalars('scalar_avg/Reward',  \n",
    "                           {'running_avg_reward': running_avg_reward\n",
    "                           }, step)\n",
    "\n",
    "            if step%5000 == 0:\n",
    "                save_model(config, logger, model, optimizer, step, vocab, running_avg_loss, \\\n",
    "                           r_loss=0, title = loggerName)\n",
    "            if step%1000 == 0 and step > 0:\n",
    "                train_rouge_l_f = decode(writer, logger, step, config, model, batch, mode = 'train') # call batch by validate_loader\n",
    "                test_rouge_l_f = decode(writer, logger, step, config, model, validate_loader, mode = 'test') # call batch by validate_loader\n",
    "\n",
    "                writer.add_scalars('scalar/Rouge-L',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, step)\n",
    "                logger.info('epoch %d: %d, train_rouge_l_f = %f, test_rouge_l_f = %f'\n",
    "                                % (epoch, step, train_rouge_l_f, test_rouge_l_f))\n",
    "\n",
    "        train_avg_acc = avg_acc(writer, logger, epoch, config, model, train_loader, mode = 'train')\n",
    "        test_avg_acc = avg_acc(writer, logger, epoch, config, model, validate_loader, mode = 'test')\n",
    "        logger.info('epoch %d: %d, test_avg_acc = %f, test_avg_acc = %f' % (epoch, step, train_avg_acc, test_avg_acc))\n",
    "except Excepation as e:\n",
    "        print(e)\n",
    "else:\n",
    "    logger.info(u'------Training SUCCESS--------')  \n",
    "finally:\n",
    "    logger.info(u'------Training END--------')                \n",
    "    removeLogger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
