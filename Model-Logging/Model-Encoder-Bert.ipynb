{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0226 14:40:58.097055 139925006210880 file_utils.py:35] PyTorch version 1.3.1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 2 tokens\n",
      "We have added 3 tokens\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "import torch as T\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from model2 import Model\n",
    "\n",
    "\n",
    "from data_util import config\n",
    "from data_util import bert_data as data\n",
    "from data_util.bert_batcher import Batcher\n",
    "from data_util.bert_data import Vocab\n",
    "\n",
    "# from data_util import data\n",
    "# from data_util.batcher import Batcher\n",
    "# from data_util.data import Vocab\n",
    "\n",
    "\n",
    "from train_util import *\n",
    "from torch.distributions import Categorical\n",
    "from rouge import Rouge\n",
    "from numpy import random\n",
    "import argparse\n",
    "import torchsnooper\n",
    "import logging\n",
    "transformers_logger = logging.getLogger(\"transformers.tokenization_utils\")\n",
    "transformers_logger.setLevel(logging.ERROR)\n",
    "transformers_logger.disabled = True\n",
    "\n",
    "# -------- Test Packages -------\n",
    "from bert_beam_search import *\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# from pytorch_pretrained_bert import BertModel\n",
    "from transformers import BertModel, BertTokenizer \n",
    "from transformers import TransfoXLTokenizer, TransfoXLModel, TransfoXLConfig\n",
    "\n",
    "config.batch_size = 1\n",
    "config.emb_dim = 768\n",
    "# config.hidden_dim = 512\n",
    "config.hidden_dim = 768\n",
    "config.max_enc_steps = 512\n",
    "config.lr = 0.0001 # 0.001\n",
    "\n",
    "# config.keywords = \"TextRank_keywords\"\n",
    "# config.max_key_num = 8\n",
    "\n",
    "config.intra_encoder = False\n",
    "config.intra_decoder = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def getLogger(loggerName, loggerPath):\n",
    "    # 設置logger\n",
    "    logger = logging.getLogger(loggerName)  # 不加名稱設置root logger\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s: - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    logging.Filter(loggerName)\n",
    "\n",
    "    # 使用FileHandler輸出到文件\n",
    "    directory = os.path.dirname(loggerPath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    fh = logging.FileHandler(loggerPath)\n",
    "\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # 使用StreamHandler輸出到屏幕\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    ch.setFormatter(formatter)\n",
    "    # 添加兩個Handler\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    # Handler只啟動一次\n",
    "    # 設置logger\n",
    "    logger.info(u'logger已啟動')\n",
    "    return logger\n",
    "\n",
    "def removeLogger(logger):\n",
    "    logger.info(u'logger已關閉')\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_words :  shot good , camera love , light outdoor\n"
     ]
    }
   ],
   "source": [
    "def test_batch():\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                           batch_size=config.batch_size, single_pass=False)\n",
    "    batch = batcher.next_batch()\n",
    "    # with torchsnooper.snoop():\n",
    "    while batch is not None:\n",
    "        example_list = batch.example_list\n",
    "        for ex in example_list:\n",
    "            r = str(ex.original_review)\n",
    "            s = str(ex.original_summary)\n",
    "            k = str(ex.key_words)\n",
    "            sent = ex.original_summary_sents\n",
    "#             print(\"original_review_sents:\", r)\n",
    "#             print(\"original_summary_sents : \", s)\n",
    "            print(\"key_words : \", k)\n",
    "#             print('------------------------------------------------------------\\n')\n",
    "        batch = batcher.next_batch()        \n",
    "        break\n",
    "test_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bin Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 29540\n",
      "\n",
      "test : 5847\n",
      "\n",
      "valid : 4243\n",
      "\n"
     ]
    }
   ],
   "source": [
    " with open(config.bin_info,'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    [print(line) for line in lines]\n",
    "    train_num = int(lines[0].split(\":\")[1])\n",
    "    test_num = int(lines[1].split(\":\")[1])\n",
    "    val_num = int(lines[2].split(\":\")[1])\n",
    "    # f.write(\"train : %s\\n\"%(len(flit_key_train_df)))\n",
    "    # f.write(\"test : %s\\n\"%(len(flit_key_test_df)))\n",
    "    # f.write(\"valid : %s\\n\"%(len(flit_key_valid_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View model summary\n",
    "#### 只有torchsummaryX成功\n",
    "#### 日後將以此模擬呈現結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0226 14:41:03.344093 139925006210880 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/eagleuser/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "I0226 14:41:03.345723 139925006210880 configuration_utils.py:199] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0226 14:41:04.216581 139925006210880 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/eagleuser/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test success\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "from model2 import Encoder,Model\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "encoder = Encoder().to(device)    \n",
    "\n",
    "vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                       batch_size=config.batch_size, single_pass=False)\n",
    "batch = batcher.next_batch()\n",
    "enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "     \n",
    "# bert_model = TransfoXLModel(xl_config) # 更改參數以傳入TransfoXLModel\n",
    "# bert_model = get_cuda(TransfoXLModel.from_pretrained('transfo-xl-wt103'))\n",
    "# all_hidden_states, _ = bert_model(enc_batch)[-2:]\n",
    "   \n",
    "# summary(encoder, enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "\n",
    "print('test success')\n",
    "# model = Model(False,'word2Vec',vocab)\n",
    "# enc_out, enc_hidden = model.encoder(enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "# print(enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0226 14:41:10.812372 139925006210880 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/eagleuser/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "I0226 14:41:10.814207 139925006210880 configuration_utils.py:199] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0226 14:41:11.691090 139925006210880 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/eagleuser/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_hidden torch.Size([1, 106, 768])\n",
      "s_t torch.Size([1, 768])\n",
      "out torch.Size([1, 2304])\n",
      "V 2304 768\n",
      "out torch.Size([1, 768])\n",
      "V1 768 50000\n",
      "---------------------------\n",
      "s_t torch.Size([1, 768])\n",
      "out torch.Size([1, 2304])\n",
      "V 2304 768\n",
      "out torch.Size([1, 768])\n",
      "V1 768 50000\n",
      "---------------------------\n",
      "===============================================================================\n",
      "                            Kernel Shape   Output Shape     Params  Mult-Adds\n",
      "Layer                                                                        \n",
      "0_x_context                  [2304, 768]       [1, 768]   1.77024M  1.769472M\n",
      "1_lstm                                 -       [1, 768]  4.724736M  4.718592M\n",
      "2_enc_attention.Linear_W_h    [768, 768]  [1, 106, 768]   589.824k   589.824k\n",
      "3_enc_attention.Linear_W_s   [1536, 768]       [1, 768]  1.180416M  1.179648M\n",
      "4_enc_attention.Linear_v        [768, 1]    [1, 106, 1]      768.0      768.0\n",
      "5_dec_attention                        -       [1, 768]          -          -\n",
      "6_p_gen_linear                 [3840, 1]         [1, 1]     3.841k      3.84k\n",
      "7_V                          [2304, 768]       [1, 768]   1.77024M  1.769472M\n",
      "8_V1                        [768, 50000]     [1, 50000]     38.45M      38.4M\n",
      "-------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params          48.490065M\n",
      "Trainable params      48.490065M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             48.431616M\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "from model2 import Decoder,Model\n",
    "from train_util import *\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "# decoder = Decoder().to(device)    \n",
    "\n",
    "model = Model(False,'word2Vec',vocab)\n",
    "# vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                        batch_size=config.batch_size, single_pass=False)\n",
    "# batch = batcher.next_batch()\n",
    "# enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# enc_batch = model.embeds(enc_batch) #Get embeddings for encoder input\n",
    "# enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "# encoder = Encoder().to(device)   \n",
    "vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                       batch_size=config.batch_size, single_pass=False)\n",
    "batch = batcher.next_batch()\n",
    "enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# print('enc_batch',enc_batch.shape)\n",
    "# print(enc_batch[0][:5])\n",
    "enc_out, enc_hidden = model.encoder(enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "# print('enc_out',enc_out.shape)\n",
    "# print('enc_hidden',enc_hidden.shape)\n",
    "# print('encoder success')  \n",
    "\n",
    "start_decoding = vocab.word2id(bert_data.START_DECODING) # start_decoding = 30524\n",
    "stop_decoding = vocab.word2id(bert_data.STOP_DECODING) # stop_decoding = 30525\n",
    "    \n",
    "# train_batch_MLE\n",
    "dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n",
    "step_losses = []\n",
    "# s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n",
    "s_t = enc_hidden\n",
    "# x_t 為decoder每一個time step 的batch input\n",
    "x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(start_decoding)) # initial batch decode word                            #Input to the decoder\n",
    "prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in DEEP REINFORCED MODEL - https://arxiv.org/pdf/1705.04304.pdf)\n",
    "sum_temporal_srcs = None     \n",
    "unk_id = vocab.word2id(data.PAD_TOKEN)\n",
    "\n",
    "# print('x_t',x_t.shape)\n",
    "# print(vocab.vocab)     \n",
    "print('enc_hidden',enc_hidden.shape)\n",
    "\n",
    "for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "#     T.rand(len(enc_out)) tensor([0.6797, 0.7603])\n",
    "    use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "    # use_gound_truth * dec_batch[:, t] : 為ground true time step token\n",
    "    # (1 - use_gound_truth) * x_t : 為previous time step token\n",
    "    x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities   \n",
    "    x_t, _ = model.encoder(x_t, None, None) # encoder summary (ok)\n",
    "    enc_key_batch = model.embeds(enc_key_batch)  \n",
    "\n",
    "    # use the output vector corresponding to [CLS] to initialize the hidden state and cell state of LSTM decoder\n",
    "#     print('s_t',len(s_t),s_t[0].shape,s_t[1].shape)\n",
    "    s_t = s_t[:,0,:] \n",
    "#     print('s_t',s_t.shape)\n",
    "    \n",
    "# #     final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "    final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(\n",
    "    x_t, s_t, enc_out, enc_padding_mask, context, \n",
    "    extra_zeros,enc_batch_extend_vocab,sum_temporal_srcs, prev_s, \n",
    "    enc_key_batch, enc_key_padding_mask)    \n",
    "    \n",
    "    target = target_batch[:, t]\n",
    "    log_probs = T.log(final_dist + config.eps)\n",
    "    step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=unk_id)\n",
    "    step_losses.append(step_loss)\n",
    "#     x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "    \n",
    "#     is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "#     x_t = (1 - is_oov) * x_t.detach() + (is_oov) * unk_id  # Replace OOVs with [UNK] token\n",
    "  \n",
    "\n",
    "    decoder_summary = summary(model.decoder, x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s,enc_key_batch, enc_key_lens) # encoder summary\n",
    "    break\n",
    "# decoder_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummaryX import summary\n",
    "class Train(object):\n",
    "    def __init__(self, opt, vocab):\n",
    "#         self.vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "        self.vocab = vocab\n",
    "        self.train_batcher = Batcher(config.train_data_path, self.vocab, mode='train',\n",
    "                               batch_size=config.batch_size, single_pass=False)\n",
    "        self.test_batcher = Batcher(config.test_data_path, self.vocab, mode='eval',\n",
    "                               batch_size=config.batch_size, single_pass=True)\n",
    "        self.opt = opt\n",
    "        self.start_id = self.vocab.word2id(data.START_DECODING)\n",
    "        self.end_id = self.vocab.word2id(data.STOP_DECODING)\n",
    "        self.pad_id = self.vocab.word2id(data.PAD_TOKEN)\n",
    "        self.unk_id = self.vocab.word2id(data.UNKNOWN_TOKEN)\n",
    "        time.sleep(5)\n",
    "\n",
    "    def save_model(self, iter, loss, r_loss):\n",
    "        if not os.path.exists(config.save_model_path):\n",
    "            os.makedirs(config.save_model_path)\n",
    "        file_path = \"/%07d_%.2f_%.2f.tar\" % (iter, loss, r_loss)\n",
    "        save_path = config.save_model_path + '/%s' % (self.opt.word_emb_type)\n",
    "        if not os.path.isdir(save_path): os.mkdir(save_path)\n",
    "        save_path = save_path + file_path\n",
    "        T.save({\n",
    "            \"iter\": iter + 1,\n",
    "            \"model_dict\": self.model.state_dict(),\n",
    "            \"trainer_dict\": self.trainer.state_dict()\n",
    "        }, save_path)\n",
    "        return file_path\n",
    "\n",
    "    def setup_train(self):\n",
    "        # BERT\n",
    "#         self.bert_model = get_cuda(BertModel.from_pretrained('bert-base-uncased'))\n",
    "        self.model = Model(opt.pre_train_emb, opt.word_emb_type, self.vocab)\n",
    "#         logger.info(str(self.model))\n",
    "\n",
    "        self.model = get_cuda(self.model)\n",
    "        device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")  # PyTorch v0.4.0\n",
    "        if opt.multi_device:\n",
    "            if T.cuda.device_count() > 1:\n",
    "                #                 print(\"Let's use\", T.cuda.device_count(), \"GPUs!\")\n",
    "                logger.info(\"Let's use \" + str(T.cuda.device_count()) + \" GPUs!\")\n",
    "                self.model = nn.DataParallel(self.model, list(range(T.cuda.device_count()))).cuda()\n",
    "\n",
    "        if isinstance(self.model, nn.DataParallel):\n",
    "            self.model = self.model.module\n",
    "        self.model.to(device)\n",
    "        #         self.model.eval()\n",
    "\n",
    "        self.trainer = T.optim.Adam(self.model.parameters(), lr=config.lr)\n",
    "        start_iter = 0\n",
    "        if self.opt.load_model is not None:\n",
    "#             load_model_path = os.path.join(config.save_model_path, self.opt.load_model)\n",
    "            load_model_path = config.save_model_path + self.opt.load_model\n",
    "            print(load_model_path)\n",
    "#             print('xxxx')\n",
    "            checkpoint = T.load(load_model_path)\n",
    "            start_iter = checkpoint[\"iter\"]\n",
    "            self.model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "            self.trainer.load_state_dict(checkpoint[\"trainer_dict\"])\n",
    "            #             print(\"Loaded model at \" + load_model_path)\n",
    "            logger.info(\"Loaded model at \" + load_model_path)\n",
    "        if self.opt.new_lr is not None:\n",
    "            self.trainer = T.optim.Adam(self.model.parameters(), lr=self.opt.new_lr)\n",
    "        return start_iter\n",
    "\n",
    "    def train_batch_MLE(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, enc_key_batch, enc_key_lens, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(\n",
    "            batch)  # Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "#         s_t = (enc_hidden[0], enc_hidden[1])  # Decoder hidden states\n",
    "        s_t = enc_hidden\n",
    "#         s_t = s_t[0]\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        try:\n",
    "#             print('-----------------')\n",
    "            for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "                use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()  # Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "                x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t  # Select decoder input based on use_ground_truth probabilities\n",
    "#                 x_t = self.model.embeds(x_t)   \n",
    "                x_t, _ = self.model.encoder(x_t, None, None) # encoder summary (ok)\n",
    "                \n",
    "                enc_key_batch = enc_key_batch.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "                enc_key_batch = self.model.embeds(enc_key_batch)  \n",
    "                \n",
    "                # use the output vector corresponding to [CLS] to initialize the hidden state and cell state of LSTM decoder\n",
    "#                 s_t = s_t[0]\n",
    "#                 print(len(s_t))\n",
    "#                 print(s_t[0].shape,s_t[1].shape)\n",
    "#                 s_t = s_t[:,0,:]\n",
    "#                 print(s_t.shape)\n",
    "                \n",
    "#                 print('s_t',len(s_t),s_t[0].shape,s_t[1].shape)\n",
    "                s_t = s_t[:,0,:] \n",
    "#                 print('s_t',s_t.shape)\n",
    "                \n",
    "\n",
    "                \n",
    "                final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask,\n",
    "                                                                                          ct_e, extra_zeros,\n",
    "                                                                                          enc_batch_extend_vocab,\n",
    "                                                                                          sum_temporal_srcs, prev_s, enc_key_batch, enc_key_lens)\n",
    "                target = target_batch[:, t]\n",
    "                log_probs = T.log(final_dist + config.eps)\n",
    "                step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=self.pad_id)\n",
    "                step_losses.append(step_loss)\n",
    "                x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "\n",
    "                is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "                x_t = (1 - is_oov) * x_t.detach() + (is_oov) * self.unk_id  # Replace OOVs with [UNK] token\n",
    "                print('finish inner loop')                \n",
    "\n",
    "        except KeyError as e:\n",
    "            logger.error('xxxxxxxxxxx')\n",
    "            traceback = sys.exc_info()[2]\n",
    "            logger.error(sys.exc_info())\n",
    "            logger.error(traceback.tb_lineno)\n",
    "            logger.error(e)\n",
    "            logger.error('xxxxxxxxxxx')\n",
    "\n",
    "                \n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)  # unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens  # Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)  # Average batch loss\n",
    "        return mle_loss\n",
    "\n",
    "    def train_batch_RL(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab,\n",
    "                       review_oovs, greedy):\n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param review_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        s_t = enc_hidden  # Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))  # Input to the decoder\n",
    "        prev_s = None  # Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None  # Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []  # Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []  # Stores padding masks of generated samples\n",
    "        log_probs = []  # Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(\n",
    "            1))  # Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = self.model.embeds(x_t)\n",
    "            probs, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e,\n",
    "                                                                             extra_zeros, enc_batch_extend_vocab,\n",
    "                                                                             sum_temporal_srcs, prev_s)\n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs)\n",
    "                x_t = multi_dist.sample()  # perform multinomial sampling\n",
    "                log_prob = multi_dist.log_prob(x_t)\n",
    "                log_probs.append(log_prob)\n",
    "            else:\n",
    "                _, x_t = T.max(probs, dim=1)  # perform greedy sampling\n",
    "            x_t = x_t.detach()\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))  # Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1  # If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "            mask[(mask == 1) + (\n",
    "            x_t == self.end_id) == 2] = 0  # If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "            is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t + (is_oov) * self.unk_id  # Replace OOVs with [UNK] token\n",
    "\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "        if greedy is False:  # If multinomial based sampling, compute log probabilites of sampled words\n",
    "            log_probs = T.stack(log_probs, dim=1)\n",
    "            log_probs = log_probs * decoder_padding_mask  # Not considering sampled words with padding mask = 0\n",
    "            lens = T.sum(decoder_padding_mask, dim=1)  # Length of sampled sentence\n",
    "            log_probs = T.sum(log_probs,\n",
    "                              dim=1) / lens  # (bs,)                                     #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy()\n",
    "            oovs = review_oovs[i]\n",
    "            S = data.outputids2words(id_list, self.vocab, oovs)  # Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:  # If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "\n",
    "        return decoded_strs, log_probs \n",
    "\n",
    "    def reward_function(self, decoded_sents, original_sents):\n",
    "        rouge = Rouge()\n",
    "        try:\n",
    "            scores = rouge.get_scores(decoded_sents, original_sents)\n",
    "        except Exception:\n",
    "            #             print(\"Rouge failed for multi sentence evaluation.. Finding exact pair\")\n",
    "            logger.info(\"Rouge failed for multi sentence evaluation.. Finding exact pair\")\n",
    "            scores = []\n",
    "            for i in range(len(decoded_sents)):\n",
    "                try:\n",
    "                    score = rouge.get_scores(decoded_sents[i], original_sents[i])\n",
    "                except Exception:\n",
    "                    #                     print(\"Error occured at:\")\n",
    "                    #                     print(\"decoded_sents:\", decoded_sents[i])\n",
    "                    #                     print(\"original_sents:\", original_sents[i])\n",
    "                    logger.info(\"Error occured at:\")\n",
    "                    logger.info(\"decoded_sents:\", decoded_sents[i])\n",
    "                    logger.info(\"original_sents:\", original_sents[i])\n",
    "                    score = [{\"rouge-l\": {\"f\": 0.0}}]\n",
    "                scores.append(score[0])\n",
    "        rouge_l_f1 = [score[\"rouge-l\"][\"f\"] for score in scores]\n",
    "        avg_rouge_l_f1 = sum(rouge_l_f1) / len(rouge_l_f1)\n",
    "        rouge_l_f1 = get_cuda(T.FloatTensor(rouge_l_f1))\n",
    "        return rouge_l_f1, scores, avg_rouge_l_f1\n",
    "\n",
    "    # def write_to_file(self, decoded, max, original, sample_r, baseline_r, iter):\n",
    "    #     with open(\"temp.txt\", \"w\") as f:\n",
    "    #         f.write(\"iter:\"+str(iter)+\"\\n\")\n",
    "    #         for i in range(len(original)):\n",
    "    #             f.write(\"dec: \"+decoded[i]+\"\\n\")\n",
    "    #             f.write(\"max: \"+max[i]+\"\\n\")\n",
    "    #             f.write(\"org: \"+original[i]+\"\\n\")\n",
    "    #             f.write(\"Sample_R: %.4f, Baseline_R: %.4f\\n\\n\"%(sample_r[i].item(), baseline_r[i].item()))\n",
    "\n",
    "\n",
    "    def train_one_batch(self, batch,test_batch, iter):\n",
    "        ans_list, batch_scores = None, None\n",
    "        # Train\n",
    "        enc_batch, enc_lens, enc_padding_mask, \\\n",
    "        enc_key_batch, enc_key_lens, enc_key_padding_mask,\\\n",
    "        enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)     \n",
    "        \n",
    "#         enc_batch = enc_batch.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "        enc_key_batch = enc_key_batch.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "#         enc_padding_mask = enc_padding_mask.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "        enc_key_padding_mask = enc_key_padding_mask.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "#         enc_batch = self.bert_model(enc_batch, attention_mask = enc_padding_mask)[-2:][0] \n",
    "#         enc_key_batch = self.bert_model(enc_key_batch, attention_mask = enc_key_padding_mask)[-2:][0]  \n",
    "        \n",
    "        \n",
    "        # enc_batch = self.model.embeds(enc_batch)  # Get embeddings for encoder input\n",
    "        enc_key_batch = self.model.embeds(enc_key_batch)  # Get key embeddings for encoder input\n",
    "        \n",
    "        # feed into bert encoder\n",
    "#         enc_out, enc_hidden = self.model.encoder(enc_batch, attention_mask = enc_padding_mask)\n",
    "        enc_out, enc_hidden = self.model.encoder(enc_batch, enc_padding_mask, enc_lens)\n",
    "        # Test\n",
    "#         enc_batch2, enc_lens2, enc_padding_mask2, enc_batch_extend_vocab2, extra_zeros2, context2 = get_enc_data(test_batch)\n",
    "        enc_batch2, enc_lens2, enc_padding_mask2, \\\n",
    "        enc_key_batch2, enc_key_lens2, enc_key_padding_mask2,\\\n",
    "        enc_batch_extend_vocab2, extra_zeros2, context2 = get_enc_data(test_batch)\n",
    "        \n",
    "#         enc_batch2 = enc_batch2.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "#         enc_key_batch2 = enc_key_batch2.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "#         enc_padding_mask2 = enc_padding_mask2.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "#         enc_key_padding_mask2 = enc_key_padding_mask2.type(T.LongTensor).cuda() #  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "        \n",
    "        \n",
    "        with T.autograd.no_grad():\n",
    "#             enc_batch2 = self.bert_model(enc_batch2, attention_mask = enc_padding_mask2)[0][0]\n",
    "#             enc_key_batch2 = self.bert_model(enc_key_batch2, attention_mask = enc_key_padding_mask2)[0][0]  \n",
    "            \n",
    "#             enc_batch2 = self.bert_model(enc_batch2, attention_mask = enc_padding_mask2)[-2:][0]\n",
    "#             enc_key_batch2 = self.bert_model(enc_key_batch2, attention_mask = enc_key_padding_mask2)[-2:][0]  \n",
    "                \n",
    "#             enc_out2, enc_hidden2 = self.model.encoder(enc_batch2, enc_lens2)\n",
    "            enc_out2, enc_hidden2 = self.model.encoder(enc_batch2, enc_padding_mask2, enc_lens2)\n",
    "        # -------------------------------Summarization-----------------------\n",
    "        if self.opt.train_mle == True:  # perform MLE training\n",
    "            mle_loss = self.train_batch_MLE(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros,\n",
    "                                            enc_batch_extend_vocab, enc_key_batch, enc_key_lens, batch)\n",
    "            mle_loss_2 = self.train_batch_MLE(enc_out2, enc_hidden2, enc_padding_mask2, context2, extra_zeros2,\n",
    "                                            enc_batch_extend_vocab2, enc_key_batch2, enc_key_lens2, test_batch)\n",
    "        else:\n",
    "            mle_loss = get_cuda(T.FloatTensor([0]))\n",
    "            mle_loss_2 = get_cuda(T.FloatTensor([0]))\n",
    "            \n",
    "        # --------------RL training-----------------------------------------------------\n",
    "        if self.opt.train_rl == True:  # perform reinforcement learning training\n",
    "            # multinomial sampling\n",
    "            sample_sents, RL_log_probs = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context,\n",
    "                                                             extra_zeros, enc_batch_extend_vocab, batch.rev_oovs,\n",
    "                                                             greedy=False)\n",
    "            sample_sents2, RL_log_probs2 = self.train_batch_RL(enc_out2, enc_hidden2, enc_padding_mask2, context2,\n",
    "                                                             extra_zeros2, enc_batch_extend_vocab2, test_batch.rev_oovs,\n",
    "                                                             greedy=False)\n",
    "            with T.autograd.no_grad():\n",
    "                # greedy sampling\n",
    "                greedy_sents, _ = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros,\n",
    "                                                      enc_batch_extend_vocab, batch.rev_oovs, greedy=True)\n",
    "\n",
    "            sample_reward, _, _ = self.reward_function(sample_sents, batch.original_summarys)\n",
    "            baseline_reward, _, _ = self.reward_function(greedy_sents, batch.original_summarys)\n",
    "            # if iter%200 == 0:\n",
    "            #     self.write_to_file(sample_sents, greedy_sents, batch.original_abstracts, sample_reward, baseline_reward, iter)\n",
    "            rl_loss = -(sample_reward - baseline_reward) * RL_log_probs  # Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "            rl_loss = T.mean(rl_loss)\n",
    "\n",
    "            batch_reward = T.mean(sample_reward).item()\n",
    "            writer.add_scalar('Train_RL/RL_log_probs', RL_log_probs, iter)\n",
    "        else:\n",
    "            rl_loss = get_cuda(T.FloatTensor([0]))\n",
    "            batch_reward = 0\n",
    "        # ------------------------------------------------------------------------------------\n",
    "        #         if opt.train_mle == True: \n",
    "        self.trainer.zero_grad()\n",
    "        (self.opt.mle_weight * mle_loss + self.opt.rl_weight * rl_loss).backward()\n",
    "        self.trainer.step()\n",
    "        #-----------------------Summarization----------------------------------------------------\n",
    "        if iter % 1000 == 0:\n",
    "            with T.autograd.no_grad():\n",
    "                train_rouge_l_f = self.calc_avg_rouge_result(iter,batch,'Train',enc_hidden, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, enc_key_batch, enc_key_lens)\n",
    "                test_rouge_l_f = self.calc_avg_rouge_result(iter,test_batch,'Test',enc_hidden2, enc_out2, enc_padding_mask2, context2, extra_zeros2, enc_batch_extend_vocab2, enc_key_batch2, enc_key_lens2)\n",
    "                writer.add_scalars('Compare/rouge-l-f',  \n",
    "                   {'train_rouge_l_f': train_rouge_l_f,\n",
    "                    'test_rouge_l_f': test_rouge_l_f\n",
    "                   }, iter)\n",
    "                logger.info('iter: %s train_rouge_l_f: %.3f test_rouge_l_f: %.3f \\n' % (iter, train_rouge_l_f, test_rouge_l_f))\n",
    "                \n",
    "#         return mle_loss.item(), batch_reward, ans_list, batch_scores\n",
    "        return mle_loss.item(),mle_loss_2.item(), batch_reward\n",
    "\n",
    "    def calc_avg_rouge_result(self, iter, batch, mode, enc_hidden, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, enc_key_batch, enc_key_lens):\n",
    "        pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask,\n",
    "        context, extra_zeros, enc_batch_extend_vocab, enc_key_batch,\n",
    "        enc_key_lens, self.model, self.start_id, self.end_id, \n",
    "        self.unk_id)\n",
    "\n",
    "        decoded_sents = []\n",
    "        ref_sents = []\n",
    "        ref_sents2 = []\n",
    "        article_sents = []\n",
    "        keywords_list = []\n",
    "        \n",
    "        summary_len = max_summary_len = long_seq_index = 0\n",
    "        for i in range(len(pred_ids)):            \n",
    "            decoded_words = data.outputids2words(pred_ids[i], self.vocab, batch.rev_oovs[i])\n",
    "            if len(decoded_words) < 2:\n",
    "                decoded_words = \"xxx\"\n",
    "            else:\n",
    "                decoded_words = \" \".join(decoded_words)\n",
    "            decoded_words = decoded_words.replace(\"[UNK]\",\"\")\n",
    "            decoded_sents.append(decoded_words)\n",
    "            summary = batch.original_summarys[i]\n",
    "            summary = summary.replace(\"<s>\",\"\").replace(\"</s>\",\"\")\n",
    "            review = batch.original_reviews[i]\n",
    "            ref_sents.append(summary)\n",
    "            article_sents.append(review) \n",
    "            keywords = batch.key_words[i]\n",
    "            keywords_list.append(str(keywords))\n",
    "            summary_len = len(summary.split(\" \"))\n",
    "            if max_summary_len < summary_len: \n",
    "                max_summary_len = summary_len\n",
    "                long_seq_index = i\n",
    "\n",
    "        rouge = Rouge()    \n",
    "        score = rouge.get_scores(decoded_sents, ref_sents, avg = True)    \n",
    "        writer.add_scalars('%s/rouge-1' % mode,  # 'rouge-2' , 'rouge-l'\n",
    "               {'f': score['rouge-1']['f'],\n",
    "                'p': score['rouge-1']['p'],\n",
    "                'r': score['rouge-1']['r']}\n",
    "                , iter)\n",
    "        writer.add_scalars('%s/rouge-2' % mode,  # 'rouge-2' , 'rouge-l'\n",
    "               {'f': score['rouge-2']['f'],\n",
    "                'p': score['rouge-2']['p'],\n",
    "                'r': score['rouge-2']['r']}\n",
    "                , iter)\n",
    "        writer.add_scalars('%s/rouge-l' % mode,  # 'rouge-2' , 'rouge-l'\n",
    "               {'f': score['rouge-l']['f'],\n",
    "                'p': score['rouge-l']['p'],\n",
    "                'r': score['rouge-l']['r']}\n",
    "                , iter)\n",
    "        for i in range(len(decoded_sents)):\n",
    "            if type(article_sents[i]) != str: continue\n",
    "            if type(ref_sents[i]) != str:  continue\n",
    "            if type(decoded_sents[i]) != str:  continue\n",
    "\n",
    "        writer.add_text('Rouge/%s/%s' % (iter,mode), decoded_sents[long_seq_index], iter)\n",
    "        writer.add_text('Rouge/%s/%s' % (iter,mode), keywords_list[long_seq_index], iter)\n",
    "        writer.add_text('Rouge/%s/%s' % (iter,mode), ref_sents[long_seq_index], iter)\n",
    "        writer.add_text('Rouge/%s/%s' % (iter,mode), article_sents[long_seq_index], iter)\n",
    "        \n",
    "#         for i in range(len(decoded_sents)):\n",
    "# #             writer.add_text('Rouge/%s/%s' % (iter,mode), decoded_sents[i], iter)\n",
    "#             writer.add_text('Rouge/%s/%s' % (iter,mode), ref_sents[i], iter)\n",
    "#             writer.add_text('Rouge/%s/%s' % (iter,mode), article_sents[i], iter)\n",
    "        \n",
    "        bleu_decode_sents = [decode.split(\" \") for decode in decoded_sents]\n",
    "        bleu_ref_sents = [[ref.split(\" \")] for ref in ref_sents]\n",
    "\n",
    "        writer.add_scalars('%s/Individual' % mode,  # 'rouge-2' , 'rouge-l'\n",
    "               {'BLEU-1': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(1, 0, 0, 0)),\n",
    "                'BLEU-2': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0, 1, 0, 0)),\n",
    "                'BLEU-3': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0, 0, 1, 0)),\n",
    "                'BLEU-4': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0, 0, 0, 1))}\n",
    "                , iter)\n",
    "       \n",
    "        writer.add_scalars('%s/Cumulative' % mode,  # 'rouge-2' , 'rouge-l'\n",
    "               {'BLEU-1': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(1, 0, 0, 0)),\n",
    "                'BLEU-2': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0.5, 0.5, 0, 0)),\n",
    "                'BLEU-3': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0.33, 0.33, 0.33, 0)),\n",
    "                'BLEU-4': corpus_bleu(bleu_ref_sents,bleu_decode_sents, weights=(0.25, 0.25, 0.25, 0.25))}\n",
    "                , iter)\n",
    "    \n",
    "        return score['rouge-l']['f']\n",
    "    \n",
    "    def get_best_res_score(self, results, scores):\n",
    "        max_score = float(0)\n",
    "        _id = 0\n",
    "        for idx in range(len(results)):\n",
    "            re_matchData = re.compile(r'\\-?\\d{1,10}\\.?\\d{1,10}')\n",
    "            data = re.findall(re_matchData, str(scores[idx]))\n",
    "            score = sum([float(d) for d in data])\n",
    "            if score > max_score:\n",
    "                _id = idx\n",
    "        return results[_id], scores[_id]\n",
    "\n",
    "    def get_lr(self):\n",
    "        for param_group in self.trainer.param_groups:\n",
    "            return param_group['lr']\n",
    "\n",
    "    def get_weight_decay(self):\n",
    "        for param_group in self.trainer.param_groups:\n",
    "            return param_group['weight_decay']\n",
    "\n",
    "    def trainIters(self):\n",
    "        final_file_path = None\n",
    "        iter = self.setup_train()\n",
    "        epoch = 0\n",
    "        count = test_mle_total = train_mle_total = r_total = 0\n",
    "        logger.info(u'------Training START--------')\n",
    "        test_batch = self.test_batcher.next_batch()\n",
    "        #         while iter <= config.max_iterations:\n",
    "        while epoch <= config.max_epochs:\n",
    "            train_batch = self.train_batcher.next_batch()\n",
    "            try:\n",
    "                train_mle_loss,test_mle_loss, r  = self.train_one_batch(train_batch,test_batch, iter)\n",
    "\n",
    "                writer.add_scalar('RL_Train/reward', r, iter)\n",
    "\n",
    "                writer.add_scalars('Compare/mle_loss' ,  \n",
    "                   {'train_mle_loss': train_mle_loss,\n",
    "                    'test_mle_loss': test_mle_loss\n",
    "                   }, iter)\n",
    "                \n",
    "#             # break\n",
    "            except KeyboardInterrupt:\n",
    "                logger.info(\"-------------------Keyboard Interrupt------------------\")\n",
    "                exit(0)\n",
    "#             except Exception as e:                \n",
    "#                 logger.info(\"-------------------Ignore error------------------\\n%s\\n\" % e)\n",
    "#                 print(\"Please load final_file_path : %s\" % final_file_path)\n",
    "#                 traceback = sys.exc_info()[2]\n",
    "#                 print(sys.exc_info())\n",
    "#                 print(traceback.tb_lineno)\n",
    "#                 print(e)\n",
    "#                 break\n",
    "            # if opt.train_mle == False: break\n",
    "            train_mle_total += train_mle_loss\n",
    "            r_total += r\n",
    "            test_mle_total += test_mle_loss\n",
    "            count += 1\n",
    "            iter += 1\n",
    "\n",
    "            if iter % 1000 == 0:\n",
    "                train_mle_avg = train_mle_total / count\n",
    "                r_avg = r_total / count\n",
    "                test_mle_avg = test_mle_total / count\n",
    "                epoch = int((iter * config.batch_size) / train_num) + 1\n",
    "#                 logger.info('epoch: %s iter: %s train_mle_loss: %.3f test_mle_loss: %.3f reward: %.3f \\n' % (epoch, iter, train_mle_avg, test_mle_avg, r_avg))\n",
    "                \n",
    "\n",
    "                count = test_mle_total = train_mle_total = r_total = 0\n",
    "                writer.add_scalar('RL_Train/r_avg', r_avg, iter)\n",
    "                \n",
    "                writer.add_scalars('Compare/mle_avg_loss' ,  \n",
    "                   {'train_mle_avg': train_mle_avg,\n",
    "                    'test_mle_avg': test_mle_avg\n",
    "                   }, iter)\n",
    "            # break\n",
    "            if iter % 5000 == 0:\n",
    "                final_file_path = self.save_model(iter, test_mle_avg, r_avg)\n",
    "#                 if opt.view:\n",
    "#                     best_res, best_score = self.get_best_res_score(ans_list, batch_scores)\n",
    "#                     logger.info('best_res: %s \\n' % (best_res))\n",
    "#                     logger.info('best_score: %s \\n' % (best_score))\n",
    "#                     writer.add_text('Train/%s' % (iter), best_res['decoded_str'], iter)\n",
    "#                     writer.add_text('Train/%s' % (iter), best_res['summary'], iter)\n",
    "#                     writer.add_text('Train/%s' % (iter), best_res['review'], iter)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_action(opt):\n",
    "#     try:       \n",
    "    opt.rl_weight = 1 - opt.mle_weight  \n",
    "\n",
    "    if opt.load_model:\n",
    "        opt.load_model = \"/%s/%s\"%(opt.word_emb_type,opt.load_model)    \n",
    "\n",
    "    logger.info(u'------Training Setting--------')  \n",
    "\n",
    "    logger.info(\"Traing Type :%s\" %(config.data_type))\n",
    "    if opt.train_mle == True:\n",
    "        logger.info(\"Training mle: %s, mle weight: %.2f\"%(opt.train_mle, opt.mle_weight))\n",
    "\n",
    "    if opt.train_rl == True:\n",
    "        logger.info(\"Training rl: %s, rl weight: %.2f \\n\"%(opt.train_rl, opt.rl_weight))\n",
    "\n",
    "#     if opt.word_emb_type == 'bert': config.emb_dim = 768\n",
    "    if opt.pre_train_emb : \n",
    "        logger.info('use pre_train_%s vocab_size %s \\n'%(opt.word_emb_type,config.vocab_size))\n",
    "\n",
    "    else:\n",
    "        logger.info('use %s vocab_size %s \\n'%(opt.word_emb_type,config.vocab_size))\n",
    "\n",
    "    logger.info(\"intra_encoder: %s intra_decoder: %s \\n\"%(config.intra_encoder, config.intra_decoder))\n",
    "    if opt.word_emb_type in ['word2Vec','glove']:\n",
    "    #   config.vocab_path = \"Embedding/%s/%s/word.vocab\"%(config.data_type, opt.word_emb_type)\n",
    "        config.vocab_path = config.Data_path + \"Embedding/%s/word.vocab\"%(opt.word_emb_type)            \n",
    "        config.vocab_size = len(open(config.vocab_path).readlines())\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    train_processor = Train(opt,vocab)\n",
    "    train_processor.trainIters()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         traceback = sys.exc_info()[2]\n",
    "#         logger.error(sys.exc_info())\n",
    "#         logger.error(traceback.tb_lineno)\n",
    "#         logger.error(e)\n",
    "    logger.info(u'------Training END--------')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "def write_enc_graph():\n",
    "    encoder_writer = SummaryWriter('runs/Pointer-Generator/word2Vec/Encoder')\n",
    "    device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "    encoder = Encoder().to(device) \n",
    "\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                           batch_size=config.batch_size, single_pass=False)\n",
    "    batch = batcher.next_batch()\n",
    "    enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "    enc_batch = Model(False,'word2Vec',vocab).embeds(enc_batch) #Get embeddings for encoder input\n",
    "\n",
    "#     enc_batch = Variable(torch.rand(enc_batch.shape)).to(device) \n",
    "    enc_lens = torch.from_numpy(enc_lens).to(device) \n",
    "\n",
    "    encoder_writer.add_graph(encoder, (enc_batch, enc_lens), verbose=True)\n",
    "    encoder_writer.close()\n",
    "\n",
    "def write_dec_graph():\n",
    "    decoder_writer = SummaryWriter('runs/Pointer-Generator/word2Vec/Decoder')\n",
    "    device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "    # decoder = Decoder().to(device)    \n",
    "\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    model = Model(False,'word2Vec',vocab)\n",
    "    \n",
    "    batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                           batch_size=config.batch_size, single_pass=False)\n",
    "    batch = batcher.next_batch()\n",
    "    enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "    enc_batch = model.embeds(enc_batch) #Get embeddings for encoder input\n",
    "    enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "    # train_batch_MLE\n",
    "    dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n",
    "    step_losses = []\n",
    "    s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n",
    "    # x_t 為decoder每一個time step 的batch input\n",
    "    x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(2))                             #Input to the decoder\n",
    "    prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in DEEP REINFORCED MODEL - https://arxiv.org/pdf/1705.04304.pdf)\n",
    "    sum_temporal_srcs = None     \n",
    "\n",
    "\n",
    "    for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "        use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "        # use_gound_truth * dec_batch[:, t] : 為ground true time step token\n",
    "        # (1 - use_gound_truth) * x_t : 為previous time step token\n",
    "        if t == 0 :temp_batch = dec_batch[:, t]\n",
    "        x_t = use_gound_truth * temp_batch + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities\n",
    "        x_t = model.embeds(x_t)\n",
    "    #     final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "        final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(\n",
    "        x_t, s_t, enc_out, enc_padding_mask,context, \n",
    "        extra_zeros,enc_batch_extend_vocab,sum_temporal_srcs, prev_s, \n",
    "        enc_key_batch, enc_key_lens)        \n",
    "\n",
    "\n",
    "        #         decoder_summary = summary(model.decoder, x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s,enc_key_batch, enc_key_lens) # encoder summary\n",
    "#         x_t = Variable(torch.rand(x_t.shape)).to(device) \n",
    "        #             s_t = Variable(torch.rand(s_t.shape)).to(device)\n",
    "#         enc_out = Variable(torch.rand(enc_out.shape)).to(device)\n",
    "#         enc_padding_mask = Variable(torch.rand(enc_padding_mask.shape)).to(device,dtype=torch.long)\n",
    "#         context = Variable(torch.rand(context.shape)).to(device)\n",
    "#         extra_zeros = Variable(torch.rand(extra_zeros.shape)).to(device)\n",
    "#         enc_batch_extend_vocab = Variable(torch.rand(enc_batch_extend_vocab.shape)).to(device)\n",
    "        #             sum_temporal_srcs = Variable(torch.rand(sum_temporal_srcs.shape)).to(device)\n",
    "        #             prev_s = Variable(torch.rand(prev_s.shape)).to(device)\n",
    "#         enc_key_batch = Variable(torch.rand(enc_key_batch.shape)).to(device)\n",
    "        enc_key_lens = torch.from_numpy(enc_key_lens).to(device) \n",
    "        \n",
    "        decoder_writer.add_graph(model.decoder, \n",
    "                         (x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s,enc_key_batch, enc_key_lens), verbose=True)\n",
    "        decoder_writer.close()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 14:41:17 - Text-Summary - INFO: - logger已啟動\n",
      "I0226 14:41:17.318312 139925006210880 <ipython-input-2-00f9962e7fdd>:30] logger已啟動\n",
      "2020-02-26 14:41:17 - Text-Summary - INFO: - ------Training Setting--------\n",
      "I0226 14:41:17.326749 139925006210880 <ipython-input-8-ec6a8d673154>:8] ------Training Setting--------\n",
      "2020-02-26 14:41:17 - Text-Summary - INFO: - Traing Type :Cameras_new\n",
      "I0226 14:41:17.329610 139925006210880 <ipython-input-8-ec6a8d673154>:10] Traing Type :Cameras_new\n",
      "2020-02-26 14:41:17 - Text-Summary - INFO: - Training mle: True, mle weight: 1.00\n",
      "I0226 14:41:17.331579 139925006210880 <ipython-input-8-ec6a8d673154>:12] Training mle: True, mle weight: 1.00\n",
      "2020-02-26 14:41:17 - Text-Summary - INFO: - use pre_train_word2Vec vocab_size 50000 \n",
      "\n",
      "I0226 14:41:17.333474 139925006210880 <ipython-input-8-ec6a8d673154>:19] use pre_train_word2Vec vocab_size 50000 \n",
      "\n",
      "2020-02-26 14:41:17 - Text-Summary - INFO: - intra_encoder: False intra_decoder: False \n",
      "\n",
      "I0226 14:41:17.335273 139925006210880 <ipython-input-8-ec6a8d673154>:24] intra_encoder: False intra_decoder: False \n",
      "\n",
      "I0226 14:41:23.265251 139925006210880 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/eagleuser/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "I0226 14:41:23.266591 139925006210880 configuration_utils.py:199] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0226 14:41:24.135438 139925006210880 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/eagleuser/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-02-26 14:41:26 - Text-Summary - INFO: - ------Training START--------\n",
      "I0226 14:41:26.938352 139925006210880 <ipython-input-7-da082004f9d2>:457] ------Training START--------\n",
      "2020-02-26 14:41:27 - Text-Summary - INFO: - logger已關閉\n",
      "I0226 14:41:27.110430 139925006210880 <ipython-input-2-00f9962e7fdd>:34] logger已關閉\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_t torch.Size([1, 768])\n",
      "out torch.Size([1, 2304])\n",
      "V 2304 768\n",
      "out torch.Size([1, 768])\n",
      "V1 768 39494\n",
      "---------------------------\n",
      "finish inner loop\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 13.50 GiB (GPU 0; 10.92 GiB total capacity; 2.17 GiB already allocated; 7.32 GiB free; 35.39 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-049cc993226f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#         write_dec_graph()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ec6a8d673154>\u001b[0m in \u001b[0;36mtrain_action\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m#     except Exception as e:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         print(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-da082004f9d2>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mtrain_mle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_mle_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RL_Train/reward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-da082004f9d2>\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[0;34m(self, batch, test_batch, iter)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# perform MLE training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             mle_loss = self.train_batch_MLE(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros,\n\u001b[0;32m--> 297\u001b[0;31m                                             enc_batch_extend_vocab, enc_key_batch, enc_key_lens, batch)\n\u001b[0m\u001b[1;32m    298\u001b[0m             mle_loss_2 = self.train_batch_MLE(enc_out2, enc_hidden2, enc_padding_mask2, context2, extra_zeros2,\n\u001b[1;32m    299\u001b[0m                                             enc_batch_extend_vocab2, enc_key_batch2, enc_key_lens2, test_batch)\n",
      "\u001b[0;32m<ipython-input-7-da082004f9d2>\u001b[0m in \u001b[0;36mtrain_batch_MLE\u001b[0;34m(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, enc_key_batch, enc_key_lens, batch)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0menc_key_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_key_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0menc_key_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_key_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# use the output vector corresponding to [CLS] to initialize the hidden state and cell state of LSTM decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 13.50 GiB (GPU 0; 10.92 GiB total capacity; 2.17 GiB already allocated; 7.32 GiB free; 35.39 MiB cached)"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/u012869752/article/details/72513141\n",
    "# 由于在jupyter notebook中，args不为空\n",
    "from glob import glob\n",
    "# nvidia-smi -pm 1\n",
    "if __name__ == \"__main__\":   \n",
    "    try:\n",
    "        # --------------------------Training ----------------------------------\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--train_mle', type=bool, default=True)\n",
    "        parser.add_argument('--train_rl', type=bool, default=False)\n",
    "        parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "    #         parser.add_argument('--load_model', type=str, default='/0015000_3.29_0.00.tar')\n",
    "        parser.add_argument('--load_model', type=str, default=None)\n",
    "        parser.add_argument('--new_lr', type=float, default=None)\n",
    "        parser.add_argument('--multi_device', type=bool, default=True)\n",
    "        parser.add_argument('--view', type=bool, default=True)\n",
    "        parser.add_argument('--pre_train_emb', type=bool, default=True)\n",
    "        parser.add_argument('--word_emb_type', type=str, default='word2Vec')\n",
    "        parser.add_argument('--train_action', type=bool, default=True)\n",
    "        opt = parser.parse_args(args=[])\n",
    "\n",
    "        today = dt.now()\n",
    "    #         loggerPath = \"LOG//%s-(%s_%s_%s)-(%s:%s:%s)\"%(opt.word_emb_type,\n",
    "    #                   today.year,today.month,today.day,\n",
    "    #                   today.hour,today.minute,today.second)\n",
    "    #         logger = getLogger(config.loggerName,loggerPath)   \n",
    "\n",
    "        loggerPath = \"LOG//%s\"%(opt.word_emb_type)\n",
    "        logger = getLogger(config.loggerName,loggerPath) \n",
    "\n",
    "        if opt.load_model == None:\n",
    "            shutil.rmtree('runs/Pointer-Generator/bert', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/bert/exp-4', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/bert/Eecoder', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/bert/Decoder', ignore_errors=True) # clear previous \n",
    "\n",
    "        writer = SummaryWriter('runs/Pointer-Generator/bert/exp-4')\n",
    "    #         write_enc_graph()\n",
    "    #         write_dec_graph()\n",
    "\n",
    "        if opt.train_action: train_action(opt)\n",
    "\n",
    "    except KeyError as e:\n",
    "        traceback = sys.exc_info()[2]\n",
    "        print(sys.exc_info())\n",
    "        print(traceback.tb_lineno)\n",
    "        print(e)\n",
    "    finally:\n",
    "        removeLogger(logger)\n",
    "        # export scalar data to JSON for external processing\n",
    "        # tensorboard --logdir /home/eagleuser/Users/leyan/Text-Summarizer-FOP/TensorBoard\n",
    "#         tensorboard --logdir ./runs\n",
    "#         if not os.path.exists('TensorBoard'): os.makedirs('TensorBoard')\n",
    "#         writer.export_scalars_to_json(\"TensorBoard/test.json\")\n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
