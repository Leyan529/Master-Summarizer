{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "import torch as T\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from model import Model\n",
    "\n",
    "\n",
    "from data_util import config, data\n",
    "from data_util.batcher import Batcher\n",
    "from data_util.data import Vocab\n",
    "\n",
    "\n",
    "from train_util import *\n",
    "from torch.distributions import Categorical\n",
    "from rouge import Rouge\n",
    "from numpy import random\n",
    "import argparse\n",
    "import torchsnooper\n",
    "\n",
    "# import torchsnooper\n",
    "# import snoop\n",
    "# from cheap_repr import cheap_repr\n",
    "\n",
    "# torchsnooper.register_snoop()\n",
    "# cheap_repr.raise_exceptions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(123)\n",
    "# T.manual_seed(123)\n",
    "# if T.cuda.is_available():\n",
    "#     T.cuda.manual_seed_all(123)\n",
    "#     print(\"is_available\", T.cuda.is_available())\n",
    "#     print(\"use_cuda\", use_cuda)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# T.cuda.set_device(1)\n",
    "\n",
    "# use_cuda = config.use_gpu and torch.cuda.is_available()\n",
    "# print(\"use_cuda\", T.cuda.is_available())\n",
    "\n",
    "# print(\"use_cuda\", use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch():\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                           batch_size=config.batch_size, single_pass=False)\n",
    "    batch = batcher.next_batch()\n",
    "    # with torchsnooper.snoop():\n",
    "    while batch is not None:\n",
    "        example_list = batch.example_list\n",
    "        for ex in example_list:\n",
    "            r = str(ex.original_review)\n",
    "            s = str(ex.original_summary)\n",
    "            k = str(ex.key_words)\n",
    "            sent = ex.original_summary_sents\n",
    "#             print(\"original_review_sents:\", r)\n",
    "#             print(\"original_summary_sents : \", s)\n",
    "#             print(\"review_key_words : \", k)\n",
    "#             print('------------------------------------------------------------\\n')\n",
    "        batch = batcher.next_batch()        \n",
    "# test_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bin Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 71316\n",
      "\n",
      "test : 23771\n",
      "\n",
      "valid : 23772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"bin/bin-info.txt\",'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    [print(line) for line in lines]\n",
    "    train_num = int(lines[0].split(\":\")[1])\n",
    "    test_num = int(lines[1].split(\":\")[1])\n",
    "    val_num = int(lines[2].split(\":\")[1])\n",
    "    # f.write(\"train : %s\\n\"%(len(flit_key_train_df)))\n",
    "    # f.write(\"test : %s\\n\"%(len(flit_key_test_df)))\n",
    "    # f.write(\"valid : %s\\n\"%(len(flit_key_valid_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View model summary\n",
    "#### 只有torchsummaryX成功\n",
    "#### 日後將以此模擬呈現結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary # 不支援RNN\n",
    "# from model import Encoder,Model\n",
    "# # https://www.cnblogs.com/lindaxin/p/8052043.html\n",
    "# device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "# encoder = Encoder().to(device)    \n",
    "\n",
    "# vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                        batch_size=config.batch_size, single_pass=False)\n",
    "# batch = batcher.next_batch()\n",
    "# enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# enc_batch = Model().embeds(enc_batch) # Get embeddings for encoder input\n",
    "\n",
    "# # summary(encoder, enc_batch, enc_lens, show_hierarchical=True) \n",
    "# # summary(encoder, [enc_batch, enc_lens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modelsummary import summary # 未知問題\n",
    "# from model import Encoder,Model\n",
    "# # https://www.cnblogs.com/lindaxin/p/8052043.html\n",
    "# device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "# encoder = Encoder().to(device)    \n",
    "\n",
    "# vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                        batch_size=config.batch_size, single_pass=False)\n",
    "# batch = batcher.next_batch()\n",
    "# enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# enc_batch = Model().embeds(enc_batch) # Get embeddings for encoder input\n",
    "\n",
    "# # summary(encoder, enc_batch, enc_lens, show_hierarchical=True) \n",
    "# # summary(encoder, enc_batch, enc_lens, show_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "           Kernel Shape Output Shape   Params  Mult-Adds\n",
      "Layer                                                   \n",
      "0_lstm                -  [557, 1024]  3334144    3325952\n",
      "1_reduce_h  [1024, 512]     [8, 512]   524800     524288\n",
      "2_reduce_c  [1024, 512]     [8, 512]   524800     524288\n",
      "--------------------------------------------------------\n",
      "                       Totals\n",
      "Total params          4383744\n",
      "Trainable params      4383744\n",
      "Non-trainable params        0\n",
      "Mult-Adds             4374528\n",
      "========================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_lstm</th>\n",
       "      <td>-</td>\n",
       "      <td>[557, 1024]</td>\n",
       "      <td>3334144</td>\n",
       "      <td>3325952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_reduce_h</th>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>[8, 512]</td>\n",
       "      <td>524800</td>\n",
       "      <td>524288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_reduce_c</th>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>[8, 512]</td>\n",
       "      <td>524800</td>\n",
       "      <td>524288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Kernel Shape Output Shape   Params  Mult-Adds\n",
       "Layer                                                   \n",
       "0_lstm                -  [557, 1024]  3334144    3325952\n",
       "1_reduce_h  [1024, 512]     [8, 512]   524800     524288\n",
       "2_reduce_c  [1024, 512]     [8, 512]   524800     524288"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "from model import Encoder,Model\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "encoder = Encoder().to(device)    \n",
    "\n",
    "vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                       batch_size=config.batch_size, single_pass=False)\n",
    "batch = batcher.next_batch()\n",
    "enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "enc_batch = Model(False,vocab).embeds(enc_batch) #Get embeddings for encoder input\n",
    "\n",
    "summary(encoder, enc_batch, enc_lens) # encoder summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummaryX import summary\n",
    "class Train(object):\n",
    "    def __init__(self, opt):\n",
    "        self.vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "        self.batcher = Batcher(config.train_data_path, self.vocab, mode='train',\n",
    "                               batch_size=config.batch_size, single_pass=False)\n",
    "        self.opt = opt\n",
    "        self.start_id = self.vocab.word2id(data.START_DECODING)\n",
    "        self.end_id = self.vocab.word2id(data.STOP_DECODING)\n",
    "        self.pad_id = self.vocab.word2id(data.PAD_TOKEN)\n",
    "        self.unk_id = self.vocab.word2id(data.UNKNOWN_TOKEN)\n",
    "        time.sleep(5)\n",
    "\n",
    "    def save_model(self, iter):\n",
    "        if not os.path.exists(config.save_model_path):\n",
    "            os.makedirs(config.save_model_path)\n",
    "        save_path = config.save_model_path + \"/%07d.tar\" % iter\n",
    "        T.save({\n",
    "            \"iter\": iter + 1,\n",
    "            \"model_dict\": self.model.state_dict(),\n",
    "            \"trainer_dict\": self.trainer.state_dict()\n",
    "        }, save_path)\n",
    "\n",
    "    def setup_train(self):\n",
    "        self.model = Model(opt.pre_train_emb,self.vocab) \n",
    "#         print(\"Model : \",self.model)\n",
    "#         print(\"Encoder : \",self.model.encoder)\n",
    "#         print(\"Decoder : \",self.model.decoder)\n",
    "#         print(\"Embeds : \",self.model.embeds)\n",
    "        self.model = get_cuda(self.model)\n",
    "        device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "        if opt.multi_device:\n",
    "            if T.cuda.device_count() > 1:\n",
    "                print(\"Let's use\", T.cuda.device_count(), \"GPUs!\")\n",
    "                self.model = nn.DataParallel(self.model, list(range(T.cuda.device_count()))).cuda()    \n",
    "                \n",
    "                \n",
    "        if isinstance(self.model,nn.DataParallel):\n",
    "            self.model = self.model.module\n",
    "        self.model.to(device)\n",
    "#         self.model.eval()\n",
    "        \n",
    "        self.trainer = T.optim.Adam(self.model.parameters(), lr=config.lr)\n",
    "        start_iter = 0\n",
    "        if self.opt.load_model is not None:\n",
    "            load_model_path = os.path.join(config.save_model_path, self.opt.load_model)\n",
    "            checkpoint = T.load(load_model_path)\n",
    "            start_iter = checkpoint[\"iter\"]\n",
    "            self.model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "            self.trainer.load_state_dict(checkpoint[\"trainer_dict\"])\n",
    "            print(\"Loaded model at \" + load_model_path)\n",
    "        if self.opt.new_lr is not None:\n",
    "            self.trainer = T.optim.Adam(self.model.parameters(), lr=self.opt.new_lr)\n",
    "        return start_iter\n",
    "\n",
    "    def train_batch_MLE(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, batch):\n",
    "        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n",
    "                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n",
    "        Args:\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param batch: batch object\n",
    "        '''\n",
    "        dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n",
    "        step_losses = []\n",
    "        s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "            use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities\n",
    "            x_t = self.model.embeds(x_t)\n",
    "            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "            target = target_batch[:, t]\n",
    "            log_probs = T.log(final_dist + config.eps)\n",
    "            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=self.pad_id)\n",
    "            step_losses.append(step_loss)\n",
    "            x_t = T.multinomial(final_dist, 1).squeeze()                                            #Sample words from final distribution which can be used as input in next time step\n",
    "            is_oov = (x_t >= config.vocab_size).long()                                              #Mask indicating whether sampled word is OOV\n",
    "            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * self.unk_id                              #Replace OOVs with [UNK] token\n",
    "\n",
    "        losses = T.sum(T.stack(step_losses, 1), 1)                                                  #unnormalized losses for each example in the batch; (batch_size)\n",
    "        batch_avg_loss = losses / dec_lens                                                          #Normalized losses; (batch_size)\n",
    "        mle_loss = T.mean(batch_avg_loss)                                                           #Average batch loss\n",
    "        return mle_loss\n",
    "\n",
    "    def train_batch_RL(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy):\n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param article_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        s_t = enc_hidden                                                                            #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []                                                                                   #Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []                                                                   #Stores padding masks of generated samples\n",
    "        log_probs = []                                                                              #Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = self.model.embeds(x_t)\n",
    "            probs, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs)\n",
    "                x_t = multi_dist.sample()                                                           #perform multinomial sampling\n",
    "                log_prob = multi_dist.log_prob(x_t)\n",
    "                log_probs.append(log_prob)\n",
    "            else:\n",
    "                _, x_t = T.max(probs, dim=1)                                                        #perform greedy sampling\n",
    "            x_t = x_t.detach()\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "            mask[(mask == 1) + (x_t == self.end_id) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "            is_oov = (x_t>=config.vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n",
    "            x_t = (1-is_oov)*x_t + (is_oov)*self.unk_id                                             #Replace OOVs with [UNK] token\n",
    "\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n",
    "            log_probs = T.stack(log_probs, dim=1)\n",
    "            log_probs = log_probs * decoder_padding_mask                                            #Not considering sampled words with padding mask = 0\n",
    "            lens = T.sum(decoder_padding_mask, dim=1)                                               #Length of sampled sentence\n",
    "            log_probs = T.sum(log_probs, dim=1) / lens  # (bs,)                                     #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy()\n",
    "            oovs = article_oovs[i]\n",
    "            S = data.outputids2words(id_list, self.vocab, oovs)                                     #Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:                                                                           #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "\n",
    "        return decoded_strs, log_probs\n",
    "    \n",
    "    def train_batch_decode(self,batch, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy):\n",
    "        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n",
    "        Args\n",
    "        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n",
    "        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n",
    "        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n",
    "        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n",
    "        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n",
    "        :param article_oovs: Batch containing list of OOVs in each example\n",
    "        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n",
    "        Returns:\n",
    "        :decoded_strs: List of decoded sentences\n",
    "        :log_probs: Log probabilities of sampled words\n",
    "        '''\n",
    "        s_t = enc_hidden                                                                            #Decoder hidden states\n",
    "        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n",
    "        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "        inds = []                                                                                   #Stores sampled indices for each time step\n",
    "        decoder_padding_mask = []                                                                   #Stores padding masks of generated samples\n",
    "        log_probs = []                                                                              #Stores log probabilites of generated samples\n",
    "        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n",
    "\n",
    "        for t in range(config.max_dec_steps):\n",
    "            x_t = self.model.embeds(x_t) \n",
    "#             with torchsnooper.snoop():\n",
    "            try:\n",
    "#                 with torchsnooper.snoop():\n",
    "#                     x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s\n",
    "                probs, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "            except:\n",
    "#                 with torchsnooper.snoop():\n",
    "#                     x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s\n",
    "                self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "            \n",
    "                \n",
    "            if greedy is False:\n",
    "                multi_dist = Categorical(probs)\n",
    "                x_t = multi_dist.sample()                                                           #perform multinomial sampling\n",
    "#                 log_prob = multi_dist.log_prob(x_t)\n",
    "#                 log_probs.append(log_prob)\n",
    "            else:\n",
    "                _, x_t = T.max(probs, dim=1)                                                        #perform greedy sampling\n",
    "            x_t = x_t.detach()\n",
    "            inds.append(x_t)\n",
    "            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n",
    "            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n",
    "#             mask[(mask == 1) + (x_t == self.end_id) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n",
    "            decoder_padding_mask.append(mask_t)\n",
    "#             is_oov = (x_t>=config.vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n",
    "#             x_t = (1-is_oov)*x_t + (is_oov)*self.unk_id                                             #Replace OOVs with [UNK] token\n",
    "\n",
    "        inds = T.stack(inds, dim=1)\n",
    "        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n",
    "#         if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n",
    "#             log_probs = T.stack(log_probs, dim=1)\n",
    "#             log_probs = log_probs * decoder_padding_mask                                            #Not considering sampled words with padding mask = 0\n",
    "#             lens = T.sum(decoder_padding_mask, dim=1)                                               #Length of sampled sentence\n",
    "#             log_probs = T.sum(log_probs, dim=1) / lens  # (bs,)                                     #compute normalizied log probability of a sentence\n",
    "        decoded_strs = []\n",
    "        ans_list = []\n",
    "        for i in range(len(enc_out)):\n",
    "            id_list = inds[i].cpu().numpy()\n",
    "            oovs = article_oovs[i]\n",
    "            S = data.outputids2words(id_list, self.vocab, oovs)                                     #Generate sentence corresponding to sampled words\n",
    "            try:\n",
    "                end_idx = S.index(data.STOP_DECODING)\n",
    "                S = S[:end_idx]\n",
    "            except ValueError:\n",
    "                S = S\n",
    "            if len(S) < 2:                                                                           #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n",
    "                S = [\"xxx\"]\n",
    "            S = \" \".join(S)\n",
    "            decoded_strs.append(S)\n",
    "            ans_dict = {\n",
    "                'review':batch.original_reviews[i],\n",
    "                'key_words':batch.key_words[i],\n",
    "                'summary':batch.original_summarys[i],                \n",
    "                'decoded_str':S                \n",
    "            }\n",
    "            ans_list.append(ans_dict)\n",
    "        return decoded_strs , ans_list\n",
    "\n",
    "    def reward_function(self, decoded_sents, original_sents):\n",
    "        rouge = Rouge()\n",
    "        try:\n",
    "            scores = rouge.get_scores(decoded_sents, original_sents)\n",
    "        except Exception:\n",
    "            print(\"Rouge failed for multi sentence evaluation.. Finding exact pair\")\n",
    "            scores = []\n",
    "            for i in range(len(decoded_sents)):\n",
    "                try:\n",
    "                    score = rouge.get_scores(decoded_sents[i], original_sents[i])\n",
    "                except Exception:\n",
    "                    print(\"Error occured at:\")\n",
    "                    print(\"decoded_sents:\", decoded_sents[i])\n",
    "                    print(\"original_sents:\", original_sents[i])\n",
    "                    score = [{\"rouge-l\":{\"f\":0.0}}]\n",
    "                scores.append(score[0])\n",
    "        rouge_l_f1 = [score[\"rouge-l\"][\"f\"] for score in scores]\n",
    "        rouge_l_f1 = get_cuda(T.FloatTensor(rouge_l_f1))\n",
    "        return rouge_l_f1 , scores\n",
    "\n",
    "    # def write_to_file(self, decoded, max, original, sample_r, baseline_r, iter):\n",
    "    #     with open(\"temp.txt\", \"w\") as f:\n",
    "    #         f.write(\"iter:\"+str(iter)+\"\\n\")\n",
    "    #         for i in range(len(original)):\n",
    "    #             f.write(\"dec: \"+decoded[i]+\"\\n\")\n",
    "    #             f.write(\"max: \"+max[i]+\"\\n\")\n",
    "    #             f.write(\"org: \"+original[i]+\"\\n\")\n",
    "    #             f.write(\"Sample_R: %.4f, Baseline_R: %.4f\\n\\n\"%(sample_r[i].item(), baseline_r[i].item()))\n",
    "\n",
    "\n",
    "    def train_one_batch(self, batch, iter):\n",
    "        ans_list, batch_scores = None , None\n",
    "        enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "\n",
    "        enc_batch = self.model.embeds(enc_batch)                                                    #Get embeddings for encoder input\n",
    "        enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "        # -------------------------------Summarization-----------------------\n",
    "        if self.opt.train_mle == \"yes\":                                                             #perform MLE training\n",
    "            mle_loss = self.train_batch_MLE(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch)\n",
    "        else:\n",
    "            mle_loss = get_cuda(T.FloatTensor([0]))\n",
    "            \n",
    "        if opt.view:\n",
    "            sample_sents,ans_list = self.train_batch_decode(batch, enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=True)\n",
    "            _ , batch_scores = self.reward_function(sample_sents, batch.original_summarys)\n",
    "        # --------------RL training-----------------------------------------------------\n",
    "        if self.opt.train_rl == \"yes\":                                                              #perform reinforcement learning training\n",
    "            # multinomial sampling\n",
    "            sample_sents, RL_log_probs = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=False)\n",
    "            with T.autograd.no_grad():\n",
    "                # greedy sampling\n",
    "                greedy_sents, _ = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=True)\n",
    "\n",
    "            sample_reward , _ = self.reward_function(sample_sents, batch.original_abstracts)\n",
    "            baseline_reward , _ = self.reward_function(greedy_sents, batch.original_abstracts)\n",
    "            # if iter%200 == 0:\n",
    "            #     self.write_to_file(sample_sents, greedy_sents, batch.original_abstracts, sample_reward, baseline_reward, iter)\n",
    "            rl_loss = -(sample_reward - baseline_reward) * RL_log_probs                             #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n",
    "            rl_loss = T.mean(rl_loss)\n",
    "\n",
    "            batch_reward = T.mean(sample_reward).item()\n",
    "        else:\n",
    "            rl_loss = get_cuda(T.FloatTensor([0]))\n",
    "            batch_reward = 0\n",
    "\n",
    "    # ------------------------------------------------------------------------------------\n",
    "        if opt.train_mle == \"yes\": \n",
    "            self.trainer.zero_grad()\n",
    "            (self.opt.mle_weight * mle_loss + self.opt.rl_weight * rl_loss).backward()\n",
    "            self.trainer.step()       \n",
    "        \n",
    "        return mle_loss.item(), batch_reward, ans_list, batch_scores\n",
    "        \n",
    "        \n",
    "    def get_best_res_score(self,results,scores):\n",
    "        max_score = float(0)\n",
    "        _id = 0\n",
    "        for idx in range(len(results)):       \n",
    "            re_matchData = re.compile(r'\\-?\\d{1,10}\\.?\\d{1,10}')\n",
    "            data = re.findall(re_matchData, str(scores[idx]))\n",
    "            score = sum([float(d) for d in data])\n",
    "            if score > max_score: \n",
    "                _id = idx\n",
    "        return results[_id],scores[_id]\n",
    "            \n",
    "        \n",
    "    \n",
    "    def trainIters(self):\n",
    "        iter = self.setup_train()\n",
    "        count = mle_total = r_total = 0\n",
    "        print(\"Start training.....\")\n",
    "        while iter <= config.max_iterations:\n",
    "            batch = self.batcher.next_batch()\n",
    "            try:\n",
    "                mle_loss, r , ans_list, batch_scores = self.train_one_batch(batch, iter)\n",
    "#                 print(iter,mle_loss)\n",
    "#                 break\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"-------------------Keyboard Interrupt------------------\")\n",
    "                exit(0)\n",
    "            if opt.train_mle == \"no\": break\n",
    "            mle_total += mle_loss\n",
    "            r_total += r\n",
    "            count += 1\n",
    "            iter += 1\n",
    "\n",
    "            if iter % 1000 == 0:\n",
    "                mle_avg = mle_total / count\n",
    "                r_avg = r_total / count\n",
    "                epoch = int((iter * config.batch_size) / train_num) + 1\n",
    "                print('epoch:',epoch ,\"iter:\", iter, \"mle_loss:\", \"%.3f\" % mle_avg, \"reward:\", \"%.4f\" % r_avg)\n",
    "                if opt.view :\n",
    "                    best_res , best_score = self.get_best_res_score(ans_list,batch_scores)\n",
    "                    print('best_res:',best_res)\n",
    "                    print('best_score:',best_score)\n",
    "                count = mle_total = r_total = 0\n",
    "#                 break\n",
    "\n",
    "            if iter % 5000 == 0:\n",
    "                self.save_model(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mle: yes, mle weight: 1.00\n",
      "use word2Vec vocab_size 36049 \n",
      "intra_encoder: True intra_decoder: True\n",
      "use word2Vec vocab_size 36049 \n",
      "torch.Size([36049, 300])\n",
      "Start training.....\n",
      "epoch: 1 iter: 1000 mle_loss: 3.521 reward: 0.0000\n",
      "best_res: {'review': 'this small case but fit both nikon coolpix and husband olympus snugly without too tight water resistant which great for when to the beach waterpark and nicely pad inside to help protect the camera the color bright and vibrant make easier to see at the bottom beach bag purse can just toss and have put the camera strap to keep from catch the zipper and so far work great ', 'key_words': ['beach', 'protect', 'camera', 'bottom', 'purse'], 'summary': '<s> cute little case </s>', 'decoded_str': '[UNK] great case [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.24999999531250006, 'p': 0.3333333333333333, 'r': 0.2}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.22368421052631188, 'p': 0.3333333333333333, 'r': 0.2}}\n",
      "epoch: 1 iter: 2000 mle_loss: 3.273 reward: 0.0000\n",
      "best_res: {'review': 'own several camera bag and pick this one up for when not want to carry lot equipment well design bag can fit small lens up to about lens and big flash unit along with the camera with lens attach pocket hold memory card battery remote filter good investment for not want to lug around giant backpack camera equipment ', 'key_words': ['small', 'big', 'flash', 'unit', 'fit', 'lens'], 'summary': '<s> small and light great when not want to carry lot equipment </s>', 'decoded_str': '[UNK] great bag [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.12499999695312508, 'p': 0.3333333333333333, 'r': 0.07692307692307693}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.08003597122308892, 'p': 0.3333333333333333, 'r': 0.07692307692307693}}\n",
      "epoch: 1 iter: 3000 mle_loss: 3.197 reward: 0.0000\n",
      "best_res: {'review': 'great bag for small mirror less camera micro buy this bag for fuji and love fit the camera ipad air plus bunch other small accessory great bag ', 'key_words': ['buy', 'small', 'fuji', 'love', 'great', 'accessory', 'camera', 'bunch', 'fit', 'bag', 'mirror'], 'summary': '<s> great little day bag for small camera </s>', 'decoded_str': '[UNK] great bag [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.33333332958333334, 'p': 0.6666666666666666, 'r': 0.2222222222222222}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.23809523809533759, 'p': 0.6666666666666666, 'r': 0.2222222222222222}}\n",
      "epoch: 1 iter: 4000 mle_loss: 3.109 reward: 0.0000\n",
      "best_res: {'review': 'buy this camera because the one that have the office always use when need this camera fit pocket and take wonderful picture easy to use and easy to get the whole house focus with the right color what great little camera ', 'key_words': ['buy', 'great', 'picture', 'camera', 'wonderful'], 'summary': '<s> great for real estate agent </s>', 'decoded_str': '[UNK] great camera [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.19999999580000008, 'p': 0.3333333333333333, 'r': 0.14285714285714285}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.15675675675685707, 'p': 0.3333333333333333, 'r': 0.14285714285714285}}\n",
      "epoch: 1 iter: 5000 mle_loss: 3.054 reward: 0.0000\n",
      "best_res: {'review': 'get this camera as christmas gift and work okay for now will not turn anything have replace the battery try to get help from panasonic still under warranty but just for to look at will cost another the store get from not even sell anymore so maybe whatever camera has wrong with common will never buy panasonic anything again ', 'key_words': ['buy', 'panasonic'], 'summary': '<s> not waste time </s>', 'decoded_str': '[UNK] not buy [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.24999999531250006, 'p': 0.3333333333333333, 'r': 0.2}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.22368421052631188, 'p': 0.3333333333333333, 'r': 0.2}}\n",
      "epoch: 1 iter: 6000 mle_loss: 3.012 reward: 0.0000\n",
      "best_res: {'review': 'this case nice for carry and protect the camera appear to good quality and has nice feature like the belt loop and the carry strap there room for spare battery and memory card the only thing not like the storage compartment too small to stuff the cordset into ', 'key_words': ['protect', 'memory', 'battery', 'card', 'belt', 'camera', 'nice', 'loop', 'feature', 'spare', 'carry', 'quality', 'strap', 'good'], 'summary': '<s> camera case </s>', 'decoded_str': '[UNK] great case [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.2857142808163266, 'p': 0.3333333333333333, 'r': 0.25}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.2747252747250878, 'p': 0.3333333333333333, 'r': 0.25}}\n",
      "epoch: 1 iter: 7000 mle_loss: 3.092 reward: 0.0000\n",
      "best_res: {'review': 'had look at mft camera for some time and the discount make this good purchase usually shoot canon xsi and this great companion to camera like that the quality far superior to and the flexibility lense nice very quick and although had not expect to like use the touch screen quite handy for quick menu item zoom shot and change the focal point overall very happy with this camera ', 'key_words': ['canon', 'great', 'purchase', 'superior', 'companion', 'quality', 'good', 'xsi'], 'summary': '<s> good camera great size </s>', 'decoded_str': '[UNK] great camera [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.44444444000000005, 'p': 0.6666666666666666, 'r': 0.3333333333333333}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.18518518518525923, 'p': 0.3333333333333333, 'r': 0.16666666666666666}}\n",
      "epoch: 1 iter: 8000 mle_loss: 2.903 reward: 0.0000\n",
      "best_res: {'review': 'begin user and buy this camera at since then have literally take photo some great most not but learn as before this use older point and shoot while have no basis for comparison believe this to very fine camera user friendly take great photo has very fast start up and relatively easy to find accessory for would recommend this camera to any dslr user any experience ', 'key_words': ['fine', 'buy', 'great', 'very', 'point', 'camera', 'fast', 'start', 'recommend', 'photo', 'older'], 'summary': '<s> great camera for great price </s>', 'decoded_str': '[UNK] great camera [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.44444444000000005, 'p': 0.6666666666666666, 'r': 0.3333333333333333}, 'rouge-2': {'f': 0.22222221777777784, 'p': 0.3333333333333333, 'r': 0.16666666666666666}, 'rouge-l': {'f': 0.37037037037044435, 'p': 0.6666666666666666, 'r': 0.3333333333333333}}\n",
      "epoch: 2 iter: 9000 mle_loss: 2.960 reward: 0.0000\n",
      "best_res: {'review': 'very nice bag and can get lot but as female little too big for so return for the reason star otherwise would highly recommend come with neck strap which would have prefer hook from side to the other instead just the back pack come with very nice zipper enclosure to protect gear ', 'key_words': ['very', 'enclosure', 'nice', 'zipper', 'bag'], 'summary': '<s> great bag but too large for </s>', 'decoded_str': '[UNK] great bag [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.3636363596694215, 'p': 0.6666666666666666, 'r': 0.25}, 'rouge-2': {'f': 0.19999999580000008, 'p': 0.3333333333333333, 'r': 0.14285714285714285}, 'rouge-l': {'f': 0.27087198515780375, 'p': 0.6666666666666666, 'r': 0.25}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eagleuser/.conda/envs/Leyan/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eagleuser/.conda/envs/Leyan/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eagleuser/Users/leyan/Text-Summarizer-FOP/data_util/batcher.py\", line 235, in fill_example_queue\n",
      "    (review, summary,keywords) = input_gen.__next__() # read the next example from file. review and summary are both strings.\n",
      "  File \"/home/eagleuser/Users/leyan/Text-Summarizer-FOP/data_util/batcher.py\", line 305, in text_generator\n",
      "    e = next(example_generator) # e is a tf.Example\n",
      "  File \"/home/eagleuser/Users/leyan/Text-Summarizer-FOP/data_util/data.py\", line 95, in example_generator\n",
      "    yield example_pb2.Example.FromString(example_str)\n",
      "google.protobuf.message.DecodeError: Error parsing message\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Found example queue thread dead. Restarting.\n",
      "epoch: 2 iter: 10000 mle_loss: 2.995 reward: 0.0000\n",
      "best_res: {'review': 'this camera great for video but absolutely horrible for sound snap crackle and pop unless sit still room not move have buy both this and gopro hero find this come with far more feature as standard and way better price unless want good quality sound exchange one over the sound issue think just the one had sell not all have terrible sound but the video fantastic the screen nice the remote awesome also and can research just like has the same mp sensor as the hd gopro other thing not as rugged as the gopro tough but outside the water proof case if fall down flight stair would probably to peice but honestly for the price sound not that big issue as record seperate audio for personal project but if sound important to may want to consider another hd mini cam give star because should not have to find out product lack major feature through trial error the manufacturer should fix warn customer ', 'key_words': ['stair', 'pop', 'crackle', 'tough', 'terrible', 'sound'], 'summary': '<s> great for video but </s>', 'decoded_str': '[UNK] great camera [UNK]'}\n",
      "best_score: {'rouge-1': {'f': 0.22222221777777784, 'p': 0.3333333333333333, 'r': 0.16666666666666666}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.18518518518525923, 'p': 0.3333333333333333, 'r': 0.16666666666666666}}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3032b8968251>\u001b[0m in \u001b[0;36mtrain_batch_decode\u001b[0;34m(self, batch, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#                     x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_temporal_srcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_batch_extend_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_temporal_srcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Text-Summarizer-FOP/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m#             d = self.x_context(T.cat([x_t, ct_e], dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;31m#         x = self.x_context(T.cat([x_t, ct_e], dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCGeneral.cpp:371",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-45acb40b5c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrain_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtrain_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3032b8968251>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0mmle_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mans_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;31m#                 print(iter,mle_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;31m#                 break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3032b8968251>\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[0;34m(self, batch, iter)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0msample_sents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_batch_extend_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mart_oovs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_summarys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# --------------RL training-----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3032b8968251>\u001b[0m in \u001b[0;36mtrain_batch_decode\u001b[0;34m(self, batch, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m#                 with torchsnooper.snoop():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m#                     x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_batch_extend_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_temporal_srcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Text-Summarizer-FOP/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;31m#             c = T.cat([x_t, ct_e], dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m#             d = self.x_context(T.cat([x_t, ct_e], dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;31m#         x = self.x_context(T.cat([x_t, ct_e], dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/u012869752/article/details/72513141\n",
    "# 由于在jupyter notebook中，args不为空\n",
    "\n",
    "# nvidia-smi -pm 1\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_mle', type=str, default=\"yes\")\n",
    "    parser.add_argument('--train_rl', type=str, default=\"no\")\n",
    "    parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "    parser.add_argument('--load_model', type=str, default=None)\n",
    "    parser.add_argument('--new_lr', type=float, default=None)\n",
    "    parser.add_argument('--multi_device', type=bool, default=True)\n",
    "    parser.add_argument('--view', type=bool, default=True)\n",
    "    parser.add_argument('--pre_train_emb', type=bool, default=True)\n",
    "    parser.add_argument('--word_emb_type', type=str, default='word2Vec')\n",
    "    \n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    opt.rl_weight = 1 - opt.mle_weight  \n",
    "    config.word_emb_type = opt.word_emb_type\n",
    "\n",
    "        \n",
    "    if opt.train_rl == 'yes':\n",
    "        print(\"Training mle: %s, Training rl: %s, mle weight: %.2f, rl weight: %.2f\"%(opt.train_mle, opt.train_rl, opt.mle_weight, opt.rl_weight))\n",
    "    else:\n",
    "        print(\"Training mle: %s, mle weight: %.2f\"%(opt.train_mle, opt.mle_weight))\n",
    "    \n",
    "    if opt.pre_train_emb :\n",
    "        config.vocab_size = int(config.vocab_path.split(\".\")[-2]) + 1\n",
    "#         config.word_emb_path = \"Embedding/%s/vector_%s_%s.300d.txt\"%(opt.word_emb_type,\n",
    "#                                                                      config.category1, \n",
    "#                                                                      config.category2) \n",
    "        print('use %s vocab_size %s '%(opt.word_emb_type,config.vocab_size))\n",
    "        \n",
    "    print(\"intra_encoder:\", config.intra_encoder, \"intra_decoder:\", config.intra_decoder)\n",
    "\n",
    "    train_processor = Train(opt)\n",
    "    train_processor.trainIters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if self.opt.train_rl == \"yes\":\n",
    "# ~/Users/leyan/Text-Summarizer-FOP/data_util/data.py in outputids2words(id_list, vocab, review_oovs)\n",
    "#     141       review_oov_idx = i - vocab.size()\n",
    "#     142       try:\n",
    "# --> 143         w = review_oovs[review_oov_idx]\n",
    "#     144       except ValueError as e: # i doesn't correspond to an review oov\n",
    "#     145         raise ValueError('Error: model produced word ID %i which corresponds to review OOV %i but this example only has %i review OOVs' % (i, review_oov_idx, len(review_oovs)))\n",
    "\n",
    "# IndexError: list index out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
