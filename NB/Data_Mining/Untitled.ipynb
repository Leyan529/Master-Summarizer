{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Program\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "D:\\Program\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.simplefilter('ignore')\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "\n",
    "\n",
    "import spacy\n",
    "# gpu = spacy.prefer_gpu()\n",
    "# print('GPU:', gpu)\n",
    "# pip install -U spacy[cuda100]\n",
    "# python -m spacy validate\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from pprint import pprint\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "import re\n",
    "from stopwords import *\n",
    "import nltk\n",
    "from preprocess import *\n",
    "# from feature import *\n",
    "\n",
    "from textblob import TextBlob\n",
    "import collections\n",
    "\n",
    "from spacy.symbols import cop, acomp, amod, conj, neg, nn, nsubj, dobj,prep,advmod\n",
    "from spacy.symbols import VERB, NOUN, PROPN, ADJ, ADV, AUX, PART\n",
    "\n",
    "pattern_counter = collections.Counter()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import networkx as nx\n",
    "from MongoDB import MongoDB\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the toshiba\n",
      "great pain\n",
      "the stereo television\n",
      "the video\n",
      "the matrix\n"
     ]
    }
   ],
   "source": [
    "matched_sents = \"\"\"\n",
    "animpulse pick the toshiba rethink great pain hook the stereo television set the video load the matrix completely blow.\n",
    "\"\"\"\n",
    "nlp_sent = nlp(matched_sents)\n",
    "# displacy.render(nlp_sent, style='dep', jupyter = True) # dependency parse tree\n",
    "for pharse in nlp_sent.noun_chunks:\n",
    "    print(pharse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sents = \"\"\"\n",
    "animpulse pick the toshiba rethink great pain hook the stereo television set the video load the matrix completely blow.\n",
    "\"\"\"\n",
    "\n",
    "from nltk.corpus import words\n",
    "wordlist = words.words()\n",
    "# for w in nltk.word_tokenize(matched_sents):\n",
    "#     print(w,w in wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\textacy\\extract.py:327: DeprecationWarning: `pos_regex_matches()` has been deprecated! for similar but more powerful and performant functionality, use `textacy.extract.matches()` instead.\n",
      "  action=\"once\",\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'dvds',\n",
       " 'ntsc',\n",
       " 'foreign',\n",
       " 'secret',\n",
       " 'problematic',\n",
       " 'first',\n",
       " 'great',\n",
       " 'overall',\n",
       " 'great']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent_pattern = r\"\"\"<JJ>\"\"\"\n",
    "#     pattern = r'<PROPN>+ (<PUNCT|CCONJ> <PUNCT|CCONJ>? <PROPN>+)*'\n",
    "\n",
    "\n",
    "# tag_pattern = \"<DT>?<JJ>*<NN.*>\"\n",
    "# regexp_pattern = tag_pattern2re_pattern(tag_pattern)\n",
    "# regexp_pattern\n",
    "# '(<(DT)>)?(<(JJ)>)*(<(NN[^\\\\{\\\\}<>]*)>)'\n",
    "import textacy\n",
    "text = \"\"\"\n",
    "I found this model to be great value for money. It can play DVDs, VCDs, CDs, CD-RW (i.e. burned CDs) as well as MP3 files. It can also convert PAL to NTSC and NTSC to PAL on any TV, which enables you to watch foreign movies. Since it has 110-220 power coversion, you can use it anywhere in the US, Europe and Israel. It also has a secret menu that allows you to play movies from every DVD region number (look on the web, you'll find it...).The downside: seems like the production quality of these machines is problematic. The first unit I got did not work properly. I returned it with no problems, and the one I have now works great.Overall - a great buy, a fully load machine.\n",
    "\"\"\"\n",
    "text = remove_word2(text)\n",
    "# sent_pattern = r\"\"\"( \n",
    "#     (<PRON>| <DET> | <VERB> | <CCONJ> | <ADJ> |\n",
    "#     <DET><NOUN> | <ADJ><ADJ> | <ADV><ADJ> | <DET><ADJ> | <PRON><AUX><VERB> | \n",
    "#     <DET><PROPN>){4, }\n",
    "    \n",
    "#     (<NOUN>|<ADJ>|<ADV><ADJ>|<AUX><VERB>|<ADJ><NOUN><NOUN>|<ADJ><PART><NOUN>|\n",
    "#     <ADP><ADJ><NOUN><NOUN>| <PART><VERB>|<AUX><ADJ>|<ADJ><PART><VERB><ADP>|<ADJ><PART><VERB>\n",
    "#     ))\n",
    "#     \"\"\"\n",
    "\n",
    "# https://transbiz.com.tw/regex-regular-expression-ga-%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E5%BC%8F/#3\n",
    "# sent_pattern = r\"\"\"\n",
    "# ( \n",
    "#     (<NOUN>|<ADJ>|<ADV>|<VERB>){, 2}  \n",
    "#     .{,2}\n",
    "#     (<ADJ><NOUN>|<ADV><VERB>)\n",
    "    \n",
    "# )\n",
    "#     \"\"\"\n",
    "\n",
    "sent_pattern = r\"\"\"\n",
    "( \n",
    "    (<NOUN>){0, 2}  \n",
    "    .{,2}\n",
    "    (<ADJ>)    \n",
    ")\n",
    "    \"\"\"\n",
    "\n",
    "#     pattern = r'<PROPN>+ (<PUNCT|CCONJ> <PUNCT|CCONJ>? <PROPN>+)*'\n",
    "extract_pharse = []\n",
    "doc = textacy.make_spacy_doc(text,lang='en_core_web_sm')\n",
    "# phrases = textacy.extract.pos_regex_matches(doc, sent_pattern)\n",
    "extract_pharse = [phrase.text for phrase in textacy.extract.pos_regex_matches(doc, sent_pattern)]\n",
    "extract_pharse\n",
    "# for phrase in phrases:\n",
    "# #         print(\"verb_phrases : \" , phrase.text)\n",
    "# #     print([(token.text,token.pos_) for token in nlp(chunk.text)])\n",
    "#     extract_pharse.append(phrase.text+\"\\n\")\n",
    "#     print(phrase.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.word_tokenize(\"lot great feature.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('VBP', 'surround'), ('NN', 'sound'), ('NN', 'compatibility'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('NNP', 'hdcd'), ('NNP', 'decoding'), ('NNP', 'dolby'), ('NNP', 'digital')\n",
    "('NNP', 'toshiba'), ('NNP', 'dvd')\n",
    "('VB', 'surround'), ('NN', 'sound'), ('JJ', 'audio'), ('NN', 'quality')\n",
    "('VBP', 'surround'), ('NN', 'sound'), ('NN', 'compatibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list= ['PERSON',\n",
    "'NORP',\n",
    "'FAC',\n",
    "'ORG',\n",
    "'GPE',\n",
    "'LOC',\n",
    "'PRODUCT',\n",
    "'EVENT',\n",
    "'WORK_OF_ART',\n",
    "'LAW',\n",
    "'LANGUAGE',\n",
    "'DATE',\n",
    "'TIME',\n",
    "'PERCENT',\n",
    "'MONEY',\n",
    "'QUANTITY',\n",
    "'ORDINAL',\n",
    "'CARDINAL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
