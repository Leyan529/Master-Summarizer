{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0319 21:33:01.254710 139846209922880 file_utils.py:35] PyTorch version 1.3.1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  30526 bert tokens now\n",
      "We have added 3 XL tokens\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "import torch as T\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# from model2 import Model\n",
    "\n",
    "\n",
    "from data_util import config\n",
    "from data_util import bert_data as data\n",
    "from data_util.bert_batcher import Batcher\n",
    "from data_util.bert_data import Vocab\n",
    "from write_result import *\n",
    "# from data_util import data\n",
    "# from data_util.batcher import Batcher\n",
    "# from data_util.data import Vocab\n",
    "\n",
    "\n",
    "from train_bert_util import *\n",
    "from torch.distributions import Categorical\n",
    "from rouge import Rouge\n",
    "from numpy import random\n",
    "import argparse\n",
    "import torchsnooper\n",
    "import logging\n",
    "# transformers_logger = logging.getLogger(\"transformers.tokenization_utils\")\n",
    "# transformers_logger.setLevel(logging.ERROR)\n",
    "# transformers_logger.disabled = True\n",
    "\n",
    "# # -------- Test Packages -------\n",
    "# from bert_enc_beam_search import *\n",
    "# import shutil\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# # from pytorch_pretrained_bert import BertModel\n",
    "# from transformers import BertModel, BertTokenizer \n",
    "# from transformers import TransfoXLTokenizer, TransfoXLModel, TransfoXLConfig\n",
    "\n",
    "config.batch_size = 1\n",
    "config.emb_dim = 768\n",
    "config.vocab_size = 50000\n",
    "\n",
    "# config.hidden_dim = 512\n",
    "config.hidden_dim = 768\n",
    "\n",
    "config.max_enc_steps = 500\n",
    "config.lr = 0.001 # 0.001\n",
    "\n",
    "# config.max_dec_steps = 60\t\t#99% of the titles are within length 15\n",
    "# config.min_dec_steps= 8\n",
    "config.ber_layer = 11 # last_layer [0~11]\n",
    "# config.key_attention = False\n",
    "# help(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## batch_size : 1\n",
      "## beam_size : 16\n",
      "## ber_layer : 11\n",
      "## data_type : Cameras_new8\n",
      "## emb_dim : 768\n",
      "## emb_grad : False\n",
      "## eps : 1e-12\n",
      "## gound_truth_prob : 0.1\n",
      "## hidden_dim : 768\n",
      "## intra_decoder : True\n",
      "## intra_encoder : True\n",
      "## key_attention : False\n",
      "## keywords : POS_FOP_keywords\n",
      "## loggerName : Text-Summary\n",
      "## lr : 0.001\n",
      "## max_dec_steps : 50\n",
      "## max_enc_steps : 500\n",
      "## max_epochs : 100\n",
      "## max_iterations : 500000\n",
      "## max_key_num : 8\n",
      "## min_dec_steps : 4\n",
      "## rand_unif_init_mag : 0.02\n",
      "## trunc_norm_init_std : 0.0001\n",
      "## vocab_size : 50000\n",
      "## word_emb_type : word2Vec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_str = ''\n",
    "for a in dir(config):\n",
    "    if type(getattr(config, a)) in [str,int,float,bool] \\\n",
    "    and 'path' not in str(a) \\\n",
    "    and '__' not in str(a) \\\n",
    "    and 'info' not in str(a):\n",
    "\n",
    "        info_str += '## %s : %s\\n'%(a,getattr(config, a))\n",
    "\n",
    "# [print(a,getattr(config, a)) for a in dir(config)\n",
    "# if type(getattr(config, a)) in [str,int,float]\n",
    "#  and 'path' not in str(a)\n",
    "#  and '__' not in str(a)\n",
    "#  and 'info' not in str(a)\n",
    "# ]\n",
    "print(info_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def getLogger(loggerName, loggerPath):\n",
    "    # 設置logger\n",
    "    logger = logging.getLogger(loggerName)  # 不加名稱設置root logger\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s: - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    logging.Filter(loggerName)\n",
    "\n",
    "    # 使用FileHandler輸出到文件\n",
    "    directory = os.path.dirname(loggerPath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    fh = logging.FileHandler(loggerPath)\n",
    "\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # 使用StreamHandler輸出到屏幕\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    ch.setFormatter(formatter)\n",
    "    # 添加兩個Handler\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    # Handler只啟動一次\n",
    "    # 設置logger\n",
    "    logger.info(u'logger已啟動')\n",
    "    return logger\n",
    "\n",
    "def removeLogger(logger):\n",
    "    logger.info(u'logger已關閉')\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_words :  ['mode', 'manual', 'difference', 'shock', 'camera', 'prehistoric', 'thing', 'good']\n"
     ]
    }
   ],
   "source": [
    "def test_batch():\n",
    "    vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "    batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "                           batch_size=config.batch_size, single_pass=False)\n",
    "    batch = batcher.next_batch()\n",
    "    # with torchsnooper.snoop():\n",
    "    while batch is not None:\n",
    "        example_list = batch.example_list\n",
    "        for ex in example_list:\n",
    "            r = str(ex.original_review)\n",
    "            s = str(ex.original_summary)\n",
    "            k = str(ex.key_words)\n",
    "            sent = ex.original_summary_sents\n",
    "#             print(\"original_review_sents:\", r)\n",
    "#             print(\"original_summary_sents : \", s)\n",
    "            print(\"key_words : \", k)\n",
    "#             print('------------------------------------------------------------\\n')\n",
    "        batch = batcher.next_batch()        \n",
    "        break\n",
    "test_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bin Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 33574\n",
      "\n",
      "test : 4196\n",
      "\n",
      "valid : 4196\n",
      "\n"
     ]
    }
   ],
   "source": [
    " with open(config.bin_info,'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    [print(line) for line in lines]\n",
    "    train_num = int(lines[0].split(\":\")[1])\n",
    "    test_num = int(lines[1].split(\":\")[1])\n",
    "    val_num = int(lines[2].split(\":\")[1])\n",
    "    # f.write(\"train : %s\\n\"%(len(flit_key_train_df)))\n",
    "    # f.write(\"test : %s\\n\"%(len(flit_key_test_df)))\n",
    "    # f.write(\"valid : %s\\n\"%(len(flit_key_valid_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View model summary\n",
    "#### 只有torchsummaryX成功\n",
    "#### 日後將以此模擬呈現結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummaryX import summary\n",
    "# from model2 import Encoder,Model\n",
    "# device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "# encoder = Encoder().to(device)    \n",
    "\n",
    "# vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                        batch_size=config.batch_size, single_pass=False)\n",
    "# batch = batcher.next_batch()\n",
    "# enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "     \n",
    "# # bert_model = TransfoXLModel(xl_config) # 更改參數以傳入TransfoXLModel\n",
    "# # bert_model = get_cuda(TransfoXLModel.from_pretrained('transfo-xl-wt103'))\n",
    "# # all_hidden_states, _ = bert_model(enc_batch)[-2:]\n",
    "   \n",
    "# # summary(encoder, enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "\n",
    "# print('test success')\n",
    "# # model = Model(False,'word2Vec',vocab)\n",
    "# # enc_out, enc_hidden = model.encoder(enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "# # print(enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummaryX import summary\n",
    "# from model2 import Decoder,Model\n",
    "# from train_bert_util import *\n",
    "# device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "# # decoder = Decoder().to(device)    \n",
    "\n",
    "# model = Model(False,'word2Vec',vocab)\n",
    "# # vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# # batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "# #                        batch_size=config.batch_size, single_pass=False)\n",
    "# # batch = batcher.next_batch()\n",
    "# # enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# # enc_batch = model.embeds(enc_batch) #Get embeddings for encoder input\n",
    "# # enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "# # encoder = Encoder().to(device)   \n",
    "# vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "# batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                        batch_size=config.batch_size, single_pass=False)\n",
    "# batch = batcher.next_batch()\n",
    "# enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# # print('enc_batch',enc_batch.shape)\n",
    "# # print(enc_batch[0][:5])\n",
    "\n",
    "# enc_out, enc_hidden = model.encoder(enc_batch, enc_padding_mask, enc_lens) # encoder summary (ok)\n",
    "# # print('enc_out',enc_out.shape)\n",
    "# # print('enc_hidden',enc_hidden.shape)\n",
    "# # print('encoder success')  \n",
    "\n",
    "# start_decoding = vocab.word2id(bert_data.START_DECODING) # start_decoding = 30524\n",
    "# stop_decoding = vocab.word2id(bert_data.STOP_DECODING) # stop_decoding = 30525\n",
    "    \n",
    "# # train_batch_MLE\n",
    "# dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n",
    "# step_losses = []\n",
    "# # s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n",
    "# s_t = (enc_hidden,enc_hidden)\n",
    "# # x_t 為decoder每一個time step 的batch input\n",
    "# x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(start_decoding)) # initial batch decode word                            #Input to the decoder\n",
    "# prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in DEEP REINFORCED MODEL - https://arxiv.org/pdf/1705.04304.pdf)\n",
    "# sum_temporal_srcs = None     \n",
    "# unk_id = vocab.word2id(data.PAD_TOKEN)\n",
    "\n",
    "# # print('x_t',x_t.shape)\n",
    "# # print(vocab.vocab)     \n",
    "# # print('enc_hidden',enc_hidden.shape)\n",
    "\n",
    "# # s_t = s_t[:,0,:]\n",
    "# for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "#     print('decoder time step %s'%t)\n",
    "# #     T.rand(len(enc_out)) tensor([0.6797, 0.7603])\n",
    "#     use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "#     # use_gound_truth * dec_batch[:, t] : 為ground true time step token\n",
    "#     # (1 - use_gound_truth) * x_t : 為previous time step token\n",
    "#     x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities   \n",
    "#     x_t, _ = model.encoder(x_t, None, None) # encoder summary (ok)\n",
    "# #     enc_key_batch = model.embeds(enc_key_batch)  \n",
    "\n",
    "#     # use the output vector corresponding to [CLS] to initialize the hidden state and cell state of LSTM decoder\n",
    "# #     print('s_t1',s_t[0].shape);print('s_t1',s_t[1].shape)\n",
    "    \n",
    "#     final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(\n",
    "#     x_t, s_t, enc_out, enc_padding_mask, context, \n",
    "#     extra_zeros,enc_batch_extend_vocab,sum_temporal_srcs, prev_s, \n",
    "#     None, None)    \n",
    "# #     print('s_t2',s_t[0].shape);print('s_t2',s_t[1].shape)\n",
    "#     target = target_batch[:, t]\n",
    "#     log_probs = T.log(final_dist + config.eps)\n",
    "#     step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=unk_id)\n",
    "#     step_losses.append(step_loss)\n",
    "# #     x_t = T.multinomial(final_dist,1).squeeze()  # Sample words from final distribution which can be used as input in next time step\n",
    "    \n",
    "# #     is_oov = (x_t >= config.vocab_size).long()  # Mask indicating whether sampled word is OOV\n",
    "# #     x_t = (1 - is_oov) * x_t.detach() + (is_oov) * unk_id  # Replace OOVs with [UNK] token\n",
    "  \n",
    "# #     print('s_t',s_t.shape)\n",
    "#     decoder_summary = summary(model.decoder, x_t, s_t, enc_out, \n",
    "#                               enc_padding_mask, context, extra_zeros,\n",
    "#                               enc_batch_extend_vocab, \n",
    "#                               sum_temporal_srcs, prev_s,None, \n",
    "#                               enc_key_lens) # encoder summary\n",
    "#     print('finish inner loop'); print('-------------------------------------------------\\n')\n",
    "#     break\n",
    "# # decoder_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "# import torch\n",
    "# def write_enc_graph():\n",
    "#     encoder_writer = SummaryWriter('runs/Pointer-Generator/word2Vec/Encoder')\n",
    "#     device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "#     encoder = Encoder().to(device) \n",
    "\n",
    "#     vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "#     batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                            batch_size=config.batch_size, single_pass=False)\n",
    "#     batch = batcher.next_batch()\n",
    "#     enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "#     enc_batch = Model(False,'word2Vec',vocab).embeds(enc_batch) #Get embeddings for encoder input\n",
    "\n",
    "# #     enc_batch = Variable(torch.rand(enc_batch.shape)).to(device) \n",
    "#     enc_lens = torch.from_numpy(enc_lens).to(device) \n",
    "\n",
    "#     encoder_writer.add_graph(encoder, (enc_batch, enc_lens), verbose=True)\n",
    "#     encoder_writer.close()\n",
    "\n",
    "# def write_dec_graph():\n",
    "#     decoder_writer = SummaryWriter('runs/Pointer-Generator/word2Vec/Decoder')\n",
    "#     device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "#     # decoder = Decoder().to(device)    \n",
    "\n",
    "#     vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "#     model = Model(False,'word2Vec',vocab)\n",
    "    \n",
    "#     batcher = Batcher(config.train_data_path, vocab, mode='train',\n",
    "#                            batch_size=config.batch_size, single_pass=False)\n",
    "#     batch = batcher.next_batch()\n",
    "#     enc_batch, enc_lens, enc_padding_mask, enc_key_batch, enc_key_lens, enc_key_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n",
    "# #     enc_batch = model.embeds(enc_batch) #Get embeddings for encoder input\n",
    "#     enc_out, enc_hidden = model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "#     # train_batch_MLE\n",
    "#     dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n",
    "#     step_losses = []\n",
    "#     s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n",
    "#     # x_t 為decoder每一個time step 的batch input\n",
    "#     x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(2))                             #Input to the decoder\n",
    "#     prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in DEEP REINFORCED MODEL - https://arxiv.org/pdf/1705.04304.pdf)\n",
    "#     sum_temporal_srcs = None     \n",
    "\n",
    "\n",
    "#     for t in range(min(max_dec_len, config.max_dec_steps)):\n",
    "#         use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n",
    "#         # use_gound_truth * dec_batch[:, t] : 為ground true time step token\n",
    "#         # (1 - use_gound_truth) * x_t : 為previous time step token\n",
    "#         if t == 0 :temp_batch = dec_batch[:, t]\n",
    "#         x_t = use_gound_truth * temp_batch + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities\n",
    "# #         x_t = model.embeds(x_t)\n",
    "#     #     final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n",
    "#         final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = model.decoder(\n",
    "#         x_t, s_t, enc_out, enc_padding_mask,context, \n",
    "#         extra_zeros,enc_batch_extend_vocab,sum_temporal_srcs, prev_s, \n",
    "#         enc_key_batch, enc_key_lens)        \n",
    "\n",
    "\n",
    "#         #         decoder_summary = summary(model.decoder, x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s,enc_key_batch, enc_key_lens) # encoder summary\n",
    "# #         x_t = Variable(torch.rand(x_t.shape)).to(device) \n",
    "#         #             s_t = Variable(torch.rand(s_t.shape)).to(device)\n",
    "# #         enc_out = Variable(torch.rand(enc_out.shape)).to(device)\n",
    "# #         enc_padding_mask = Variable(torch.rand(enc_padding_mask.shape)).to(device,dtype=torch.long)\n",
    "# #         context = Variable(torch.rand(context.shape)).to(device)\n",
    "# #         extra_zeros = Variable(torch.rand(extra_zeros.shape)).to(device)\n",
    "# #         enc_batch_extend_vocab = Variable(torch.rand(enc_batch_extend_vocab.shape)).to(device)\n",
    "#         #             sum_temporal_srcs = Variable(torch.rand(sum_temporal_srcs.shape)).to(device)\n",
    "#         #             prev_s = Variable(torch.rand(prev_s.shape)).to(device)\n",
    "# #         enc_key_batch = Variable(torch.rand(enc_key_batch.shape)).to(device)\n",
    "#         enc_key_lens = torch.from_numpy(enc_key_lens).to(device) \n",
    "        \n",
    "#         decoder_writer.add_graph(model.decoder, \n",
    "#                          (x_t, s_t, enc_out, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s,enc_key_batch, enc_key_lens), verbose=True)\n",
    "#         decoder_writer.close()\n",
    "#         break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-19 21:33:09 - Text-Summary - INFO: - logger已啟動\n",
      "I0319 21:33:09.378670 139846209922880 <ipython-input-3-00f9962e7fdd>:30] logger已啟動\n",
      "2020-03-19 21:33:09 - Text-Summary - INFO: - ------Training Setting--------\n",
      "I0319 21:33:09.383221 139846209922880 transformer_run.py:156] ------Training Setting--------\n",
      "2020-03-19 21:33:09 - Text-Summary - INFO: - Traing Type :Cameras_new8\n",
      "I0319 21:33:09.385606 139846209922880 transformer_run.py:158] Traing Type :Cameras_new8\n",
      "2020-03-19 21:33:09 - Text-Summary - INFO: - Training mle: True, mle weight: 1.00\n",
      "I0319 21:33:09.386460 139846209922880 transformer_run.py:160] Training mle: True, mle weight: 1.00\n",
      "2020-03-19 21:33:09 - Text-Summary - INFO: - use pre_train_None vocab_size 50000 \n",
      "\n",
      "I0319 21:33:09.387500 139846209922880 transformer_run.py:167] use pre_train_None vocab_size 50000 \n",
      "\n",
      "2020-03-19 21:33:09 - Text-Summary - INFO: - intra_encoder: True intra_decoder: True \n",
      "\n",
      "I0319 21:33:09.388511 139846209922880 transformer_run.py:172] intra_encoder: True intra_decoder: True \n",
      "\n",
      "2020-03-19 21:33:14 - Text-Summary - INFO: - Init Transformer model\n",
      "I0319 21:33:14.405826 139846209922880 transformer_run.py:224] Init Transformer model\n",
      "2020-03-19 21:33:36 - Text-Summary - INFO: - Initial our transformer model ...\n",
      "I0319 21:33:36.717279 139846209922880 transformer_run.py:273] Initial our transformer model ...\n",
      "2020-03-19 21:33:36 - Text-Summary - INFO: - ------Training START--------\n",
      "I0319 21:33:36.718883 139846209922880 transformer_run.py:588] ------Training START--------\n",
      "2020-03-19 21:33:36 - Text-Summary - INFO: - logger已關閉\n",
      "I0319 21:33:36.837862 139846209922880 <ipython-input-3-00f9962e7fdd>:34] logger已關閉\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c5af2eb49687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_action\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtrain_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Text-Summarizer-FOP/transformer_run.py\u001b[0m in \u001b[0;36mtrain_action\u001b[0;34m(opt, logger, writer, train_num)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mtrain_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mtrain_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# except Exception as e:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m#     print(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Text-Summarizer-FOP/transformer_run.py\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0mtrain_mle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_mle_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RL_Train/reward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Users/leyan/Text-Summarizer-FOP/transformer_run.py\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[0;34m(self, batch, test_batch, iter)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# feed into bert encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0menc_batch2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_lens2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Leyan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/u012869752/article/details/72513141\n",
    "# 由于在jupyter notebook中，args不为空\n",
    "from glob import glob\n",
    "# nvidia-smi -pm 1\n",
    "from transformer_run import *\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    try:\n",
    "        # --------------------------Training ----------------------------------\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--train_mle', type=bool, default=True)\n",
    "        parser.add_argument('--train_rl', type=bool, default=False)\n",
    "        parser.add_argument('--mle_weight', type=float, default=1.0)\n",
    "    #         parser.add_argument('--load_model', type=str, default='/0015000_3.29_0.00.tar')\n",
    "        parser.add_argument('--load_model', type=str, default=None)\n",
    "        parser.add_argument('--new_lr', type=float, default=None)\n",
    "        parser.add_argument('--multi_device', type=bool, default=True)\n",
    "        parser.add_argument('--view', type=bool, default=True)\n",
    "        parser.add_argument('--pre_train_emb', type=bool, default=True)\n",
    "        parser.add_argument('--word_emb_type', type=str, default=None)\n",
    "        parser.add_argument('--train_action', type=bool, default=True)\n",
    "        opt = parser.parse_args(args=[])\n",
    "\n",
    "        today = dt.now()\n",
    "    #         loggerPath = \"LOG//%s-(%s_%s_%s)-(%s:%s:%s)\"%(opt.word_emb_type,\n",
    "    #                   today.year,today.month,today.day,\n",
    "    #                   today.hour,today.minute,today.second)\n",
    "    #         logger = getLogger(config.loggerName,loggerPath)   \n",
    "\n",
    "        loggerPath = \"LOG//%s\"%(opt.word_emb_type)\n",
    "        logger = getLogger(config.loggerName,loggerPath) \n",
    "\n",
    "        if opt.load_model == None:\n",
    "            shutil.rmtree('runs/Pointer-Generator/Transformer', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/Transformer/exp-4', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/Transformer/Eecoder', ignore_errors=True) # clear previous \n",
    "            shutil.rmtree('runs/Pointer-Generator/Transformer/Decoder', ignore_errors=True) # clear previous \n",
    "\n",
    "        writer = SummaryWriter('runs/Pointer-Generator/Transformer')\n",
    "        writer.add_text('Train_Para/',info_str,0)\n",
    "    #         write_enc_graph()\n",
    "    #         write_dec_graph()\n",
    "\n",
    "        if opt.train_action: \n",
    "            train_action(opt, logger, writer, train_num)\n",
    "\n",
    "    except KeyError as e:\n",
    "        traceback = sys.exc_info()[2]\n",
    "        print(sys.exc_info())\n",
    "        print(traceback.tb_lineno)\n",
    "        print(e)\n",
    "    finally:\n",
    "        removeLogger(logger)\n",
    "        # export scalar data to JSON for external processing\n",
    "        # tensorboard --logdir /home/eagleuser/Users/leyan/Text-Summarizer-FOP/TensorBoard\n",
    "#         tensorboard --logdir ./runs\n",
    "#         if not os.path.exists('TensorBoard'): os.makedirs('TensorBoard')\n",
    "#         writer.export_scalars_to_json(\"TensorBoard/test.json\")\n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
